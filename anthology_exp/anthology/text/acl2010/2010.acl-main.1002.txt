  Dependency Parsing and Projection Based on Word-Pair Classification
                                        Wenbin Jiang and Qun Liu
                         Key Laboratory of Intelligent Information Processing
                                 Institute of Computing Technology
                                   Chinese Academy of Sciences
                               P.O. Box 2704, Beijing 100190, China
                            {jiangwenbin, liuqun}@ict.ac.cn

                      Abstract                                    For dependency projection, the relationship be-
    In this paper we describe an intuitionistic                tween words in the parsed sentences can be sim-
    method for dependency parsing, where a                     ply projected across the word alignment to words
    classifier is used to determine whether a                  in the unparsed sentences, according to the DCA
    pair of words forms a dependency edge.                     assumption (Hwa et al., 2005). Such a projec-
    And we also propose an effective strategy                  tion procedure suffers much from the word align-
    for dependency projection, where the de-                   ment errors and syntactic isomerism between lan-
    pendency relationships of the word pairs                   guages, which usually lead to relationship projec-
    in the source language are projected to the                tion conflict and incomplete projected dependency
    word pairs of the target language, leading                 structures. To tackle this problem, Hwa et al.
    to a set of classification instances rather                (2005) use some filtering rules to reduce noise,
    than a complete tree. Experiments show                     and some hand-designed rules to handle language
    that, the classifier trained on the projected              heterogeneity. Smith and Eisner (2009) perform
    classification instances significantly out-                dependency projection and annotation adaptation
    performs previous projected dependency                     with quasi-synchronous grammar features. Jiang
    parsers. More importantly, when this clas-                 and Liu (2009) resort to a dynamic programming
    sifier is integrated into a maximum span-                  procedure to search for a completed projected tree.
    ning tree (MST) dependency parser, ob-                     However, these strategies are all confined to the
    vious improvement is obtained over the                     same category that dependency projection must
    MST baseline.                                              produce completed projected trees. Because of the
                                                               free translation, the syntactic isomerism between
1 Introduction                                                 languages and word alignment errors, it would
Supervised dependency parsing achieves the state-              be strained to completely project the dependency
of-the-art in recent years (McDonald et al., 2005a;            structure from one language to another.
McDonald and Pereira, 2006; Nivre et al., 2006).                  We propose an effective method for depen-
Since it is costly and difficult to build human-               dency projection, which does not have to pro-
annotated treebanks, a lot of works have also been             duce complete projected trees. Given a word-
devoted to the utilization of unannotated text. For            aligned bilingual corpus with source language sen-
example, the unsupervised dependency parsing                   tences parsed, the dependency relationships of the
(Klein and Manning, 2004) which is totally based               word pairs in the source language are projected to
on unannotated data, and the semisupervised de-                the word pairs of the target language. A depen-
pendency parsing (Koo et al., 2008) which is                   dency relationship is a boolean value that repre-
based on both annotated and unannotated data.                  sents whether this word pair forms a dependency
Considering the higher complexity and lower per-               edge. Thus a set of classification instances are ob-
formance in unsupervised parsing, and the need of              tained. Meanwhile, we propose an intuitionistic
reliable priori knowledge in semisupervised pars-              model for dependency parsing, which uses a clas-
ing, it is a promising strategy to project the de-             sifier to determine whether a pair of words form
pendency structures from a resource-rich language              a dependency edge. The classifier can then be
to a resource-scarce one across a bilingual corpus             trained on the projected classification instance set,
(Hwa et al., 2002; Hwa et al., 2005; Ganchev et al.,           so as to build a projected dependency parser with-
2009; Smith and Eisner, 2009; Jiang et al., 2009).             out the need of complete projected trees.


                                                          12
         Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 12–20,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


                j                        j


          i                        i




  Figure 1: Illegal (a) and incomplete (b) dependency tree produced by the simple-collection method.


   Experimental results show that, the classifier            can be a boolean value:
trained on the projected classification instances
significantly outperforms the projected depen-                        C(i, j) = p       p ∈ {0, 1}            (1)
dency parsers in previous works. The classifier              as produced by a support vector machine (SVM)
trained on the Chinese projected classification in-          classifier (Vapnik, 1998). p = 1 indicates that the
stances achieves a precision of 58.59% on the CTB            classifier supports the candidate edge (i, j), and
standard test set. More importantly, when this               p = 0 the contrary. C(i, j) can also be a real-
classifier is integrated into a 2nd-ordered max-             valued probability:
imum spanning tree (MST) dependency parser
(McDonald and Pereira, 2006) in a weighted aver-                      C(i, j) = p       0≤p≤1                 (2)
age manner, significant improvement is obtained
                                                             as produced by an maximum entropy (ME) classi-
over the MST baselines. For the 2nd-order MST
                                                             fier (Berger et al., 1996). p is a probability which
parser trained on Penn Chinese Treebank (CTB)
                                                             indicates the degree the classifier support the can-
5.0, the classifier give an precision increment of
                                                             didate edge (i, j). Ideally, given the classifica-
0.5 points. Especially for the parser trained on the
                                                             tion results for all candidate word pairs, the depen-
smaller CTB 1.0, more than 1 points precision in-
                                                             dency parse tree can be composed of the candidate
crement is obtained.
                                                             edges with higher score (1 for the boolean-valued
   In the rest of this paper, we first describe
                                                             classifier, and large p for the real-valued classi-
the word-pair classification model for dependency
                                                             fier). However, more robust strategies should be
parsing (section 2) and the generation method
                                                             investigated since the ambiguity of the language
of projected classification instances (section 3).
                                                             syntax and the classification errors usually lead to
Then we describe an application of the projected
                                                             illegal or incomplete parsing result, as shown in
parser: boosting a state-of-the-art 2nd-ordered
                                                             Figure 1.
MST parser (section 4). After the comparisons
                                                                Follow the edge based factorization method
with previous works on dependency parsing and
                                                             (Eisner, 1996), we factorize the score of a de-
projection, we finally five the experimental results.
                                                             pendency tree s(x, y) into its dependency edges,
                                                             and design a dynamic programming algorithm
2 Word-Pair Classification Model
                                                             to search for the candidate parse with maximum
2.1   Model Definition                                       score. This strategy alleviate the classification er-
                                                             rors to some degree and ensure a valid, complete
Following (McDonald et al., 2005a), x is used to             dependency parsing tree. If a boolean-valued clas-
denote the sentence to be parsed, and xi to denote           sifier is used, the search algorithm can be formal-
the i-th word in the sentence. y denotes the de-             ized as:
pendency tree for sentence x, and (i, j) ∈ y rep-
resents a dependency edge from word xi to word                         ỹ = argmax s(x, y)
                                                                                y
xj , where xi is the parent of xj .                                                    X                      (3)
                                                                         = argmax              C(i, j)
   The task of the word-pair classification model                               y
                                                                                     (i,j)∈y
is to determine whether any candidate word pair,
xi and xj s.t. 1 ≤ i, j ≤ |x| and i 6= j, forms a            And if a probability-valued classifier is used in-
dependency edge. The classification result C(i, j)           stead, we replace the accumulation with cumula-


                                                        13


      Type          Features
      Unigram       wordi ◦ posi                     wordi                             posi
                    wordj ◦ posj                     wordj                             posj
      Bigram        wordi ◦ posi ◦ wordj ◦ posj      posi ◦ wordj ◦ posj               wordi ◦ wordj ◦ posj
                    wordi ◦ posi ◦ posj              wordi ◦ posi ◦ wordj              wordi ◦ wordj
                    posi ◦ posj                      wordi ◦ posj                      posi ◦ wordj
      Surrounding   posi ◦ posi+1 ◦ posj−1 ◦ posj    posi−1 ◦ posi ◦ posj−1 ◦ posj     posi ◦ posi+1 ◦ posj ◦ posj+1
                    posi−1 ◦ posi ◦ posj ◦ posj+1    posi−1 ◦ posi ◦ posj−1            posi−1 ◦ posi ◦ posj+1
                    posi ◦ posi+1 ◦ posj−1           posi ◦ posi+1 ◦ posj+1            posi−1 ◦ posj−1 ◦ posj
                    posi−1 ◦ posj ◦ posj+1           posi+1 ◦ posj−1 ◦ posj            posi+1 ◦ posj ◦ posj+1
                    posi ◦ posj−1 ◦ posj             posi ◦ posj ◦ posj+1              posi−1 ◦ posi ◦ posj
                    posi ◦ posi+1 ◦ posj

                      Table 1: Feature templates for the word-pair classification model.


tive product:                                                      to enrich the features with word distance infor-
                                                                   mation. However, in order to utilize some syntax
            ỹ = argmax s(x, y)
                     y                                             information between the pair of words, we adopt
                            Y                          (4)         the syntactic distance representation of (Collins,
                = argmax             C(i, j)
                     y                                             1996), named Collins distance for convenience. A
                           (i,j)∈y
                                                                   Collins distance comprises the answers of 6 ques-
Where y is searched from the set of well-formed                    tions:
dependency trees.
   In our work we choose a real-valued ME clas-                      • Does word i precede or follow word j?
sifier. Here we give the calculation of dependency                   • Are word i and word j adjacent?
probability C(i, j). We use w to denote the param-
eter vector of the ME model, and f (i, j, r) to de-                  • Is there a verb between word i and word j?
note the feature vector for the assumption that the
                                                                     • Are there 0, 1, 2 or more than 2 commas be-
word pair i and j has a dependency relationship r.
                                                                       tween word i and word j?
The symbol r indicates the supposed classification
result, where r = + means we suppose it as a de-                     • Is there a comma immediately following the
pendency edge and r = − means the contrary. A                          first of word i and word j?
feature fk (i, j, r) ∈ f (i, j, r) equals 1 if it is ac-
tivated by the assumption and equals 0 otherwise.                    • Is there a comma immediately preceding the
The dependency probability can then be defined                         second of word i and word j?
as:
                                                                   Besides the original features generated according
              exp(w · f (i, j, +))                                 to the templates in Table 1, the enhanced features
   C(i, j) = P
               r exp(w  · f (i, j, r))                             with Collins distance as postfixes are also used in
                   P                                   (5)
              exp( k wk × fk (i, j, +))                            training and decoding of the word-pair classifier.
           =P        P
               r exp( k wk × fk (i, j, r))                         2.3 Parsing Algorithm
2.2    Features for Classification                                 We adopt logarithmic dependency probabilities
The feature templates for the classifier are simi-                 in decoding, therefore the cumulative product of
lar to those of 1st-ordered MST model (McDon-                      probabilities in formula 6 can be replaced by ac-
ald et al., 2005a). 1 Each feature is composed                     cumulation of logarithmic probabilities:
of some words and POS tags surrounded word i
                                                                          ỹ = argmax s(x, y)
and/or word j, as well as an optional distance rep-                               y
resentations between this two words. Table shows                                       Y
                                                                             = argmax       C(i, j)
the feature templates we use.                                                     y                                    (6)
                                                                                       (i,j)∈y
   Previous graph-based dependency models usu-                                           X
ally use the index distance of word i and word j                            = argmax             log(C(i, j))
                                                                                  y
    1                                                                                  (i,j)∈y
      We exclude the in between features of McDonald et al.
(2005a) since preliminary experiments show that these fea-
tures bring no improvement to the word-pair classification         Thus, the decoding algorithm for 1st-ordered MST
model.                                                             model, such as the Chu-Liu-Edmonds algorithm


                                                              14


Algorithm 1 Dependency Parsing Algorithm.
 1:   Input: sentence x to be parsed
 2:   for hi, ji ⊆ h1, |x|i in topological order do
 3:       buf ← ∅
 4:       for k ← i..j − 1 do                      ⊲ all partitions
 5:            for l ∈ V[i, k] and r ∈ V[k + 1, j] do
 6:                insert D ERIV(l, r) into buf
 7:                insert D ERIV(r, l) into buf
 8:       V[i, j] ← top K derivations of buf
 9:   Output: the best derivation of V[1, |x|]
10:   function D ERIV(p, c)
11:       d ← p ∪ c ∪ {(p · root, c · root)} ⊲ new derivation              Figure 2: The word alignment matrix between a
12:       d · evl ← E VAL(d)                ⊲ evaluation function          Chinese sentence and its English translation. Note
13:       return d                                                         that probabilities need not to be normalized across
                                                                           rows or columns.
used in McDonald et al. (2005b), is also appli-
cable here. In this work, however, we still adopt                          s+ (i, j), can be defined as:
the more general, bottom-up dynamic program-                                            X
ming algorithm Algorithm 1 in order to facilitate                          s+ (i, j) =      Ai,i′ × Aj,j ′ × δ(ye , i′ , j ′ , +) (8)
                                                                                        i′ ,j ′
the possible expansions. Here, V[i, j] contains the
candidate parsing segments of the span [i, j], and                         The score that they do not form a projected depen-
the function E VAL(d) accumulates the scores of                            dency edge can be defined similarly:
all the edges in dependency segment d. In prac-                                        X
tice, the cube-pruning strategy (Huang and Chi-                            s− (i, j) =     Ai,i′ × Aj,j ′ × δ(ye , i′ , j ′ , −) (9)
ang, 2005) is used to speed up the enumeration of                                       i′ ,j ′
derivations (loops started by line 4 and 5).
                                                                           Note that for simplicity, the condition factors ye
3 Projected Classification Instance                                        and A are omitted from these two formulas. We
                                                                           finally define the probability of the supposed pro-
After the introduction of the word-pair classifica-                        jected dependency edge as:
tion model, we now describe the extraction of pro-
jected dependency instances. In order to allevi-                                                   exp(s+ (i, j))
                                                                             Cp (i, j) =                                        (10)
ate the effect of word alignment errors, we base                                           exp(s+ (i, j)) + exp(s− (i, j))
the projection on the alignment matrix, a compact                             The probability Cp (i, j) is a real value between
representation of multiple GIZA++ (Och and Ney,                            0 and 1. Obviously, Cp (i, j) = 0.5 indicates the
2000) results, rather than a single word alignment                         most ambiguous case, where we can not distin-
in previous dependency projection works. Figure                            guish between positive and negative at all. On the
2 shows an example.                                                        other hand, there are as many as 2|f |(|f |−1) candi-
   Suppose a bilingual sentence pair, composed of                          date projected dependency instances for the target
a source sentence e and its target translation f . ye                      sentence f . Therefore, we need choose a threshold
is the parse tree of the source sentence. A is the                         b for Cp (i, j) to filter out the ambiguous instances:
alignment matrix between them, and each element                            the instances with Cp (i, j) > b are selected as the
Ai,j denotes the degree of the alignment between                           positive, and the instances with Cp (i, j) < 1 − b
word ei and word fj . We define a boolean-valued                           are selected as the negative.
function δ(y, i, j, r) to investigate the dependency
relationship of word i and word j in parse tree y:                         4 Boosting an MST Parser
                
                    (i, j) ∈ y and r = +                                   The classifier can be used to boost a existing parser
                
                
                
                
                 1      or                                                trained on human-annotated trees. We first estab-
δ(y, i, j, r) =     (i, j) ∈
                           / y and r = −                       (7)         lish a unified framework for the enhanced parser.
                
                
                                                                          For a sentence to be parsed, x, the enhanced parser
                                                                           selects the best parse ỹ according to both the base-
                
                  0 otherwise
                
                                                                           line model B and the projected classifier C.
Then the score that word i and word j in the target
                                                                                ỹ = argmax[sB (x, y) + λsC (x, y)]             (11)
sentence y forms a projected dependency edge,                                              y


                                                                      15


Here, sB and sC denote the evaluation functions             they differ from each other in the classification re-
of the baseline model and the projected classi-             sults. The classifier in our model predicates a de-
fier, respectively. The parameter λ is the relative         pendency probability for each pair of words, while
weight of the projected classifier against the base-        the classifier in a transition-based model gives a
line model.                                                 possible next transition operation such as shift or
   There are several strategies to integrate the two        reduce. Another difference lies in the factoriza-
evaluation functions. For example, they can be in-          tion strategy. For our method, the evaluation score
tegrated deeply at each decoding step (Carreras et          of a candidate parse is factorized into each depen-
al., 2008; Zhang and Clark, 2008; Huang, 2008),             dency edge, while for the transition-based models,
or can be integrated shallowly in a reranking man-          the score is factorized into each transition opera-
ner (Collins, 2000; Charniak and Johnson, 2005).            tion.
As described previously, the score of a depen-                 Thanks to the reminding of the third reviewer
dency tree given by a word-pair classifier can be           of our paper, we find that the pairwise classifica-
factored into each candidate dependency edge in             tion schema has also been used in Japanese de-
this tree. Therefore, the projected classifier can          pendency parsing (Uchimoto et al., 1999; Kudo
be integrated with a baseline model deeply at each          and Matsumoto, 2000). However, our work shows
dependency edge, if the evaluation score given by           more advantage in feature engineering, model
the baseline model can also be factored into de-            training and decoding algorithm.
pendency edges.
                                                            5.2 Dependency Projection
   We choose the 2nd-ordered MST model (Mc-
Donald and Pereira, 2006) as the baseline. Es-              Many works try to learn parsing knowledge from
pecially, the effect of the Collins distance in the         bilingual corpora.        Lü et al. (2002) aims to
baseline model is also investigated. The relative           obtain Chinese bracketing knowledge via ITG
weight λ is adjusted to maximize the performance            (Wu, 1997) alignment. Hwa et al. (2005) and
on the development set, using an algorithm similar          Ganchev et al. (2009) induce dependency gram-
to minimum error-rate training (Och, 2003).                 mar via projection from aligned bilingual cor-
                                                            pora, and use some thresholds to filter out noise
5 Related Works                                             and some hand-written rules to handle heterogene-
                                                            ity. Smith and Eisner (2009) perform depen-
5.1   Dependency Parsing                                    dency projection and annotation adaptation with
Both the graph-based (McDonald et al., 2005a;               Quasi-Synchronous Grammar features. Jiang and
McDonald and Pereira, 2006; Carreras et al.,                Liu (2009) refer to alignment matrix and a dy-
2006) and the transition-based (Yamada and Mat-             namic programming search algorithm to obtain
sumoto, 2003; Nivre et al., 2006) parsing algo-             better projected dependency trees.
rithms are related to our word-pair classification              All previous works for dependency projection
model.                                                      (Hwa et al., 2005; Ganchev et al., 2009; Smith and
   Similar to the graph-based method, our model             Eisner, 2009; Jiang and Liu, 2009) need complete
is factored on dependency edges, and its decod-             projected trees to train the projected parsers. Be-
ing procedure also aims to find a maximum span-             cause of the free translation, the word alignment
ning tree in a fully connected directed graph. From         errors, and the heterogeneity between two lan-
this point, our model can be classified into the            guages, it is reluctant and less effective to project
graph-based category. On the training method,               the dependency tree completely to the target lan-
however, our model obviously differs from other             guage sentence. On the contrary, our dependency
graph-based models, that we only need a set of              projection strategy prefer to extract a set of depen-
word-pair dependency instances rather than a reg-           dency instances, which coincides our model’s de-
ular dependency treebank. Therefore, our model is           mand for training corpus. An obvious advantage
more suitable for the partially bracketed or noisy          of this strategy is that, we can select an appropriate
training corpus.                                            filtering threshold to obtain dependency instances
   The most apparent similarity between our                 of good quality.
model and the transition-based category is that                 In addition, our word-pair classification model
they all need a classifier to perform classification        can be integrated deeply into a state-of-the-art
conditioned on a certain configuration. However,            MST dependency model. Since both of them are


                                                       16


      Corpus              Train      Dev       Test
      WSJ (section)        2-21      22         23                                              87




                                                                    Dependency Precision (%)
      CTB 5.0 (chapter)   others   301-325   271-300                                           86.5

                                                                                                86
Table 2: The corpus partition for WSJ and CTB
5.0.                                                                                           85.5
                                                                                                85
                                                                                               84.5
factorized into dependency edges, the integration                                                                             WSJ
                                                                                                84                          CTB 5.0
can be conducted at each dependency edge, by
                                                                                                      1      1.5        2        2.5        3
weightedly averaging their evaluation scores for                                                          Ratio r (#negative/#positive)
this dependency edge. This strategy makes better
use of the projected parser while with faster de-            Figure 3: Performance curves of the word-pair
coding, compared with the cascaded approach of               classification model on the development sets of
Jiang and Liu (2009).                                        WSJ and CTB 5.0, with respect to a series of ratio
                                                             r.
6 Experiments
                                                                 Corpus                           System                                  P%
                                                                 WSJ                               Yamada and Matsumoto (2003)             90.3
In this section, we first validate the word-pair                                                   Nivre and Scholz (2004)                 87.3
classification model by experimenting on human-                                                   1st-ordered MST                          90.7
annotated treebanks. Then we investigate the ef-                                                  2nd-ordered MST                          91.5
                                                                                                  our model                                86.8
fectiveness of the dependency projection by eval-                CTB 5.0                          1st-ordered MST                         86.53
uating the projected classifiers trained on the pro-                                              2nd-ordered MST                         87.15
jected classification instances. Finally, we re-                                                  our model                               82.06
port the performance of the integrated dependency
                                                             Table 3: Performance of the word-pair classifica-
parser which integrates the projected classifier and
                                                             tion model on WSJ and CTB 5.0, compared with
the 2nd-ordered MST dependency parser. We
                                                             the current state-of-the-art models.
evaluate the parsing accuracy by the precision of
lexical heads, which is the percentage of the words
that have found their correct parents.                       For example, r = 2 means we reserve negative
                                                             instances two times as many as the positive ones.
6.1    Word-Pair Classification Model                           The MaxEnt toolkit by Zhang 2 is adopted to
                                                             train the ME classifier on extracted instances. We
We experiment on two popular treebanks, the Wall
                                                             set the gaussian prior as 1.0 and the iteration limit
Street Journal (WSJ) portion of the Penn English
                                                             as 100, leaving other parameters as default values.
Treebank (Marcus et al., 1993), and the Penn Chi-
                                                             We first investigate the impact of the ratio r on
nese Treebank (CTB) 5.0 (Xue et al., 2005). The
                                                             the performance of the classifier. Curves in Fig-
constituent trees in the two treebanks are trans-
                                                             ure 3 show the performance of the English and
formed to dependency trees according to the head-
                                                             Chinese parsers, each of which is trained on an in-
finding rules of Yamada and Matsumoto (2003).
                                                             stance set corresponding to a certain r. We find
For English, we use the automatically-assigned
                                                             that for both English and Chinese, maximum per-
POS tags produced by an implementation of the
                                                             formance is achieved at about r = 2.5. 3 The
POS tagger of Collins (2002). While for Chinese,
                                                             English and Chinese classifiers trained on the in-
we just use the gold-standard POS tags following
                                                             stance sets with r = 2.5 are used in the final eval-
the tradition. Each treebank is splitted into three
                                                             uation phase. Table 3 shows the performances on
partitions, for training, development and testing,
                                                             the test sets of WSJ and CTB 5.0.
respectively, as shown in Table 2.
                                                                We also compare them with previous works on
   For a dependency tree with n words, only n −
                                                             the same test sets. On both English and Chinese,
1 positive dependency instances can be extracted.
                                                             the word-pair classification model falls behind of
They account for only a small proportion of all the
                                                             the state-of-the-art. We think that it is probably
dependency instances. As we know, it is important
                                                                2
to balance the proportions of the positive and the                 http://homepages.inf.ed.ac.uk/s0450736/
negative instances for a batched-trained classifier.         maxent toolkit.html.
                                                                 3
                                                                   We did not investigate more fine-grained ratios, since the
We define a new parameter r to denote the ratio of           performance curves show no dramatic fluctuation along with
the negative instances relative to the positive ones.        the alteration of r.


                                                        17


                                  56                                                               Corpus    System                  P%
                                                                                                   CTB 2.0    Hwa et al. (2005)       53.9

      Dependency Precision (%)
                                                                                                             our model                56.9
                                 55.5                                                              CTB 5.0    Jiang and Liu (2009)   53.28
                                                                                                             our model               58.59
                                  55
                                                                                           Table 4: The performance of the projected classi-
                                 54.5                                                      fier on the test sets of CTB 2.0 and CTB 5.0, com-
                                                                                           pared with the performance of previous works on
                                  54                                                       the corresponding test sets.
                                        0.65   0.7   0.75   0.8   0.85   0.9   0.95
                                                      Threshold b
                                                                                                  Corpus     Baseline P%    Integrated P%
Figure 4: The performance curve of the word-                                                      CTB 1.0       82.23            83.70
                                                                                                  CTB 5.0       87.15            87.65
pair classification model on the development set
of CTB 5.0, with respect to a series of threshold b.                                       Table 5: Performance improvement brought by
                                                                                           the projected classifier to the baseline 2nd-ordered
                                                                                           MST parsers trained on CTB 1.0 and CTB 5.0, re-
due to the local optimization of the training pro-
                                                                                           spectively.
cedure. Given complete trees as training data, it
is easy for previous models to utilize structural,
global and linguistical information in order to ob-                                        with different thresholds. Then, on each instance
tain more powerful parameters. The main advan-                                             set we train a classifier and test it on the develop-
tage of our model is that it doesn’t need complete                                         ment set of CTB 5.0. Figure 4 presents the ex-
trees to tune its parameters. Therefore, if trained                                        perimental results. The curve shows that the max-
on instances extracted from human-annotated tree-                                          imum performance is achieved at the threshold of
banks, the word-pair classification model would                                            about 0.85. The classifier corresponding to this
not demonstrate its advantage over existed state-                                          threshold is evaluated on the test set of CTB 5.0,
of-the-art dependency parsing methods.                                                     and the test set of CTB 2.0 determined by Hwa et
                                                                                           al. (2005). Table 4 shows the performance of the
6.2          Dependency Projection                                                         projected classifier, as well as the performance of
In this work we focus on the dependency projec-                                            previous works on the corresponding test sets. The
tion from English to Chinese. We use the FBIS                                              projected classifier significantly outperforms pre-
Chinese-English bitext as the bilingual corpus for                                         vious works on both test sets, which demonstrates
dependency projection. It contains 239K sen-                                               that the word-pair classification model, although
tence pairs with about 6.9M/8.9M words in Chi-                                             falling behind of the state-of-the-art on human-
nese/English. Both English and Chinese sentences                                           annotated treebanks, performs well in projected
are tagged by the implementations of the POS tag-                                          dependency parsing. We give the credit to its good
ger of Collins (2002), which trained on WSJ and                                            collaboration with the word-pair classification in-
CTB 5.0 respectively. The English sentences are                                            stance extraction for dependency projection.
then parsed by an implementation of 2nd-ordered
MST model of McDonald and Pereira (2006),                                                  6.3 Integrated Dependency Parser
which is trained on dependency trees extracted                                             We integrate the word-pair classification model
from WSJ. The alignment matrixes for sentence                                              into the state-of-the-art 2nd-ordered MST model.
pairs are generated according to (Liu et al., 2009).                                       First, we implement a chart-based dynamic pro-
   Similar to the ratio r, the threshold b need also                                       gramming parser for the 2nd-ordered MST model,
be assigned an appropriate value to achieve a bet-                                         and develop a training procedure based on the
ter performance. Larger thresholds result in better                                        perceptron algorithm with averaged parameters
but less classification instances, the lower cover-                                        (Collins, 2002). On the WSJ corpus, this parser
age of the instances would hurt the performance of                                         achieves the same performance as that of McDon-
the classifier. On the other hand, smaller thresh-                                         ald and Pereira (2006). Then, at each derivation
olds lead to worse but more instances, and too                                             step of this 2nd-ordered MST parser, we weight-
much noisy instances will bring down the classi-                                           edly add the evaluation score given by the pro-
fier’s discriminating power.                                                               jected classifier to the original MST evaluation
   We extract a series of classification instance sets                                     score. Such a weighted summation of two eval-


                                                                                      18


uation scores provides better evaluation for can-            tal data. We also thank Dr. Yang Liu for sharing
didate parses. The weight parameter λ is tuned               the codes of alignment matrix generation, and Dr.
by a minimum error-rate training algorithm (Och,             Liang Huang for helpful discussions.
2003).
   Given a 2nd-ordered MST parser trained on
CTB 5.0 as the baseline, the projected classi-               References
fier brings an accuracy improvement of about 0.5             Adam L. Berger, Stephen A. Della Pietra, and Vin-
points. For the baseline trained on the smaller                cent J. Della Pietra. 1996. A maximum entropy
CTB 1.0, whose training set is chapters 1-270 of               approach to natural language processing. Compu-
CTB 5.0, the accuracy improvement is much sig-                 tational Linguistics.
nificant, about 1.5 points over the baseline. It             Xavier Carreras, Mihai Surdeanu, and Lluis Marquez.
indicates that, the smaller the human-annotated                2006. Projective dependency parsing with percep-
treebank we have, the more significant improve-                tron. In Proceedings of the CoNLL.
ment we can achieve by integrating the project-              Xavier Carreras, Michael Collins, and Terry Koo.
ing classifier. This provides a promising strategy             2008. Tag, dynamic programming, and the percep-
for boosting the parsing performance of resource-              tron for efficient, feature-rich parsing. In Proceed-
scarce languages. Table 5 summarizes the experi-               ings of the CoNLL.
mental results.                                              Eugene Charniak and Mark Johnson. 2005. Coarse-
                                                               to-fine-grained n-best parsing and discriminative
7 Conclusion and Future Works                                  reranking. In Proceedings of the ACL.
In this paper, we first describe an intuitionis-             Michael Collins. 1996. A new statistical parser based
tic method for dependency parsing, which re-                   on bigram lexical dependencies. In Proceedings of
sorts to a classifier to determine whether a word              ACL.
pair forms a dependency edge, and then propose               Michael Collins. 2000. Discriminative reranking for
an effective strategy for dependency projection,               natural language parsing. In Proceedings of the
which produces a set of projected classification in-           ICML, pages 175–182.
stances rather than complete projected trees. Al-
                                                             Michael Collins. 2002. Discriminative training meth-
though this parsing method falls behind of pre-                ods for hidden markov models: Theory and exper-
vious models, it can collaborate well with the                 iments with perceptron algorithms. In Proceedings
word-pair classification instance extraction strat-            of the EMNLP, pages 1–8, Philadelphia, USA.
egy for dependency projection, and achieves the
                                                             Jason M. Eisner. 1996. Three new probabilistic mod-
state-of-the-art in projected dependency parsing.               els for dependency parsing: An exploration. In Pro-
In addition, when integrated into a 2nd-ordered                 ceedings of COLING, pages 340–345.
MST parser, the projected parser brings signifi-
cant improvement to the baseline, especially for             Kuzman Ganchev, Jennifer Gillenwater, and Ben
                                                               Taskar. 2009. Dependency grammar induction via
the baseline trained on smaller treebanks. This                bitext projection constraints. In Proceedings of the
provides a new strategy for resource-scarce lan-               47th ACL.
guages to train high-precision dependency parsers.
However, considering its lower performance on                Liang Huang and David Chiang. 2005. Better k-best
                                                               parsing. In Proceedings of the IWPT, pages 53–64.
human-annotated treebanks, the dependency pars-
ing method itself still need a lot of investigations,        Liang Huang. 2008. Forest reranking: Discriminative
especially on the training method of the classifier.           parsing with non-local features. In Proceedings of
                                                               the ACL.
Acknowledgement                                              Rebecca Hwa, Philip Resnik, Amy Weinberg, and
                                                               Okan Kolak. 2002. Evaluating translational corre-
This project was supported by National Natural                 spondence using annotation projection. In Proceed-
Science Foundation of China, Contract 60736014,                ings of the ACL.
and 863 State Key Project No. 2006AA010108.
We are grateful to the anonymous reviewers for               Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
                                                               Cabezas, and Okan Kolak. 2005. Bootstrapping
their thorough reviewing and valuable sugges-                  parsers via syntactic projection across parallel texts.
tions. We show special thanks to Dr. Rebecca                   In Natural Language Engineering, volume 11, pages
Hwa for generous help of sharing the experimen-                311–325.


                                                        19


Wenbin Jiang and Qun Liu. 2009. Automatic adapta-              Franz Joseph Och. 2003. Minimum error rate training
  tion of annotation standards for dependency parsing            in statistical machine translation. In Proceedings of
  using projected treebank as source corpus. In Pro-             the ACL, pages 160–167.
  ceedings of IWPT.
                                                               David Smith and Jason Eisner. 2009. Parser adap-
Wenbin Jiang, Liang Huang, and Qun Liu. 2009. Au-                tation and projection with quasi-synchronous gram-
  tomatic adaptation of annotation standards: Chinese            mar features. In Proceedings of EMNLP.
  word segmentation and pos tagging–a case study. In
  Proceedings of the 47th ACL.                                 Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isa-
                                                                 hara. 1999. Japanese dependency structure analysis
Dan Klein and Christopher D. Manning. 2004. Cor-                 based on maximum entropy models. In Proceedings
  pusbased induction of syntactic structure: Models of           of the EACL.
  dependency and constituency. In Proceedings of the
                                                               Vladimir N. Vapnik. 1998. Statistical learning theory.
  ACL.
                                                                 In A Wiley-Interscience Publication.
Terry Koo, Xavier Carreras, and Michael Collins.               Dekai Wu. 1997. Stochastic inversion transduction
  2008. Simple semi-supervised dependency parsing.               grammars and bilingual parsing of parallel corpora.
  In Proceedings of the ACL.                                     Computational Linguistics.
Taku Kudo and Yuji Matsumoto. 2000. Japanese de-               Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
  pendency structure analysis based on support vector            Palmer. 2005. The penn chinese treebank: Phrase
  machines. In Proceedings of the EMNLP.                         structure annotation of a large corpus. In Natural
                                                                 Language Engineering.
Yang Liu, Tian Xia, Xinyan Xiao, and Qun Liu. 2009.
  Weighted alignment matrices for statistical machine          H Yamada and Y Matsumoto. 2003. Statistical depen-
  translation. In Proceedings of the EMNLP.                      dency analysis using support vector machines. In
                                                                 Proceedings of IWPT.
Yajuan Lü, Sheng Li, Tiejun Zhao, and Muyun Yang.
  2002.     Learning chinese bracketing knowledge              Yue Zhang and Stephen Clark. 2008. Joint word seg-
  based on a bilingual language model. In Proceed-               mentation and pos tagging using a single perceptron.
  ings of the COLING.                                            In Proceedings of the ACL.

Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
  Marcinkiewicz. 1993. Building a large annotated
  corpus of english: The penn treebank. In Computa-
  tional Linguistics.

Ryan McDonald and Fernando Pereira. 2006. Online
  learning of approximate dependency parsing algo-
  rithms. In Proceedings of EACL, pages 81–88.

Ryan McDonald, Koby Crammer, and Fernando
  Pereira. 2005a. Online large-margin training of de-
  pendency parsers. In Proceedings of ACL, pages 91–
  98.

Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
  Jan Hajic̆. 2005b. Non-projective dependency pars-
  ing using spanning tree algorithms. In Proceedings
  of HLT-EMNLP.

J. Nivre and M. Scholz. 2004. Deterministic depen-
   dency parsing of english text. In Proceedings of the
   COLING.

Joakim Nivre, Johan Hall, Jens Nilsson, Gulsen
  Eryigit, and Svetoslav Marinov. 2006. Labeled
  pseudoprojective dependency parsing with support
  vector machines. In Proceedings of CoNLL, pages
  221–225.

Franz J. Och and Hermann Ney. 2000. Improved
  statistical alignment models. In Proceedings of the
  ACL.


                                                          20

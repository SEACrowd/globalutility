                  A Risk Minimization Framework for Extractive
                             Speech Summarization

                                Shih-Hsiang Lin and Berlin Chen
                                National Taiwan Normal University
                                          Taipei, Taiwan
                            {shlin, berlin}@csie.ntnu.edu.tw
                                                               concise abstract that reflects the key concepts of
                     Abstract                                  a document is generated, whereas in extractive
                                                               summarization, the summary is usually formed
    In this paper, we formulate extractive                     by selecting salient sentences from the original
    summarization as a risk minimization                       document (Mani and Maybury, 1999). The for-
    problem and propose a unified probabilis-                  mer requires highly sophisticated natural lan-
    tic framework that naturally combines su-                  guage processing techniques, including semantic
    pervised and unsupervised summarization                    representation and inference, as well as natural
    models to inherit their individual merits as               language generation, while this would make ab-
    well as to overcome their inherent limita-                 stractive approaches difficult to replicate or ex-
    tions. In addition, the introduction of vari-              tend from constrained domains to more general
    ous loss functions also provides the sum-                  domains. In addition to being extractive or ab-
    marization framework with a flexible but                   stractive, a summary may also be generated by
    systematic way to render the redundancy                    considering several other aspects like being ge-
    and coherence relationships among sen-                     neric or query-oriented summarization, single-
    tences and between sentences and the                       document or multi-document summarization, and
    whole document, respectively. Experi-                      so forth. The readers may refer to (Mani and
    ments on speech summarization show that                    Maybury, 1999) for a comprehensive overview
    the methods deduced from our framework                     of automatic text summarization. In this paper,
    are very competitive with existing summa-                  we focus exclusively on generic, single-
    rization approaches.                                       document extractive summarization which forms
                                                               the building block for many other summarization
1    Introduction                                              tasks.
                                                                  Aside from traditional ad-hoc extractive sum-
Automated summarization systems which enable
                                                               marization methods (Mani and Maybury, 1999),
user to quickly digest the important information
                                                               machine-learning approaches with either super-
conveyed by either a single or a cluster of docu-
                                                               vised or unsupervised learning strategies have
ments are indispensible for managing the rapidly
                                                               gained much attention and been applied with
growing amount of textual information and mul-
                                                               empirical success to many summarization tasks
timedia content (Mani and Maybury, 1999). On
                                                               (Kupiec et al., 1999; Lin et al., 2009). For super-
the other hand, due to the maturity of text sum-
                                                               vised learning strategies, the summarization task
marization, the research paradigm has been ex-
                                                               is usually cast as a two-class (summary and non-
tended to speech summarization over the years
                                                               summary) sentence-classification problem: A
(Furui et al., 2004; McKeown et al., 2005).
                                                               sentence with a set of indicative features is input
Speech summarization is expected to distill im-
                                                               to the classifier (or summarizer) and a decision is
portant information and remove redundant and
                                                               then returned from it on the basis of these fea-
incorrect information caused by recognition er-
                                                               tures. In general, they usually require a training
rors from spoken documents, enabling user to
                                                               set, comprised of several documents and their
efficiently review spoken documents and under-
                                                               corresponding handcrafted summaries (or labeled
stand the associated topics quickly. It would also
                                                               data), to train the classifiers. However, manual
be useful for improving the efficiency of a num-
                                                               labeling is expensive in terms of time and per-
ber of potential applications like retrieval and
                                                               sonnel. The other potential problem is the so-
mining of large volumes of spoken documents.
                                                               called “bag-of-sentences” assumption implicitly
   A summary can be either abstractive or extrac-
                                                               made by most of these summarizers. That is, sen-
tive. In abstractive summarization, a fluent and
                                                               tences are classified independently of each other,

                                                          79
         Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 79–87,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


without leveraging the dependence relationships          2.1    Supervised summarizers
among the sentences or the global structure of           Extractive speech summarization can be treated
the document (Shen et al., 2007).                        as a two-class (positive/negative) classification
   Another line of thought attempts to conduct           problem. A spoken sentence S i is characterized
document summarization using unsupervised                by set of T indicative features X i  xi1 ,, xiT  ,
machine-learning approaches, getting around the          and they may include lexical features (Koumpis
need for manually labeled training data. Most            and Renals, 2000), structural features (Maskey
previous studies conducted along this line have          and Hirschberg, 2003), acoustic features (Inoue
their roots in the concept of sentence centrality        et al., 2004), discourse features (Zhang et al.,
(Gong and Liu, 2001; Erkan and Radev, 2004;              2007) and relevance features (Lin et al., 2009).
Radev et al., 2004; Mihalcea and Tarau, 2005).           Then, the corresponding feature vector X i of S i
Put simply, sentences more similar to others are         is taken as the input to the classifier. If the output
deemed more salient to the main theme of the             (classification) score belongs to the positive class,
document; such sentences thus will be selected            S i will be selected as part of the summary; oth-
as part of the summary. Even though the perfor-          erwise, it will be excluded (Kupiec et al., 1999).
mance of unsupervised summarizers is usually             Specifically, the problem can be formulated as
worse than that of supervised summarizers, their         follows: Construct a sentence ranking model that
domain-independent and easy-to-implement                 assigns a classification score (or a posterior
                                                         probability) of being in the summary class to
properties still make them attractive.
                                                         each sentence of a spoken document to be sum-
   Building on these observations, we expect that
                                                         marized; important sentences are subsequently
researches conducted along the above-mentioned           ranked and selected according to these scores. To
two directions could complement each other, and          this end, several popular machine-learning me-
it might be possible to inherit their individual         thods could be utilized, like Bayesian classifier
merits to overcome their inherent limitations. In        (BC) (Kupiec et al., 1999), Gaussian mixture
this paper, we present a probabilistic summariza-        model (GMM) (Fattah and Ren, 2009) , hidden
tion framework stemming from Bayes decision              Markov model (HMM) (Conroy and O'leary,
theory (Berger, 1985) for speech summarization.          2001), support vector machine (SVM) (Kolcz et
This framework can not only naturally integrate          al., 2001), maximum entropy (ME) (Ferrier,
the above-mentioned two modeling paradigms               2001), conditional random field (CRF) (Galley,
but also provide a flexible yet systematic way to        2006; Shen et al., 2007), to name a few.
render the redundancy and coherence relation-                Although such supervised summarizers are ef-
ships among sentences and between sentences              fective, most of them (except CRF) usually im-
and the whole document, respectively. Moreover,          plicitly assume that sentences are independent of
we also illustrate how the proposed framework            each other (the so-called “bag-of-sentences” as-
can unify several existing summarization models.         sumption) and classify each sentence individual-
   The remainder of this paper is structured as          ly without leveraging the relationship among the
follows. We start by reviewing related work on           sentences (Shen et al., 2007). Another major
                                                         shortcoming of these summarizers is that a set of
extractive summarization. In Section 3 we for-
                                                         handcrafted document-reference summary ex-
mulate the extractive summarization task as a            emplars are required for training the summarizers;
risk minimization problem, followed by a de-             however, such summarizers tend to limit their
tailed elucidation of the proposed methods in            generalization capability and might not be readi-
Section 4. Then, the experimental setup and a            ly applicable for new tasks or domains.
series of experiments and associated discussions
are presented in Sections 5 and 6, respectively.         2.2    Unsupervised summarizers
Finally, Section 7 concludes our presentation and        The related work conducted along this direction
discusses avenues for future work.                       usually relies on some heuristic rules or statistic-
2   Background                                           al evidences between each sentence and the doc-
                                                         ument, avoiding the need of manually labeled
Speech summarization can be conducted using              training data. For example, the vector space
either supervised or unsupervised methods (Furui         model (VSM) approach represents each sentence
et al., 2004, McKeown et al., 2005, Lin et al.,          of a document and the document itself in vector
2008). In the following, we briefly review a few         space (Gong and Liu, 2001), and computes the
celebrated methods that have been applied to             relevance score between each sentence and the
extractive speech summarization tasks with good          document (e.g., the cosine measure of the simi-
success.

                                                    80


larity between two vectors). Then, the sentences            where pθ|O  is the posterior probability of the
with the highest relevance scores are included in           state of nature being  given the observation O .
the summary. A natural extension is to represent            Bayes decision theory states that the optimum
each document or each sentence vector in a latent           decision can be made by contemplating each ac-
semantic space (Gong and Liu, 2001), instead of             tion ai , and then choosing the action for which
simply using the literal term information as that           the expected risk is minimum:
done by VSM.                                                  a*  arg min R ai | O .                      (2)
   On the other hand, the graph-based methods,                         ai
such as TextRank (Mihalcea and Tarau, 2005)
and LexRank (Erkan and Radev, 2004), concep-                   The notion of minimizing the Bayes risk has
                                                            gained much attention and been applied with
tualize the document to be summarized as a net-
                                                            success to many natural language processing
work of sentences, where each node represents a             (NLP) tasks, such as automatic speech recogni-
sentence and the associated weight of each link             tion (Goel and Byrne, 2000), statistical machine
represents the lexical or topical similarity rela-          translation (Kumar and Byrne, 2004) and statis-
tionship between a pair of nodes. Document                  tical information retrieval (Zhai and Lafferty,
summarization thus relies on the global structural          2006). Following the same spirit, we formulate
information conveyed by such conceptualized                 the extractive summarization task as a Bayes risk
network, rather than merely considering the local           minimization problem. Without loss of generality,
features of each node (sentence).                           let us denote   Π as one of possible selection
   However, due to the lack of document-                    strategies (or state of nature) which comprises a
summary reference pairs, the performance of the             set of indicators used to address the importance
unsupervised summarizers is usually worse than              of each sentence Si in a document D to be
that of the supervised summarizers. Moreover,               summarized. A feasible selection strategy can be
most of the unsupervised summarizers are con-               fairly arbitrary according to the underlying prin-
structed solely on the basis of the lexical infor-          ciple. For example, it could be a set of binary
mation without considering other sources of in-             indicators denoting whether a sentence should be
formation cues like discourse features, acoustic            selected as part of summary or not. On the con-
features, and so forth.                                     trary, it may also be a ranked list used to address
                                                            the significance of each individual sentence.
3      A risk minimization framework for                    Moreover, we refer to the k -th action ak as
       extractive summarization                             choosing the k -th selection strategy  k , and the
                                                            observation O as the document D to be summa-
Extractive summarization can be viewed as a                 rized. As a result, the expected risk of a certain
decision making process in which the summariz-              selection strategy  k is given by
er attempts to select a representative subset of
sentences or paragraphs from the original docu-               R  k | D    L k ,   p  | D d .   (3)
ments. Among the several analytical methods
that can be employed for the decision process,              Consequently, the ultimate goal of extractive
the Bayes decision theory, which quantifies the             summarization could be stated as the search of
tradeoff between various decisions and the po-              the best selection strategy from the space of all
tential cost that accompanies each decision, is             possible selection strategies that minimizes the
perhaps the most suited one that can be used to             expected risk defined as follows:
guide the summarizer in choosing a course of                   *  arg min R k | D 
action in the face of some uncertainties underly-                       k
ing the decision process (Berger, 1985). Stated
formally, a decision problem may consist of four                    arg min  L k ,   p  | D d .   (4)
                                                                         k
basic elements: 1) an observation O from a ran-
dom variable O , 2) a set of possible decisions                Although we have described a general formu-
(or actions) a  Α , 3) the state of nature   Θ ,         lation for the extractive summarization problem
and 4) a loss function Lai ,  which specifies the        on the grounds of the Bayes decision theory, we
cost associated with a chosen decision ai given             consider hereafter a special case of it where the
that  is the true state of nature. The expected            selection strategy is represented by a binary deci-
risk (or conditional risk) associated with taking           sion vector, of which each element corresponds
decision ai is given by                                     to a specific sentence S i in the document D and
                                                            designates whether it should be selected as part
    R ai | O   θ Lai ,θ  p θ|O dθ ,    (1)          of the summary or not, as the first such attempt.
                                                            More concretely, we assume that the summary

                                                       81


sentences of a given document can be iteratively                                      4           Proposed Methods
chosen (i.e., one at each iteration) from the doc-
ument until the aggregated summary reaches a                                          There are many ways to construct the above
                                                                                      mentioned three component models, i.e., the sen-
predefined target summarization ratio. It turns                                                                      ~
                                                                                                                             
                                                                                      tence generative model P D | S j , the sentence
                                                                                      prior model PS j  , and the loss function LSi , S j  .
out that the binary vector for each possible action
will have just one element equal to 1 and all oth-
ers equal to zero (or the so-called “one-of-n”                                        In what follows, we will shed light on one possi-
coding). For ease of notation, we denote the bi-                                      ble attempt that can accomplish this goal elegant-
nary vector by S i when the i -th element has a                                       ly.
value of 1. Therefore, the risk minimization                                          4.1          Sentence generative model
framework can be reduced to
                                                                                      In order to estimate the sentence generative
                        ~
  S *  arg min R S i | D
                ~
                                                                                    probability, we explore the language modeling
             SiD                                                                     (LM) approach, which has been introduced to a
                                                                          (5)
                         ~LSi , S j PS j | D ,
                                                              ~                       wide spectrum of IR tasks and demonstrated with
         arg min
                 ~
              SiD    S j D                                                          good empirical success, to predict the sentence
          ~                                                                           generative probability. In the LM approach, each
where D denotes the remaining sentences that                                          sentence in a document can be simply regarded
have not been selected into the summary yet (i.e.,                                    as a probabilistic generative model consisting of
                                    ~
the “residual” document); P S j | D is the post-
                                          ~
                                                                                    a unigram distribution (the so-called “bag-of-
erior probability of a sentence S j given D . Ac-                                     words” assumption) for generating the document
cording to the~ Bayes’ rule, we can further ex-                                       (Chen et al., 2009):
                    
press P S j | D as (Chen et al., 2009)
                                                                                              
                                                                                                         ,
                                                                                                                      ~
                                                                                            ~                    c w, D

                   
                  ~                                                                       P D S j  ~ P w S j                    (9)
         ~ P D|Sj P Sj
  P Sj |D             ~     ,                  (6)                                                    wD

                                                                                      where cw, D  is the number of times that index
                    PD                                                                           ~
           ~
              
where P D | S j is the sentence generative prob-
                                 ~
                                                                                                                  ~
                                                                                      term (or word) w occurs in D , reflecting that w
ability, i.e., the likelihood of D being generated                                    will contribute more in the calculation of
               
by S j ; P S j is the prior probability of S j being
                                                                                         ~
                                                                                                                               ~
                                                                                       P D S j if it occurs more frequently in D . Note
                                  ~
important; and the evidence P D is the marginal
                  ~
                                                                                                                           
                                                                                      that the sentence model P w S j is simply esti-
probability of D , which can be approximated by                                       mated on the basis of the frequency of index
                                                                                      term w occurring in the sentence S j with the
    ~           ~
                         
  P D   ~ P D | S m PS m .                 (7)                                   maximum likelihood (ML) criterion. In a sense,
             SmD
                                                                                      (9) belongs to a kind of literal term matching
   By substituting (6) and (7) into (5), we obtain                                    strategy (Chen, 2009) and may suffer the prob-
the following final selection strategy for extrac-                                    lem of unreliable model estimation owing partic-
tive summarization:                                                                   ularly to only a few sampled index terms present
                                                                                      in the sentence (Zhai, 2008). To mitigate this
                                                         
                                                         ~
                                                                
                                                       P D|Sj P Sj                    potential defect, a unigram probability estimated
  S *  arg min      ~         L Si , S j               ~
                                                                       . (8)        from a general collection, which models the gen-
             ~
             SiD    S j D                            P D | S m PS m 
                                                      ~                               eral distribution of words in the target language,
                                                  S mD
                                                                                      is often used to smooth the sentence model. In-
   A remarkable feature of this framework lies in                                     terested readers may refer to (Zhai, 2008; Chen
that a sentence to be considered as part of the                                       et al., 2009) for a thorough discussion on various
summary is actually evaluated by three different                                      ways to construct the sentence generative model.
fundamental factors: (1) P S j  is the sentence
prior probability that addresses the importance of                                    4.2          Sentence prior model
                                ~
sentence S j itself; (2) P D | S j is the sentence                                  The sentence prior probability P S j  can be re-
generative probability that captures the degree of                                    garded as the likelihood of a sentence being im-
                                               ~
relevance of S j to the residual document D ; and                                     portant without seeing the whole document. It
(3) LSi , S j  is the loss function that characteriz-                               could be assumed uniformly distributed over sen-
es the relationship between sentence Si and any                                       tences or estimated from a wide variety of factors,
other sentence S j . As we will soon see, such a                                      such as the lexical information, the structural
framework can be regarded as a generalization of                                      information or the inherent prosodic properties of
several existing summarization methods. A de-                                         a spoken sentence.
tailed account on the construction of these three                                        A straightforward way is to assume that the
component models in the framework will be giv-                                        sentence prior probability P S j  is in proportion
en in the following section.                                                          to the posterior probability of a sentence S j be-

                                                                                 82


ing included in the summary class when observ-                          contained in the already selected summary sen-
ing a set of indicative features X j of S j derived                     tences. To alleviate this problem, the concept of
from such factors or other sentence importance                          maximum marginal relevance (MMR) (Carbonell
measures (Kupiec et al., 1999). These features                          and Goldstein, 1998), which performs sentence
can be integrated in a systematic way into the                          selection iteratively by striking the balance be-
proposed framework by taking the advantage of                           tween topic relevance and coverage, can be in-
the learning capability of the supervised ma-                           corporated into the loss function:
chine-learning methods. Specifically, the prior
probability P S j  can be approximated by:                                                                 
                                                                                                Sim S i , S j                  
                                                                                      
                                                                            L Si , S j  1                                       , (12)
                                                                                              1     S 'max  SimS i , S '
        PX | SpPXSj | SPPXS | S PS  ,
  P Sj                                                     (10)
                                                                                                                Summ               
             j                        j                                 where Summ represents the set of sentences that
where PX j | S  and P X j | S  are the likelihoods                  have already been included into the summary
that a sentence S j with features X j are generat-                      and the novelty factor  is used to trade off be-
ed by the summary class S and the non-                                  tween relevance and redundancy.
summary class S , respectively; the prior proba-                        4.4        Relation to other summarization models
bility PS  and P S  are set to be equal in this
research. To estimate PX j | S  and P X j | S  ,                    In this subsection, we briefly illustrate the rela-
several popular supervised classifiers (or summa-                       tionship between our proposed summarization
rizers), like BC or SVM, can be leveraged for                           framework and a few existing summarization
this purpose.                                                           approaches. We start by considering a special
                                                                        case where a 0-1 loss function is used in (8),
4.3           Loss function                                             namely, the loss function will take value 0 if the
The loss function introduced in the proposed                            two sentences are identical, and 1 otherwise.
summarization framework is to measure the rela-                         Then, (8) can be alternatively represented by
tionship between any pair of sentences. Intuitive-
ly, when a given sentence is more dissimilar                                S *  arg min
                                                                                                                         ~
                                                                                                                             
                                                                                                                      P D|Sj P Sj   
from most of the other sentences, it may incur                                          ~
                                                                                     SiD
                                                                                                 ~
                                                                                                  
                                                                                            S j D ,S j  Si
                                                                                                                           ~
                                                                                                                                  
                                                                                                                      ~ P D | S m PS m 
                                                                                                                 SmD
higher loss as it is taken as the representative
sentence (or summary sentence) to represent the
                                                                                   arg max
                                                                                                 ~
                                                                                                     
                                                                                              P D | S i PS i                               (13)
main theme embedded in the other ones. Conse-
quently, the loss function can be built on the no-
                                                                                          ~
                                                                                      Si D
                                                                                                   ~
                                                                                                         
                                                                                             ~ P D | S m PS m 
                                                                                                                  ,
                                                                                                                         
                                                                                            SmD
tion of the similarity measure. In this research,                       which actually provides a natural integration of
we adopt the cosine measure (Gong and Liu,                              the supervised and unsupervised summarizers
2001) to fulfill this goal. We first represent each                     (Lin et al., 2009), as mentioned previously.
sentence S i in vector form where each dimension                            If we further assume the prior probability
specifies the weighted statistic zt ,i , e.g., the                       P S j  is uniformly distributed, the important (or
product of the term frequency (TF) and inverse                          summary) sentence selection problem has now
document frequency (IDF) scores, associated                             been reduced to the problem of measuring the
with an index term wt in sentence S i . Then, the
cosine similarity between any given two sen-
                                                                                                    ~
                                                                                                                 
                                                                        document-likelihood P D | S j , or the relevance         
                                                                        between the document and the sentence. Alone a
tences Si , S j  is                                                   similar vein, the important sentences of a docu-
                           Tt1 z t ,i  zt , j
                                                                        ment can be selected (or ranked) solely based on
          
  Sim S i , S j                                      .    (10)        the prior probability PS j  with the assumption
                                2              2
                        Tt1 z t ,i  Tt1 z t , j
                                                                                                                ~
                                                                        of an equal document-likelihood P D | S j .                      
The loss function is thus defined by                                    5         Experimental setup
                            
  L S i , S j  1  Sim S i , S j .                        (11)        5.1        Data

   Once the sentence generative model P D | S j ,          ~          The summarization dataset used in this research
the sentence prior model PS j  and the loss func-
                                                                        is a widely used broadcast news corpus collected
tion LSi , S j  have been properly estimated, the                     by the Academia Sinica and the Public Televi-
summary sentences can be selected iteratively by                        sion Service Foundation of Taiwan between No-
(8) according to a predefined target summariza-                         vember 2001 and April 2003 (Wang et al., 2005).
tion ratio. However, as can be seen from (8), a                         Each story contains the speech of one studio
new summary sentence is selected without con-                           anchor, as well as several field reporters and in-
sidering the redundant information that is also                         terviewees. A subset of 205 broadcast news doc-

                                                                   83


      Kappa    ROGUE-1 ROUGE-2 ROUGE-L                      measure were used to quantify the utility of the
      0.400      0.600   0.532   0.527                      proposed method. They are, respectively, the
                                                            ROUGE-1 (unigram) measure, the ROUGE-2
Table 1: The agreement among the subjects for impor-
                                                            (bigram) measure and the ROUGE-L (longest
     tant sentence ranking for the evaluation set.
                                                            common subsequence) measure (Lin, 2004).
               1.Duration of the current sentence             The summarization ratio, defined as the ratio of
  Structural
               2.Position of the current sentence           the number of words in the automatic (or manual)
   features
               3.Length of the current sentence             summary to that in the reference transcript of a
               1.Number of named entities                   spoken document, was set to 10% in this re-
  Lexical      2.Number of stop words
                                                            search. Since increasing the summary length
  Features     3.Bigram language model scores
               4.Normalized bigram scores                   tends to increase the chance of getting higher
               1.The 1st formant                            scores in the recall rate of the various ROUGE
               2.The 2nd formant                            measures and might not always select the right
  Acoustic                                                  number of informative words in the automatic
               3.The pitch value
  Features
               4.The peak normalized cross-                 summary as compared to the reference summary,
               correlation of pitch                         all the experimental results reported hereafter are
  Relevance                                                 obtained by calculating the F-scores of these
              1.VSM score
   Feature                                                  ROUGE measures, respectively (Lin, 2004). Ta-
    Table 2: Basic sentence features used by BC.            ble 1 shows the levels of agreement (the Kappa
                                                            statistic and ROUGE measures) between the
uments compiled between November 2001 and
                                                            three subjects for important sentence ranking.
August 2002 was reserved for the summarization
                                                            They seem to reflect the fact that people may not
experiments.
                                                            always agree with each other in selecting the im-
   Three subjects were asked to create summaries
                                                            portant sentences for representing a given docu-
of the 205 spoken documents for the summariza-
                                                            ment.
tion experiments as references (the gold standard)
for evaluation. The summaries were generated by             5.3    Features for supervised summarizers
ranking the sentences in the reference transcript
                                                            We take BC as the representative supervised
of a spoken document by importance without
                                                            summarizer to study in this paper. The input to
assigning a score to each sentence. The average
                                                            BC consists of a set of 28 indicative features
Chinese character error rate (CER) obtained for
                                                            used to characterize a spoken sentence, including
the 205 spoken documents was about 35%.
                                                            the structural features, the lexical features, the
   Since broadcast news stories often follow a
                                                            acoustic features and the relevance feature. For
relatively regular structure as compared to other
                                                            each kind of acoustic features, the minimum,
speech materials like conversations, the position-
                                                            maximum, mean, difference value and mean dif-
al information would play an important (domi-
                                                            ference value of a spoken sentence are extracted.
nant) role in extractive summarization of broad-
                                                            The difference value is defined as the difference
cast news stories; we, hence, chose 20 docu-
                                                            between the minimum and maximum values of
ments for which the generation of reference
                                                            the spoken sentence, while the mean difference
summaries is less correlated with the positional
                                                            value is defined as the mean difference between
information (or the position of sentences) as the
                                                            a sentence and its previous sentence. Finally, the
held-out test set to evaluate the general perfor-
                                                            relevance feature (VSM score) is use to measure
mance of the proposed summarization frame-
                                                            the degree of relevance for a sentence to the
work, and 100 documents as the development set.
                                                            whole document (Gong and Liu, 2001). These
5.2     Performance evaluation                              features are outlined in Table 2, where each of
                                                            them was further normalized to zero mean and
For the assessment of summarization perfor-
                                                            unit variance.
mance, we adopted the widely used ROUGE
measure (Lin, 2004) because of its higher corre-            6     Experimental results and discussions
lation with human judgments. It evaluates the
                                                            6.1    Baseline experiments
quality of the summarization by counting the
number of overlapping units, such as N-grams,               In the first set of experiments, we evaluate the
longest common subsequences or skip-bigram,                 baseline performance of the LM and BC summa-
between the automatic summary and a set of ref-             rizers (cf. Sections 4.1 and 4.2), respectively.
erence summaries. Three variants of the ROGUE               The corresponding results are detailed in Table 3,


                                                       84


                               Text Document (TD)                             Spoken Document (SD)
                         ROGUE-1 ROUGE-2 ROUGE-L                         ROGUE-1 ROUGE-2 ROUGE-L
         BC               0.445      0.346      0.404                     0.369       0.241      0.321
                         (0.390 - 0.504) (0.201 - 0.415) (0.348 - 0.468) (0.316 - 0.426) (0.183 - 0.302) (0.268 - 0.378)
         LM                 0.387           0.264           0.334           0.319            0.164           0.253
                         (0.302 - 0.474) (0.168 - 0.366) (0.251 - 0.415) (0.274 - 0.367) (0.115 - 0.224) (0.215 - 0.301)
                 Table 3: The results achieved by the BC and LM summarizers, respectively.
                          Text Document (TD)                                 Spoken Document (SD)
         Prior Loss ROGUE-1 ROUGE-2 ROUGE-L                              ROGUE-1 ROUGE-2 ROUGE-L
                0-1  0.501      0.401      0.459                            0.417            0.281           0.356
         BC    SIM   0.524      0.425      0.473                            0.475            0.351           0.420
               MMR   0.529      0.426      0.479                            0.475            0.351           0.420
               SIM   0.405      0.281      0.348                            0.365            0.209           0.305
       Uniform
               MMR   0.417      0.282      0.359                    0.391       0.236       0.338
    Table 4: The results achieved by several methods derived from the proposed summarization framework.

where the values in the parentheses are the asso-                transcripts. The relative performance degrada-
ciated 95% confidence intervals. It is also worth                tions are about 15%, 34% and 23%, respectively,
mentioning that TD denotes the summarization                     for ROUGE-1, ROUGE2 and ROUGE-L meas-
results obtained based on manual transcripts of                  ures. One possible explanation is that the errone-
the spoken documents while SD denotes the re-                    ous speech recognition transcripts of spoken sen-
sults using the speech recognition transcripts                   tences would probably carry wrong information
which may contain speech recognition errors and                  and thus deviate somewhat from representing the
sentence boundary detection errors. In this re-                  true theme of the spoken document. Second, the
search, sentence boundaries were determined by                   supervised summarizer (i.e., BC) outperforms the
speech pauses. For the TD case, the acoustic fea-                unsupervised summarizer (i.e., LM). The better
tures were obtained by aligning the manual tran-                 performance of BC can be further explained by
scripts to their spoken documents counterpart by                 two reasons. One is that BC is trained with the
performing word-level forced alignment.                          handcrafted document-summary sentence labels
   Furthermore, the ROGUE measures, in es-                       in the development set while LM is instead con-
sence, are evaluated by counting the number of                   ducted in a purely unsupervised manner. Another
overlapping units between the automatic sum-                     is that BC utilizes a rich set of features to charac-
mary and the reference summary; the corres-                      terize a given spoken sentence while LM is con-
ponding evaluation results, therefore, would be                  structed solely on the basis of the lexical (uni-
severely affected by speech recognition errors                   gram) information.
when applying the various ROUGE measures to
                                                                 6.2    Experiments on the proposed methods
quantify the performance of speech summariza-
tion. In order to get rid of the cofounding effect               We then turn our attention to investigate the utili-
of this factor, it is assumed that the selected                  ty of several methods deduced from our pro-
summary sentences can also be presented in                       posed summarization framework. We first con-
speech form (besides text form) such that users                  sider the case when a 0-1 loss function is used (cf.
can directly listen to the audio segments of the                 (13)), which just show a simple combination of
summary sentences to bypass the problem caused                   BC and LM. As can be seen from the first row of
by speech recognition errors. Consequently, we                   Table 4, such a combination can give about 4%
can align the ASR transcripts of the summary                     to 5% absolute improvements as compared to the
sentences to their respective audio segments to                  results of BC illustrated in Table 3. It in some
obtain the correct (manual) transcripts for the                  sense confirms the feasibility of combining the
summarization performance evaluation (i.e., for                  supervised and unsupervised summarizers.
the SD case).                                                    Moreover, we consider the use of the loss func-
   Observing Table 3 we notice two particulari-                  tions defined in (11) (denoted by SIM) and (12)
ties. First, there are significant performance gaps              (denoted by MMR), and the corresponding re-
between summarization using the manual tran-                     sults are shown in the second and the third rows
scripts and the erroneous speech recognition                     of Table 4, respectively. It can be found that


                                                            85


MMR delivers higher summarization perfor-                                   ROGUE-1 ROUGE-2 ROUGE-L
mance than SIM (especially for the SD case),                      TD         0.320   0.197    0.283
which in turn verifies the merit of incorporating          LEAD
                                                                  SD         0.312   0.168    0.251
the MMR concept into the proposed framework
                                                                  TD         0.345   0.220    0.287
for extractive summarization. If we further com-           VSM
pare the results achieved by MMR with those of                    SD         0.337   0.189    0.277
BC and LM as shown in Table 3, we can find                        TD         0.435   0.314    0.377
                                                          LexRank
significant improvements both for the TD and                      SD         0.348   0.204    0.294
SD cases. By and large, for the TD case, the pro-                 TD         0.431   0.315    0.383
posed summarization method offers relative per-             CRF
                                                                  SD         0.358   0.220    0.291
formance improvements of about 19%, 23% and
19%, respectively, in the ROUGE-1, ROUGE-2                    Table 5: The results achieved by four conventional
                                                                           summarization methods.
and ROUGE-L measures as compared to the BC
baseline; while the relative improvements are             promising performance in spite that it only uti-
29%, 46% and 31%, respectively, in the same               lizes lexical information in an unsupervised
measurements for the SD case. On the other hand,          manner. This somewhat reflects the importance
the performance gap between the TD and SD                 of capturing the global relationship for the sen-
cases are reduced to a good extent by using the           tences in the spoken document to be summarized.
proposed summarization framework.                         As compared to the results shown in the “BC”
   In the next set of experiments, we simply as-          part of Table 4, we can see that our proposed
sume the sentence prior probability PS j  de-           methods significantly outperform all the conven-
fined in (8) is uniformly distributed, namely, we         tional summarization methods compared in this
do not use any supervised information cue but             paper, especially for the SD case.
use the lexical information only. The importance          7      Conclusions and future work
of a given sentence is thus considered from two
angles: 1) the relationship between a sentence            We have proposed a risk minimization frame-
and the whole document, and 2) the relationship           work for extractive speech summarization, which
between the sentence and the other individual             enjoys several advantages. We have also pre-
sentences. The corresponding results are illu-            sented a simple yet effective implementation that
strated in the lower part of Table 4 (denoted by          selects the summary sentences in an iterative
Uniform). We can see that the additional consid-          manner. Experimental results demonstrate that
eration of the sentence-sentence relationship ap-         the methods deduced from such a framework can
pears to be beneficial as compared to that only           yield substantial improvements over several
considering the document-sentence relevance               popular summarization methods compared in this
information (cf. the second row of Table 3). It           paper. We list below some possible future exten-
also gives competitive results as compared to the         sions: 1) integrating different selection strategies,
performance of BC (cf. the first row of Table 3)          e.g., the listwise strategy that defines the loss
for the SD case.                                          function on all the sentences associated with a
                                                          document to be summarized, into this framework,
6.3   Comparison with conventional summa-                 2) exploring different modeling approaches for
      rization methods                                    this framework, 3) investigating discriminative
In the final set of experiments, we compare our           training criteria for training the component mod-
proposed summarization methods with a few                 els in this framework, and 4) extending and ap-
existing summarization methods that have been             plying the proposed framework to multi-
widely used in various summarization tasks, in-           document summarization tasks.
cluding LEAD, VSM, LexRank and CRF; the                   References
corresponding results are shown in Table 5. It
should be noted that the LEAD-based method                James O. Berger Statistical decision theory and
                                                             Bayesian analysis. Springer-Verlap, 1985.
simply extracts the first few sentences in a doc-
                                                          Berlin Chen. 2009. Word topic models for spoken
ument as the summary. To our surprise, CRF                   document retrieval and transcription. ACM
does not provide superior results as compared to             Transactions on Asian Language Information
the other summarization methods. One possible                Processing, 8, (1): 2:1 - 2:27.
explanation is that the structural evidence of the        Jaime Carbonell and Jade Goldstein. 1998. The use of
spoken documents in the test set is not strong               mmr, diversity-based reranking for reordering
enough for CRF to show its advantage of model-               documents and producing summaries. In Proc. of
ing the local structural information among sen-              Annual International ACM SIGIR Conference on
tences. On the other hand, LexRank gives a very

                                                     86


    Research and Development in Information                    Konstantinos Koumpis and Steve Renals. 2000.
    Retrieval: 335 - 336.                                          Transcription And Summarization Of Voicemail
Yi-Ting Chen, Berlin Chen and Hsin-Min Wang.                       Speech. In Proc. of International Conference on
    2009. A probabilistic generative framework for                 Spoken Language Processing: 688 - 691.
    extractive broadcast news speech summarization.            Chin-Yew Lin. 2004. ROUGE: a Package for
    IEEE Transactions on Audio, Speech and                         Automatic Evaluation of Summaries. In Proc. of
    Language Processing, 17, (1): 95 - 106.                        Workshop on Text Summarization Branches Out.
John M. Conroy and Dianne P. O’Leary. 2001. Text               Shih-Hsiang Lin, Berlin Chen and Hsin-Min Wang.
    summarization via hidden Markov models. In                     2009. A comparative study of probabilistic
    Proc. of Annual International ACM SIGIR                        ranking models for Chinese spoken document
    Conference on Research and Development in                      summarization. ACM Transactions on Asian
    Information Retrieval: 406 - 407.                              Language Information Processing, 8, (1): 3:1 -
Güneş Erkan and Dragomir R. Radev. 2004. LexRank:                  3:23.
    graph-based lexical centrality as salience in text         Shih-Hsiang Lin, Yueng-Tien Lo, Yao-Ming Yeh and
    summarization. Journal or Artificial Intelligence              Berlin Chen. 2009. Hybrids of supervised and
    Research, 22: 457 - 479.                                       unsupervised models for extractive speech
Mohamed Abdel Fattah and Fuji Ren. 2009. GA, MR,                   summarization. In Proc. of Annual Conference of
    FFNN, PNN and GMM based models for                             the     International   Speech      Communication
    automatic text summarization. Computer Speech                  Association: 1507 - 1510.
    and Language, 23, (1): 126 - 144.                          Inderjeet Mani and Mark T. Maybury Advances in
Louisa Ferrier A maximum entropy approach to text                  automatic text summarization. MIT Press,
    summarization. School of Artificial Intelligence,              Cambridge, 1999.
    University of Edinburgh, 2001.                             Sameer R. Maskey and Julia Hirschberg. 2003.
Sadaoki Furui, Tomonori Kikuchi, Yousuke Shinnaka                  Automatic Summarization of Broadcast News
    and Chiori Hori. 2004. Speech-to-text and speech-              using Structural Features. In Proc. of the Euro-
    to-speech summarization of spontaneous speech.                 pean Conf. Speech Communication and Technolo-
    IEEE Transactions on Speech and Audio                          gy: 1173 - 1176.
    Processing, 12, (4): 401 - 408.                            Kathleen McKeown, Julia Hirschberg, Michel Galley
Michel Galley. 2006. A skip-chain conditional                      and Sameer Maskey. 2005. From text to speech
    random field for ranking meeting utterances by                 summarization. In Proc. of IEEE International
    importance. In Proc. of Conference on Empirical                Conference on Acoustics, Speech, and Signal
    Methods in Natural Language Processing: 364 -                  Processing: 997 - 1000.
    372.                                                       Rada Mihalcea and Paul Tarau. 2005. TextRank:
Vaibhava Goel and William Byrne. 2000. Minimum                     bringing order into texts. In Proc. of Conference
    Bayes-risk     automatic     speech    recognition.            on Empirical Methods in Natural Language
    Computer Speech and Language, 14, (2): 115 -                   Processing: 404 - 411.
    135.                                                       Dragomir R. Radev, Hongyan Jing, Małgorzata Stys
Yihong Gong and Xin Liu. 2001. Generic text                        and Daniel Tam. 2004. Centroid-based
    summarization using relevance measure and latent               summarization       of     multiple    documents.
    semantic analysis. In Proc. of Annual                          Information Processing and Management, 40: 919
    International ACM SIGIR Conference on                          - 938.
    Research and Development in Information                    Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang and
    Retrieval: 19 - 25.                                            Zheng Chen. 2007. Document summarization
Akira Inoue, Takayoshi Mikami and Yoichi                           using conditional random fields. In Proc. of
    Yamashita. 2004. Improvement of speech                         International Joint Conference on Artificial
    summarization using prosodic information, In                   Intelligence: 2862 - 2867.
    Proc. of Speech Prosody: 599 - 602.                        Hsin-Min Wang, Berlin Chen, Jen-Wei Kuo and Shih-
Shankar Kumar and William Byrne. 2004. Minimum                     Sian Cheng. 2005. MATBN: A Mandarin Chinese
    Bayes-risk decoding for statistical machine                    broadcast news corpus. International Journal of
    translation. In Proc. of Human Language                        Computational Linguistics and Chinese Language
    Technology conference / North American chapter                 Processing, 10, (2): 219 - 236.
    of the Association for Computational Linguistics           ChengXiang Zhai and John Lafferty. 2006. A risk
    annual meeting: 169 - 176.                                     minimization framework for information retrieval.
Aleksander Kolcz, Vidya Prabakarmurthi and Jugal                   Information Processing & Management, 42, (1):
    Kalita. 2001. Summarization as feature selection               31 - 55.
    for text categorization. In Proc. of Conference on         ChengXiang Zhai. Statistical language models for
    Information and Knowledge Management: 365 -                    information retrieval. Morgan & Claypool
    370.                                                           Publishers, 2008.
Julian Kupiec, Jan Pedersen and Francine Chen. 1999.           Justin Jian Zhang, Ho Yin Chan and Pascale Fung.
    A trainable document summarizer. In Proc. of                 2007. Improving Lecture Speech Summarization
    Annual International ACM SIGIR Conference on                 Using Rhetorical Information. In Proc. of Workshop
    Research and Development in Information                      of Automatic Speech Recognition Understanding:
    Retrieval: 68 - 73.                                          195 - 200.

                                                          87

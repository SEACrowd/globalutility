                          Hierarchical Search for Word Alignment

                                      Jason Riesa and Daniel Marcu                                                                 Visualization generated by riesa: Feb 12, 2010 20:06:24
                                       Information Sciences Institute                                                                                                         683.g (a1)
                                       Viterbi School of Engineering                                                                                                   683.union.a (a2)
                                      University of Southern California                                                                                                        683.e (e)
                                                                                                                                                                               683.f (f)
                                        {riesa, marcu}@isi.edu
                                                               Sentence 1
                      Abstract




                                                                      s
                                                               te viou




                                                               to ited




                                                               an sile
                                                               mi get
                                                               ha ts




                                                               bo er
                                                               pr e


                                                                 ve

                                                               li n




                                                               . y
                                                                 e
                                                                 v
                                                                 e
                                                                 s

                                                                 e
                                                                 m

                                                                 e
                                                                 r
                                                                 s
                                                                 d
                                                                 e
                                                                 h
                                                                 d
                                                               th
                                                               fi




                                                               be


                                                               th
                                                               ta


                                                               on
                                                               ot
    We present a simple yet powerful hier-
                                                                                                                  ! !&'(! )
                                                                                                               "#$%
    archical search algorithm for automatic
                                                                                                               "* +,-*!&.(
                                                                                                               /0213 4(
    word alignment. Our algorithm induces

                                                                                                                5!67! * ,8.(
    a forest of alignments from which we
    can efficiently extract a ranked k-best list.
    We score a given alignment within the                                                                      9:;
                                                                                                               <)+,=.(
    forest with a flexible, linear discrimina-
                                                                                                               >?@   1 A8BC(
                                                                                                                          !
    tive model incorporating hundreds of fea-
    tures, and trained on a relatively small                                                                   DEFG* )
    amount of annotated data. We report re-                                                                    #G(1
    sults on Arabic-English word alignment                                                                     ?H()
                                                                                                              *
    and translation tasks. Our model out-
    performs a GIZA++ Model-4 baseline by
    6.3 points in F-measure, yielding a 1.1                    Figure 1: Model-4 alignment vs. a gold stan-
    BLEU score increase over a state-of-the-art                dard. Circles represent links in a human-annotated
    syntax-based machine translation system.                   alignment, and black boxes represent links in the
                                                               Model-4 alignment. Bold gray boxes show links
1   Introduction                                               gained after fully connecting the alignment.

Automatic word alignment is generally accepted
as a first step in training any statistical machine
                                                               has motivated much recent work in discriminative
translation system. It is a vital prerequisite for
                                                               modeling for word alignment (Moore, 2005; Itty-
generating translation tables, phrase tables, or syn-
                                                               cheriah and Roukos, 2005; Liu et al., 2005; Taskar
tactic transformation rules. Generative alignment
                                                               et al., 2005; Blunsom and Cohn, 2006; Lacoste-
models like IBM Model-4 (Brown et al., 1993)
                                                               Julien et al., 2006; Moore et al., 2006).
have been in wide use for over 15 years, and while
not perfect (see Figure 1), they are completely un-               We present in this paper a discriminative align-
supervised, requiring no annotated training data to            ment model trained on relatively little data, with
learn alignments that have powered many current                a simple, yet powerful hierarchical search proce-
state-of-the-art translation system.                           dure. We borrow ideas from both k-best pars-
   Today, there exist human-annotated alignments               ing (Klein and Manning, 2001; Huang and Chi-
and an abundance of other information for many                 ang, 2005; Huang, 2008) and forest-based, and
language pairs potentially useful for inducing ac-             hierarchical phrase-based translation (Huang and
curate alignments. How can we take advantage                   Chiang, 2007; Chiang, 2007), and apply them to
of all of this data at our fingertips? Using fea-              word alignment.
ture functions that encode extra information is one               Using a foreign string and an English parse
good way. Unfortunately, as Moore (2005) points                tree as input, we formulate a bottom-up search
out, it is usually difficult to extend a given genera-         on the parse tree, with the structure of the tree
tive model with feature functions without chang-               as a backbone for building a hypergraph of pos-
ing the entire generative story. This difficulty               sible alignments. Our algorithm yields a forest of


                                                         157                                                                   1
        Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 157–166,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


                                                  d
                          an



                                   e

                                              ea
                                  e
                      e




                                th
                               at
                   th
                          m




                                             br
                                                   ‫ﺍﻛﻞ‬

                                                   ‫ﺍﻟﺮﺟﻞ‬

                                                   ‫ﺍﳋﺒﺰ‬


                                                                                         S



                                                                                                  VP
                        an
                        e




                                                                        NP
                      th
                      m




                                                                                                        NP
                                    ‫ﺍﻛﻞ‬

                                    ‫ﺍﻟﺮﺍﺟﻞ‬

                                    ‫ﺍﳋﺒﺰ‬

                                                           the               man         ate      the        bread




                                                                                                                          d
                                                                                                                     ea
                                                                                                                     br
                                e




                                                         e
                               th




                                                      th




                                                                                                                              ‫ﺍﻛﻞ‬
                                      ‫ﺍﻛﻞ‬                        ‫ﺍﻛﻞ‬
                                                                                                                              ‫ﺍﻟﺮﺟﻞ‬
                                      ‫ﺍﻟﺮﺟﻞ‬                      ‫ﺍﻟﺮﺟﻞ‬
                                                                                                                              ‫ﺍﳋﺒﺰ‬
                                      ‫ﺍﳋﺒﺰ‬                       ‫ﺍﳋﺒﺰ‬




Figure 2: Example of approximate search through a hypergraph with beam size = 5. Each black square
implies a partial alignment. Each partial alignment at each node is ranked according to its model score.
In this figure, we see that the partial alignment implied by the 1-best hypothesis at the leftmost NP
node is constructed by composing the best hypothesis at the terminal node labeled “the” and the 2nd-
best hypothesis at the terminal node labeled “man”. (We ignore terminal nodes in this toy example.)
Hypotheses at the root node imply full alignment structures.


word alignments, from which we can efficiently                                           2     Word Alignment as a Hypergraph
extract the k-best. We handle an arbitrary number
of features, compute them efficiently, and score                                         Algorithm input The input to our alignment al-
alignments using a linear model. We train the                                            gorithm is a sentence-pair (en1 , f1m ) and a parse tree
parameters of the model using averaged percep-                                           over one of the input sentences. In this work,
tron (Collins, 2002) modified for structured out-                                        we parse our English data, and for each sentence
puts, but can easily fit into a max-margin or related                                    E = en1 , let T be its syntactic parse. To gener-
framework. Finally, we use relatively little train-                                      ate parse trees, we use the Berkeley parser (Petrov
ing data to achieve accurate word alignments. Our                                        et al., 2006), and use Collins head rules (Collins,
model can generate arbitrary alignments and learn                                        2003) to head-out binarize each tree.
from arbitrary gold alignments.                                                          Overview We present a brief overview here and
                                                                                         delve deeper in Section 2.1. Word alignments are
                                                                                         built bottom-up on the parse tree. Each node v in
                                                                                         the tree holds partial alignments sorted by score.


                                                                                   158


                            u1212 uu13
                uu11u1111 uu12      u1313                            u1212 uu13
                                                         uu11u1111 uu12      u1313                uu11u1111 uu12
                                                                                                              u1212 uu13
                                                                                                                      u1313
         uu21
           u2121 2.2
                  2.2    4.1 5.5
                        4.1   5.5
                               5.5
                   2.2 4.1                         u2121 2.2
                                                 uu21     2.2
                                                           2.2 4.1
                                                                4.1   5.5
                                                                       5.5
                                                                 4.1 5.5                   uu21
                                                                                             u2121 2.2
                                                                                                    2.2
                                                                                                     2.2 4.1
                                                                                                          4.1
                                                                                                           4.1 5.5
                                                                                                                5.5
                                                                                                                 5.5
         uu22
           u2222 2.4
                  2.4    3.5 7.2
                        3.5   7.2
                               7.2
                   2.4 3.5                         u2222 2.4
                                                 uu22     2.4
                                                           2.4 3.5
                                                                3.5   7.2
                                                                       7.2
                                                                 3.5 7.2                   uu22
                                                                                             u2222 2.4
                                                                                                    2.4
                                                                                                     2.4 3.5
                                                                                                          3.5
                                                                                                           3.5 7.2
                                                                                                                7.2
                                                                                                                 7.2
         uu23
           u2323 3.2
                  3.2    4.5 11.4
                        4.5   11.4
                               11.4
                   3.2 4.5                         u2323 3.2
                                                 uu23     3.2
                                                           3.2 4.5
                                                                4.5   11.4
                                                                       11.4
                                                                 4.5 11.4                  uu23
                                                                                             u2323 3.2
                                                                                                    3.2
                                                                                                     3.2 4.5
                                                                                                          4.5
                                                                                                           4.5 11.4
                                                                                                                11.4
                                                                                                                 11.4

         (a) Score the left corner align-       (b) Expand the frontier of align-        (c) Expand the frontier further.
         ment first. Assume it is the 1-        ments. We are now looking for            After this step we have our top
         best. Numbers in the rest of the       the 2nd best.                            k alignments.
         boxes are hidden at this point.

Figure 3: Cube pruning with alignment hypotheses to select the top-k alignments at node v with children
hu1 , u2 i. In this example, k = 3. Each box represents the combination of two partial alignments to create
a larger one. The score in each box is the sum of the scores of the child alignments plus a combination
cost.


Each partial alignment comprises the columns of                         (1) that using the structure of 1-best English syn-
the alignment matrix for the e-words spanned by                         tactic parse trees is a reasonable way to frame and
v, and each is scored by a linear combination of                        drive our search, and (2) that F-measure approxi-
feature functions. See Figure 2 for a small exam-                       mately decomposes over hyperedges.
ple.                                                                       We perform an oracle experiment to validate
   Initial partial alignments are enumerated and                        these assumptions. We find the oracle for a given
scored at preterminal nodes, each spanning a sin-                       (T ,e, f ) triple by proceeding through our search al-
gle column of the word alignment matrix. To                             gorithm, forcing ourselves to always select correct
speed up search, we can prune at each node, keep-                       links with respect to the gold alignment when pos-
ing a beam of size k. In the diagram depicted in                        sible, breaking ties arbitrarily. The the F1 score of
Figure 2, the beam is size k = 5.                                       our oracle alignment is 98.8%, given this “perfect”
   From here, we traverse the tree nodes bottom-                        model.
up, combining partial alignments from child nodes
until we have constructed a single full alignment at                    2.1   Hierarchical search
the root node of the tree. If we are interested in the                  Initial alignments We can construct a word
k-best, we continue to populate the root node until                     alignment hierarchically, bottom-up, by making
we have k alignments.1                                                  use of the structure inherent in syntactic parse
   We use one set of feature functions for preter-                      trees. We can think of building a word alignment
minal nodes, and another set for nonterminal                            as filling in an M ×N matrix (Figure 1), and we be-
nodes. This is analogous to local and nonlo-                            gin by visiting each preterminal node in the tree.
cal feature functions for parse-reranking used by                       Each of these nodes spans a single e word. (Line
Huang (2008). Using nonlocal features at a non-                         2 in Algorithm 1).
terminal node emits a combination cost for com-                            From here we can assign links from each e word
posing a set of child partial alignments.                               to zero or more f words (Lines 6–14). At this
   Because combination costs come into play, we                         level of the tree the span size is 1, and the par-
use cube pruning (Chiang, 2007) to approxi-                             tial alignment we have made spans a single col-
mate the k-best combinations at some nonterminal                        umn of the matrix. We can make many such partial
node v. Inference is exact when only local features                     alignments depending on the links selected. Lines
are used.                                                               5 through 9 of Algorithm 1 enumerate either the
Assumptions There are certain assumptions re-                           null alignment, single-link alignments, or two-link
lated to our search algorithm that we must make:                        alignments. Each partial alignment is scored and
                                                                        stored in a sorted heap (Lines 9 and 13).
    1
      We use approximate dynamic programming to store                      In practice enumerating all two-link alignments
alignments, keeping only scored lists of pointers to initial
single-column spans. Each item in the list is a derivation that         can be prohibitive for long sentence pairs; we set
implies a partial alignment.                                            a practical limit and score only pairwise combina-


                                                                  159


                                                                Sentence 1
                                                                                      TOP1
                                                                                       S2
  Algorithm 1: Hypergraph Alignment
                                                                                                               S-BAR1
    Input:
                                                                                      VP1
      Source sentence en1
                                                                                            VP-C1
      Target sentence f1m
                                                                                                    VP-C1
      Parse tree T over en1
                                                                                                              PP1
      Set of feature functions h
                                                                                                                       NP-C1
      Weight vector w
                                                                    NP-C1                                    NP-C-BAR1
      Beam size k
                                                                    NPB2                                    NP1                NP1
    Output:
                                                                     NPB-BAR2                               NPB2               NPB2
      A k-best list of alignments over en1 and f1m
                                                                           NPB-BAR2                         NPB-BAR2           NPB-BAR2
  1 function A(e , f , T )
                       n m
                       1 1                                      DT CD JJ NNS VBP VBN VBN IN DT NN NN CC CD JJ NN                           .
  2   for v ∈ T in bottom-up order do
  3      αv ← ∅
  4      if -PN(v) then




                                                                                   s
                                                                            te viou




                                                                            to ited




                                                                            an sile
                                                                            mi get
  5         i ← index-of(v)




                                                                            ha ts




                                                                            bo er
                                                                            pr e


                                                                              ve

                                                                            li n




                                                                            . y
                                                                              e
                                                                              v
                                                                              e
                                                                              s

                                                                              e
                                                                              m

                                                                              e
                                                                              r
                                                                              s
                                                                              d
                                                                              e
                                                                              h
                                                                              d
            for j = 0 to m do




                                                                            th
                                                                            fi




                                                                            be


                                                                            th
                                                                            ta


                                                                            on
                                                                            ot
                                                                                                                              ! !&'(! )
  6
                                                                                                                           "#$%
               links ← (i, j)
                                                                                                                           "* +,-*!&.(
  7
  8            score ← w · h(links, v, en1 , f1m )                                                                         /0213 4(
  9            P(αv , hscore, linksi, k )                                                                                5!67! * ,8.(
 10            for k = j + 1 to m do                                                                                       9:;
 11               links ← (i, j), (i, k)                                                                                   <)+,=.(
                                                                                                                           >?@   1 A8BC(
                                                                                                                                      !
 12               score ← w · h(links, v, en1 , f1m )
                                                                                                                           DEFG* )
                  P(αv , hscore, linksi, k )
                                                                                                                           #G(1
 13

 14            end                                                                                                         ?H()
 15         end                                                                                                           *
 16      else
 17         αv ← GS(children(v), k)                       Figure 4: Correct version of Figure 1 after hyper-
 18      end                                                    graph alignment. Subscripts on the nonterminal
 19   end                                                       labels denote the branch containing the head word
 20 end                                                         for that span.
 21 function GS(hu1 , u2 i, k)
 22   return CP(hαu1 , αu2 i, k,w,h)
 23 end                                                         that Algorithm 1 assumes a binary tree2 , but is not
                                                                necessary. In the general case, cube pruning will
                                                                operate on a d-dimensional hypercube, where d is
tions of the top n = max |2f | , 10 scoring single-
                              n      o                          the branching factor of node v.
link alignments.                                                   We cannot enumerate and score every possibil-
                                                                ity; without the cube pruning approximation, we
    We limit the number of total partial alignments
                                                                will have kc possible combinations at each node,
αv kept at each node to k. If at any time we wish to
                                                                exploding the search space exponentially. Figure 3
push onto the heap a new partial alignment when
                                                                depicts how we select the top-k alignments at a
the heap is full, we pop the current worst off the
                                                                node v from its children h u1 , u2 i.
heap and replace it with our new partial alignment
if its score is better than the current worst.                  3     Discriminative training
Building the hypergraph We now visit internal                   We incorporate all our new features into a linear
nodes (Line 16) in the tree in bottom-up order. At              model and learn weights for each using the on-
each nonterminal node v we wish to combine the                  line averaged perceptron algorithm (Collins, 2002)
partial alignments of its children u1 , . . . , uc . We         with a few modifications for structured outputs in-
use cube pruning (Chiang, 2007; Huang and Chi-                  spired by Chiang et al. (2008). We define:
ang, 2007) to select the k-best combinations of the                2
                                                                     We find empirically that using binarized trees reduces
partial alignments of u1 , . . . , uc (Line 19). Note           search errors in cube pruning.


                                                          160


                                 ...
                                                                   alignment structure into a single high-dimensional




                   in




                                            in

                                                 ...
                                                                   feature vector. Our hierarchical search framework
                                                 !"
                                                                   allows us to compute these features when needed,
                                                                   and affords us extra useful syntactic information.




                                                 ...
                                                                      We use two classes of features: local and non-
                                                                   local. Huang (2008) defines a feature h to be lo-
                                                 !"
                                                                   cal if and only if it can be factored among the lo-
                                                                   cal productions in a tree, and non-local otherwise.
Figure 5: A common problem with GIZA++
                                                                   Analogously for alignments, our class of local fea-
Model 4 alignments is a weak distortion model.
                                                                   tures are those that can be factored among the local
The second English “in” is aligned to the wrong
                                                                   partial alignments competing to comprise a larger
Arabic token. Circles show the gold alignment.
                                                                   span of the matrix, and non-local otherwise. These
                                                                   features score a set of links and the words con-
                                                                   nected by them.
             γ(y) = `(yi , y) + w · (h(yi ) − h(y))    (1)         Feature development Our features are inspired
                                                                   by analysis of patterns contained among our gold
where `(yi ,y) is a loss function describing how bad
                                                                   alignment data and automatically generated parse
it is to guess y when the correct answer is yi . In our
                                                                   trees. We use both local lexical and nonlocal struc-
case, we define `(yi ,y) as 1−F1 (yi ,y). We select the
                                                                   tural features as described below.
oracle alignment according to:
                                                                   4.1   Local features
                        y+ = arg min γ(y)              (2)
                                y∈(x)                          These features fire on single-column spans.

where (x) is a set of hypothesis alignments                      • From the output of GIZA++ Model 4, we
generated from input x. Instead of the traditional                     compute lexical probabilities p(e | f ) and
oracle, which is calculated solely with respect to                     p( f | e), as well as a fertility table φ(e).
the loss `(yi ,y), we choose the oracle that jointly                   From the fertility table, we fire features φ0 (e),
minimizes the loss and the difference in model                         φ1 (e), and φ2+ (e) when a word e is aligned
score to the true alignment. Note that Equation 2                      to zero, one, or two or more words, respec-
is equivalent to maximizing the sum of the F-                          tively. Lexical probability features p(e | f )
measure and model score of y:                                          and p( f | e) fire when a word e is aligned to
                                                                       a word f .
             y+ = arg max (F1 (yi , y) + w · h(y))     (3)
                    y∈(x)                                        • Based on these features, we include a binary
                                                                       lexical-zero feature that fires if both p(e | f )
 Let ŷ be the 1-best alignment according to our                       and p( f | e) are equal to zero for a given word
model:                                                                 pair (e, f ). Negative weights essentially pe-
              ŷ = arg max w · h(y)          (4)                       nalize alignments with links never seen be-
                          y∈(x)
                                                                       fore in the Model 4 alignment, and positive
Then, at each iteration our weight update is:                          weights encourage such links. We employ a
                                                                       separate instance of this feature for each En-
                  w ← w + η(h(y+ ) − h(ŷ))            (5)             glish part-of-speech tag: p( f | e, t).
   where η is a learning rate parameter.3 We find                        We learn a different feature weight for each.
that this more conservative update gives rise to a                       Critically, this feature tells us how much to
much more stable search. After each iteration, we                        trust alignments involving nouns, verbs, ad-
expect y+ to get closer and closer to the true yi .                      jectives, function words, punctuation, etc.
                                                                         from the Model 4 alignments from which our
4       Features                                                         p(e | f ) and p( f | e) tables are built. Ta-
                                                                         ble 1 shows a sample of learned weights. In-
Our simple, flexible linear model makes it easy to
                                                                         tuitively, alignments involving English parts-
throw in many features, mapping a given complex
                                                                         of-speech more likely to be content words
    3
        We set η to 0.05 in our experiments.                             (e.g. NNPS, NNS, NN) are more trustworthy


                                                             161


                PP                                    NP                                      VP




         IN                NP                 DT                  NP                  VBD             VP



        eprep        ...    ehead             edet         ...      ehead             everb     ...    ehead

                                     f                                      f                                  f

Figure 6: Features PP-NP-head, NP-DT-head, and VP-VP-head fire on these tree-alignment patterns. For
example, PP-NP-head fires exactly when the head of the PP is aligned to exactly the same f words as the
head of it’s sister NP.


                                Penalty                                link (e, f ) if the part-of-speech tag of e is t.
                  NNPS           −1.11                                 The conditional probabilities in this table are
                  NNS            −1.03                                 computed from our parse trees and the base-
                  NN             −0.80                                 line Model 4 alignments.
                  NNP            −0.62
                  VB             −0.54                             • In cases where the lexical probabilities are
                  VBG            −0.52                               too strong for the distortion feature to
                  JJ             −0.50                               overcome (see Figure 5), we develop the
                  JJS            −0.46                               multiple-distortion feature. Although local
                  VBN            −0.45                               features do not know the partial alignments at
                                                                     other spans, they do have access to the entire
                     ...



                                    ...




                  POS           −0.0093                              English sentence at every step because our in-
                  EX            −0.0056                              put is constant. If some e exists more than
                  RP            −0.0037                              once in en1 we fire this feature on all links con-
                  WP$           −0.0011                              taining word e, returning again the distance to
                  TO              0.037                              the diagonal for that link. We learn a strong
                                Reward                               negative weight for this feature.
                                                                   • We find that binary identity and
Table 1: A sampling of learned weights for the lex-                  punctuation-mismatch features are im-
ical zero feature. Negative weights penalize links                   portant. The binary identity feature fires if
never seen before in a baseline alignment used to                    e = f , and proves useful for untranslated
initialize lexical p(e | f ) and p( f | e) tables. Posi-             numbers, symbols, names, and punctuation
tive weights outright reward such links.                             in the data. Punctuation-mismatch fires on
                                                                     any link that causes nonpunctuation to be
                                                                     aligned to punctuation.
     than those likely to be function words (e.g.
     TO, RP, EX), where the use of such words is                 Additionally, we include fine-grained versions of
     often radically different across languages.                 the lexical probability, fertility, and distortion fea-
                                                                 tures. These fire for for each link (e, f ) and part-
   • We also include a measure of distortion.                    of-speech tag. That is, we learn a separate weight
     This feature returns the distance to the diag-              for each feature for each part-of-speech tag in our
     onal of the matrix for any link in a partial                data. Given the tag of e, this affords the model the
     alignment. If there is more than one link, we               ability to pay more or less attention to the features
     return the distance of the link farthest from               described above depending on the tag given to e.
     the diagonal.
                                                                 Arabic-English specific features We describe
   • As a lexical backoff, we include a tag prob-                here language specific features we implement to
     ability feature, p(t | f ) that fires for some              exploit shallow Arabic morphology.


                                                           162


                            PP                                                 In Figure 4, when the search arrives at the
                                                                               left-most NPB node, the NP-DT-head fea-
                                                                               ture will fire given this structure and links
                    IN                NP                                       over the span [the ... tests]. When
                                                                               search arrives at the second NPB node, it
                                                                               will fire given the structure and links over the
                  from                ...                                      span [the ... missle], but will not fire at
                                                                               the right-most NPB node.
                                                  !"



                                                ...
                                                                             • Local lexical preference features compete
                                                                               with the headword features described above.
                                                                               However, we also introduce nonlocal lexical-
Figure 7: This figure depicts the tree/alignment
                                                                               ized features for the most common types of
structure for which the feature PP-from-prep
                                                                               English and foreign prepositions to also com-
fires. The English preposition “from” is aligned
to Arabic word áÓ. Any aligned words in the span
                                                                               pete with these general headword features.

of the sister NP are aligned to words following áÓ.                            PP features PP-of-prep, PP-from-prep, PP-
English preposition structure commonly matches                                 to-prep, PP-on-prep, and PP-in-prep fire at
that of Arabic in our gold data. This family of fea-                           any PP whose left child is a preposition and
tures captures these observations.                                             right child is an NP. The head of the PP is one
                                                                               of the enumerated English prepositions and is
                                                                               aligned to any of the three most common for-
   • We observe the Arabic prefix ð, transliterated                            eign words to which it has also been observed
     w- and generally meaning and, to prepend to                               aligned in the gold alignments. The last con-
     most any word in the lexicon, so we define                                straint on this pattern is that all words un-
     features p¬w (e | f ) and p¬w ( f | e). If f be-                          der the span of the sister NP, if aligned, must
     gins with w-, we strip off the prefix and return                          align to words following the foreign preposi-
     the values of p(e | f ) and p( f | e). Otherwise,                         tion. Figure 7 illustrates this pattern.
     these features return 0.
                                                                             • Finally, we have a tree-distance feature to
   • We also include analogous feature functions                               avoid making too many many-to-one (from
     for several functional and pronominal pre-                                many English words to a single foreign word)
     fixes and suffixes.4                                                      links. This is a simplified version of and sim-
4.2      Nonlocal features                                                     ilar in spirit to the tree distance metric used
                                                                               in (DeNero and Klein, 2007). For any pair of
These features comprise the combination cost
                                                                               links (ei , f ) and (e j , f ) in which the e words
component of a partial alignment score and may
                                                                               differ but the f word is the same token in
fire when concatenating two partial alignments
                                                                               each, return the tree height of first common
to create a larger span. Because these features
                                                                               ancestor of ei and e j .
can look into any two arbitrary subtrees, they
are considered nonlocal features as defined by                                 This feature captures the intuition that it is
Huang (2008).                                                                  much worse to align two English words at
                                                                               different ends of the tree to the same foreign
   • Features PP-NP-head, NP-DT-head, and
                                                                               word, than it is to align two English words
     VP-VP-head (Figure 6) all exploit head-
                                                                               under the same NP to the same foreign word.
     words on the parse tree. We observe English
     prepositions and determiners to often align to                            To see why a string distance feature that
     the headword of their sister. Likewise, we ob-                            counts only the flat horizontal distance from
     serve the head of a VP to align to the head of                            ei to e j is not the best strategy, consider the
     an immediate sister VP.                                                   following. We wish to align a determiner
   4
       Affixes used by our model are currently: K., Ë, Ë@, ËAK.,           to the same f word as its sister head noun
ù, Õº, AÒº, Ñê, AÒê.Others either we did not experiment                   under the same NP. Now suppose there are
with, or seemed to provide no significant benefit, and are not                 several intermediate adjectives separating the
included.                                                                      determiner and noun. A string distance met-


                                                                       163


                                                                                             0.775
        ric, with no knowledge of the relationship be-
        tween determiner and noun will levy a much                                              0.77

        heavier penalty than its tree distance analog.                                       0.765


5       Related Work                                                                            0.76




                                                                     Training F−measure
                                                                                             0.755
Recent work has shown the potential for syntac-
tic information encoded in various ways to sup-                                                 0.75

port inference of superior word alignments. Very                                             0.745

recent work in word alignment has also started to                                               0.74
report downstream effects on BLEU score.
                                                                                             0.735
   Cherry and Lin (2006) introduce soft syntac-
tic ITG (Wu, 1997) constraints into a discrimi-                                                 0.73
                                                                                                       0      5     10      15          20      25    30   35   40
                                                                                                                                 Training epoch
native model, and use an ITG parser to constrain
the search for a Viterbi alignment. Haghighi et
al. (2009) confirm and extend these results, show-                   Figure 8: Learning curves for 10 random restarts
ing BLEU improvement for a hierarchical phrase-                      over time for parallel averaged perceptron train-
based MT system on a small Chinese corpus.                           ing. These plots show the current F-measure on
As opposed to ITG, we use a linguistically mo-                       the training set as time passes. Perceptron training
tivated phrase-structure tree to drive our search                    here is quite stable, converging to the same general
and inform our model. And, unlike ITG-style ap-                      neighborhood each time.
proaches, our model can generate arbitrary align-
ments and learn from arbitrary gold alignments.                                                        0.76
                                                                                                       0.75
   DeNero and Klein (2007) refine the distor-                                                          0.74
tion model of an HMM aligner to reflect tree                                                           0.73
                                                                                          F-measure




                                                                                                       0.72
distance instead of string distance. Fossum et                                                         0.71
al. (2008) start with the output from GIZA++                                                           0.70
Model-4 union, and focus on increasing precision                                                       0.69
                                                                                                       0.68
by deleting links based on a linear discriminative                                                     0.67
model exposed to syntactic and lexical informa-                                                                   Model 1              HMM            Model 4
tion.                                                                                                                            Initial alignments
   Fraser and Marcu (2007) take a semi-supervised
approach to word alignment, using a small amount                     Figure 9: Model robustness to the initial align-
of gold data to further tune parameters of a                         ments from which the p(e | f ) and p( f | e) features
headword-aware generative model. They show                           are derived. The dotted line indicates the baseline
a significant improvement over a Model-4 union                       accuracy of GIZA++ Model 4 alone.
baseline on a very large corpus.

6       Experiments
                                                                     6.1                               Alignment Quality
We evaluate our model and and resulting align-
ments on Arabic-English data against those in-                       We empirically choose our beam size k from the
duced by IBM Model-4 using GIZA++ (Och and                           results of a series of experiments, setting k=1, 2,
Ney, 2003) with both the union and grow-diag-                        4, 8, 16, 32, and 64. We find setting k = 16 to yield
final heuristics. We use 1,000 sentence pairs and                    the highest accuracy on our held-out test data. Us-
gold alignments from LDC2006E86 to train model                       ing wider beams results in higher F-measure on
parameters: 800 sentences for training, 100 for                      training data, but those gains do not translate into
testing, and 100 as a second held-out development                    higher accuracy on held-out data.
set to decide when to stop perceptron training. We                      The first three columns of Table 2 show the
also align the test data using GIZA++5 along with                    balanced F-measure, Precision, and Recall of our
50 million words of English.                                         alignments versus the two GIZA++ Model-4 base-
    5
                                                                     lines. We report an F-measure 8.6 points over
     We use a standard training procedure: 5 iterations of
Model-1, 5 iterations of HMM, 3 iterations of Model-3, and 3         Model-4 union, and 6.3 points over Model-4 grow-
iterations of Model-4.                                               diag-final.


                                                               164


                                           F       P             R    Arabic/English     # Unknown
                                                                              BLEU           Words
              M4 (union)                .665    .636     .696                     45.1       2,538
              M4 (grow-diag-final)      .688    .702     .674                     46.4       2,262
              Hypergraph alignment      .751    .780     .724                     47.5       1,610

Table 2: F-measure, Precision, Recall, the resulting BLEU score, and number of unknown words on a
held-out test corpus for three types of alignments. BLEU scores are case-insensitive IBM BLEU. We
show a 1.1 BLEU increase over the strongest baseline, Model-4 grow-diag-final. This is statistically
significant at the p < 0.01 level.


   Figure 8 shows the stability of the search proce-            Columns 4 and 5 in Table 2 show the results
dure over ten random restarts of parallel averaged           of our MT experiments. Our hypergraph align-
perceptron training with 40 CPUs. Training ex-               ment algorithm allows us a 1.1 BLEU increase over
amples are randomized at each epoch, leading to              the best baseline system, Model-4 grow-diag-final.
slight variations in learning curves over time but           This is statistically significant at the p < 0.01
all converge into the same general neighborhood.             level. We also report a 2.4 BLEU increase over
   Figure 9 shows the robustness of the model to             a system trained with alignments from Model-4
initial alignments used to derive lexical features           union.
p(e | f ) and p( f | e). In addition to IBM Model 4,
we experiment with alignments from Model 1 and               7       Conclusion
the HMM model. In each case, we significantly                We have opened up the word alignment task to
outperform the baseline GIZA++ Model 4 align-                advances in hypergraph algorithms currently used
ments on a heldout test set.                                 in parsing and machine translation decoding. We
                                                             treat word alignment as a parsing problem, and
6.2   MT Experiments                                         by taking advantage of English syntax and the hy-
We align a corpus of 50 million words with                   pergraph structure of our search algorithm, we re-
GIZA++ Model-4, and extract translation rules                port significant increases in both F-measure and
from a 5.4 million word core subset. We align                BLEU score over standard baselines in use by most
the same core subset with our trained hypergraph             state-of-the-art MT systems today.
alignment model, and extract a second set of trans-
                                                             Acknowledgements
lation rules. For each set of translation rules, we
train a machine translation system and decode a              We would like to thank our colleagues in the Nat-
held-out test corpus for which we report results be-         ural Language Group at ISI for many meaningful
low.                                                         discussions and the anonymous reviewers for their
   We use a syntax-based translation system for              thoughtful suggestions. This research was sup-
these experiments. This system transforms Arabic             ported by DARPA contract HR0011-06-C-0022
strings into target English syntax trees Translation         under subcontract to BBN Technologies, and a
rules are extracted from (e-tree, f -string, align-          USC CREATE Fellowship to the first author.
ment) triples as in (Galley et al., 2004; Galley et
al., 2006).
   We use a randomized language model (similar
                                                             References
to that of Talbot and Brants (2008)) of 472 mil-             Phil Blunsom and Trevor Cohn. 2006. Discriminative
lion English words. We tune the the parameters                 Word Alignment with Conditional Random Fields.
                                                               In Proceedings of the 44th Annual Meeting of the
of the MT system on a held-out development cor-                ACL. Sydney, Australia.
pus of 1,172 parallel sentences, and test on a held-
out parallel corpus of 746 parallel sentences. Both          Peter F. Brown, Stephen A. Della Pietra, Vincent Della
                                                               J. Pietra, and Robert L. Mercer. 1993. The mathe-
corpora are drawn from the NIST 2004 and 2006                  matics of statistical machine translation: Parameter
evaluation data, with no overlap at the document               estimation. Computational Linguistics, 19(2):263–
or segment level with our training data.                       312. MIT Press. Camrbidge, MA. USA.


                                                       165


Colin Cherry and Dekang Lin. 2006. Soft Syntactic             Michel Galley, Mark Hopkins, Kevin Knight, and
  Constraints for Word Alignment through Discrimi-              Daniel Marcu. 2004. What’s in a Translation Rule?
  native Training. In Proceedings of the 44th Annual            In Proceedings of NAACL.
  Meeting of the ACL. Sydney, Australia.
                                                              Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
David Chiang. 2007. Hierarchical phrase-based trans-            Marcu, Steve DeNeefe, Wei Wang, and Ignacio
  lation. Computational Linguistics. 33(2):201–228.             Thayer. 2006. Scalable Inference and Training of
  MIT Press. Cambridge, MA. USA.                                Context-Rich Syntactic Models In Proceedings of
                                                                the 44th Annual Meeting of the ACL. Sydney, Aus-
David Chiang, Yuval Marton, and Philip Resnik. 2008.            tralia.
  Online Large-Margin Training of Syntactic and
  Structural Translation Features. In Proceedings of          Abraham Ittycheriah and Salim Roukos. 2005. A max-
  EMNLP. Honolulu, HI. USA.                                     imum entropy word aligner for Arabic-English ma-
                                                                chine translation. In Proceedings of HLT-EMNLP.
Michael Collins. 2003. Head-Driven Statistical Mod-             Vancouver, BC. Canada.
  els for Natural Language Parsing. Computational             Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
  Linguistics. 29(4):589–637. MIT Press. Cam-                   Michael I. Jordan. 2006. Word alignment via
  bridge, MA. USA.                                              Quadratic Assignment. In Proceedings of HLT-
                                                                EMNLP. New York, NY. USA.
Michael Collins 2002. Discriminative training meth-
  ods for hidden markov models: Theory and exper-             Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-
  iments with perceptron algorithms. In Proceedings             linear Models for Word Alignment In Proceedings
  of the Conference on Empirical Methods in Natural             of the 43rd Annual Meeting of the ACL. Ann Arbor,
  Language Processing.                                          Michigan. USA.
John DeNero and Dan Klein. 2007. Tailoring Word               Robert C. Moore. 2005. A Discriminative Framework
  Alignments to Syntactic Machine Translation. In               for Word Alignment. In Proceedings of EMNLP.
  Proceedings of the 45th Annual Meeting of the ACL.            Vancouver, BC. Canada.
  Prague, Czech Republic.
                                                              Robert C. Moore, Wen-tau Yih, and Andreas Bode.
Alexander Fraser and Daniel Marcu. 2007. Getting                2006. Improved Discriminative Bilingual Word
  the Structure Right for Word Alignment: LEAF. In              Alignment In Proceedings of the 44th Annual Meet-
  Proceedings of EMNLP-CoNLL. Prague, Czech Re-                 ing of the ACL. Sydney, Australia.
  public.
                                                              Franz Josef Och and Hermann Ney. 2003. A System-
                                                                 atic Comparison of Various Statistical Alignment
Victoria Fossum, Kevin Knight, and Steven Abney.
                                                                 Models. Computational Linguistics. 29(1):19–52.
  2008. Using Syntax to Improve Word Alignment
                                                                 MIT Press. Cambridge, MA. USA.
  Precision for Syntax-Based Machine Translation. In
  Proceedings of the Third Workshop on Statistical            Slav Petrov, Leon Barrett, Romain Thibaux and Dan
  Machine Translation. Columbus, Ohio.                           Klein 2006. Learning Accurate, Compact, and In-
                                                                 terpretable Tree Annotation In Proceedings of the
Dan Klein and Christopher D. Manning. 2001. Parsing              44th Annual Meeting of the ACL. Sydney, Australia.
  and Hypergraphs. In Proceedings of the 7th Interna-
  tional Workshop on Parsing Technologies. Beijing,           Kishore Papineni, Salim Roukos, T. Ward, and W-J.
  China.                                                        Zhu. 2002. BLEU: A Method for Automatic Evalu-
                                                                ation of Machine Translation In Proceedings of the
Aria Haghighi, John Blitzer, and Dan Klein. 2009.               40th Annual Meeting of the ACL. Philadelphia, PA.
  Better Word Alignments with Supervised ITG Mod-               USA.
  els. In Proceedings of ACL-IJCNLP 2009. Singa-
  pore.                                                       Ben Taskar, Simon Lacoste-Julien, and Dan Klein.
                                                                2005. A Discriminative Matching Approach to
Liang Huang and David Chiang. 2005. Better k-best               Word Alignment. In Proceedings of HLT-EMNLP.
   Parsing. In Proceedings of the 9th International             Vancouver, BC. Canada.
   Workshop on Parsing Technologies. Vancouver, BC.
   Canada.                                                    David Talbot and Thorsten Brants. 2008. Random-
Liang Huang and David Chiang. 2007. Forest Rescor-              ized Language Models via Perfect Hash Functions.
   ing: Faster Decoding with Integrated Language                In Proceedings of ACL-08: HLT. Columbus, OH.
   Models. In Proceedings of the 45th Annual Meet-              USA.
   ing of the ACL. Prague, Czech Republic.
                                                              Dekai Wu. 1997. Stochastic inversion transduction
Liang Huang. 2008. Forest Reranking: Discriminative             grammars and bilingual parsing of parallel corpora.
   Parsing with Non-Local Features. In Proceedings              Computational Linguistics. 23(3):377–404. MIT
   of the 46th Annual Meeting of the ACL. Columbus,             Press. Cambridge, MA. USA.
   OH. USA.


                                                        166

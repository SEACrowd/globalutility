        Entity-based local coherence modelling using topological fields

                                Jackie Chi Kit Cheung and Gerald Penn
                                    Department of Computer Science
                                         University of Toronto
                                    Toronto, ON, M5S 3G4, Canada
                               {jcheung,gpenn}@cs.toronto.edu


                      Abstract                                 good reason to believe that the importance of these
                                                               factors vary across languages. For instance, freer-
    One goal of natural language generation is                 word-order languages exhibit word order patterns
    to produce coherent text that presents in-                 which are dependent on discourse factors relating
    formation in a logical order. In this pa-                  to information structure, in addition to the gram-
    per, we show that topological fields, which                matical roles of nominal arguments of the main
    model high-level clausal structure, are an                 verb. We thus expect word order information to be
    important component of local coherence                     particularly important in these languages in dis-
    in German. First, we show in a sen-                        course analysis, which includes coherence mod-
    tence ordering experiment that topologi-                   elling.
    cal field information improves the entity                     For example, Strube and Hahn (1999) introduce
    grid model of Barzilay and Lapata (2008)                   Functional Centering, a variant of Centering The-
    more than grammatical role and simple                      ory which utilizes information status distinctions
    clausal order information do, particularly                 between hearer-old and hearer-new entities. They
    when manual annotations of this informa-                   apply their model to pronominal anaphora reso-
    tion are not available. Then, we incor-                    lution, identifying potential antecedents of sub-
    porate the model enhanced with topolog-                    sequent anaphora by considering syntactic and
    ical fields into a natural language gen-                   word order information, classifying constituents
    eration system that generates constituent                  by their familiarity to the reader. They find that
    orders for German text, and show that                      their approach correctly resolves more pronomi-
    the added coherence component improves                     nal anaphora than a grammatical role-based ap-
    performance slightly, though not statisti-                 proach which ignores word order, and the differ-
    cally significantly.                                       ence between the two approaches is larger in Ger-
                                                               man corpora than in English ones. Unfortunately,
1   Introduction
                                                               their criteria for ranking potential antecedents re-
One type of coherence modelling that has captured              quire complex syntactic information in order to
recent research interest is local coherence mod-               classify whether proper names are known to the
elling, which measures the coherence of a docu-                hearer, which makes their algorithm hard to auto-
ment by examining the similarity between neigh-                mate. Indeed, all evaluation is done manually.
bouring text spans. The entity-based approach,                    We instead use topological fields, a model of
in particular, considers the occurrences of noun               clausal structure which is indicative of information
phrase entities in a document (Barzilay and Lap-               structure in German, but shallow enough to be au-
ata, 2008). Local coherence modelling has been                 tomatically parsed at high accuracy. We test the
shown to be useful for tasks like natural language             hypothesis that they would provide a good com-
generation and summarization, (Barzilay and Lee,               plement or alternative to grammatical roles in lo-
2004) and genre classification (Barzilay and Lap-              cal coherence modelling. We show that they are
ata, 2008).                                                    superior to grammatical roles in a sentence or-
   Previous work on English, a language with rel-              dering experiment, and in fact outperforms sim-
atively fixed word order, has identified factors that          ple word-order information as well. We further
contribute to local coherence, such as the gram-               show that these differences are particularly large
matical roles associated with the entities. There is           when manual syntactic and grammatical role an-


                                                         186
        Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 186–195,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


                                                         S

                                                                                        NF
                                                                                         S
                 VF              LK               MF            LK MF      VC
         Millionen von Mark verschwendet der Senat jeden Monat, weil er sparen will.
             “The senate wastes millions of marks each month, because it wants to save.”

Figure 1: The clausal and topological field structure of a German sentence. Notice that the subordinate
clause receives its own topology.


notations are not available.                                   such as verbal arguments, adjuncts, and discourse
   We then embed these topological field annota-               cues.
tions into a natural language generation system to                The VF (Vorfeld or “pre-field”) is so-named be-
show the utility of local coherence information in             cause it occurs before the left bracket. As the first
an applied setting. We add contextual features                 constituent of most matrix clauses in declarative
using topological field transitions to the model               sentences, it has special significance for the coher-
of Filippova and Strube (2007b) and achieve a                  ence of a passage, which we will further discuss
slight improvement over their model in a con-                  below. The MF (Mittelfeld or “middle field”) is
stituent ordering task, though not statistically sig-          the field bounded by the two brackets. Most verb
nificantly. We conclude by discussing possible                 arguments, adverbs, and prepositional phrases are
reasons for the utility of topological fields in lo-           found here, unless they have been fronted and put
cal coherence modelling.                                       in the VF, or are prosodically heavy and postposed
                                                               to the NF field. The NF (Nachfeld or “post-field”)
2   Background and Related Work                                contains prosodically heavy elements such as post-
2.1 German Topological Field Parsing                           posed prepositional phrases or relative clauses,
                                                               and occasionally postposed noun phrases.
Topological fields are sequences of one or more
contiguous phrases found in an enclosing syntac-               2.2 The Role of the Vorfeld
tic region, which is the clause in the case of the             One of the reasons that we use topological fields
German topological field model (Höhle, 1983).                 for local coherence modelling is the role that the
These fields may have constraints on the number                VF plays in signalling the information structure of
of words or phrases they contain, and do not nec-              German clauses, as it often contains the topic of
essarily form a semantically coherent constituent.             the sentence.
In German, the topology serves to identify all of                 In fact, its role is much more complex than be-
the components of the verbal head of a clause, as              ing simply the topic position. Dipper and Zins-
well as clause-level structure such as complemen-              meister (2009) distinguish multiple uses of the VF
tizers and subordinating conjunctions. Topologi-               depending on whether it contains an element re-
cal fields are a useful abstraction of word order,             lated to the surrounding discourse. They find that
because while Germanic word order is relatively                45.1% of VFs are clearly related to the previous
free with respect to grammatical functions, the or-            context by a reference or discourse relation, and a
der of the topological fields is strict and unvarying.         further 21.9% are deictic and refer to the situation
   A German clause can be considered to be an-                 described in the passage in a corpus study. They
chored by two “brackets” which contain modals,                 also run a sentence insertion experiment where
verbs and complementizers. The left bracket (linke             subjects are asked to place an extracted sentence
Klammer, LK) may contain a complementizer,                     in its original location in a passage. The authors
subordinating conjunction, or a finite verb, de-               remark that extracted sentences with VFs that are
pending on the clause type, and the right bracket              referentially related to previous context (e.g., they
contains the verbal complex (VC). The other topo-              contain a coreferential noun phrase or a discourse
logical fields are defined in relation to these two            relation like “therefore”) are reinserted at higher
brackets, and contain all other parts of the clause            accuracies.


                                                         187


a)
     #   Original Sentence and Translation
         Einen Zufluchtsort für Frauen, die von ihren Männern mißhandelt werden, gibt es nunmehr auch
     1   in Treptow.
         “There is now a sanctuary for women who are mistreated by their husbands in Treptow as well.”
         Das Bezirksamt bietet Frauen (auch mit Kindern) in derartigen Notsituationen vorübergehend
         eine Unterkunft.
     2
         “The district office offers women (even with children) in this type of emergency temporary
         accommodation.”
         Zugleich werden die Betroffenen der Regelung des Unterhalts, bei Behördengängen und auch
         bei der Wohnungssuche unterstützt.
     3
         “At the same time, the affected are supported with provisions of necessities, in dealing with
         authorities, and also in the search for new accommodations.”

b)
 DE      Zufluchtsort       Frauen                Männern                Treptow              Kindern
 EN      sanctuary          women                 husbands                Treptow              children
   1     acc                oth                   oth                     oth                  −
   2     −                  oth                   −                       −                    oth
   3     −                  nom                   −                       −                    −

c)
 −−            − nom         − acc        − oth           nom −           nom nom       nom acc      nom oth
 0.3           0.0           0.0          0.1             0.0             0.0           0.0          0.0
 acc −         acc nom       acc acc      acc oth         oth −           oth nom       oth acc      oth oth
 0.1           0.0           0.0          0.0             0.3             0.1           0.0          0.1

Table 1: a) An example of a document from TüBa-D/Z, b) an abbreviated entity grid representation of
it, and c) the feature vector representation of the abbreviated entity grid for transitions of length two.
Mentions of the entity Frauen are underlined. nom: nominative, acc: accusative, oth: dative, oblique,
and other arguments


   Filippova and Strube (2007c) also examine the              important for coherence modelling because men-
role of the VF in local coherence and natural lan-            tions of an entity tend to appear in clusters of
guage generation, focusing on the correlation be-             neighbouring or nearby sentences in coherent doc-
tween VFs and sentential topics. They follow Ja-              uments. This last assumption is adapted from Cen-
cobs (2001) in distinguishing the topic of addres-            tering Theory approaches to discourse modelling.
sation, which is the constituent for which the                   In Barzilay and Lapata (2008), an entity grid is
proposition holds, and frame-setting topics, which            constructed for each document, and is represented
is the domain in which the proposition holds, such            as a matrix in which each row represents a sen-
as a temporal expression. They show in a user                 tence, and each column represents an entity. Thus,
study that frame-setting topics are preferred to top-         a cell in the matrix contains information about an
ics of addressation in the VF, except when a con-             entity in a sentence. The cell is marked by the
stituent needs to be established as the topic of ad-          presence or absence of the entity, and can also be
dressation.                                                   augmented with other information about the en-
                                                              tity in this sentence, such as the grammatical role
2.3 Using Entity Grids to Model Local                         of the noun phrase representing that entity in that
    Coherence                                                 sentence, or the topological field in which the noun
Barzilay and Lapata (2008) introduce the entity               phrase appears.
grid as a method of representing the coherence of a              Consider the document in Table 1. An entity
document. Entity grids indicate the location of the           grid representation which incorporates the syntac-
occurrences of an entity in a document, which is              tic role of the noun phrase in which the entity ap-


                                                        188


pears is also shown (not all entities are listed for          ence, grammatical role and topological field infor-
brevity). We tabulate the transitions of entities be-         mation. This set is larger than the set that was used
tween different syntactic positions (or their non-            in Experiment 1 of Barzilay and Lapata (2008),
occurrence) in sentences, and convert the frequen-            which consists of 400 documents in two English
cies of transitions into a feature vector representa-         subcorpora on earthquakes and accidents respec-
tion of transition probabilities in the document.             tively. The average document length in the TüBa-
   To calculate transition probabilities, we divide           D/Z subcorpus is also greater, at 19.2 sentences
the frequency of a particular transition by the total         compared to about 11 for the two subcorpora. Up
number of transitions of that length.                         to 20 random permutations of sentences were gen-
   This model of local coherence was investigated             erated from each document, with duplicates re-
for German by Filippova and Strube (2007a). The               moved.
main focus of that work, however, was to adapt                   There are 216 documents and 4126 original-
the model for use in a low-resource situation when            permutation pairs in the training set, and 24 docu-
perfect coreference information is not available.             ments and 465 pairs in the development set. The
This is particularly useful in natural language un-           remaining 240 documents are in the final test set
derstanding tasks. They employ a semantic clus-               (4243 pairs). The entity-based model is parame-
tering model to relate entities. In contrast, our             terized as follows.
work focuses on improving performance by anno-                   Transition length – the maximum length of the
tating entities with additional linguistic informa-           transitions used in the feature vector representa-
tion, such as topological fields, and is geared to-           tion of a document.
wards natural language generation systems where                  Representation – when marking the presence of
perfect information is available.                             an entity in a sentence, what information about
   Similar models of local coherence include vari-            the entity is marked (topological field, grammat-
ous Centering Theory accounts of local coherence              ical role, or none). We will describe the represen-
((Kibble and Power, 2004; Poesio et al., 2004)                tations that we try in section 3.2.
inter alia). The model of Elsner and Charniak                    Salience – whether to set a threshold for the fre-
(2007) uses syntactic cues to model the discourse-            quency of occurrence of entities. If this is set, all
newness of noun phrases. There are also more                  entities below a certain frequency are treated sep-
global content models of topic shifts between sen-            arately from those reaching this frequency thresh-
tences like Barzilay and Lee (2004).                          old when calculating transition probabilities. In
                                                              the example in Table 1, with a salience thresh-
3   Sentence Ordering Experiments                             old of 2, Frauen would be treated separately from
3.1 Method                                                    Männern or Kindern.
                                                                 Transition length, salience, and a regularization
We test a version of the entity grid representa-
                                                              parameter are tuned on the development set. We
tion augmented with topological fields in a sen-
                                                              only report results using the setting of transition
tence ordering experiment corresponding to Ex-
                                                              length ≤ 4, and no salience threshold, because
periment 1 of Barzilay and Lapata (2008). The
                                                              they give the best performance on the development
task is a binary classification task to identify the
                                                              set. This is in contrast to the findings of Barzi-
original version of a document from another ver-
                                                              lay and Lapata (2008), who report that transition
sion which contains the sentences in a randomly
                                                              length ≤ 3 and a salience threshold of 2 perform
permuted order, which is taken to be incoherent.
                                                              best on their data.
We solve this problem in a supervised machine
learning setting, where the input is the feature vec-         3.2 Entity Representations
tor representations of the two versions of the doc-           The main goal of this study is to compare word
ument, and the output is a binary value indicating            order, grammatical role and topological field in-
the document with the original sentence ordering.             formation, which is encoded into the entity grid at
We use SVMlight’s ranking module for classifi-                each occurrence of an entity. Here, we describe
cation (Joachims, 2002).                                      the variants of the entity representations that we
   The corpus in our experiments consists of the              compare.
last 480 documents of TüBa-D/Z version 4 (Telljo-
hann et al., 2004), which contains manual corefer-


                                                        189


Baseline Representations We implement sev-                    other. Prepositional objects are treated the same
eral baseline representations against which we test           as other noun phrases here.
our topological field-enhanced model. The sim-
                                                              Combined We tried a representation which
plest baseline representation marks the mere ap-
                                                              combines grammatical role and topological field
pearance of an entity without any additional infor-
                                                              into a single representation, subj/obj×vf,
mation, which we refer to as default.
                                                              which takes the Cartesian product of subj/obj
   Another class of baseline representations mark
                                                              and vf above.
the order in which entities appear in the clause.
                                                                 Topological fields do not map directly to topic-
The correlation between word order and informa-
                                                              focus distinctions. For example, besides the topic
tion structure is well known, and has formed the
                                                              of the sentence, the Vorfeld may contain discourse
basis of some theories of syntax such as the Prague
                                                              cues, expletive pronouns, or the informational or
School’s (Sgall et al., 1986). The two versions
                                                              contrastive focus. Furthermore, there are addi-
of clausal order we tried are order 1/2/3+,
                                                              tional constraints on constituent order related to
which marks a noun phrase as the first, the sec-
                                                              pronominalization. Thus, we devised additional
ond, or the third or later to appear in a clause, and
                                                              entity representations to account for these aspects
order 1/2+, which marks a noun phrase as the
                                                              of German.
first, or the second or later to appear in a clause.
                                                                 topic attempts to identify the sentential topic
Since noun phrases can be embedded in other
                                                              of a clause. A noun phrase is marked as TOPIC
noun phrases, overlaps can occur. In this case, the
                                                              if it is in VF as in vfpp, or if it is the first
dominating noun phrase takes the smallest order
                                                              noun phrase in MF and also the first NP in the
number among its dominated noun phrases.
                                                              clause. Other noun phrases in MF are marked
   The third class of baseline representations we
                                                              as NONTOPIC. Categories for NF and miscella-
employ mark an entity by its grammatical role
                                                              neous noun phrases also exist. While this repre-
in the clause. Barzilay and Lapata (2008) found
                                                              sentation may appear to be very similar to sim-
that grammatical role improves performance in
                                                              ply distinguishing the first entity in a clause as for
this task for an English corpus. Because Ger-
                                                              order 1/2+ in that TOPIC would correspond
man distinguishes more grammatical roles mor-
                                                              to the first entity in the clause, they are in fact dis-
phologically than English, we experiment with
                                                              tinct. Due to issues related to coordination, appos-
various granularities of role labelling. In particu-
                                                              itive constructions, and fragments which do not
lar, subj/obj distinguishes the subject position,
                                                              receive a topology of fields, the first entity in a
the object position, and another category for all
                                                              clause is labelled the TOPIC only 80.8% of the
other positions. cases distinguishes five types of
                                                              time in the corpus. This representation also distin-
entities corresponding to the four morphological
                                                              guishes NFs, which clausal order does not.
cases of German in addition to another category
                                                                 topic+pron refines the above by taking into
for noun phrases which are not complements of
                                                              account a word order restriction in German that
the main verb.
                                                              pronouns appear before full noun phrases in the
Topological Field-Based These representations                 MF field. The following set of decisions repre-
mark the topological field in which an entity ap-             sents how a noun phrase is marked: If the first NP
pears. Some versions mark entities which are                  in the clause is a pronoun in an MF field and is the
prepositional objects separately. We try versions             subject, we mark it as TOPIC. If it is not the sub-
which distinguish VF from non-VF, as well as                  ject, we mark it as NONTOPIC. For other NPs, we
more general versions that make use of a greater              follow the topic representation.
set of topological fields. vf marks the noun phrase
as belonging to a VF (and not in a PP) or not.                3.3 Automatic annotations
vfpp is the same as above, but allows preposi-                While it is reasonable to assume perfect annota-
tional objects inside the VF to be marked as VF.              tions of topological fields and grammatical roles in
topf/pp distinguishes entities in the topological             many NLG contexts, this assumption may be less
fields VF, MF, and NF, contains a separate cat-               appropriate in other applications involving text-to-
egory for PP, and a category for all other noun               text generation where the input to the system is
phrases. topf distinguishes between VF, MF, and               text such as paraphrasing or machine translation.
NF, on the one hand, and everything else on the               Thus, we test the robustness of the entity repre-


                                                        190


 Representation           Manual        Automatic                  Annotation                  Accuracy (%)
 topf/pp                  94.44            94.89                   Grammatical role                 83.6
 topic                    94.13            94.53                   Topological field (+PP)          93.8
 topic+pron               94.08            94.51                   Topological field (−PP)          95.7
 topf                     93.87            93.11                   Clausal order                    90.8
 subj/obj                 93.831           91.7++
 cases                    93.312           90.93++            Table 3: Accuracy of automatic annotations of
 order 1/2+               92.51++          92.1+              noun phrases with coreferents. +PP means that
                                                              prepositional objects are treated as a separate cate-
 subj/obj×vf              92.32++          90.74++
                                                              gory from topological fields. −PP means they are
 default                  91.42++          91.42++
                                                              treated as other noun phrases.
 vfpp                     91.37++          91.68++
 vf                       91.21++          91.16++
 order 1/2/3+             91.16++          90.71++
                                                              tional phrases. However, we can approximate the
Table 2: Accuracy (%) of the permutation de-                  grammatical role of an entity using the morpho-
tection experiment with various entity represen-              logical case. We follow the annotation conven-
tations using manual and automatic annotations                tions of TüBa-D/Z in not assigning a grammati-
of topological fields and grammatical roles. The              cal role when the noun phrase is a prepositional
baseline without any additional annotation is un-             object. We also do not assign a grammatical role
derlined. Two-tailed sign tests were calculated for           when the noun phrase is in the genitive case, as
each result against the best performing model in              genitive objects are very rare in German and are
each column (1 : p = 0.101; 2 : p = 0.053; +: statis-         far outnumbered by the possessive genitive con-
tically significant, p < 0.05; ++: very statistically         struction.
significant, p < 0.01 ).
                                                              3.4 Results
                                                              Table 2 shows the results of the sentence ordering
sentations to automatic extraction in the absence             permutation detection experiment. The top four
of manual annotations. We employ the following                performing entity representations are all topologi-
two systems for extracting topological fields and             cal field-based, and they outperform grammatical
grammatical roles.                                            role-based and simple clausal order-based mod-
   To parse topological fields, we use the Berke-             els. These results indicate that the information
ley parser of Petrov and Klein (2007), which has              that topological fields provide about clause struc-
been shown to perform well at this task (Cheung               ture, appositives, right dislocation, etc. which is
and Penn, 2009). The parser is trained on sections            not captured by simple clausal order is important
of TüBa-D/Z which do not overlap with the sec-               for coherence modelling. The representations in-
tion from which the documents for this experiment             corporating linguistics-based heuristics do not out-
were drawn, and obtains an overall parsing per-               perform purely topological field-based models.
formance of 93.35% F1 on topological fields and                  Surprisingly, the VF-based models fare quite
clausal nodes without gold POS tags on the section            poorly, performing worse than not adding any an-
of TüBa-D/Z it was tested on.                                notations, despite the fact that topological field-
   We tried two methods to obtain grammatical                 based models in general perform well. This result
roles. First, we tried extracting grammatical roles           may be a result of the heterogeneous uses of the
from the parse trees which we obtained from the               VF.
Berkeley parser, as this information is present in               The automatic topological field annotations are
the edge labels that can be recovered from the                more accurate than the automatic grammatical role
parse. However, we found that we achieved bet-                annotations (Table 3), which may partly explain
ter accuracy by using RFTagger (Schmid and                    why grammatical role-based models suffer more
Laws, 2008), which tags nouns with their morpho-              when using automatic annotations. Note, how-
logical case. Morphological case is distinct from             ever, that the models based on automatic topolog-
grammatical role, as noun phrases can function as             ical field annotations outperform even the gram-
adjuncts in possessive constructions and preposi-             matical role-based models using manual annota-
                                                              tion (at marginal significance, p < 0.1). The topo-


                                                        191


logical field annotations are accurate enough that                       Representation                   Accuracy (%)
automatic annotations produce no decrease in per-                        topf/pp                               93.83
formance.                                                                topic                                 93.31
   These results show the upper bound of entity-                         topic+pron                            93.31
based local coherence modelling with perfect                             topf                                  92.49
coreference information. The results we obtain                           subj/obj                              88.99
are higher than the results for the English cor-                         order 1/2+                            88.89
pora of Barzilay and Lapata (2008) (87.2% on the                         order 1/2/3+                          88.84
Earthquakes corpus and 90.4% on the Accidents                            cases                                 88.63
corpus), but this is probably due to corpus differ-                      vf                                    87.60
ences as well as the availability of perfect corefer-                    vfpp                                  88.17
ence information in our experiments1 .                                   default                               87.55
   Due to the high performance we obtained, we
                                                                         subj/obj×vf                           87.71
calculated Kendall tau coefficients (Lapata, 2006)
                                                                         (Filippova and Strube, 2007)           75
over the sentence orderings of the cases in which
our best performing model is incorrect, to deter-                      Table 4: Accuracy (%) of permutation detection
mine whether the remaining errors are instances                        experiment with various entity representations us-
where the permuted ordering is nearly identical to                     ing manual and automatic annotations of topolog-
the original ordering. We obtained a τ of 0.0456                       ical fields and grammatical roles on subset of cor-
in these cases, compared to a τ of −0.0084 for all                     pus used by Filippova and Strube (2007a).
the pairs, indicating that this is not the case.
   To facilitate comparison to the results of Filip-
pova and Strube (2007a), we rerun this experiment                      may be nested NP nodes in the original corpus.
on the same subsections of the corpus as in that                       There may also be noise in the dependency con-
work for training and testing. The first 100 arti-                     version process.
cles of TüBa-D/Z are used for testing, while the                         The relative rankings of different entity repre-
next 200 are used for training and development.                        sentations in this experiment are similar to the
   Unlike the previous experiments, we do not do                       rankings of the previous experiment, with topolog-
parameter tuning on this set of data. Instead, we                      ical field-based models outperforming grammati-
follow Filippova and Strube (2007a) in using tran-                     cal role and clausal order models.
sition lengths of up to three. We do not put in
a salience threshold. We see that our results are                      4 Local Coherence for Natural Language
much better than the ones reported in that work,                         Generation
even for the default representation. The main
                                                                       One of the motivations of the entity grid-based
reason for this discrepancy is probably the way
                                                                       model is to improve surface realization decisions
that entities are created from the corpus. In our
                                                                       in NLG systems. A typical experimental design
experiments, we create an entity for every single
                                                                       would pass the contents of the test section of a
noun phrase node that we encounter, then merge
                                                                       corpus as input to the NLG system with the order-
the entities that are linked by coreference. Filip-
                                                                       ing information stripped away. The task is then to
pova and Strube (2007a) convert the annotations
                                                                       regenerate the ordering of the information found
of TüBa-D/Z into a dependency format, then ex-
                                                                       in the original corpus. Various coherence models
tract entities from the noun phrases found there.
                                                                       have been tested in corpus-based NLG settings.
They may thus annotate fewer entities, as there
                                                                       For example, Karamanis et al. (2009) compare
    1
      Barzilay and Lapata (2008) use the coreference sys-              several versions of Centering Theory-based met-
tem of Ng and Cardie (2002) to obtain coreference anno-
tations. We are not aware of similarly well-tested, pub-
                                                                       rics of coherence on corpora by examining how
licly available coreference resolution systems that handle all         highly the original ordering found in the corpus
types of anaphora for German. We considered adapting the               is ranked compared to other possible orderings of
BART coreference resolution toolkit (Versley et al., 2008) to
German, but a number of language-dependent decisions re-               propositions. A metric performs well if it ranks
garding preprocessing, feature engineering, and the learning           the original ordering better than the alternative or-
paradigm would need to be made in order to achieve rea-                derings.
sonable performance comparable to state-of-the-art English
coreference resolution systems.                                           In our next experiment, we incorporate local co-


                                                                 192


herence information into the system of Filippova                • the semantic class of the constituent (per-
and Strube (2007b). We embed entity topologi-                     son, temporal, location, etc.) The biographee,
cal field transitions into their probabilistic model,             in particular, is marked by its own semantic
and show that the added coherence component                       class.
slightly improves the performance of the baseline
NLG system in generating constituent orderings in                In the first VF selection step, MAXENT simply
a German corpus, though not to a statistically sig-           produces a probability of each constituent being a
nificant degree.                                              VF, and the constituent with the highest probabil-
                                                              ity is selected. In the second step, MAXENT2 takes
4.1 Method                                                    the featural representation of two constituents, and
We use the WikiBiography corpus2 for our exper-               produces an output probability of the first con-
iments. The corpus consists of more than 1100 bi-             stituent preceding the second constituent. The fi-
ographies taken from the German Wikipedia, and                nal ordering is achieved by first randomizing the
contains automatic annotations of morphological,              order of the constituents in a clause (besides the
syntactic, and semantic information. Each article             first one, which is selected to be the VF), then
also contains the coreference chain of the subject            sorting them according to the precedence proba-
of the biography (the biographee). The first 100              bilities. Specifically, a constituent A is put before
articles are used for testing, the next 200 for de-           a constituent B if MAXENT2(A,B) > 0.5. Because
velopment, and the rest for training.                         this precedence relation is not antisymmetric (i.e.,
   The baseline generation system already incor-              MAXENT2(A,B) > 0.5 and MAXENT2(B,A) >
porates topological field information into the con-           0.5 may be simultaneously true or simultaneously
stituent ordering process. The system operates in             false), different initializations of the order pro-
two steps. First, in main clauses, one constituent            duce different sorted results. In our experiments,
is selected as the Vorfeld (VF). This is done us-             we correct this by defining the precedence rela-
ing a maximum entropy model (call it MAXENT).                 tion to be A precedes B iff MAXENT2(A,B) >
Then, the remaining constituents are ordered using            MAXENT2(B,A). This change does not greatly im-
a second maximum entropy model (MAXENT2).                     pact the performance, and removes the random-
Significantly, Filippova and Strube (2007b) found             ized element of the algorithm.
that selecting the VF first, and then ordering the               The baseline system does not directly model the
remaining constituents results in a 9% absolute               context when ordering constituents. All of the
improvement over the corresponding model where                features but one in the original maximum entropy
the selection is performed in one step by the sort-           models rely on local properties of the clause. We
ing algorithm alone.                                          incorporate local coherence information into the
   The maximum entropy model for both steps rely              model by adding entity transition features which
on the following features:                                    we found to be useful in the sentence ordering ex-
                                                              periment in Section 3 above.
  • features on the voice, valency, and identity of              Specifically, we add features indicating the
    the main verb of the clause                               topological fields in which entities occur in the
                                                              previous sentences. We found that looking back
  • features on the morphological and syntactic               up to two sentences produces the best results (by
    status of the constituent to be ordered                   tuning on the development set). Because this cor-
  • whether the constituent occurs in the preced-             pus does not come with general coreference in-
    ing sentence                                              formation except for the coreference chain of the
                                                              biographee, we use the semantic classes instead.
  • features for whether the constituent contains             So, all constituents in the same semantic class are
    a determiner, an anaphoric pronoun, or a rel-             treated as one coreference chain. An example of a
    ative clause                                              feature may be biog-last2, which takes on a value
                                                              such as ‘v−’, meaning that this constituent refers
  • the size of the constituent in number of mod-
                                                              to the biographee, and the biographee occurs in
    ifiers, in depth, and in number of words
                                                              the VF two clauses ago (v), but does not appear in
   2
   http://www.eml-research.de/english/                        the previous clause (−). For a constituent which is
research/nlp/download/wikibiography.php                       not the biographee, this feature would be marked


                                                        193


    Method        VF Acc (%)      Acc (%)    Tau                 We suggest that the utility of topological fields
    Baseline             68.7       60.9     0.72             in local coherence modelling comes from the in-
    +Coherence           69.2       61.5     0.72             teraction between word order and information
                                                              structure in freer-word-order languages. Crucially,
Table 5: Results of adding coherence features into            topological fields take into account issues such
a natural language generation system. VF Acc%                 as coordination, appositives, sentential fragments
is the accuracy of selecting the first constituent in         and differences in clause types, which word or-
main clauses. Acc % is the percentage of per-                 der alone does not. They are also shallow enough
fectly ordered clauses, tau is Kendall’s τ on the             to be accurately parsed automatically for use in
constituent ordering. The test set contains 2246              resource-poor applications.
clauses, of which 1662 are main clauses.                         Further refinement of the topological field an-
                                                              notations to take advantage of the fact that they
                                                              do not correspond neatly to any single information
‘na’ (not applicable).                                        status such as topic or focus could provide addi-
                                                              tional performance gains. The model also shows
4.2 Results
                                                              promise for other discourse-related tasks such as
Table 5 shows the results of adding these contex-             coreference resolution and discourse parsing.
tual features into the maximum entropy models.
We see that we obtain a small improvement in the              Acknowledgements
accuracy of VF selection, and in the accuracy of
                                                              We are grateful to Katja Filippova for providing us
correctly ordering the entire clause. These im-
                                                              with source code for the experiments in Section 4
provements are not statistically significant by Mc-
                                                              and for answering related questions, and to Tim-
Nemar’s test. We suggest that the lack of coref-
                                                              othy Fowler for useful discussions and comments
erence information for all entities in the article
                                                              on a draft of the paper. This work is supported in
may have reduced the benefit of the coherence
                                                              part by the Natural Sciences and Engineering Re-
component. Also, the topline of performance is
                                                              search Council of Canada.
substantially lower than 100%, as multiple order-
ings are possible and equally valid. Human judge-
ments on information structuring for both inter-              References
and intra-sentential units are known to have low
                                                              R. Barzilay and M. Lapata. 2008. Modeling local co-
agreement (Barzilay et al., 2002; Filippova and                  herence: An entity-based approach. Computational
Strube, 2007c; Lapata, 2003; Chen et al., 2007).                 Linguistics, 34(1):1–34.
Thus, the relative error reduction is higher than the
                                                              R. Barzilay and L. Lee. 2004. Catching the drift: Prob-
absolute reduction might suggest.                                abilistic content models, with applications to gen-
                                                                 eration and summarization. In Proc. HLT-NAACL
5    Conclusions                                                 2004, pages 113–120.
We have shown that topological fields are a use-              R. Barzilay, N. Elhadad, and K. McKeown. 2002. In-
ful source of information for local coherence mod-               ferring strategies for sentence ordering in multidoc-
elling. In a sentence-order permutation detection                ument news summarization. Journal of Artificial In-
task, models which use topological field infor-                  telligence Research, 17:35–55.
mation outperform both grammatical role-based                 E. Chen, B. Snyder, and R. Barzilay. 2007. Incremen-
models and models based on simple clausal or-                    tal text structuring with online hierarchical ranking.
der, with the best performing model achieving a                  In Proceedings of EMNLP, pages 83–91.
relative error reduction of 40.4% over the original           J.C.K. Cheung and G. Penn. 2009. Topological Field
baseline without any additional annotation. Ap-                  Parsing of German. In Proc. 47th ACL and 4th IJC-
plying our local coherence model in another set-                 NLP, pages 64–72. Association for Computational
                                                                 Linguistics.
ting, we have embedded topological field transi-
tions of entities into an NLG system which orders             S. Dipper and H. Zinsmeister. 2009. The Role of
constituents in German clauses. We find that the                 the German Vorfeld for Local Coherence: A Pi-
                                                                 lot Study. In Proceedings of the Conference of the
coherence-enhanced model slightly outperforms                    German Society for Computational Linguistics and
the baseline system, but this was not statistically              Language Technology (GSCL), pages 69–79. Gunter
significant.                                                     Narr.


                                                        194


M. Elsner and E. Charniak. 2007. A generative                    P. Sgall, E. Hajičová, J. Panevová, and J. Mey. 1986.
  discourse-new model for text coherence. Technical                 The meaning of the sentence in its semantic and
  report, Technical Report CS-07-04, Brown Univer-                  pragmatic aspects. Springer.
  sity.
                                                                 M. Strube and U. Hahn. 1999. Functional center-
K. Filippova and M. Strube. 2007a. Extending the                   ing: Grounding referential coherence in information
  entity-grid coherence model to semantically related              structure. Computational Linguistics, 25(3):309–
  entities. In Proceedings of the Eleventh European                344.
  Workshop on Natural Language Generation, pages
  139–142. Association for Computational Linguis-                H. Telljohann, E. Hinrichs, and S. Kubler. 2004.
  tics.                                                            The TüBa-D/Z treebank: Annotating German with
                                                                   a context-free backbone. In Proc. Fourth Interna-
K. Filippova and M. Strube. 2007b. Generating con-                 tional Conference on Language Resources and Eval-
  stituent order in German clauses. In Proc. 45th ACL,             uation (LREC 2004), pages 2229–2235.
  pages 320–327.
                                                                 Y. Versley, S.P. Ponzetto, M. Poesio, V. Eidelman,
K. Filippova and M. Strube. 2007c. The German Vor-                  A. Jern, J. Smith, X. Yang, and A. Moschitti. 2008.
  feld and Local Coherence. Journal of Logic, Lan-                  BART: A modular toolkit for coreference resolution.
  guage and Information, 16(4):465–485.                             In Proc. 46th ACL-HLT Demo Session, pages 9–12.
                                                                    Association for Computational Linguistics.
T.N. Höhle. 1983. Topologische Felder. Ph.D. thesis,
  Köln.
J. Jacobs. 2001. The dimensions of topiccomment.
   Linguistics, 39(4):641–681.

T. Joachims. 2002. Learning to Classify Text Using
   Support Vector Machines. Kluwer.

N. Karamanis, C. Mellish, M. Poesio, and J. Oberlan-
  der. 2009. Evaluating centering for information or-
  dering using corpora. Computational Linguistics,
  35(1):29–46.

R. Kibble and R. Power. 2004. Optimizing referential
   coherence in text generation. Computational Lin-
   guistics, 30(4):401–416.

M. Lapata. 2003. Probabilistic text structuring: Exper-
  iments with sentence ordering. In Proc. 41st ACL,
  pages 545–552.

M. Lapata. 2006. Automatic evaluation of information
  ordering: Kendall’s tau. Computational Linguistics,
  32(4):471–484.

V. Ng and C. Cardie. 2002. Improving machine learn-
   ing approaches to coreference resolution. In Proc.
   40th ACL, pages 104–111.
S. Petrov and D. Klein. 2007. Improved inference
   for unlexicalized parsing. In Proceedings of NAACL
   HLT 2007, pages 404–411.

M. Poesio, R. Stevenson, B.D. Eugenio, and J. Hitze-
  man. 2004. Centering: A parametric theory
  and its instantiations. Computational Linguistics,
  30(3):309–363.

H. Schmid and F. Laws. 2008. Estimation of condi-
  tional probabilities with decision trees and an appli-
  cation to fine-grained POS tagging. In Proc. 22nd
  COLING, pages 777–784. Association for Compu-
  tational Linguistics.




                                                           195

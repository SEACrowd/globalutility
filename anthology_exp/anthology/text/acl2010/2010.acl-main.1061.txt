          Evaluating Multilanguage-Comparability of Subjectivity Analysis
                                    Systems

                             Jungi Kim, Jin-Ji Li and Jong-Hyeok Lee
                           Division of Electrical and Computer Engineering
                Pohang University of Science and Technology, Pohang, Republic of Korea
                           {yangpa,ljj,jhlee}@postech.ac.kr


                          Abstract                                 translate other languages into English, up-to-date
                                                                   research provides various ways to analyze subjec-
        Subjectivity analysis is a rapidly grow-                   tivity in multilingual environments.
        ing field of study. Along with its ap-                        Given sentiment analysis systems in differ-
        plications to various NLP tasks, much                      ent languages, there are many situations when
        work have put efforts into multilingual                    the analysis outcomes need to be multilanguage-
        subjectivity learning from existing re-                    comparable. For example, it has been common
        sources. Multilingual subjectivity analy-                  these days for the Internet users across the world
        sis requires language-independent crite-                   to share their views and opinions on various top-
        ria for comparable outcomes across lan-                    ics including music, books, movies, and global af-
        guages. This paper proposes to mea-                        fairs and incidents, and also multinational compa-
        sure the multilanguage-comparability of                    nies such as Apple and Samsung need to analyze
        subjectivity analysis tools, and provides                  customer feedbacks for their products and services
        meaningful comparisons of multilingual                     from many countries in different languages. Gov-
        subjectivity analysis from various points                  ernments may also be interested in monitoring ter-
        of view.                                                   rorist web forums or its global reputation. Sur-
1       Introduction                                               veying these opinions and sentiments in various
                                                                   languages involves merging the analysis outcomes
The field of NLP has seen a recent surge in the                    into a single database, thereby objectively compar-
amount of research on subjectivity analysis. Along                 ing the result across languages.
with its applications to various NLP tasks, there                     If there exists an ideal subjectivity analy-
have been efforts made to extend the resources                     sis system for each language, evaluating the
and tools created for the English language to other                multilanguage-comparability would be unneces-
languages. These endeavors have been success-                      sary because the analysis in each language would
ful in constructing lexicons, annotated corpora,                   correctly identify the exact meanings of all in-
and tools for subjectivity analysis in multiple lan-               put texts regardless of the language. However, this
guages.                                                            requirement is not fulfilled with current technol-
   There are multilingual subjectivity analysis sys-               ogy, thus the need for defining and measuring the
tems available that have been built to monitor and                 multilanguage-comparability of subjectivity anal-
analyze various concerns and opinions on the In-                   ysis systems is evident.
ternet; among the better known are OASYS from                         This paper proposes to evaluate the
the University of Maryland that analyzes opinions                  multilanguage-comparability of multilingual
on topics from news article searches in multiple                   subjectivity analysis systems. We build a number
languages (Cesarano et al., 2007)1 and TextMap,                    of subjectivity classifiers that distinguishes sub-
an entity search engine developed by Stony Brook                   jective texts from objective ones, and measure
University for sentiment analysis along with other                 the multilanguage-comparability according to our
functionalities (Bautin et al., 2008).2 Though these               proposed evaluation method. Since subjectivity
systems currently rely on English analysis tools                   analysis tools in languages other than English are
and a machine translation (MT) technology to                       not readily available, we focus our experiments on
    1
        http://oasys.umiacs.umd.edu/oasysnew/                      comparing different methods to build multilingual
    2
        http://www.textmap.com/                                    analysis systems from the resources and systems


                                                             595
            Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 595–603,
                     Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


created for English. These approaches enable us to                 Texts with an identical negative sentiment:
extend a monolingual system to many languages                      * The iPad could cannibalize the e-reader market.
with a number of freely available NLP resources                    * 아이패드가(iPad) 전자책 시장을(e-reader market)
                                                                   위축시킬 수 있다(could cannibalize).
and tools.
                                                                   Texts with different strengths of positive sentiments:
2   Related Work                                                   * Samsung cell phones have excellent battery life.
                                                                   * 삼성(Samsung) 휴대전화(cell phone) 배터리는
Much research have been put into developing                        (battery) 그럭저럭(somehow or other) 오래간다(last
methods for multilingual subjectivity analysis re-                 long).
cently. With the high availability of subjectivity re-
sources and tools in English, an easy and straight-            Figure 1: Examples of sentiments in multilingual
forward approach would be to employ a machine                  text
translation (MT) system to translate input texts
in target languages into English then carry out
the analyses using an existing subjectivity analy-             Banea et al. (2008) have attributed the variations
sis tool (Kim and Hovy, 2006; Bautin et al., 2008;             in the difficulty level of subjectivity learning to
Banea et al., 2008). Mihalcea et al. (2007) and                the differences in language construction. Bautin et
Banea et al. (2008) proposed a number of ap-                   al. (2008)’s system analyzes the sentiment scores
proaches exploiting a bilingual dictionary, a paral-           of entities in multilingual news and blogs and ad-
lel corpus, and an MT system to port the resources             justed the sentiment scores using entity sentiment
and systems available in English to languages with             probabilities of languages.
limited resources.
                                                               3     Multilanguage-Comparability
   For subjectivity lexicons translation, Mihalcea
et al. (2007) and Wan (2008) used the first sense in           3.1    Motivation
a bilingual dictionary, Kim and Hovy (2006) used               The quality of a subjectivity analysis tool is mea-
a parallel corpus and a word alignment tool to ex-             sured by its ability to distinguish subjectivity from
tract translation pairs, and Kim et al. (2009) used            objectivity and/or positive sentiments from nega-
a dictionary to translate and a link analysis algo-            tive sentiments. Additionally, a multilingual sub-
rithm to refine the matching intensity.                        jectivity analysis system is required to generate
   To overcome the shortcomings of available re-               unbiased analysis results across languages; the
sources and to take advantage of ensemble sys-                 system should base its outcome solely on the sub-
tems, Wan (2008) and Wan (2009) explored meth-                 jective meanings of input texts irrespective of the
ods for developing a hybrid system for Chinese us-             language, and the equalities and inequalities of
ing English and Chinese sentiment analyzers. Ab-               subjectivity labels and intensities must be useful
basi et al. (2008) and Boiy and Moens (2009) have              within and throughout the languages.
created manually annotated gold standards in tar-                 Let us consider two cases where the pairs of
get languages and studied various feature selec-               multilingual inputs in English and Korean have
tion and learning techniques in machine learning               identical and different subjectivity meanings (Fig-
approaches to analyze sentiments in multilingual               ure 1). The first pair of texts carry a negative sen-
web documents.                                                 timent about how the release of a new electronics
   For learning multilingual subjectivity, the lit-            device might affect an emerging business market.
erature tentatively concludes that translating lex-            When a multilanguage-comparable system is in-
icon is less dependable in terms of preserving sub-            putted with such a pair, its output should appropri-
jectivity than corpus translation (Mihalcea et al.,            ately reflect the negative sentiment, and be identi-
2007; Wan, 2008), and though corpus translation                cal for both texts. The second pair of texts share
results in modest performance degradation, it pro-             a similar positive sentiment about a mobile de-
vides a viable approach because no manual la-                  vice’s battery capacity but with different strengths.
bor is required (Banea et al., 2008; Brooke et al.,            A good multilingual system must be able to iden-
2009).                                                         tify the positive sentiments and distinguish the dif-
   Based on the observation that the performances              ferences in their intensities.
of subjectivity analysis systems in comparable                    However, these kinds of conditions cannot be
experimental settings for two languages differ,                measured with performance evaluations indepen-


                                                         596


dently carried out on each language; A system                      In this paper, we utilize the first approach be-
with a dissimilar ability to analyze subjective ex-             cause it provides a more rational means; we can
pressions from one language to another may de-                  reasonably hypothesize that text translated into an-
liver opposite labels or biased scores on texts with            other language by a skilled translator carries an
an identical subjective meaning, and vice versa,                identical semantic meaning and thereby conveys
but still might produce similar performances on                 identical subjectivity. Therefore the required re-
the evaluation data.                                            source is more easily attained in relatively inex-
   Macro evaluations on individual languages can-               pensive ways.
not provide any conclusions on the system’s                        For evaluation, we measure the consistency in
multilanguage-comparability capability. To mea-                 the subjectivity labels and the correlation of sub-
sure how much of a system’s judgment principles                 jectivity intensity scores of parallel texts. Section
are preserved across languages, an evaluation from              5.1 describes the details of evaluation metrics.
a different perspective is necessary.
                                                                4     Multilingual Subjectivity System
3.2   Evaluation Approach                                       We create a number of multilingual systems con-
An evaluation of multilanguage-comparability                    sisting of multiple subsystems each processing a
may be done in two ways: measuring agreements                   language, where one system analyzes English, and
in the outcomes of a pair of multilingual texts with            the other systems analyze the Korean, Chinese,
an identical subjective meaning, or measuring the               and Japanese languages. We try to reproduce a set
consistencies in the label and/or accordance in the             of systems using diverse methods in order to com-
order of intensity of a pair of texts with different            pare the systems and find out which methods are
subjectivities.                                                 more suitable for multilanguage-comparability.
    There are advantages and disadvantages to each
                                                                4.1    Source Language System
approaches. The first approach requires multi-
lingual texts aligned at the level of specificity,              We adopt the three systems described below as our
for instance, document, sentence and phrase, that               source language systems: a state-of-the-art sub-
the subjectivity analysis system works. Text cor-               jectivity classifier, a corpus-based, and a lexicon-
pora for MT evaluation such as newspapers,                      based systems. The resources needed for devel-
books, technical manuals, and government offi-                  oping the systems or the system itself are readily
cial records provide a wide variety of parallel                 available for research purposes. In addition, these
texts, typically at the sentence level. Annotating              systems cover the general spectrum of current ap-
these types of corpus can be efficient; as par-                 proaches to subjectivity analysis.
allel texts must have identical semantic mean-                  State-of-the-art (S-SA): OpinionFinder is a
ings, subjectivity–related annotations for one lan-             publicly-available NLP tool for subjectivity analy-
guage can be projected into other languages with-               sis (Wiebe and Riloff, 2005; Wilson et al., 2005).3
out much loss of accuracy.                                      The software and its resources have been widely
    The latter approach accepts any pair of multi-              used in the field of subjectivity analysis, and it
lingual texts as long as they are annotated with la-            has been the de facto standard system against
bels and/or intensity. In this case, evaluating the la-         which new systems are validated. We use a high-
bel consistency of a multilingual system is only as             coverage classifier from the OpinionFinder’s two
difficult as evaluating that of a monolingual sys-              sentence-level subjectivity classifiers. This Naive
tem; we can produce all possible pairs of texts                 Bayes classifier builds upon a corpus annotated by
from test corpora annotated with labels for each                a high-precision classifier with the bootstrapping
language. Evaluating with intensity is not easy for             of the corpus and extraction patterns. The classi-
the latter approach; if test corpora already exist              fier assesses a sentence’s subjectivity with a label
with intensity annotations for both languages, nor-             and a score for confidence in its judgment.
malizing the intensity scores to a comparable scale             Corpus-based (S-CB): The MPQA opinion cor-
is necessary (yet is uncertain unless every pair is             pus is a collection of 535 newspaper articles in En-
checked manually), otherwise every pair of mul-                 glish annotated with opinions and private states at
tilingual texts needs a manual annotation with its                 3
                                                                     http://www.cs.pitt.edu/mpqa/opinionfinderrelease/, ver-
relative order of intensity.                                    sion 1.5


                                                          597


the sub-sentence level (Wiebe et al., 2003).4 We                               a source language system (Kim and Hovy,
retrieve the sentence level subjectivity labels for                            2006; Bautin et al., 2008; Banea et al., 2008)
11,111 sentences using the set of rules described                           2. translating a source language training corpus
in (Wiebe and Riloff, 2005). The corpus provides                               into target language and creating a corpus-
a relatively balanced corpus with 55% subjective                               based system in target language (Banea et al.,
sentences. We train an ML-based classifier us-                                 2008)
ing the corpus. Previous studies have found that,                           3. translating a subjectivity lexicon from source
among several ML-based approaches, the SVM                                     language to target language and creating a
classifier generally performs well in many subjec-                             lexicon-based system in target language (Mi-
tivity analysis tasks (Pang et al., 2002; Banea et                             halcea et al., 2007)
al., 2008).
                                                                             Each approach has its advantages and disadvan-
   We use SVMLight with its default configura-                            tages. The advantage of the first approach is its
tions,5 inputted with a sentence represented as a                         simple architecture, clear separation of subjectiv-
feature vector of word unigrams and their counts                          ity and MT systems, and that it has only one sub-
in the sentence. An SVM score (a margin or the                            jectivity system, and is thus easier to maintain.
distance from a learned decision boundary) with a                         Its disadvantage is that the time-consuming MT
positive value predicts the input as being subjec-                        has to be executed for each text input. In the sec-
tive, and negative value as objective.                                    ond and third approaches, a subjectivity system in
Lexicon-based (S-LB): OpinionFinder contains a                            the target language is constructed sharing corpora,
list of English subjectivity clue words with in-                          rules, and/or features with the source language
tensity labels (Wilson et al., 2005). The lexicon                         system. Later on, it may also include its own set
is compiled from several manually and automati-                           of resources specifically engineered for the target
cally built resources and contains 6885 unique en-                        language as a performance improvement. How-
tries.                                                                    ever, keeping the systems up-to-date would require
   Riloff and Wiebe (2003) constructed a high-                            as much effort as the number of languages. All
precision classifier for contiguous sentences us-                         three approaches use MT, and would suffer sig-
ing the number of strong and weak subjective                              nificantly if the translation results are poor.
words in current and nearby sentences. Unlike pre-                           Using the first approach, we can easily adopt all
vious work, we do not (or rather, cannot) main-                           three source language systems;
tain assumptions about the proximity of input text.
Using the lexicon, we build a simple and high-                               • Target input translated into source, analyzed
coverage rule-based subjectivity classifier. Setting                           by source language system S-SA
the scores of strong and weak subjective words as                            • Target input translated into source, analyzed
1.0 and 0.5, we evaluate the subjectivity of a given                           by source language system S-CB
sentence as the sum of subjectivity scores; above                            • Target input translated into source, analyzed
a threshold, the input is subjective, and otherwise                            by source language system S-LB
objective. The threshold value is optimized for an                           The second and the third approaches are carried
F-measure using the MPQA corpus, and is set to                            out as follows:
1.0 throughout our experiments.                                           Corpus-based (T-CB): We translate the MPQA
                                                                          corpus into the target languages sentence by sen-
4.2         Target Language System                                        tence using a web-based service.6 Using the same
To construct a target language system leveraging                          method for S-CB, we train an SVM model for
on available resources in the source language, we                         each language with the translated training corpora.
consider three approaches from previous litera-                           Lexicon-based (T-LB): This classifier is identi-
ture:                                                                     cal to S-LB, where the English lexicon is replaced
                                                                          by one of the target languages. We automatically
  1. translating test sentences in target language                        translate the lexicon using free bilingual dictionar-
     into source language and inputting them into                         ies.7 First, the entries in the lexicon are looked
                                                                             6
                                                                              Google Translate (http://translate.google.com/)
      4                                                                      7
          http://www.cs.pitt.edu/mpqa/databaserelease/,   version             quick english-korean, quick eng-zh CN, and JMDict
1.2                                                                       from StarDict (http://stardict.sourceforge.net/) licensed under
      5
          http://svmlight.joachims.org/, version 6.02                     GPL and EDRDG.


                                                                    598


Table 1: Agreement on subjectivity (S for subjec-                   Table 2: Agreement on projection of subjectivity
tive, O objective) of 859 sentence chunks in Ko-                    (S for subjective, O objective) from Korean (KR)
rean between two annotators (An. 1 and An. 2).                      to English (EN) by one annotator.
                            An. 2                                                                 EN
                       S     O Total                                                       S      O Total
                S     371 93       464                                              S     458     6     464
            An. 1




                                                                              KR
                O      23 372 395                                                   O     12 383 395
              Total 394 465 859                                                   Total 470 389 859


up in the dictionary, if they are found, we se-                        To assess the performance of our subjectiv-
lect the first word in the first sense of the def-                  ity analysis systems, the Korean sentence chunks
inition. If the entry is not in the dictionary, we                  were manually annotated by two native speakers
lemmatize it,8 then repeat the search. Our sim-                     of Korean with Subjective and Objective labels
ple approach produces moderate-sized lexicons                       (Table 1). A proportion agreement of 0.86 and a
(3,808, 3,980, 3,027 for Korean, Chinese, and                       kappa value of 0.73 indicate a substantial agree-
Japanese) compared to Mihalcea et al. (2007)’s                      ment between the two annotators. We set aside
complicated translation approach (4,983 Roma-                       743 sentence chunks that both annotators agreed
nian words). The threshold values are optimized                     on for the automatic evaluation of subjectivity
using the MPQA corpus translated into each tar-                     analysis systems, thereby removing the borderline
get language.9                                                      cases, which are difficult even for humans to as-
                                                                    sess. The corresponding sentence chunks for other
5       Experiment                                                  languages were extracted and tagged with labels
                                                                    equivalent to Korean chunks.
5.1      Experimental Setup
                                                                       In addition, to verify how consistently the sub-
Test Corpus                                                         jectivity of the original texts is projected to the
   Our evaluation corpus consists of 50 parallel                    translated, we carried out another manual annota-
newspaper articles from the Donga Daily News                        tion and agreement study with Korean and English
Website.10 The website provides news articles in                    sentence chunks (Table 2).
Korean and their human translations in English,                        Note that our cross-lingual agreement study is
Japanese, and Chinese. We selected articles that                    similar to the one carried out by Mihalcea et
contain Editorial in its English title from a 30-                   al. (2007), where two annotators labeled the sen-
day period. Three human annotators who are flu-                     tence subjectivity of a parallel text in different lan-
ent in the two languages manually annotated N-                      guages. They reported that, similarly to monolin-
to-N sentence alignments for each language pairs                    gual annotations, most cases of disagreements on
(KR-EN, KR-CH, KR-JP). By keeping only the                          annotations are due to the differences in the anno-
sentence chunks whose Korean chunk appears in                       tators’ judgments on subjectivity, and the rest from
all language pairs, we were left with 859 sentence                  subjective meanings lost in the translation process
chunk pairs.                                                        and figurative language such as irony.
   The corpus was preprocessed with NLP tools                          To avoid the role played by annotators’ pri-
for each language,11 and the Korean, Chinese, and                   vate views from disagreements, the subjectivity of
Japanese texts were translated into English with                    sentence chunks in English were manually anno-
the same web-based service used to translate the                    tated by one of the annotators for the Korean text.
training corpus in Section 4.2.                                     Judged by the same annotator, we speculate that
Manual Annotation and Agreement Study                               the disagreement in the annotation should account
    8
     JWI (http://projects.csail.mit.edu/jwi/)
                                                                    only for the inconsistency in the subjectivity pro-
    9
     Korean 1.0, Chinese 1.0, and Japanese 0.5                      jection. By proportion, the agreement between the
  10
     http://www.donga.com/                                          annotation of Korean and English is 0.97, and the
  11
     Stanford POS Tagger 1.5.1 and Stanford Chinese Word            kappa is 0.96, suggesting an almost perfect agree-
Segmenter 2008-05-21 (http://nlp.stanford.edu/software/),
Chasen 2.4.4 (http://chasen-legacy.sourceforge.jp/), Korean         ment. Only a small number of sentence chunk
Morphological Analyzer (KoMA) (http://kle.postech.ac.kr/)           pairs have inconsistent labels; six chunks in Ko-


                                                              599


  Implicit sentiment expressed through translation:                      well and provides the most balanced results among
  * 시간이 갈수록(with time) 그 격차가(disparity/gap)                              the three source language systems; The corpus-
  벌어지고 있다(widening).                                                     based system (S-CB) classifies with a high pre-
  * Worse, the (economic) disparity (between South
                                                                         cision, and the lexicon-based (S-LB) with a high
  Korea and North Korea) is worsening with time.
                                                                         recall. The source language systems (S-SA,-CB,-
  Sentiment lost in translation:                                         LB) lose a small percentage in precision when in-
  * 인도의 타타 자동차회사는(India's Tata Motors)                                   putted with translations, but the recalls are gener-
  2200달러짜리 자동차 나노를(2,200-dollar                                          ally on a par or even higher in the target languages.
  automobile Nano) 내놓아(presented) 주목을 끌었다
                                                                            For the systems created from target language re-
  (drew attention).
  * India's Tata Motors has produced the 2,200-dollar                    sources, Corpus-based systems (T-CB) generally
  subcompact Nano.                                                       perform better than the ones with source language
                                                                         resource (S-CB), and lexicon-based systems (T-
Figure 2: Excerpts from Donga Daily News with                            LB) perform worse than (S-LB). Similarly to sys-
differing sentiments between parallel texts                              tems with source language resources, T-CB clas-
                                                                         sifies with a high precision and T-LB with a high
                                                                         recall, but the gap is less. Among the target lan-
rean lost subjectivity in translation, and implied                       guages, Korean tends to have a higher precision,
subjective meanings in twelve chunks were ex-                            and Japanese a higher recall than other languages
pressed explicitly through interpretation. Excerpts                      in most systems.
from our corpus show two such cases (Figure 2).                             Overall, S-SA provides easy accessibility when
Evaluation Metrics                                                       analyzing both the source and the target languages,
   To evaluate the multilanguage-comparability of                        with a balanced precision and recall performance.
subjectivity analysis systems, we measure 1) how                         Among the other approaches, only T-CB is bet-
consistently the system assigns subjectivity labels                      ter in all measures than S-SA, and S-LB performs
and 2) how closely numeric scores for systems’                           best on F-measure evaluations.
confidences correlate with regard to parallel texts
in different languages.                                                  5.3   Multilanguage-Comparability
   In particular, we use Cohen’s kappa coefficient
                                                                         The evaluation results on multilanguage-
for the first and Pearson’s correlation coefficient
                                                                         comparability are presented in Table 4. The
for the latter. These widely used metrics provide
                                                                         subjectivity analysis systems are evaluated with
useful comparability measures for categorical and
                                                                         all language pairs with kappa and Pearson’s
quantitative data.
                                                                         correlation coefficients. Kappa and Pearson’s
   Both coefficients are scaled from −1 to +1, in-
                                                                         correlation values are consistent with each other;
dicating negative to positive correlations. Kappa
                                                                         Pearson’s correlation between the two evaluation
measures are corrected for chance, thereby yield-
                                                                         measures is 0.91.
ing better measurements than agreement by pro-
portion. The characteristics of Pearson’s correla-                          We observe a distinct contrast in performances
tion coefficient that it measures linear relation-                       between corpus-based systems (S-CB and T-CB)
ships and is independent of change in origin, scale,                     and lexicon-based systems (S-LB and T-LB); All
and unit comply with our experiments.                                    corpus-based systems show moderate agreements
                                                                         while agreements on lexicon-based systems are
5.2      Subjectivity Classification                                     only fair.
                                                                            Within corpus-based systems, S-CB performs
Our multilingual subjectivity analysis systems
                                                                         better with language pairs that include English,
were evaluated on the test corpora described in
                                                                         and T-CB performs better with language pairs of
Section 5.1 (Table 3).
                                                                         the target languages.
   Due to the difference in testbeds, the perfor-
                                                                            For lexicon-based systems, systems in the tar-
mance of the state-of-the-art English system (S-
                                                                         get languages (T-LB) performs the worst with
SA) on our corpus is lower by about 10% rela-
                                                                         only slight to fair agreements between languages.
tively than the performance reported on the MPQA
                                                                         Lexicon-based systems and state-of-the-art sys-
corpus.12 However, it still performs sufficiently
                                                                         tems in the source language (S-LB and S-SA) re-
  12
       precision, recall, and F-measure of 79.4, 70.6, and 74.7.         sult in average performances.


                                                                   600


Table 3: Performance of subjectivity analysis with precision (P), recall (R), and F-measure (F). S-SA,-
CB,-LB systems in Korean, Chinese, Japanese indicate English analysis systems inputted with transla-
tions of the target languages into English.
                    English                 Korean                Chinese                Japanese
               P       R     F         P      R    F          P      R       F        P      R      F
  S-SA        71.1 63.5 67.1         70.7 61.1 65.6         67.3 68.8 68.0           69.1 67.5 68.3
  S-CB        74.4 53.9 62.5         74.5 52.2 61.4         71.1 63.3 67.0           72.9 65.3 68.9
  S-LB        62.5 87.7 73.0         62.9 87.7 73.3         59.9 91.5 72.4           61.8 94.1 74.6
  T-CB                               72.4 67.5 69.8         75.0 66.2 70.3           72.5 70.3 71.4
  T-LB                               59.4 71.0 64.7         58.4 82.3 68.2           56.9 92.4 70.4



Table 4: Performance of multilanguage-comparability: kappa coefficient (κ) for measuring comparability
of classification labels and Pearson’s correlation coefficient (ρ) for classification scores for English (EN),
Korean (KR), Chinese (CH), and Japanese (JP). Evaluations of T-CB,-LB for language pairs including
English are carried out with results from S-CB,-LB for English and T-CB,-LB for target languages.
                        S-SA             S-CB              S-LB               T-CB              T-LB
                      κ      ρ         κ      ρ          κ       ρ          κ       ρ         κ      ρ
      EN & KR 0.41 0.55              0.45 0.60         0.37 0.59          0.42 0.60         0.25 0.41
      EN & CH 0.39 0.54              0.41 0.62         0.33 0.52          0.39 0.57         0.22 0.38
       EN & JP 0.39 0.53             0.43 0.65         0.30 0.59          0.40 0.59         0.15 0.33
      KR & CH 0.36 0.54              0.39 0.59         0.28 0.57          0.46 0.64         0.23 0.37
       KR & JP 0.37 0.60             0.44 0.69         0.50 0.69          0.63 0.76         0.18 0.38
       CH & JP 0.37 0.53             0.49 0.66         0.29 0.57          0.46 0.63         0.22 0.46
       Average 0.38 0.55             0.44 0.64         0.35 0.59          0.46 0.63         0.21 0.39


       100                                                                                                                             10
                                                                         4


                                                                         3

        50                                                                                                                              5
                                                                         2


                                                                         1


         0                                                               0                                                              0


                                                                         -1


                                                                         -2
        -50                                                                                                                             -5

                                                                         -3


                                                                         -4
       -100                                                                                                                            -10
          -100   -50        0                  50              100            -4   -3   -2    -1    0            1   2    3    4          -10       -5          0   5   10



                       (a) S-SA                                                              (b) S-CB                                                    (c) S-LB

                                                                                                        10
                                4


                                3

                                                                                                         5
                                2


                                1


                                0                                                                        0


                                -1


                                -2
                                                                                                         -5

                                -3


                                -4
                                                                                                        -10
                                     -4   -3        -2    -1         0        1    2    3     4            -10           -5        0            5          10



                                                         (d) T-CB                                                             (e) T-LB

Figure 3: Scatter plots of English (x-axis) and Korean (y-axis) subjectivity scores from state-of-the-art
(S-SA), corpus-based (S-CB), and lexicon-based (S-LB) systems of the source language, and corpus-
based with translated corpora (T-CB), and lexicon-based with translated lexicon (T-LB) systems. Slanted
lines in figures are best-fit lines through the origins.



                                                                                                   601


    Figure 3 shows scatter plots of subjectivity             Pearson’s correlation metrics to measure the corre-
scores of our English and Korean test corpora eval-          lations of precision (P), recall (R), and F-measures
uated on different systems; the data points on the           (F) to kappa (κ) and Pearson’s correlation (ρ) val-
first and the third quadrants are occurrences of la-         ues.
bel agreements, and the second and the fourth are               Specifically, we measure the correlations be-
disagreements. Linearly scattered data points are            tween the sums of P, the sums of R, and the
more correlated regardless of the slope.                     sums of F to κ and ρ for all pairs of systems.13
    Figure 3a shows a moderate correlation for mul-          The correlations of P with κ and ρ are 0.78
tilingual results from the state-of-the-art system           and 0.68, R −0.38 and −0.28, and F −0.20
(S-SA). Agreements on objective instances are                and −0.05. These numbers strongly suggest that
clustered together while agreements on subjective            multilanguage-comparability correlates with the
instances are diffused over a wide region.                   precisions of classifiers.
    Agreements between the source language                      However, we cannot always expect a high-
corpus-based system (S-CB) and the corpus-based              precision multilingual subjectivity classifier to be
system trained with translated resources (T-CB)              multilanguage-comparable as well. For example,
are more distinctively correlated than the results           the S-SA system has a much higher precision
for other pairs of systems (Figures 3b and 3d). We           than S-LB consistently over all languages, but
notice that S-CB seems to have a lower number of             their multilanguage-comparability performances
outliers than T-CB, but slightly more diffusive.             differed only by small amounts.
    Lexicon-based systems (S-LB, T-LB) gener-
ate noticeably uncorrelated scores (Figures 3c and           7    Conclusion
3e). We observe that the results from the English
system with translated inputs (S-LB) is more cor-            Multilanguage-comparability is an analysis sys-
related than those from systems with translated              tem’s ability to retain its decision criteria across
lexicons (T-LB), and that analysis results from              different languages. We implemented a number of
both systems are biased toward subjective scores.            previously proposed approaches to learning mul-
                                                             tilingual subjectivity, and evaluated the systems
6   Discussion                                               on multilanguage-comparability as well as clas-
                                                             sification performance. Our experimental results
Which approach is most suitable for multilingual
                                                             provide meaningful comparisons of the multilin-
subjectivity analysis?
                                                             gual subjectivity analysis systems across various
   In our experiments, the corpus-based sys-
                                                             aspects.
tems trained on corpora translated from English
                                                                 Also, we developed a multilingual subjectivity
to the target languages (T-CB) perform well
                                                             evaluation corpus from a parallel text, and studied
for subjectivity classification and multilanguage-
                                                             inter-annotator, inter-language agreements on sub-
comparability measures on the whole. However,
                                                             jectivity, and observed persistent subjectivity pro-
the methods we employed to expand the languages
                                                             jections from one language to another from a par-
were naively carried out without much considera-
                                                             allel text.
tions for optimization. Further adjustments could
improve the other systems for both classification                For future work, we aim extend this work to
and multilanguage-comparability performances.                constructing a multilingual sentiment analysis sys-
Is there a correlation between classification per-           tem and evaluate it with multilingual datasets
formance and multilanguage-comparability?                    such as product reviews collected from different
                                                             countries. We also plan to resolve the lexicon-
   Lexicon-based systems in the source language
                                                             based classifiers’ classification bias towards sub-
(S-LB) have good overall classification perfor-
                                                             jective meanings with a list of objective words
mances, especially on recall and F-measures.
                                                             (Esuli and Sebastiani, 2006) and their multilin-
However, these systems performs worse on
                                                             gual expansion (Kim et al., 2009), and evaluate
multilanguage-comparability than other systems
                                                             the multilanguage-comparability of systems con-
with poorer classification performances. Intrigued
                                                             structed with resources from different sources.
by the observation, we tried to measure which
criteria for classification performance influences              13
                                                                   Pairs of values such as 71.1 + 70.7 and 0.41 for preci-
multilanguage-comparability. We again employed               sions and Kappa of S-SA for English and Korean.


                                                       602


Acknowledgement                                                  and a link analysis algorithm. In ICCPOL ’09: Pro-
                                                                 ceedings of the 22nd International Conference on
We thank the anonymous reviewers for valuable                    Computer Processing of Oriental Languages. Lan-
comments and helpful suggestions. This work is                   guage Technology for the Knowledge-based Econ-
supported in part by Basic Science Research Pro-                 omy, pages 112–121, Berlin, Heidelberg.
gram through the National Research Foundation                  Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
of Korea (NRF) funded by the Ministry of Edu-                    2007. Learning multilingual subjective language via
cation, Science and Technology (MEST) (2009-                     cross-lingual projections. In Proceedings of the 45th
                                                                 Annual Meeting of the Association of Computational
0075211), and in part by the BK 21 project in
                                                                 Linguistics (ACL’07), pages 976–983, Prague, CZ.
2010.
                                                               Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
                                                                 2002. Thumbs up? Sentiment classification using
References                                                       machine learning techniques. In Proceedings of the
                                                                 Conference on Empirical Methods in Natural Lan-
Ahmed Abbasi, Hsinchun Chen, and Arab Salem.                     guage Processing (EMNLP), pages 79–86.
  2008. Sentiment analysis in multiple languages:
  Feature selection for opinion classification in web          Ellen Riloff and Janyce Wiebe. 2003. Learning ex-
  forums. ACM Transactions on Information Systems,                traction patterns for subjective expressions. In Pro-
  26(3):1–34.                                                     ceedings of the Conference on Empirical Methods in
                                                                  Natural Language Processing (EMNLP).
Carmen Banea, Rada Mihalcea, Janyce Wiebe, and
  Samer Hassan. 2008. Multilingual subjectivity                Xiaojun Wan. 2008. Using bilingual knowledge and
  analysis using machine translation. In EMNLP ’08:              ensemble techniques for unsupervised Chinese sen-
  Proceedings of the Conference on Empirical Meth-               timent analysis. In Proceedings of the 2008 Con-
  ods in Natural Language Processing, pages 127–                 ference on Empirical Methods in Natural Language
  135, Morristown, NJ, USA.                                      Processing, pages 553–561, Honolulu, Hawaii, Oc-
                                                                 tober. Association for Computational Linguistics.
Mikhail Bautin, Lohit Vijayarenu, and Steven Skiena.
  2008. International sentiment analysis for news and          Xiaojun Wan. 2009. Co-training for cross-lingual sen-
  blogs. In Proceedings of the International Confer-             timent classification. In Proceedings of the Joint
  ence on Weblogs and Social Media (ICWSM).                      Conference of the 47th Annual Meeting of the ACL
                                                                 and the 4th International Joint Conference on Nat-
Erik Boiy and Marie-Francine Moens. 2009. A                      ural Language Processing of the AFNLP, pages
   machine learning approach to sentiment analysis               235–243, Suntec, Singapore, August. Association
   in multlingual Web texts. Information Retrieval,              for Computational Linguistics.
   12:526–558.
                                                               Janyce Wiebe and Ellen Riloff. 2005. Creating subjec-
Julian Brooke, Milan Tofiloski, and Maite Taboada.                tive and objective sentence classifiers from unanno-
   2009. Cross-linguistic sentiment analysis: From en-            tated texts. In Proceedings of the 6th International
   glish to spanish. In Proceedings of RANLP 2009,                Conference on Intelligent Text Processing and Com-
   Borovets, Bulgaria.                                            putational Linguistics (CICLing-2005), pages 486–
                                                                  497, Mexico City, Mexico.
Carmine Cesarano, Antonio Picariello, Diego Refor-
  giato, and V.S. Subrahmanian. 2007. The oasys 2.0            Janyce Wiebe, E. Breck, Christopher Buckley, Claire
  opinion analysis system: A demo. In Proceedings of              Cardie, P. Davis, B. Fraser, Diane Litman, D. Pierce,
  the International Conference on Weblogs and Social              Ellen Riloff, Theresa Wilson, D. Day, and Mark
  Media (ICWSM).                                                  Maybury. 2003. Recognizing and organizing opin-
                                                                  ions expressed in the world press. In Proceedings
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-                of the 2003 AAAI Spring Symposium on New Direc-
  wordnet: A publicly available lexical resource for              tions in Question Answering.
  opinion mining. In Proceedings of the 5th Con-
  ference on Language Resources and Evaluation                 Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
  (LREC’06), pages 417–422, Geneva, IT.                          2005. Recognizing contextual polarity in phrase-
                                                                 level sentiment analysis. In Proceedings of the Con-
Soo-Min Kim and Eduard Hovy. 2006. Identifying
                                                                 ference on Human Language Technology and Em-
  and analyzing judgment opinions. In Proceedings
                                                                 pirical Methods in Natural Language Processing
  of the Human Language Technology Conference of
                                                                 (HLT-EMNLP’05), pages 347–354, Vancouver, CA.
  the NAACL (HLT/NAACL’06), pages 200–207, New
  York, USA.
Jungi Kim, Hun-Young Jung, Sang-Hyob Nam, Yeha
  Lee, and Jong-Hyeok Lee. 2009. Found in trans-
  lation: Conveying subjectivity of a lexicon of one
  language into another using a bilingual dictionary


                                                         603

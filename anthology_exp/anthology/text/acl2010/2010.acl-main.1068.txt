      Towards robust multi-tool tagging. An OWL/DL-based approach

                                           Christian Chiarcos
                                      University of Potsdam, Germany
                                     chiarcos@uni-potsdam.de




                      Abstract                                 (parts of speech, pos) and morphology in German:
                                                               In comparison to English, German shows a rich
    This paper describes a series of experi-                   and polysemous morphology, and a considerable
    ments to test the hypothesis that the paral-               number of NLP tools are available, making it a
    lel application of multiple NLP tools and                  promising candidate for such an experiment.
    the integration of their results improves the                 Previous research indicates that the integration
    correctness and robustness of the resulting                of multiple part of speech taggers leads to more
    analysis.                                                  accurate analyses. So far, however, this line of re-
    It is shown how annotations created by                     search focused on tools that were trained on the
    seven NLP tools are mapped onto tool-                      same corpus (Brill and Wu, 1998; Halteren et al.,
    independent descriptions that are defined                  2001), or that specialize to different subsets of the
    with reference to an ontology of linguistic                same tagset (Zavrel and Daelemans, 2000; Tufiş,
    annotations, and how a majority vote and                   2000; Borin, 2000). An even more substantial in-
    ontological consistency constraints can be                 crease in accuracy and detail can be expected if
    used to integrate multiple alternative ana-                tools are combined that make use of different an-
    lyses of the same token in a consistent                    notation schemes.
    way.                                                          For this task, ontologies of linguistic annota-
                                                               tions are employed to assess the linguistic infor-
    For morphosyntactic (parts of speech) and                  mation conveyed in a particular annotation and to
    morphological annotations of three Ger-                    integrate the resulting ontological descriptions in a
    man corpora, the resulting merged sets of                  consistent and tool-independent way. The merged
    ontological descriptions are evaluated in                  set of ontological descriptions is then evaluated
    comparison to (ontological representation                  with reference to morphosyntactic and morpho-
    of) existing reference annotations.                        logical annotations of three corpora of German
                                                               newspaper articles, the NEGRA corpus (Skut et
1   Motivation and overview                                    al., 1998), the TIGER corpus (Brants et al., 2002)
NLP systems for higher-level operations or com-                and the Potsdam Commentary Corpus (Stede,
plex annotations often integrate redundant modu-               2004, PCC).
les that provide alternative analyses for the same
                                                               2   Ontologies and annotations
linguistic phenomenon in order to benefit from
their respective strengths and to compensate for               Various repositories of linguistic annotation termi-
their respective weaknesses, e.g., in parsing (Crys-           nology have been developed in the last decades,
mann et al., 2002), or in machine translation (Carl            ranging from early texts on annotation standards
et al., 2000). The current trend to parallel and dis-          (Bakker et al., 1993; Leech and Wilson, 1996)
tributed NLP architectures (Aschenbrenner et al.,              over relational data base models (Bickel and
2006; Gietz et al., 2006; Egner et al., 2007; Luı́s            Nichols, 2000; Bickel and Nichols, 2002) to
and de Matos, 2009) opens the possibility of ex-               more recent formalizations in OWL/RDF (or with
ploring the potential of redundant parallel annota-            OWL/RDF export), e.g., the General Ontology of
tions also for lower levels of linguistic analysis.            Linguistic Description (Farrar and Langendoen,
   This paper evaluates the potential benefits of              2003, GOLD), the ISO TC37/SC4 Data Cate-
such an approach with respect to morphosyntax                  gory Registry (Ide and Romary, 2004; Kemps-


                                                         659
        Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659–670,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


Snijders et al., 2009, DCR), the OntoTag ontology              to the formal representation and documentation of
(Aguado de Cea et al., 2002), or the Typological               annotation schemes, and for concept-based anno-
Database System ontology (Saulwick et al., 2005,               tation queries over to multiple, heterogeneous cor-
TDS). Despite their common level of representa-                pora annotated with different annotation schemes
tion, however, these efforts have not yet converged            (Rehm et al., 2007; Chiarcos et al., 2008). NLP
into a unified and generally accepted ontology of              applications of the OLiA ontologies include a pro-
linguistic annotation terminology, but rather, dif-            posal to integrate them with the OntoTag ontolo-
ferent resources are maintained by different com-              gies and to use them for interface specifications
munities, so that a considerable amount of dis-                between modules in NLP pipeline architectures
agreement between them and their respective defi-              (Buyko et al., 2008). Further, Hellmann (2010)
nitions can be observed.1                                      described the application of the OLiA ontologies
    Such conceptual mismatches and incompatibi-                within NLP2RDF, an OWL-based blackboard ap-
lities between existing terminological repositories            proach to assess the meaning of text from gram-
have been the motivation to develop the OLiA ar-               matical analyses and subsequent enrichment with
chitecture (Chiarcos, 2008) that employs a shal-               ontological knowledge sources.
low Reference Model to mediate between (onto-                     OLiA distinguishes three different classes of
logical models of) annotation schemes and several              ontologies:
existing terminology repositories, incl. GOLD, the               • The OL I A R EFERENCE M ODEL specifies
DCR, and OntoTag. When an annotation receives                      the common terminology that different anno-
a representation in the OLiA Reference Model,                      tation schemes can refer to. It is primarily
it is thus also interpretable with respect to other                based on a blend of concepts of EAGLES and
linguistic ontologies. Therefore, the findings for                 GOLD, and further extended in accordance
the OLiA Reference Model in the experiments de-                    with different annotation schemes, with the
scribed below entail similar results for an applica-               TDS ontology and with the DCR (Chiarcos,
tion of GOLD or the DCR to the same task.                          2010).
2.1 The OLiA ontologies                                          • Multiple OL I A A NNOTATION M ODELs for-
The Ontologies of Linguistic Annotations –                         malize annotation schemes and tag sets. An-
briefly, OLiA ontologies (Chiarcos, 2008) – re-                    notation Models are based on the original
present an architecture of modular OWL/DL on-                      documentation and data samples, so that they
tologies that formalize several intermediate steps                 provide an authentic representation of the an-
of the mapping between concrete annotations, a                     notation not biased with respect to any partic-
Reference Model and existing terminology reposi-                   ular interpretation.
tories (‘External Reference Models’ in OLiA ter-                 • For every Annotation Model, a L INKING
minology) such as the DCR.2                                        M ODEL defines subClassOf (v) relation-
   The OLiA ontologies were originally develo-                     ships between concepts/properties in the re-
ped as part of an infrastructure for the sustain-                  spective Annotation Model and the Refe-
able maintenance of linguistic resources (Schmidt                  rence Model. Linking Models are interpre-
et al., 2006) where they were originally applied                   tations of Annotation Model concepts and
    1
      As one example, a GOLD Numeral is a De-                      properties in terms of the Reference Model,
terminer (Numeral v Quantifier v Determiner,                       and thus multiple alternative Linking Models
http://linguistics-ontology.org/gold/2008/                         for the same Annotation Model are possi-
Numeral),      whereas a DCR Numeral is de-
fined on the basis of its semantic function,                       ble. Other Linking Models specify v re-
without any references to syntactic categories                     lationships between Reference Model con-
(http://www.isocat.org/datcat/DC-1334).                            cepts/properties and concepts/properties of
Thus, two in two of them is a DCR Numeral but not a GOLD
Numeral.                                                           an External Reference Model such as GOLD
    2
      The OLiA Reference Model is accessible via                   or the DCR.
http://nachhalt.sfb632.uni-potsdam.de/owl/
olia.owl. Several annotation models, e.g., stts.owl,           The OLiA Reference Model (namespace olia)
tiger.owl, connexor.owl, morphisto.owl can be                  specifies concepts that describe linguistic cate-
found in the same directory together with the corresponding
linking files stts-link.rdf, tiger-link.rdf,                   gories (e.g., olia:Determiner) and grammati-
connexor-link.rdf and morphisto-link.rdf.                      cal features (e.g., olia:Accusative), as well


                                                         660


 Figure 1: Attributive demonstrative pronouns               Figure 2: Selected morphosyntactic categories in the
 (PDAT) in the STTS Annotation Model                        OLiA Reference Model




 Figure 3: Individuals for accusative and sin-              Figure 4: Selected morphological features in the
 gular in the TIGER Annotation Model                        OLiA Reference Model

as properties that define possible relations be-                         Figs. 2 and 4 show excerpts of category and fea-
tween those (e.g., olia:hasCase). More gen-                           ture hierarchies in the Reference Model.
eral concepts that represent organizational in-
formation rather than possible annotations (e.g.,                         With respect to morphosyntactic annotations
MorphosyntacticCategory and CaseFeature)                              (parts of speech, pos) and morphological an-
are stored in a separate ontology (namespace                          notations (morph), five Annotation Models for
olia top).                                                            German are currently available: STTS (Schiller
                                                                      et al., 1999, pos), TIGER (Brants and Hansen,
   The Reference Model is a shallow ontology: It
                                                                      2002, morph), Morphisto (Zielinski and Simon,
does not specify disjointness conditions of con-
                                                                      2008, pos, morph), RFTagger (Schmid and Laws,
cepts and cardinality or domain restrictions of
                                                                      2008, pos, morph), Connexor (Tapanainen and
properties. Instead, it assumes that such con-
                                                                      Järvinen, 1997, pos, morph). Further Annotation
straints are inherited by means of v relationships
                                                                      Models for pos and morph cover five different an-
from an External Reference Model. Different Ex-
                                                                      notation schemes for English (Marcus et al., 1994;
ternal Reference Models may take different posi-
                                                                      Sampson, 1995; Mandel, 2006; Kim et al., 2003,
tions on the issue – as languages do3 –, so that
                                                                      Connexor), two annotation schemes for Russian
this aspect is left underspecified in the Reference
                                                                      (Meyer, 2003; Sharoff et al., 2008), an annotation
Model.
                                                                      scheme designed for typological research and cur-
    3
      Based on primary experience with Western Euro-                  rently applied to approx. 30 different languages
pean languages, for example, one might assume that a                  (Dipper et al., 2007), an annotation scheme for
hasGender property applies to nouns, adjectives, pronouns             Old High German (Petrova et al., 2009), and an an-
and determiners only. Yet, this is language-specific restric-
tion: Russian finite verbs, for example, show gender congru-          notation scheme for Tibetan (Wagner and Zeisler,
ency in past tense.                                                   2004).


                                                                661


                                                            or the DCR).
                                                               As an example, consider the attributive demon-
                                                            strative pronoun diese in (1).
                                                                   Diese      nicht         neue     Erkenntnis     konnte
                                                            (1)    this       not           new      insight        could
                                                                   der     Markt          der      Möglichkeiten   am
                                                                   the     market         of.the   possibilities    on.the
                                                                   Sonnabend     in       Treuenbrietzen   bestens
                                                                   Saturday      in       Treuenbrietzen   in.the.best.way
                                                                   unterstreichen     .
                                                                   underline
                                                                  ‘The ‘Market of Possibilities’, held this Saturday
                                                                  in Treuenbrietzen, provided best evidence for this
                                                                  well-known (lit. ‘not new’) insight.’ (PCC, #4794)

                                                            The phrase diese nicht neue Erkenntnis poses two
                                                            challenges. First, it has to be recognized that the
                                                            demonstrative pronoun is attributive, although it is
                                                            separated from adjective and noun by nicht ‘not’.
Figure 5: The STTS tags PDAT and ART, their rep-            Second, the phrase is in accusative case, although
resentation in the Annotation Model and linking             the morphology is ambiguous between accusative
with the Reference Model.                                   and nominative, and nominative case would be ex-
                                                            pected for a sentence-initial NP.
                                                                The Connexor analysis (Tapanainen and
   Annotation Models differ from the Reference
                                                            Järvinen, 1997) actually fails in both aspects (2).
Model mostly in that they include not only con-
cepts and properties, but also individuals: An-             (2) PRON Dem FEM SG NOM (Connexor)
notation Model concepts reflect an abstract con-            The ontological analysis of this annotation begins
ceptual categorization, whereas individuals re-             by identifying the set of individuals from the Con-
present concrete values used to annotate the                nexor Annotation Model that match it according
corresponding phenomenon. An individual is                  to their hasTag (etc.) properties. The RDF triplet
applicable to all annotations that match the                connexor:NOM connexor:hasTagContaining
string value specified by this individual’s hasTag,         ‘NOM’4   indicates that the tag is an application
hasTagContaining, hasTagStartingWith, or
                                                            of the individual connexor:NOM, an instance
hasTagEndingWith properties.          Fig. 1 illus-         of connexor:Case.           Further, the annota-
trates the structure of the STTS Annotation                 tion matches connexor:PRON (an instance of
Model (namespace stts) for the individual                   connexor:Pronoun), etc. The result is a set of
stts:PDAT that represents the tag used for at-
                                                            individuals that express different aspects of the
tributive demonstrative pronouns (demonstrative             meaning of the annotation.
determiners). Fig. 3 illustrates the individuals               For these individuals, the Annotation Model
tiger:accusative and tiger:singular from
                                                            specifies superclasses (rdf:type) and other prop-
the hierarchy of morphological features in the              erties, i.e., connexor:NOM connexor:hasCase
TIGER Annotation Model (namespace tiger).                   connexor:NOM, etc. The linguistic unit repre-
   Fig. 5 illustrates the linking between the STTS          sented by the actual token can now be character-
Annotation Model and the OLiA Reference Model               ized by these properties: Every property applica-
for the individuals stts:PDAT and stts:ART.                 ble to a member in the individual set is assumed to
                                                            be applicable to the linguistic unit as well. In order
2.2 Integrating different morphosyntactic                   to save space, we use a notation closer to predicate
    and morphological analyses                              logic (with the token as implicit subject). In terms
With the OLiA ontologies as described above, an-            of the Annotation Model, the token diese is thus
notations from different annotation schemes can             described by the following descriptions:
now be interpreted in terms of the OLiA Reference              4
                                                                 RDF triplets are quoted in simplified form, with XML
Model (or External Reference Models like GOLD               namespaces replacing the actual URIs.


                                                      662


(3) rdf:type(connexor:Pronoun)
    connexor:hasCase(connexor:NOM) ...

The Linking Model connexor-link.rdf
provides us with the information that (i)
connexor:Pronoun is a subclass of the Re-
ference Model concept olia:Pronoun, (ii)
connexor:NOM is an instance of the Reference
Model concept olia:Nominative, and (iii)
olia:hasCase is a subproperty of olia:hasCase.
   Accordingly, the predicates that describe the to-
ken diese can be reformulated in terms of the Re-
ference Model. rdf:type(connexor:Pronoun)
entails rdf:type(olia:Pronoun), etc. Similarly,
we know that for some i:olia:Nominative it is
true that olia:hasCase(i), abbreviated here as
olia:hasCase(some olia:Nominative).                                              Figure 6: Evaluation setup
   In this way, the grammatical information con-
veyed in the original Connexor annotation can
be represented in an annotation-independent and                       TIGER/NEGRA-style morphosyntactic or mor-
tagset-neutral way as shown for the Connexor a-                       phological annotation (Skut et al., 1998; Brants
nalysis in (4).                                                       and Hansen, 2002) whose annotations are used as
                                                                      gold standard.
(4) rdf:type(olia:PronounOrDeterminer)                                  From the annotated document, the plain tok-
    rdf:type(olia:Pronoun)
    olia:hasNumber(some olia:Singular)
                                                                      enized text is extracted and analyzed by one or
    olia:hasGender(some olia:Feminine)                                more of the following NLP tools:
    rdf:type(olia:DemonstrativePronoun)
    olia:hasCase(some olia:Nominative)                                (i) Morphisto, a morphological analyzer without
                                                                          contextual disambiguation (Zielinski and Si-
Analogously, the corresponding RFTagger analy-
                                                                          mon, 2008),
sis (Schmid and Laws, 2008) given in (5) can
be transformed into a description in terms of the                 (ii) two part of speech taggers: the TreeTag-
OLiA Reference Model such as in (6).                                   ger (Schmid, 1994) and the Stanford Tagger
(5) PRO.Dem.Attr.-3.Acc.Sg.Fem (RFTagger)                              (Toutanova et al., 2003),

(6) rdf:type(olia:PronounOrDeterminer)                           (iii) the RFTagger that performs part of speech and
    olia:hasNumber(some olia:Singular)                                 morphological analysis (Schmid and Laws,
    olia:hasGender(some olia:Feminine)
    olia:hasCase(some olia:Accusative)                                 2008),
    rdf:type(olia:DemonstrativeDeterminer)
    rdf:type(olia:Determiner)                                     (iv) two PCFG parsers: the StanfordParser (Klein
                                                                       and Manning, 2003) and the BerkeleyParser
For every description obtained from these (and                         (Petrov and Klein, 2007), and
further) analyses, an integrated and consistent gen-
eralization can be established as described in the                (v) the Connexor dependency parser (Tapanainen
following section.                                                    and Järvinen, 1997).

3    Processing linguistic annotations                                These tools annotate parts of speech, and those in
                                                                      (i), (iii) and (v) also provide morphological fea-
3.1 Evaluation setup
                                                                      tures. All components ran in parallel threads on
Fig. 6 sketches the architecture of the evalua-                       the same machine, with the exception of Mor-
tion environment set up for this study.5 The in-                      phisto that was addressed as a web service. The set
put to the system is a set of documents with                          of matching Annotation Model individuals for ev-
  5
    The code used for the evaluation setup is available under         ery annotation and the respective set of Reference
http://multiparse.sourceforge.net.                                    Model descriptions are determined by means of


                                                                663


                             P
 OLiA description                  Morphisto    Connexor          RF        Tree        Stanford        Stanford           Berkeley
                                                                Tagger     Tagger        Tagger          Parser             Parser
 word class type(...)
 PronounOrDeterminer          7     1(4/4)∗        1               1            1            1              1                  1
 Determiner                  5.5     0.5∗∗         0               1            1            1              1                  1
 DemonstrativeDeterminer     5.5     0.5∗∗         0               1            1            1              1                  1
 Pronoun                     1.5     0.5∗∗         1               0            0            0              0                  0
 DemonstrativePronoun        1.5     0.5∗∗         1               0            0            0              0                  0
 morphology hasXY(...)                                                         n/a          n/a            n/a                n/a
 hasNumber(some Singular)    2.5    0.5 (2/4)      1               1       ∗
                                                                             Morphisto produces four alternative candidate analyses
 hasGender(some Feminine)    2.5    0.5 (2/4)      1               1       for this example, so every alternative analysis receives the
 hasCase(some Accusative)    1.5    0.5 (2/4)      0               1       confidence score 0.25
 hasCase(some Nominative)    1.5    0.5 (2/4)      1               0       ∗∗
                                                                               Morphisto does not distinguish attributive and substitutive
 hasNumber(some Plural)      0.5    0.5 (2/4)      0               0       pronouns, it predicts type(Determiner t Pronoun)


                               Table 1: Confidence scores for diese in ex. (1)


the Pellet reasoner (Sirin et al., 2007) as described           The consistency of ontological descriptions is de-
above.                                                          fined here as follows:6
   A disambiguation routine (see below) then de-
termines the maximal consistent set of ontological                 • Two concepts A and B are consistent iff
descriptions. Finally, the outcome of this process                                   A ≡ B or A v B or B v A
is compared to the set of descriptions correspond-
ing to the original annotation in the corpus.                          Otherwise, A and B are disjoint.

3.2 Disambiguation                                                 • Two descriptions pred1 (A) and pred2 (B)
                                                                     are consistent iff
Returning to examples (4) and (6) above, we
see that the resulting set of descriptions con-                                    A and B are consistent or
veys properties that are obviously contradic-                                    pred1 is neither a subproperty
ting, e.g., hasCase(some Nominative) besides                                     nor a superproperty of pred2
hasCase(some Accusative).
                                                                This heuristic formalizes an implicit disjoint-
   Our approach to disambiguation combines on-
                                                                ness assumption for all concepts in the on-
tological consistency criteria with a confidence
                                                                tology (all concepts are disjoint unless one
ranking. As we simulate an uninformed approach,
                                                                is a subconcept of the other).         Further, it
the confidence ranking follows a majority vote.
                                                                imposes an implicit cardinality constraint on
   For diese in (1), the consultation of all seven
                                                                properties (e.g., hasCase(some Accusative) and
tools results a confidence ranking as shown in Tab.
                                                                hasCase(some Nominative) are inconsistent be-
1: If a tool supports a description with its analy-
                                                                cause Accusative and Nominative are sibling
sis, the confidence score is increased by 1 (or by
                                                                concepts and thus disjoint).
1/n if the tool proposes n alternative annotations).
                                                                   For the example diese, the descriptions
A maximal consistent set of descriptions is then
                                                                type(Pronoun) and type(DemonstrativePro-
established as follows:
                                                                noun) are inconsistent with type(Determiner),
                                                                and hasNumber(some Plural) is inconsistent
  (i) Given a confidence-ranked list of available               with hasNumber(some Singular) (Figs. 2 and
      descriptions S = (s1 , ..., sn ) and a result set         4); these descriptions are thus ruled out. The
      T = ∅.                                                    hasCase descriptions have identical confidence
                                                                scores, so that the first hasCase description that
 (ii) Let s1 be the first element of S              =           the algorithm encounters is chosen for the set of
      (s1 , ..., sn ).                                          resulting descriptions, the other one is ruled out
                                                                because of their inconsistency.
(iii) If s1 is consistent with every description t ∈
                                                                   6
      T , then add s1 to T :        T := T ∪ {s1 }                   The OLiA Reference Model does not specify disjoint-
                                                                ness constraints, and neither do GOLD or the DCR as Exter-
                                                                nal Reference Models. The axioms of the OntoTag ontolo-
(iv) Remove s1 from S and iterate in (ii) until S               gies, however, are specific to Spanish and cannot be directly
     is empty.                                                  applied to German.


                                                          664


                          PCC           TIGER           NEGRA                                      TIGER        NEGRA
          best-performing tool (StanfordTagger)                                  1 tool          .678 (.106)   .660 (.091)
                           .960           .956            .990∗                      Morphisto      .573          .568
          average (and std. deviation) for tool combinations                         Connexor       .674          .662
              1 tool   .868 (.109) .864 (.122)         .870 (.113)                   RFTagger       .786          .751
              2 tools .928 (.018) .931 (.021)          .943 (.028)               2 tools         .761 (.019)   .740 (.012)
              3 tools .947 (.014) .948 (.013)          .956 (.018)                   C+M            .738          .730
              4 tools .956 (.006) .955 (.009)          .963 (.013)                   M+R            .769          .737
              5 tools .959 (.006) .960 (.007)          .964 (.009)                   C+R            .773          .753
              6 tools .963 (.003) .963 (.007)          .965 (.007)               all tools          .791          .770
          all tools        .967           .960             .965
          ∗
              The Stanford Tagger was trained on the NEGRA corpus.
                                                                               Table 3:     Recall for morphological
    Table 2: Recall for rdf:type descriptions for word classes                 hasXY()    descriptions


   The resulting, maximal consistent set of de-                      4.1   Word classes
scriptions is then compared with the ontological
                                                                     Table 2 shows that the recall of rdf:type de-
descriptions that correspond to the original anno-
                                                                     scriptions (for word classes) increases continu-
tation in the corpus.
                                                                     ously with the number of NLP tools applied. The
                                                                     combination of all seven tools actually shows a
4       Evaluation
                                                                     better recall than the best-performing single NLP
Six experiments were conducted with the goal to                      tool. (The NEGRA corpus is an apparent excep-
evaluate the prediction of word classes and mor-                     tion only; the exceptionally high recall of the Stan-
phological features on parts of three corpora of                     ford Tagger reflects the fact that it was trained on
German newspaper articles: NEGRA (Skut et al.,                       NEGRA.)
1998), TIGER (Brants et al., 2002), and the Pots-                       A particularly high increase in recall occurs
dam Commentary Corpus (Stede, 2004, PCC).                            when tools are combined that compensate for their
From every corpus 10,000 tokens were considered                      respective deficits. Morphisto, for example, ge-
for the analysis.                                                    nerates alternative morphological analyses, so that
   TIGER and NEGRA are well-known resources                          the disambiguation algorithm performs a random
that also influenced the design of several of the                    choice between these. Morphisto has thus the
tools considered. For this reason, the PCC was                       worst recall among all tools considered (PCC .69,
consulted, a small collection of newspaper com-                      TIGER .65, NEGRA .70 for word classes). As
mentaries, 30,000 tokens in total, annotated with                    compared to this, Connexor performs a contextual
TIGER-style parts of speech and syntax (by mem-                      disambiguation; its recall is, however, limited by
bers of the TIGER project). None of the tools con-                   its coarse-grained word classes (PCC .73, TIGER
sidered here were trained on this data, so that it                   .72, NEGRA .73). The combination of both tools
provides independent test data.                                      yields a more detailed and context-sensitive ana-
   The ontological descriptions were evaluated for                   lysis and thus results in a boost in recall by more
recall:7                                                             than 13% (PCC .87, TIGER .86, NEGRA .86).
                    Pn
                            |Dpredicted (ti )∩Dtarget (ti )|
(7) recall(T ) =      i=1     Pn
                                                                     4.2 Morphological features
                               i=1 |Dtarget (ti )|


In (7), T is a text (a list of tokens) with T =                      For morphological features, Tab. 3 shows the
(t1 , ..., tn ), Dpredicted (t) are descriptions retrieved           same tendencies that were also observed for word
from the NLP analyses of the token t, and                            classes: The more tools are combined, the greater
Dtarget (t) is the set of descriptions that corres-                  the recall of the generated descriptions, and the re-
pond to the original annotation of t in the corpus.                  call of combined tools often outperforms the recall
    7
                                                                     of individual tools.
     Precision and accuracy may not be appropriate measure-
ments in this case: Annotation schemes differ in their ex-              The three tools that provide morphological an-
pressiveness, so that a description predicted by an NLP tool         notations (Morphisto, Connexor, RFTagger) were
but not found in the reference annotation may nevertheless           evaluated against 10,000 tokens from TIGER and
be correct. The RFTagger, for example, assigns demonstra-
tive pronouns the feature ‘3rd person’, that is not found in         NEGRA respectively. The best-performing tool
TIGER/NEGRA-style annotation because of its redundancy.              was the RFTagger, which possibly reflects the fact


                                                               665


that it was trained on TIGER-style annotations,                   a particular approach (e.g., differences in the co-
whereas Morphisto and Connexor were developed                     verage of the linguistic context).
on the basis of independent resources and thus dif-                  It can thus be stated that the integration of mul-
fer from the reference annotation in their respec-                tiple alternative analyses has the potential to pro-
tive degree of granularity.                                       duce linguistic analyses that are both more robust
                                                                  and more detailed than those of the original tools.
5   Summary and Discussion                                           The primary field of application of this ap-
With the ontology-based approach described in                     proach is most likely to be seen in a context where
this paper, the performance of annotation tools can               applications are designed that make direct use of
be evaluated on a conceptual basis rather than by                 OWL/RDF representations as described, for ex-
means of a string comparison with target annota-                  ample, by Hellmann (2010). It is, however, also
tions. A formal model of linguistic concepts is ex-               possible to use ontological representations to boot-
tensible, finer-grained and, thus, potentially more               strap novel and more detailed annotation schemes,
adequate for the integration of linguistic annota-                cf. Zavrel and Daelemans (2000). Further, the
tions than string-based representations, especially               conversion from string-based representations to
for heterogeneous annotations, if the tagsets in-                 ontological descriptions is reversible, so that re-
volved are structured according to different design               sults of ontology-based disambiguation and vali-
principles (e.g., due to different terminological tra-            dation can also be reintegrated with the original
ditions, different communities involved, etc.).                   annotation scheme. The idea of such a reversion
   It has been shown that by abstracting from                     algorithm was sketched by Buyko et al. (2008)
tool-specific representations of linguistic anno-                 where the OLiA ontologies were suggested as a
tations, annotations from different tagsets can be                means to translate between different annotation
represented with reference to the OLiA ontologies                 schemes.9
(and/or with other OWL/RDF-based terminology
repositories linked as External Reference Models).                6        Extensions and Related Research
In particular, it is possible to compare an existing              Natural extensions of the approach described in
reference annotation with annotations produced by                 this paper include:
NLP tools that use independently developed and
differently structured annotation schemes (such as
                                                                      (i) Experiments with formally defined consis-
Connexor vs. RFTagger vs. Morphisto).
                                                                          tency conditions (e.g., with respect to restric-
   Further, an algorithm for the integration of dif-
                                                                          tions on the domain of properties).
ferent annotations has been proposed that makes
use of a majority-based confidence ranking and
                                                                   (ii) Context-sensitive disambiguation of mor-
ontological consistency conditions. As consis-
                                                                        phological features (e.g., by combination
tency conditions are not formally defined in the
                                                                        with a chunker and adjustment of confidence
OLiA Reference Model (which is expected to in-
                                                                        scores for morphological features over all to-
herit such constraints from External Reference
                                                                        kens in the current chunk, cf. Kermes and
Models), a heuristic, structure-based definition of
                                                                        Evert, 2002).
consistency was applied.
   This heuristic consistency definition is overly                (iii) Replacement of majority vote by more elab-
rigid and rules out a number of consistent alter-                       orate strategies to merge grammatical analy-
native analyses, as it is the case for overlapping                      ses.
categories.8 Despite this rigidity, we witness an
                                                                       9
increase of recall when multiple alternative analy-                    The mapping from ontological descriptions to tags of a
                                                                  particular scheme is possible, but neither trivial nor neces-
ses are integrated. This increase of recall may re-               sarily lossless: Information of ontological descriptions that
sult from a compensation of tool-specific deficits,               cannot be expressed in the annotation scheme under consid-
e.g., with respect to annotation granularity. Also,               eration (e.g., the distinction between attributive and substitu-
                                                                  tive pronouns in the Morphisto scheme) will be missing in
the improved recall can be explained by a compen-                 the resulting string representation. For complex annotations,
sation of overfitting, or deficits that are inherent to           where ontological descriptions correspond to different sub-
                                                                  strings, an additional ‘tag grammar’ may be necessary to de-
    8
      Preposition-determiner compounds like German am ‘on         termine the appropriate ordering of substrings according to
the’, for example, are both prepositions and determiners.         the annotation scheme (e.g., in the Connexor analysis).


                                                            666


(iv) Application of the algorithm for the ontolog-             resources such as WordNet (Gangemi et al., 2003),
     ical processing of node labels and edge labels            FrameNet (Scheffczyk et al., 2006), the linking of
     in syntax annotations.                                    corpora with such ontologies (Hovy et al., 2006),
                                                               the modelling of entire corpora in OWL/DL (Bur-
 (v) Integration with other ontological knowledge              chardt et al., 2008), and the extension of existing
     sources in order to improve the recall of                 ontologies with ontological representations of se-
     morphosyntactic and morphological analy-                  lected linguistic features (Buitelaar et al., 2006;
     ses (e.g., for disambiguating grammatical                 Davis et al., 2008).
     case).                                                       Aguado de Cea et al. (2004) sketched an ar-
                                                               chitecture for the closer ontology-based integra-
Extensions (iii) and (iv) are currently pursued in
                                                               tion of grammatical and semantic information u-
an ongoing research effort described by Chiarcos
                                                               sing OntoTag and several NLP tools for Spanish.
et al. (2010). Like morphosyntactic and morpho-
                                                               Aguado de Cea et al. (2008) evaluate the benefits
logical features, node and edge labels of syntac-
                                                               of this approach for the Spanish particle se, and
tic trees are ontologically represented in several
                                                               conclude for this example that the combination of
Annotation Models, the OLiA Reference Model,
                                                               multiple tools yields more detailed and more ac-
and External Reference Models, the merging al-
                                                               curate linguistic analyses of particularly proble-
gorithm as described above can thus be applied
                                                               matic, polysemous function words. A similar in-
for syntax, as well. Syntactic annotations, how-
                                                               crease in accuracy has also been repeatedly re-
ever, involve the additional challenge to align dif-
                                                               ported for ensemble combination approaches, that
ferent structures before node and edge labels can
                                                               are, however, limited to tools that produce annota-
be addressed, an issue not further discussed here
                                                               tions according to the same tagset (Brill and Wu,
for reasons of space limitations.
                                                               1998; Halteren et al., 2001).
   Alternative strategies to merge grammatical a-
                                                                  These observations provide further support for
nalyses may include alternative voting strategies
                                                               our conclusion that the ontology-based integration
as discussed in literature on classifier combina-
                                                               of morphosyntactic analyses enhances both the ro-
tion, e.g., weighted majority vote, pairwise voting
                                                               bustness and the level of detail of morphosyntac-
(Halteren et al., 1998), credibility profiles (Tufiş,
                                                               tic and morphological analyses. Our approach ex-
2000), or hand-crafted rules (Borin, 2000). A
                                                               tends the philosophy of ensemble combination ap-
novel feature of our approach as compared to exis-
                                                               proaches to NLP tools that do not only employ dif-
ting applications of these methods is that confi-
                                                               ferent strategies and philosophies, but also differ-
dence scores are not attached to plain strings, but
                                                               ent annotation schemes.
to ontological descriptions: Tufiş, for example,
assigned confidence scores not to tools (as in a
weighted majority vote), but rather, assessed the
‘credibility’ of a tool with respect to the predicted
tag. If this approach is applied to ontological de-
scriptions in place of tags, it allows us to consider
                                                               Acknowledgements
the credibility of pieces of information regardless
of the actual string representation of tags. For ex-           From 2005 to 2008, the research on linguistic
ample, the credibility of hasCase descriptions can             ontologies described in this paper was funded
be assessed independently from the credibility of              by the German Research Foundation (DFG) in
hasGender descriptions even if the original anno-              the context of the Collaborative Research Center
tation merged both aspects in one single tag (as the           (SFB) 441 “Linguistic Data Structures”, Project
RFTagger does, for example, cf. ex. 5).                        C2 “Sustainability of Linguistic Resources” (Uni-
   Extension (v) has been addressed in previous re-            versity of Tübingen), and since 2007 in the context
search, although mostly with the opposite perspec-             of the SFB 632 “Information Structure”, Project
tive: Already Cimiano and Reyle (2003) noted that              D1 “Linguistic Database” (University of Pots-
the integration of grammatical and semantic ana-               dam). The author would also like to thank Ju-
lyses may be used to resolve ambiguity and un-                 lia Ritz, Angela Lahee, Olga Chiarcos and three
derspecifications, and this insight has also moti-             anonymous reviewers for helpful hints and com-
vated the ontological representation of linguistic             ments.


                                                         667


References                                                     E. Brill and J. Wu. 1998. Classifier combination
                                                                  for improved lexical disambiguation. In Procee-
G. Aguado de Cea, Á. I. de Mon-Rego, A. Pareja-Lora,             dings of the 36th Annual Meeting of the Association
   and R. Plaza-Arteche. 2002. OntoTag: A semantic                for Computational Linguistics and the 17th Inter-
   web page linguistic annotation model. In Procee-               national Conference on Computational Linguistics
   dings of the ECAI 2002 Workshop on Semantic Au-                (COLING-ACL 1998), pages 191–195, Montréal,
   thoring, Annotation and Knowledge Markup, Lyon,                Canada, August.
   France, July.
                                                               P. Buitelaar, T. Declerck, A. Frank, S. Racioppa,
G. Aguado de Cea, A. Gomez-Perez, I. Alvarez de                   M. Kiesel, M. Sintek, R. Engel, M. Romanelli,
  Mon, and A. Pareja-Lora. 2004. OntoTag’s lin-                   D. Sonntag, B. Loos, V. Micelli, R. Porzel, and
  guistic ontologies: Improving semantic web anno-                P. Cimiano. 2006. LingInfo: Design and applica-
  tations for a better language understanding in ma-              tions of a model for the integration of linguistic in-
  chines. In Proceedings of the International Confe-              formation in ontologies. In Proceedings of the 5th
  rence on Information Technology: Coding and Com-                International Conference on Language Resources
  puting (ITCC’04), Las Vegas, Nevada, USA, April.                and Evaluation (LREC 2006), Genoa, Italy, May.

G. Aguado de Cea, J. Puch, and J.Á. Ramos. 2008.              A. Burchardt, S. Padó, D. Spohr, A. Frank, and
  Tagging Spanish texts: The problem of “se”. In Pro-            U. Heid. 2008. Formalising Multi-layer Corpora in
  ceedings of the Sixth International Conference on              OWL/DL – Lexicon Modelling, Querying and Con-
  Language Resources and Evaluation (LREC 2008),                 sistency Control. In Proceedings of the 3rd Inter-
  Marrakech, Morocco, May.                                       national Joint Conference on NLP (IJCNLP 2008),
                                                                 Hyderabad, India, January.
A. Aschenbrenner, P. Gietz, M.W. Küster, C. Ludwig,
                                                               E. Buyko, C. Chiarcos, and A. Pareja-Lora. 2008.
  and H. Neuroth. 2006. TextGrid. A modular plat-
                                                                  Ontology-based interface specifications for a NLP
  form for collaborative textual editing. In Procee-
                                                                  pipeline architecture. In Proceedings of the Interna-
  dings of the International Workshop on Digital Lib-
                                                                  tional Conference on Language Resources and Eva-
  rary Goes e-Science (DLSci06), pages 27–36, Ali-
                                                                  luation (LREC 2008), Marrakech, Morocco, May.
  cante, Spain, September.
                                                               M. Carl, C. Pease, L.L. Iomdin, and O. Streiter. 2000.
D. Bakker, O. Dahl, M. Haspelmath, M. Koptjevskaja-              Towards a dynamic linkage of example-based and
  Tamm, C. Lehmann, and A. Siewierska. 1993.                     rule-based machine translation. Machine Transla-
  EUROTYP guidelines. Technical report, European                 tion, 15(3):223–257.
  Science Foundation Programme in Language Typol-
  ogy.                                                         C. Chiarcos, S. Dipper, M. Götze, U. Leser,
                                                                 A. Lüdeling, J. Ritz, and M. Stede. 2008. A Flexible
B. Bickel and J. Nichols.               2000.    The             Framework for Integrating Annotations from Differ-
  goals   and   principles         of       AUTOTYP.             ent Tools and Tag Sets. Traitement Automatique des
  http://www.uni-leipzig.de/∼autotyp/                            Langues, 49(2).
  theory.html. version of 01/12/2007.
                                                               C. Chiarcos, K. Eckart, and J. Ritz. 2010. Creating and
B. Bickel and J. Nichols. 2002. Autotypologizing                  exploiting a resource of parallel parses. In 4th Lin-
  databases and their use in fieldwork. In Proceedings            guistic Annotation Workshop (LAW 2010), held in
  of the LREC 2002 Workshop on Resources and Tools                conjunction with ACL-2010, Uppsala, Sweden, July.
  in Field Linguistics, Las Palmas, Spain, May.
                                                               C. Chiarcos. 2008. An ontology of linguistic annota-
L. Borin. 2000. Something borrowed, something                     tions. LDV Forum, 23(1):1–16. Foundations of On-
  blue: Rule-based combination of POS taggers. In                 tologies in Text Technology, Part II: Applications.
  Proceedings of the 2nd International Conference on           C. Chiarcos. 2010. Grounding an ontology of lin-
  Language Resources and Evaluation (LREC 2000),                 guistic annotations in the Data Category Registry.
  Athens, Greece, May, 31st – June, 2nd.                         In Workshop on Language Resource and Language
                                                                 Technology Standards (LR&LTS 2010), held in con-
S. Brants and S. Hansen. 2002. Developments in the               junction with LREC 2010, Valetta, Malta, May.
   TIGER annotation scheme and their realization in
   the corpus. In Proceedings of the Third Interna-            P. Cimiano and U. Reyle. 2003. Ontology-based se-
   tional Conference on Language Resources and Eva-               mantic construction, underspecification and disam-
   luation (LREC 2002), pages 1643–1649, Las Pal-                 biguation. In Proceedings of the Lorraine/Saarland
   mas, Spain, May.                                               Workshop on Prospects and Recent Advances in the
                                                                  Syntax-Semantics Interface, pages 33–38, Nancy,
S. Brants, S. Dipper, S. Hansen, W. Lezius, and                   France, October.
   G. Smith. 2002. The TIGER treebank. In Procee-
   dings of the Workshop on Treebanks and Linguistic           B. Crysmann, A. Frank, B. Kiefer, S. Müller, G. Neu-
   Theories, pages 24–41, Sozopol, Bulgaria, Septem-              mann, J. Piskorski, U. Schäfer, M. Siegel, H. Uszko-
   ber.                                                           reit, F. Xu, M. Becker, and H. Krieger. 2002. An


                                                         668


  integrated architecture for shallow and deep proces-         E. Hovy, M. Marcus, M. Palmer, L. Ramshaw, and
  sing. In Proceedings of 40th Annual Meeting of the              R. Weischedel. 2006. Ontonotes: the 90% solu-
  Association for Computational Linguistics, pages                tion. In Conference of the North American Chapter
  441–448, Philadelphia, Pennsylvania, USA, July.                 of the Association for Computational Linguistics on
                                                                  Human Language Technology (HLT-NAACL 2006),
B. Davis, S. Handschuh, A. Troussov, J. Judge, and                pages 57–60, New York, June.
  M. Sogrin. 2008. Linguistically light lexical ex-
  tensions for ontologies. In Proceedings of the Sixth         N. Ide and L. Romary. 2004. A registry of standard
  International Conference on Language Resources                 data categories for linguistic annotation. In Procee-
  and Evaluation (LREC 2008), Marrakech, Morocco,                dings of the Fourth Language Resources and Evalu-
  May.                                                           ation Conference (LREC 2004), pages 135–39, Lis-
                                                                 boa, Portugal, May.
S. Dipper, M. Götze, and S. Skopeteas, editors. 2007.
                                                               M. Kemps-Snijders, M. Windhouwer, P. Wittenburg,
   Information Structure in Cross-Linguistic Corpora:
                                                                 and S.E. Wright. 2009. ISOcat: remodelling meta-
   Annotation Guidelines for Phonology, Morpholo-
                                                                 data for language resources. International Journal
   gy, Syntax, Semantics, and Information Structure.
                                                                 of Metadata, Semantics and Ontologies, 4(4):261–
   Interdisciplinary Studies on Information Structure
                                                                 276.
   (ISIS), Working Papers of the SFB 632; 7. Univer-
   sitätsverlag Potsdam, Potsdam, Germany.                    H. Kermes and S. Evert. 2002. YAC – A recur-
                                                                 sive chunker for unrestricted German text. In Pro-
M.T. Egner, M. Lorch, and E. Biddle. 2007. UIMA                  ceedings of the Third International Conference on
  Grid: Distributed large-scale text analysis. In Pro-           Language Resources and Evaluation (LREC 2002),
  ceedings of the Seventh IEEE International Sym-                pages 1805–1812, Las Palmas, Spain, May.
  posium on Cluster Computing and the Grid (CC-
  GRID’07), pages 317–326, Rio de Janeiro, Brazil,             J.D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE-
  May.                                                            NIA corpus – A semantically annotated corpus for
                                                                  bio-textmining. Bioinformatics, 19(1):180–182.
S. Farrar and D.T. Langendoen. 2003. Markup and
   the GOLD ontology. In EMELD Workshop on Di-                 D. Klein and C.D. Manning. 2003. Accurate unlexi-
   gitizing and Annotating Text and Field Recordings.            calized parsing. In Proceedings of the 41st Annual
   Michigan State University, July.                              Meeting of the Association for Computational Lin-
                                                                 guistics, pages 423–430, Sapporo, Japan, July.
A. Gangemi, R. Navigli, and P. Velardi. 2003. The On-          G. Leech and A. Wilson. 1996. EAGLES recommen-
   toWordNet project: Extension and axiomatization of            dations for the morphosyntactic annotation of cor-
   conceptual relations in WordNet. In R. Meersman               pora. Version of March 1996.
   and Z. Tari, editors, Proceedings of On the Move
   to Meaningful Internet Systems (OTM2003), pages             T. Luı́s and D.M. de Matos. 2009. High-performance
   820–838, Catania, Italy, November.                             high-volume layered corpora annotation. In Procee-
                                                                  dings of the Third Linguistic Annotation Workshop
P. Gietz, A. Aschenbrenner, S. Budenbender, F. Jan-               (LAW-III) held in conjunction with ACL-IJCNLP
   nidis, M.W. Küster, C. Ludwig, W. Pempe, T. Vitt,             2009, pages 99–107, Singapore, August.
   W. Wegstein, and A. Zielinski. 2006. TextGrid
   and eHumanities. In Proceedings of the Second               M. Mandel. 2006. Integrated annotation of biomedical
   IEEE International Conference on e-Science and                text: Creating the PennBioIE corpus. In Text Min-
   Grid Computing (E-SCIENCE ’06), pages 133–141,                ing Ontologies and Natural Language Processing in
   Amsterdam, The Netherlands, December.                         Biomedicine, Manchester, UK, March.
                                                               M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz.
H. van Halteren, J. Zavrel, and W. Daelmans. 1998.
                                                                 1994. Building a large annotated corpus of En-
  Improving data driven wordclass tagging by system
                                                                 glish: The Penn Treebank. Computational linguis-
  combination. In Proceedings of the 36th Annual
                                                                 tics, 19(2):313–330.
  Meeting of the Association for Computational Lin-
  guistics and the 17th International Conference on            R. Meyer. 2003. Halbautomatische morphosyntak-
  Computational Linguistics (COLING-ACL 1998),                   tische Annotation russischer Texte. In R. Ham-
  Montréal, Canada, August.                                     mel and L. Geist, editors, Linguistische Beiträge
                                                                 zur Slavistik aus Deutschland und Österreich. X.
H. van Halteren, J. Zavrel, and W. Daelmans. 2001.               JungslavistInnen-Treffen, Berlin 2001, pages 92–
  Improving accuracy in word class tagging through               105. Sagner, München.
  the combination of machine learning systems. Com-
  putational Linguistics, 27(2):199–229.                       S. Petrov and D. Klein. 2007. Improved inference for
                                                                  unlexicalized parsing. In Proceedings of the Confe-
S. Hellmann. 2010. The semantic gap of formalized                 rence of the North American Chapter of the Associ-
   meaning. In The 7th Extended Semantic Web Confe-               ation for Computational Linguistics on Human Lan-
   rence (ESWC 2010), Heraklion, Greece, May 30th –               guage Technology (HLT-NAACL 2007), pages 404–
   June 3rd.                                                      411, Rochester, NY, April.


                                                         669


S. Petrova, C. Chiarcos, J. Ritz, M. Solf, and A. Zeldes.         W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998.
   2009. Building and using a richly annotated inter-               A linguistically interpreted corpus of German news-
   linear diachronic corpus: The case of Old High Ger-              paper text. In In Proceedings of the ESSLLI Work-
   man Tatian. Traitement automatique des langues et                shop on Recent Advances in Corpus Annotation,
   langues anciennes, 50(2):47–71.                                  Saarbrücken, Germany, August.
G. Rehm, R. Eckart, and C. Chiarcos. 2007. An OWL-                M. Stede. 2004. The Potsdam Commentary Corpus.
   and XQuery-based mechanism for the retrieval of                  In Proceedings of the 2004 ACL Workshop on Dis-
   linguistic patterns from XML-corpora. In Procee-                 course Annotation, pages 96–102, Barcelona, Spain,
   dings of Recent Advances in Natural Language Pro-                July.
   cessing (RANLP 2007), Borovets, Bulgaria, Septem-
   ber.                                                           P. Tapanainen and T. Järvinen. 1997. A nonprojec-
                                                                     tive dependency parser. In Proceedings of the 5th
G. Sampson. 1995. English for the computer: The SU-                  Conference on Applied Natural Language Process-
   SANNE corpus and analytic scheme. Oxford Uni-                     ing, pages 64–71, Washington, DC, April.
   versity Press.
                                                                  K. Toutanova, D. Klein, C.D. Manning, and Y. Singer.
A. Saulwick, M. Windhouwer, A. Dimitriadis, and                     2003. Feature-rich part-of-speech tagging with a
  R. Goedemans. 2005. Distributed tasking in on-                    cyclic dependency network. In Proceedings of the
  tology mediated integration of typological databases              2003 Conference of the North American Chapter
  for linguistic research. In Proceedings of the 17th               of the Association for Computational Linguistics on
  Conference on Advanced Information Systems Engi-                  Human Language Technology (HLT-NAACL 2003),
  neering (CAiSE’05), Porto, Portugal, June.                        Edmonton, Canada, May.
J. Scheffczyk, A. Pease, and M. Ellsworth. 2006.
                                                                  D. Tufiş. 2000. Using a large set of EAGLES-
   Linking FrameNet to the suggested upper merged
                                                                    compliant morpho-syntactic descriptors as a tagset
   ontology. In Proceedings of the Fourth Interna-
                                                                    for probabilistic tagging. In Proceedings of the 2nd
   tional Conference on Formal Ontology in Informa-
                                                                    International Conference on Language Resources
   tion Systems (FOIS 2006), pages 289–300, Balti-
                                                                    and Evaluation (LREC 2000), pages 1105–1112,
   more, Maryland, USA, November.
                                                                    Athens, Greece, May, 31st – June, 2nd.
A. Schiller, S. Teufel, C. Thielen, and C. Stöckert.
  1999.      Guidelines für das Tagging deutscher                A. Wagner and B. Zeisler. 2004. A syntactically an-
  Textcorpora mit STTS. Technical report, University                notated corpus of Tibetan. In Fourth International
  of Stuttgart, University of Tübingen.                            Conference on Language Resources and Evaluation
                                                                    (LREC 2004), Lisboa, Portugal, May.
H. Schmid and F. Laws. 2008. Estimation of condi-
  tional probabilities with decision trees and an ap-             J. Zavrel and W. Daelemans. 2000. Bootstrapping a
  plication to fine-grained pos tagging. In Procee-                  tagged corpus through combination of existing het-
  dings of the 22nd International Conference on Com-                 erogeneous taggers. In Proceedings of the 2nd In-
  putational Linguistics (COLING 2008), Manchester,                  ternational Conference on Language Resources and
  UK, August.                                                        Evaluation (LREC 2000), Athens, Greece, May, 31st
                                                                     – June, 2nd.
H. Schmid. 1994. Probabilistic part-of-speech tagging
  using decision trees. In Proceedings of International           A. Zielinski and C. Simon. 2008. Morphisto: An
  Conference on New Methods in Language Process-                    open-source morphological analyzer for German. In
  ing, pages 44–49, Manchester, UK, September.                      Proceedings of the Conference on Finite State Meth-
                                                                    ods in Natural Language Processing (FSMNLP), Is-
T. Schmidt, C. Chiarcos, T. Lehmberg, G. Rehm,                      pra, Italy, September.
   A. Witt, and E. Hinrichs. 2006. Avoiding data
   graveyards: From heterogeneous data collected in
   multiple research projects to sustainable linguistic
   resources. In Proceedings of the E-MELD work-
   shop on Digital Language Documentation: Tools
   and Standards: The State of the Art, East Lansing,
   Michigan, US, June.
S. Sharoff, M. Kopotev, T. Erjavec, A. Feldman, and
   D. Divjak. 2008. Designing and evaluating Rus-
   sian tagsets. In Proceedings of the 6th International
   Conference on Language Resources and Evaluation
   (LREC 2008), Marrakech, Morocco, May.
E. Sirin, B. Parsia, B.C. Grau, A. Kalyanpur, and
  Y. Katz. 2007. Pellet: A practical OWL/DL rea-
  soner. Web Semantics: Science, Services and Agents
  on the World Wide Web, 5(2):51–53.


                                                            670

                   Temporal information processing of a new language:
                          fast porting with minimal resources

                                    Francisco Costa and António Branco
                                           Universidade de Lisboa




                         Abstract                                 all systems achieved quite similar results. In the
                                                                  TERN2004 competition (aimed at identifying and
       We describe the semi-automatic adapta-                     normalizing temporal expressions), a symbolic
       tion of a TimeML annotated corpus from                     system performed best, but since then machine
       English to Portuguese, a language for                      learning solutions, such as (Ahn et al., 2007), have
       which TimeML annotated data was not                        appeared that obtain similar results.
       available yet. In order to validate this                      These evaluations made available sets of anno-
       adaptation, we use the obtained data to                    tated data for English and other languages, used
       replicate some results in the literature that              for training and evaluation. One natural question
       used the original English data. The fact                   to ask is whether it is feasible to adapt the training
       that comparable results are obtained indi-                 and test data made available in these competitions
       cates that our approach can be used suc-                   to other languages, for which no such data still ex-
       cessfully to rapidly create semantically an-               ist. Since the annotations are largely of a seman-
       notated resources for new languages.                       tic nature, not many changes need to be done in
                                                                  the annotations once the textual material is trans-
1 Introduction
                                                                  lated. In essence, this would be a fast way to create
Temporal information processing is a topic of nat-                temporal information processing systems for lan-
ural language processing boosted by recent eval-                  guages for which there are no annotated data yet.
uation campaigns like TERN2004,1 TempEval-1                          In this paper, we report on an experiment
(Verhagen et al., 2007) and the forthcoming                       that consisted in adapting the English data of
TempEval-22 (Pustejovsky and Verhagen, 2009).                     TempEval-1 to Portuguese. The results of ma-
For instance, in the TempEval-1 competition, three                chine learning algorithms over the data thus ob-
tasks were proposed: a) identifying the temporal                  tained are compared to those reported for the En-
relation (such as overlap, before or after) hold-                 glish TempEval-1 competition. Since the results
ing between events and temporal entities such as                  are quite similar, this permits to conclude that
dates, times and temporal durations denoted by ex-                such an approach can rapidly generate relevant and
pressions (i.e. temporal expressions) occurring in                comparable data and is useful when porting tem-
the same sentence; b) identifying the temporal re-                poral information processing solutions to new lan-
lation holding between events expressed in a doc-                 guages.
ument and its creation time; c) identifying the tem-                 The advantages of adapting an existing corpus
poral relation between the main events expressed                  instead of annotating text from scratch are: i)
by two adjacent sentences.                                        potentially less time consuming, if it is faster to
   Supervised machine learning approaches are                     translate the original text than it is to annotate
pervasive in the tasks of temporal information pro-               new text (this can be the case if the annotations
cessing. Even when the best performing sys-                       are semantic and complex); b) the annotations can
tems in these competitions are symbolic, there are                be transposed without substantial modifications,
machine learning solutions with results close to                  which is the case if they are semantic in nature;
their performance. In TempEval-1, where there                     c) less man power required: text annotation re-
were statistical and rule-based systems, almost                   quires multiple annotators in order to guarantee
   1
       http://timex2.mitre.org                                    the quality of the annotation tags, translation of
   2
       http://www.timeml.org/tempeval2                            the markables and transposition of the annotations


                                                            671
           Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 671–677,
                    Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


in principle do not; d) the data obtained are com-           time (functionInDocument) and whether its
parable to the original data in all respects except          value can be determined from the expression
for language: genre, domain, size, style, annota-            alone or requires other sources of information
tion decisions, etc., which allows for research to           (temporalFunction and anchorTimeID).
be conducted with a derived corpus that is compa-               The <TLINK> elements encode temporal re-
rable to research using the original corpus. There           lations. The attribute relType represents the
is of course the caveat that the adaptation process          type of relation, the feature eventID is a ref-
can introduce errors.                                        erence to the first argument of the relation.
   This paper proceeds as follows. In Section 2,             The second argument is given by the attribute
we provide a quick overview of the TimeML an-                relatedToTime (if it is a time interval or du-
notations in the TempEval-1 data. In Section 3,              ration) or relatedToEvent (if it is another
it is described how the data were adapted to Por-            event; this is for task C). The task feature is the
tuguese. Section 4 contains a brief quantitative             name of the TempEval-1 task to which this tempo-
comparison of the two corpora. In Section 5, the             ral relation pertains.
results of replicating one of the approaches present
in the TempEval-1 challenge with the Portuguese              3 Data Adaptation
data are presented. We conclude this paper in Sec-           We cleaned all TimeML markup in the
tion 6.                                                      TempEval-1 data and the result was fed to
                                                             the Google Translator Toolkit.3 This tool com-
2 Brief Description of the Annotations                       bines machine translation with a translation
Figure 1 contains an example of a document from              memory.       A human translator corrected the
the TempEval-1 corpus, which is similar to the               proposed translations manually.
TimeBank corpus (Pustejovsky et al., 2003).                     After that, we had the three collections of docu-
                                                             ments (the TimeML data, the English unannotated
   In this corpus, event terms are tagged with
                                                             data and the Portuguese unannotated data) aligned
<EVENT>. The relevant attributes are tense,
                                                             by paragraphs (we just kept the line breaks from
aspect, class, polarity, pos, stem. The
                                                             the original collection in the other collections). In
stem is the term’s lemma, and pos is its part-of-
                                                             this way, for each paragraph in the Portuguese data
speech. Grammatical tense and aspect are encoded
                                                             we know all the corresponding TimeML tags in
in the features tense and aspect. The attribute
                                                             the original English paragraph.
polarity takes the value NEG if the event term
                                                                We tried using machine translation software (we
is in a negative syntactic context, and POS other-
                                                             used GIZA++ (Och and Ney, 2003)) to perform
wise. The attribute class contains several lev-
                                                             word alignment on the unannotated texts, which
els of information. It makes a distinction between
                                                             would have enabled us to transpose the TimeML
terms that denote actions of speaking, which take
                                                             annotations automatically. However, word align-
the value REPORTING and those that do not.
                                                             ment algorithms have suboptimal accuracy, so the
For these, it distinguishes between states (value
                                                             results would have to be checked manually. There-
STATE) and non-states (value OCCURRENCE),
                                                             fore we abandoned this idea, and instead we sim-
and it also encodes whether they create an in-
                                                             ply placed the different TimeML markup in the
tensional context (value I STATE for states and
                                                             correct positions manually. This is possible since
value I ACTION for non-states).
                                                             the TempEval-1 corpus is not very large. A small
   Temporal expressions (timexes) are inside
                                                             script was developed to place all relevant TimeML
<TIMEX3> elements. The most important fea-
                                                             markup at the end of each paragraph in the Por-
tures for these elements are value, type and
                                                             tuguese text, and then each tag was manually repo-
mod. The timex’s value encodes a normal-
                                                             sitioned. Note that the <TLINK> elements always
ized representation of this temporal entity, its
                                                             occur at the end of each document, each in a sep-
type can be e.g. DATE, TIME or DURATION.
                                                             arate line: therefore they do not need to be reposi-
The mod attribute is optional. It is used for ex-
                                                             tioned.
pressions like early this year, which are anno-
                                                                During this manual repositioning of the anno-
tated with mod="START". As can be seen in
                                                             tations, some attributes were also changed man-
Figure 1 there are other attributes for timexes
                                                                3
that encode whether it is the document’s creation                   http://translate.google.com/toolkit


                                                       672


<?xml version="1.0" ?>
<TempEval>

ABC<TIMEX3 tid="t52" type="DATE" value="1998-01-14" temporalFunction="false"
functionInDocument="CREATION_TIME">19980114</TIMEX3>.1830.0611
NEWS STORY

<s>In Washington <TIMEX3 tid="t53" type="DATE" value="1998-01-14" temporalFunction="true"
functionInDocument="NONE" anchorTimeID="t52">today</TIMEX3>, the Federal Aviation Administration <EVENT
eid="e1" class="OCCURRENCE" stem="release" aspect="NONE" tense="PAST" polarity="POS" pos="VERB">released
</EVENT> air traffic control tapes from <TIMEX3 tid="t54" type="TIME" value="1998-XX-XXTNI"
temporalFunction="true" functionInDocument="NONE" anchorTimeID="t52">the night</TIMEX3> the TWA Flight
eight hundred <EVENT eid="e2" class="OCCURRENCE" stem="go" aspect="NONE" tense="PAST" polarity="POS"
pos="VERB">went</EVENT>down.</s>
...
<TLINK lid="l1" relType="BEFORE" eventID="e2" relatedToTime="t53" task="A"/>
<TLINK lid="l2" relType="OVERLAP" eventID="e2" relatedToTime="t54" task="A"/>
<TLINK lid="l4" relType="BEFORE" eventID="e2" relatedToTime="t52" task="B"/>
...
</TempEval>



           Figure 1: Extract of a document contained in the training data of the first TempEval-1


ually. In particular, the attributes stem, tense                         obviously different in Portuguese. The attributes
and aspect of <EVENT> elements are language                              aspect and tense have a different set of
specific and needed to be adapted. Sometimes, the                        possible values in the Portuguese data, simply
pos attribute also needs to be changed, since e.g.                       because the morphology of the two languages
a verb in English can be translated as a noun in                         is different. In the example in Figure 1 the
Portuguese. The attribute class of the same kind                         value PPI for the attribute tense stands for
of elements can be different, too, because natural                       pretérito perfeito do indicativo. We chose to
sounding translations are sometimes not literal.                         include mood information in the tense attribute
                                                                         because the different tenses of the indicative and
3.1    Annotation Decisions                                              the subjunctive moods do not line up perfectly
When porting the TimeML annotations from En-                             as there are more tenses for the indicative than
glish to Portuguese, a few decisions had to be                           for the subjunctive. For the aspect attribute,
made. For illustration purposes, Figure 2 contains                       which encodes grammatical aspect, we only
the Portuguese equivalent of the extract presented                       use the values NONE and PROGRESSIVE,
in Figure 1.                                                             leaving out the values PERFECTIVE and
   For <TIMEX3> elements, the issue is that if the                       PERFECTIVE PROGRESSIVE, as in Portuguese
temporal expression to be annotated is a preposi-                        there is no easy match between perfective aspect
tional phrase, the preposition should not be inside                      and grammatical categories.
the <TIMEX3> tags according to the TimeML                                   The attributes of <TIMEX3> elements carry
specification. In the case of Portuguese, this raises                    over to the Portuguese corpus unchanged, and the
the question of whether to leave contractions of                         <TLINK> elements are taken verbatim from the
prepositions with determiners outside these tags                         original documents.
(in the English data the preposition is outside and
the determiner is inside).4 We chose to leave them                       4 Data Description
outside, as can be seen in that Figure. In this ex-
                                                                         The original English data for TempEval-1 are
ample the prepositional phrase from the night/da
                                                                         based on the TimeBank data, and they are split
noite is annotated with the English noun phrase
                                                                         into one dataset for training and development and
the night inside the <TIMEX3> element, but the
                                                                         another dataset for evaluation. The full data are or-
Portuguese version only contains the noun noite
                                                                         ganized in 182 documents (162 documents in the
inside those tags.
                                                                         training data and another 20 in the test data). Each
   For <EVENT> elements, some of the attributes
                                                                         document is a news report from television broad-
are adapted. The value of the attribute stem is
                                                                         casts or newspapers. A large amount of the doc-
   4
     The fact that prepositions are placed outside of temporal           uments (123 in the training set and 12 in the test
expressions seems odd at first, but this is because in the orig-         data) are taken from a 1989 issue of the Wall Street
inal TimeBank, from which the TempEval data were derived,
they are tagged as <SIGNAL>s. The TempEval-1 data does                   Journal.
not contain <SIGNAL> elements, however.                                     The training data comprise 162 documents with


                                                                   673


<?xml version="1.0" encoding="UTF-8" ?>
<TempEval>

ABC<TIMEX3 tid="t52" type="DATE" value="1998-01-14" temporalFunction="false"
functionInDocument="CREATION_TIME">19980114</TIMEX3>.1830.1611
REPORTAGEM

<s>Em Washington, <TIMEX3 tid="t53" type="DATE" value="1998-01-14" temporalFunction="true"
functionInDocument="NONE" anchorTimeID="t52">hoje</TIMEX3>, a Federal Aviation Administration <EVENT
eid="e1" class="OCCURRENCE" stem="publicar" aspect="NONE" tense="PPI" polarity="POS" pos="VERB">publicou
</EVENT> gravaoes do controlo de trfego areo da <TIMEX3 tid="t54" type="TIME" value="1998-XX-XXTNI"
temporalFunction="true" functionInDocument="NONE" anchorTimeID="t52">noite</TIMEX3> em que o voo TWA800
<EVENT eid="e2" class="OCCURRENCE" stem="cair" aspect="NONE" tense="PPI" polarity="POS" pos="VERB">caiu
</EVENT>
.</s>
...
<TLINK lid="l1" relType="BEFORE" eventID="e2" relatedToTime="t53" task="A"/>
<TLINK lid="l2" relType="OVERLAP" eventID="e2" relatedToTime="t54" task="A"/>
<TLINK lid="l4" relType="BEFORE" eventID="e2" relatedToTime="t52" task="B"/>
...
</TempEval>



                    Figure 2: Extract of a document contained in the Portuguese data


2,236 sentences (i.e. 2236 <s> elements) and                 than any other”. In spite of its simplicity, they ob-
52,740 words. It contains 6799 <EVENT> el-                   tained results quite close to the best systems.
ements, 1,244 <TIMEX3> elements and 5,790                       For us, the results of (Hepple et al., 2007) are in-
<TLINK> elements. Note that not all the events               teresting as they allow for a straightforward evalu-
are included here: the ones expressed by words               ation of our adaptation efforts, since the same ma-
that occur less than 20 times in TimeBank were               chine learning implementations can be used with
removed from the TempEval-1 data.                            the Portuguese data, and then compared to their
   The test dataset contains 376 sentences and               results.
8,107 words. The number of <EVENT> elements                     The differences in the data are mostly due to
is 1,103; there are 165 <TIMEX3>s and 758                    language. Since the languages are different, the
<TLINK>s.                                                    distribution of the values of several attributes are
   The Portuguese data of course contain the same            different. For instance, we included both tense
(translated) documents. The training dataset has             and mood information in the tense attribute of
2,280 sentences and 60,781 words. The test data              <EVENT>s, as mentioned in Section 3.1, so in-
contains 351 sentences and 8,920 words.                      stead of seven possible values for this attribute, the
                                                             Portuguese data contains more values, which can
5 Comparing the two Datasets                                 cause more data sparseness. Other attributes af-
                                                             fected by language differences are aspect, pos,
One of the systems participating in the                      and class, which were also possibly changed
TempEval-1 competition, the USFD system                      during the adaptation process.
(Hepple et al., 2007), implemented a very                       One important difference between the English
straightforward solution: it simply trained classi-          and the Portuguese data originates from the fact
fiers with Weka (Witten and Frank, 2005), using              that events with a frequency lower than 20 were
as attributes information that was readily available         removed from the English TempEval-1 data. Since
in the data and did not require any extra natural            there is not a 1 to 1 relation between English event
language processing (for all tasks, the attribute            terms and Portuguese event terms, we do not have
relType of <TLINK> elements is unknown and                   the guarantee that all event terms in the Portuguese
must be discovered, but all the other information            data have a frequency of at least 20 occurrences in
is given).                                                   the entire corpus.5
   The authors’ objectives were to see “whether a
                                                                The work of (Hepple et al., 2007) reports on
‘lite’ approach of this kind could yield reasonable
                                                             both cross-validation results for various classifiers
performance, before pursuing possibilities that re-
                                                             over the training data and evaluation results on the
lied on ‘deeper’ NLP analysis methods”, “which
                                                             training data, for the English dataset. We we will
of the features would contribute positively to sys-
tem performance” and “if any [machine learning]                 5
                                                                  In fact, out of 1,649 different stems for event terms in the
approach was better suited to the TempEval tasks             Portuguese training data, only 45 occur at least 20 times.


                                                       674


                                       Task                                                             Task
  Attribute                     A      B       C                Algorithm                         A      B      C
  EVENT-aspect                  ! ! !                           baseline                         49.8   62.1   42.0
  EVENT-polarity                ! ! ×                           lazy.KStar                       58.2   76.7   54.0
  EVENT-POS                     ! ! !                           rules.DecisionTable              53.3   79.0   52.9
  EVENT-stem                    ! × ×                           functions.SMO
                                                                rules.JRip
                                                                                                 55.1
                                                                                                 50.7
                                                                                                        78.1
                                                                                                        78.6
                                                                                                               55.5
                                                                                                               53.4
  EVENT-string
                                   ! !
                                ×  ×   ×
                                                                bayes.NaiveBayes                 56.3   76.2   50.7
  EVENT-class
                                   ! !
                                ×
  EVENT-tense                                                  Table 2: Performance of several machine learn-
                                ! N/A N/A
                                ×
  ORDER-adjacent                                               ing algorithms on the English TempEval-1 train-
  ORDER-event-first             ! N/A N/A                      ing data, with cross-validation. The best result
  ORDER-event-between           ×     N/A     N/A              for each task is in boldface. From (Hepple et al.,
  ORDER-timex-between                 N/A     N/A              2007).
                                !
                                ×
  TIMEX3-mod                                  N/A
                                !
                                       ×
  TIMEX3-type                          ×      N/A              also correspond to attributes of the relevant
                                                               <TIMEX3> element. The ORDER features are
Table 1: Features used for the English TempEval-1
                                                               boolean and computed as follows:
tasks. N/A means the feature was not applicable to
         !
the task, means the feature was used by the best
                                                                 •   ORDER -event-first is whether the
performing classifier for the task, and × means it
                                                                     <EVENT> element occurs in the text before
was not used by that classifier. From (Hepple et
                                                                     the <TIMEX3> element;
al., 2007).
                                                                 •   ORDER -event-between is whether an
be comparing their results to ours.                                  <EVENT> element occurs in the text between
   Our purpose with this comparison is to validate                   the two temporal entities being ordered;
the corpus adaptation. Similar results would not
                                                                 •   ORDER -timex-between        is the same, but
necessarily indicate the quality of the adapted cor-
pus. After all, a word-by-word translation would                     for temporal expressions;
produce data that would yield similar results, but
                                                                 •   ORDER -adjacent     is whether both
it would also be a very poor translation, and there-
                                                                     ORDER -event-between and ORDER -
fore the resulting corpus would not be very inter-
                                                                     timex-between are false (but other
esting. The quality of the translation is not at stake
                                                                     textual data may occur between the two
here, since it was manually revised. But similar
                                                                     entities).
results would indicate that the obtained data are
comparable to the original data, and that they are
                                                                  Cross-validation over the training data pro-
similarly useful to tackle the problem for which
                                                               duced the results in Table 2.          The base-
the original data were collected. This would con-
                                                               line used is the majority class baseline, as
firm our hypothesis that adapting an existing cor-
                                                               given by Weka’s rules.ZeroR implemen-
pus can be an effective way to obtain new data for
                                                               tation.     The lazy.KStar algorithm is a
a different language.
                                                               nearest-neighbor classifier that uses an entropy-
                                                               based measure to compute instance similarity.
5.1   Results for English
                                                               Weka’s rules.DecisionTable algorithm as-
The attributes employed for English by (Hepple et              signs to an unknown instance the majority class
al., 2007) are summarized in Table 1. The class is             of the training examples that have the same
the attribute relType of <TLINK> elements.                     attribute values as that instance that is be-
   The EVENT features are taken from <EVENT>                   ing classified. functions.SMO is an imple-
elements. The EVENT-string attribute is the                    mentation of Support Vector Machines (SVM),
character data inside the element. The other at-               rules.JRip is the RIPPER algorithm, and
tributes correspond to the feature of <EVENT>                  bayes.NaiveBayes is a Naive Bayes classi-
with the same name. The TIMEX 3 features                       fier.


                                                         675


                                         Task                 performing classifier for task A is the same as for
 Algorithm                         A      B       C           English. For task B, Weka’s functions.SMO
 baseline                         49.8   62.1    42.0         produced better results with the Portuguese data
 lazy.KStar                       57.4   77.7    53.3         than rules.DecisionTable, the best per-
 rules.DecisionTable              54.2   78.1    51.6         forming classifier with the English data for this
 functions.SMO                    55.5   79.3    56.8         task. In task C, the SVM algorithm was also the
 rules.JRip                       52.1   77.6    52.1         best performing algorithm among those that were
 bayes.NaiveBayes                 56.0   78.2    53.5         also tried on the English data, but decision trees
 trees.J48                        55.6   79.0    59.3         produced even better results here.
                                                                 For English, the best performing classifier for
Table 3: Performance of several machine learn-
                                                              each task on the training data, according to Ta-
ing algorithms on the Portuguese data for the
                                                              ble 2, was used for evaluation on the test data: the
TempEval-1 tasks. The best result for each task
                                                              results showed a 59% F-measure for task A, 73%
is in boldface.
                                                              for task B, and 54% for task C.
                                                                 Similarly, we also evaluated the best algorithm
5.2   Attributes                                              for each task (according to Table 3) with the Por-
We created a small script to convert the XML an-              tuguese test data, after training it on the entire
notated files into CSV files, that can be read by             training dataset. The results are: in task A the
Weka. In this process, we included the same at-               lazy.KStar classifier scored 58.6%, and the
tributes as the USFD authors used for English.                SVM classifier scored 75.5% in task B and 59.4%
   For task C, (Hepple et al., 2007) are not very             in task C, with trees.J48 scoring 61% in this
clear whether the EVENT attributes used were re-              task.
lated to just one of the two events being temporally             The results on the test data are also fairly similar
related. In any case, we used two of each of the              for the two languages/datasets.
EVENT attributes, one for each event in the tempo-               We inspected the decision trees and rule sets
ral relation to be determined. So, for instance, an           produced by trees.J48 and rules.JRip, in
extra attribute EVENT 2-tense is where the tense              order to see what the classifiers are doing.
of the second event in the temporal relation is kept.            Task B is probably the easiest task to check this
                                                              way, because we expect grammatical tense to be
5.3   Results                                                 highly predictive of the temporal order between an
                                                              event and the document’s creation time.
The majority class baselines produce the same
results as for English. This was expected: the                   And, indeed, the top of the tree induced by
class distribution is the same in the two datasets,           trees.J48 is quite interesting:
since the <TLINK> elements were copied to the                  eTense =     PI: OVERLAP (388.0/95.0)
                                                               eTense =     PPI: BEFORE (1051.0/41.0)
adapted corpus without any changes.
   For the sake of comparison, we used the same                  Here, eTense is the EVENT-tense attribute
classifiers as (Hepple et al., 2007), and we used the         of <EVENT> elements, PI stands for present in-
attributes that they found to work best for English           dicative, and PPI is past indicative (pretérito per-
(presented above in Table 1). The results for the             feito do indicativo). In general, one sees past
Portuguese dataset are in Table 3, using 10-fold              tenses associated with the BEFORE class and fu-
cross-validation on the training data.                        ture tenses associated with the AFTER class (in-
   We also present the results for Weka’s imple-              cluding the conditional forms of verbs). Infini-
mentation of the C4.5 algorithm, to induce deci-              tives are mostly associated with the AFTER class,
sion trees. The motivation to run this algorithm              and present subjunctive forms with AFTER and
over these data is that decision trees are human              OVERLAP. Figure 3 shows the rule set induced by
readable and make it easy to inspect what deci-               the RIPPER algorithm.
sions the classifier is making. This is also true of             The classifiers for the other tasks are more dif-
rules.JRip. The results for the decision trees                ficult to inspect. For instance, in task A, the event
are in this table, too.                                       term and the temporal expression that denote the
   The results obtained are almost identical to the           entities that are to be ordered may not even be di-
results for the original dataset in English. The best         rectly syntactically related. Therefore, it is hard to


                                                        676


(eClass = OCCURRENCE) and ( eTense =                INF) and ( ePolarity =           POS) =>     lRelType= AFTER
                                                                                                    (183.0/77.0)
( eTense = FI) => lRelType= AFTER (55.0/10.0)
(eClass = OCCURRENCE) and ( eTense = IR-PI+INF) => lRelType= AFTER (26.0/4.0)
(eClass = OCCURRENCE) and ( eTense = PC) => lRelType= AFTER (15.0/3.0)
(eClass = OCCURRENCE) and ( eTense = C) => lRelType= AFTER (17.0/2.0)
( eTense = PI) => lRelType= OVERLAP (388.0/95.0)
(eClass = ASPECTUAL) and ( eTense = PC) => lRelType= OVERLAP (9.0/2.0)
 => lRelType= BEFORE (1863.0/373.0)


Figure 3: rules.JRip classifier induced for task B. INF stands for infinitive, FI is future indicative,
IR-PI+INF is an infinitive form following a present indicative form of the verb ir (to go), PC is present
subjunctive, C is conditional, PI is present indicative.


see how interesting the inferred rules are, because           approach to adapt existing annotated data to a dif-
we do not know what would be interesting in this              ferent language is fruitful.
scenario. In any case, the top of the induced tree
for task A is:
                                                              References
 oAdjacent =       True: OVERLAP (554.0/128.0)
                                                              David Ahn, Joris van Rantwijk, and Maarten de Ri-
                                                                jke. 2007. A cascaded machine learning approach
   Here, oAdjacent is the ORDER-adjacent                        to interpreting temporal expressions. In Human
attribute. Assuming this attribute is an indication             Language Technologies 2007: The Conference of
that the event term and the temporal expression are             the North American Chapter of the Association for
related syntactically, it is interesting to see that the        Computational Linguistics; Proceedings of the Main
                                                                Conference, pages 420–427, Rochester, New York,
typical temporal relation between the two entities              April. Association for Computational Linguistics.
in this case is an OVERLAP relation. The rest of
the tree is much more ad-hoc, making frequent use             Mark Hepple, Andrea Setzer, and Rob Gaizauskas.
                                                               2007.     USFD: Preliminary exploration of fea-
of the stem attribute of <EVENT> elements, sug-                tures and classifiers for the TempEval-2007 tasks.
gesting the classifier is memorizing the data.                 In Proceedings of SemEval-2007, pages 484–487,
   Task C, where two events are to be ordered, pro-            Prague, Czech Republic. Association for Computa-
duced more complicated classifiers. Generally the              tional Linguistics.
induced rules and the tree paths compare the tense            Franz Josef Och and Hermann Ney. 2003. A sys-
and the class of the two event terms, showing some              tematic comparison of various statistical alignment
expected heuristics (such as, if the tense of the first         models. Computational Linguistics, 29(1):19–51.
event is future and the tense of the second event             James Pustejovsky and Marc Verhagen.           2009.
is past, assign AFTER). But there are also many                 Semeval-2010 task 13: evaluating events, time ex-
several rules for which we do not have clear intu-              pressions, and temporal relations (tempeval-2). In
                                                                Proceedings of the Workshop on Semantic Evalua-
itions.                                                         tions: Recent Achievements and Future Directions,
                                                                pages 112–116, Boulder, Colorado. Association for
6 Discussion                                                    Computational Linguistics.

In this paper, we described the semi-automatic                James Pustejovsky, Patrick Hanks, Roser Saurı́, An-
adaptation of a TimeML annotated corpus from                    drew See, Robert Gaizauskas, Andrea Setzer,
                                                                Dragomir Radev, Beth Sundheim, David Day, Lisa
English to Portuguese, a language for which                     Ferro, and Marcia Lazo. 2003. The TIMEBANK
TimeML annotated data was not available yet.                    corpus. In Proceedings of Corpus Linguistics 2003,
   Because most of the TimeML annotations are                   pages 647–656.
semantic in nature, they can be transposed to a               M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple,
translation of the original corpus, with few adap-              and J. Pustejovsky. 2007. SemEval-2007 Task 15:
tations being required.                                         TempEval temporal relation identification. In Pro-
   In order to validate this adaptation, we used the            ceedings of SemEval-2007.
obtained data to replicate some results in the liter-         Ian H. Witten and Eibe Frank. 2005. Data Mining:
ature that used the original English data.                       Practical Machine Learning Tools and Techniques
   The results for the Portuguese data are very sim-             with Java Implementations. Morgan Kaufmann, San
                                                                 Francisco. second edition.
ilar to the ones for English. This indicates that our


                                                        677

     A new Approach to Improving Multilingual Summarization using a
                          Genetic Algorithm
        Marina Litvak                               Mark Last                               Menahem Friedman
     Ben-Gurion University                     Ben-Gurion University                       Ben-Gurion University
         of the Negev                              of the Negev                                of the Negev
       Beer Sheva, Israel                        Beer Sheva, Israel                          Beer Sheva, Israel
    litvakm@bgu.ac.il                          mlast@bgu.ac.il                            fmenahem@bgu.ac.il


                       Abstract                                      with on a daily basis (Filippova et al., 2009), as-
                                                                     sist in the automated classification and filtering of
    Automated summarization methods can                              documents, and increase search engines precision.
    be defined as “language-independent,” if                            Automated summarization methods can
    they are not based on any language-                              use different levels of linguistic analysis:
    specific knowledge. Such methods can                             morphological, syntactic, semantic and dis-
    be used for multilingual summarization                           course/pragmatic (Mani, 2001). Although the
    defined by Mani (2001) as “processing                            summary quality is expected to improve when
    several languages, with summary in the                           a summarization technique includes language
    same language as input.” In this pa-                             specific knowledge, the inclusion of that knowl-
    per, we introduce MUSE, a language-                              edge impedes the use of the summarizer on
    independent approach for extractive sum-                         multiple languages. Only systems that perform
    marization based on the linear optimiza-                         equally well on different languages without
    tion of several sentence ranking measures                        language-specific knowledge (including linguistic
    using a genetic algorithm. We tested our                         analysis) can be considered language-independent
    methodology on two languages—English                             summarizers.
    and Hebrew—and evaluated its perfor-                                The publication of information on the Internet
    mance with ROUGE-1 Recall vs. state-                             in an ever-increasing variety of languages 2 dic-
    of-the-art extractive summarization ap-                          tates the importance of developing multilingual
    proaches. Our results show that MUSE                             summarization approaches. There is a particu-
    performs better than the best known multi-                       lar need for language-independent statistical tech-
    lingual approach (TextRank1 ) in both lan-                       niques that can be readily applied to text in any
    guages. Moreover, our experimental re-                           language without depending on language-specific
    sults on a bilingual (English and Hebrew)                        linguistic tools. In the absence of such techniques,
    document collection suggest that MUSE                            the only alternative to language-independent sum-
    does not need to be retrained on each lan-                       marization would be the labor-intensive transla-
    guage and the same model can be used                             tion of the entire document into a common lan-
    across at least two different languages.                         guage.
                                                                        Here we introduce MUSE (MUltilingual Sen-
1   Introduction                                                     tence Extractor), a new approach to multilingual
                                                                     single-document extractive summarization where
Document summaries should use a minimum                              summarization is considered as an optimization or
number of words to express a document’s main                         a search problem. We use a Genetic Algorithm
ideas. As such, high quality summaries can sig-                      (GA) to find an optimal weighted linear combina-
nificantly reduce the information overload many                      tion of 31 statistical sentence scoring methods that
professionals in a variety of fields must contend                    are all language-independent and are based on ei-
   1                                                                 ther a vector or a graph representation of a docu-
     We evaluated several summarizers—SUMMA, MEAD,
Microsoft Word Autosummarize and TextRank—on the DUC                 ment, where both representations are based on a
2002 corpus. Our results show that TextRank performed
                                                                        2
best. In addition, TextRank can be considered language-                   Gulli and Signorini (2005) used Web searches in 75 dif-
independent as long as it does not perform any morphological         ferent languages to estimate the size of the Web as of the end
analysis.                                                            of January 2005.


                                                               927
         Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 927–936,
                  Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


word segmentation.                                          of which use the vector space model for text repre-
   We have evaluated our approach on two mono-              sentation and a set of predefined or user-specified
lingual corpora of English and Hebrew documents             weights for a combination of position, frequency,
and, additionally, on one bilingual corpora com-            title, and centroid-based (MEAD) features. Gold-
prising English and Hebrew documents. Our eval-             stein et al. (1999) integrated linguistic and statisti-
uation experiments sought to                                cal features. In none of these works, however, did
- Compare the GA-based approach for single-                 the researchers attempt to find the optimal weights
document extractive summarization (MUSE) to                 for the best linear combination.
the best known sentence scoring methods.                        Information retrieval and machine learning
- Determine whether the same weighting model is             techniques were integrated to determine sentence
applicable across two different languages.                  importance (Kupiec et al., 1995; Wong et al.,
   This paper is organized as follows. The next             2008). Gong and Liu (2001) and Steinberger and
section describes the related work in statistical           Jezek (2004) used singular value decomposition
extractive summarization. Section 3 introduces              (SVD) to generate extracts. Ishikawa et al. (2002)
MUSE, the GA-based approach to multilingual                 combined conventional sentence extraction and a
single-document extractive summarization. Sec-              trainable classifier based on support vector ma-
tion 4 presents our experimental results on mono-           chines.
lingual and bilingual corpora. Our conclusions                  Some authors reduced the summarization pro-
and suggestions for future work comprise the fi-            cess to an optimization or a search problem. Has-
nal section.                                                sel and Sjobergh (2006) used a standard hill-
                                                            climbing algorithm to build summaries that max-
2   Related Work                                            imize the score for the total impact of the sum-
                                                            mary. A summary consists of first sentences from
Extractive summarization is aimed at the selec-             the document was used as a starting point for the
tion of a subset of the most relevant fragments             search, and all neighbours (summaries that can
from a source text into the summary. The frag-              be created by simply removing one sentence and
ments can be paragraphs (Salton et al., 1997), sen-         adding another) were examined, looking for a bet-
tences (Luhn, 1958), keyphrases (Turney, 2000)              ter summary.
or keywords (Litvak and Last, 2008). Statisti-
                                                                Kallel et al. (2004) and Liu et al. (2006b)
cal methods for calculating the relevance score
                                                            used genetic algorithms (GAs), which are known
of each fragment can be categorized into sev-
                                                            as prominent search and optimization meth-
eral classes: cue-based (Edmundson, 1969), key-
                                                            ods (Goldberg, 1989), to find sets of sentences that
word- or frequency-based (Luhn, 1958; Edmund-
                                                            maximize summary quality metrics, starting from
son, 1969; Neto et al., 2000; Steinberger and
                                                            a random selection of sentences as the initial pop-
Jezek, 2004; Kallel et al., 2004; Vanderwende et
                                                            ulation. In this capacity, however, the high com-
al., 2007), title-based (Edmundson, 1969; Teufel
                                                            putational complexity of GAs is a disadvantage.
and Moens, 1997), position-based (Baxendale,
                                                            To choose the best summary, multiple candidates
1958; Edmundson, 1969; Lin and Hovy, 1997;
                                                            should be generated and evaluated for each docu-
Satoshi et al., 2001) and length-based (Satoshi et
                                                            ment (or document cluster).
al., 2001).
                                                                Following a different approach, Turney (2000)
   Considered the first work on sentence scoring
                                                            used a GA to learn an optimized set of parame-
for automated text summarization, Luhn (1958)
                                                            ters for a keyword extractor embedded in the Ex-
based the significance factor of a sentence on the
                                                            tractor tool.3 Orăsan et al. (2000) enhanced the
frequency and the relative positions of signifi-
                                                            preference-based anaphora resolution algorithms
cant words within a sentence. Edmundson (1969)
                                                            by using a GA to find an optimal set of values for
tested different linear combinations of four sen-
                                                            the outcomes of 14 indicators and apply the opti-
tence ranking scoring methods—cue, key, title and
                                                            mal combination of values from data on one text
position—to identify that which performed best
                                                            to a different text. With such approach, training
on a training corpus. Linear combinations of sev-
                                                            may be the only time-consuming phase in the op-
eral statistical sentence ranking methods were also
                                                            eration.
applied in the MEAD (Radev et al., 2001) and
                                                               3
SUMMA (Saggion et al., 2003) approaches, both                      http://www.extractor.com/


                                                      928


   Today, graph-based text representations are be-           frequency of the term t by tf (t). In the LUHN
coming increasingly popular, due to their abil-              method, Wi and Ni are the number of keywords
ity to enrich the document model with syntactic              and the total number of words in the ith cluster, re-
and semantic relations. Salton et al. (1997) were            spectively, such that clusters are portions of a sen-
among the first to make an attempt at using graph-           tence bracketed by keywords, i.e., frequent, non-
based ranking methods in single document ex-                 common words.4
tractive summarization, generating similarity links             Figure 1 demonstrates the taxonomy of the
between document paragraphs and using degree                 methods listed in Table 1. Methods that require
scores in order to extract the important paragraphs          pre-defined threshold values are marked with a
from the text. Erkan and Radev (2004) and Mi-                cross and listed in Table 2 together with the aver-
halcea (2005) introduced algorithms for unsuper-             age threshold values obtained after method eval-
vised extractive summarization that rely on the              uation on English and Hebrew corpora. Each
application of iterative graph-based ranking algo-           method was evaluated on both corpora, with dif-
rithms, such as PageRank (Brin and Page, 1998)               ferent threshold t ∈ [0, 1] (only numbers with one
and HITS (Kleinberg, 1999). Their methods rep-               decimal digit were considered). Threshold val-
resent a document as a graph of sentences inter-             ues resulted in the best ROUGE-1 scores, were
connected by similarity relations. Various sim-              selected. A threshold of 1 means that all terms
ilarity functions can be applied: cosine similar-            are considered, while a value of 0 means that
ity as in (Erkan and Radev, 2004), simple over-              only terms with the highest rank (tf, degree, or
lap as in (Mihalcea, 2005), or other functions.              pagerank) are considered. The methods are di-
Edges representing the similarity relations can be           vided into three main categories—structure-, vec-
weighted (Mihalcea, 2005) or unweighted (Erkan               tor-, and graph-based—according to the text rep-
and Radev, 2004): two sentences are connected if             resentation model, and each category is divided
their similarity is above some predefined threshold          into sub-categories.
value.                                                          Section 3.3 describes our application of a GA to
                                                             the summarization task.
3   MUSE – MUltilingual Sentence
    Extractor                                                Table 2: Selected thresholds for threshold-based
                                                             scoring methods
In this paper we propose a learning approach
                                                                             Method         Threshold
to language-independent extractive summariza-                                LUHN           0.9
tion where the best set of weights for a linear com-                         LUHN DEG       0.9
bination of sentence scoring methods is found by                             LUHN PR        0.0
                                                                             KEY            [0.8, 1.0]
a genetic algorithm trained on a collection of doc-                          KEY DEG        [0.8, 1.0]
ument summaries. The weighting vector thus ob-                               KEY PR         [0.1, 1.0]
                                                                             COV            0.9
tained is used for sentence scoring in future sum-                           COV DEG        [0.7, 0.9]
marizations. Since most sentence scoring methods                             COV PR         0.1
have a linear computational complexity, only the
training phase of our approach is time-consuming.
                                                             3.2 Text representation models
3.1 Sentence scoring methods                                 The vector-based scoring methods listed in Ta-
Our work is aimed at identifying the best linear             ble 1 use tf or tf-idf term weights to evaluate
combination of the 31 sentence scoring methods               sentence importance. In contrast, representation
listed in Table 1. Each method description in-               used by the graph-based methods (except for Tex-
cludes a reference to the original work where the            tRank) is based on the word-based graph represen-
method was proposed for extractive summariza-                tation models described in (Schenker et al., 2004).
tion. Methods proposed in this paper are denoted             Schenker et al. (2005) showed that such graph
by new. Formulas incorporate the following nota-             representations can outperform the vector space
tion: a sentence is denoted by S, a text document            model on several document categorization tasks.
by D, the total number of words in S by N , the to-          In the graph representation used by us in this work
tal number of sentences in D by n, the sequential               4
                                                                  Luhn’s experiments suggest an optimal limit of 4 or 5
number of S in D by i, and the in-document term              non-significant words between keywords.


                                                       929


                                           Table 1: Sentence scoring metrics
Name          Description                                                                        Source
POS F         Closeness to the beginning of the document: 1i                                     (Edmundson, 1969)
POS L         Closeness to the end of the document: i                                            (Baxendale, 1958)
POS B         Closeness to the borders of the document: max( 1i ,     1
                                                                    n−i+1
                                                                          )                      (Lin and Hovy, 1997)
LEN W         Number of words in the sentence                                                    (Satoshi et al., 2001)
LEN CH        Number of characters in the sentence5
                                                    W2
LUHN          maxi∈{clusters(S)} {CSi }, CSi = Nii                                               (Luhn, 1958)
                                              P
KEY           Sum of the keywords frequencies: t∈{Keywords(S)} tf (t)                            (Edmundson, 1969)
                                                         |Keywords(S)|
COV           Ratio of keywords number (Coverage):                                               (Liu et al., 2006a)
                                                                P
                                                         |Keywords(D)|
                                                                          tf (t)
                                                               t∈S
TF       Average term frequency for all sentence words:                                          (Vanderwende et al., 2007)
         P                                       log(n(t))
                                                                 N
TFISF       t∈S
                tf (t) × isf (t), isf (t) = 1 − log(n) ,                                         (Neto et al., 2000)
         n(t) is the number of sentences containing t
SVD      Length of a sentence vector in Σ2 · V T after computing Singular Value                  (Steinberger and Jezek, 2004)
         Decomposition of a term by sentences matrix A = U ΣV T
                                                             |S∩T |
TITLE O Overlap similarity6 to the title: sim(S, T ) = min{|S|,|T   |}
                                                                                                 (Edmundson, 1969)
                                                        |S∩T |
TITLE J  Jaccard similarity to the title: sim(S, T ) = |S∪T  |
                                              ~ T~ ) = cos(S,
                                                            ~ T~ ) = S•  ~ T~
TITLE C  Cosine similarity to the title: sim(S,
                                                                      |S~ |•|T~ |
D COV O Overlap similarity to the document complement                                            new
                                   |S∩T |
         sim(S, D − S) = min{|S|,|D−S|}
                                                                                       |S∩T |
D COV J  Jaccard similarity to the document complement sim(S, D − S) = |S∪D−S|
                                                                ~ D ~− S) = S•D−S    ~    ~
D COV C Cosine similarity to the document complement cos(S,
                                                                                  |S~ |•|D−S
                                                                                           ~ |
LUHN DEG Graph-based extensions of LUHN, KEY and COV measures respectively.
KEY DEG Node degree is used instead of a word frequency: words are considered
COV DEG significant if they are represented by nodes having a degree higher
         than a predefined threshold               P
                                                                          Degi
                                                          i∈{words(S)}
DEG           Average degree for all sentence nodes:            N
GRASE         Frequent sentences from bushy paths are selected. Each sentence in the bushy
              path gets a domination score that is the number of edges with its label in the
              path normalized by the sentence length. The relevance score for a sentence
              is calculated as a sum of its domination scores over all paths.
LUHN PR       Graph-based extensions of LUHN, KEY and COV measures respectively.
KEY PR        Node PageRank score is used instead of a word frequency: words are considered
COV PR        significant if they are represented by nodes having a PageRank score higher
              than a predefined threshold                  P
                                                                  P R(t)
                                                      t∈S
PR        Average PageRank for all sentence nodes:       N
TITLE E O Overlap-based edge matching between title and sentence graphs
TITLE E J Jaccard-based edge matching between title and sentence graphs
D COV E O Overlap-based edge matching between sentence and a document complement
          graphs
D COV E J Jaccard-based edge matching between sentence and a document complement
          graphs
ML TR     Multilingual version of TextRank without morphological analysis:                       (Mihalcea, 2005)
          Sentence score equals to PageRank
                                     P      (Brin and Page, 1998) rank of its node:
          W S(Vi ) = (1 − d) + d ∗ V ∈In(V ) P
                                                        wji
                                                                   W S(Vj )
                                              j      i                    wjk
                                                           Vk ∈Out(Vj )




nodes represent unique terms (distinct words) and                   3.3 Optimization—learning the best linear
edges represent order-relationships between two                         combination
terms. There is a directed edge from A to B if an A                 We found the best linear combination of the meth-
term immediately precedes the B term in any sen-                    ods listed in Table 1 using a Genetic Algorithm
tence of the document. We label each edge with                      (GA). GAs are categorized as global search heuris-
the IDs of sentences that contain both words in the                 tics. Figure 2 shows a simplified GA flowchart.
specified order.                                                    A typical genetic algorithm requires (1) a genetic
                                                                    representation of the solution domain, and (2) a
                                                                    fitness function to evaluate the solution domain.
                                                                       We represent the solution as a vector of weights


                                                              930


                                                                      Language-independent sentence
                                                                             scoring methods




                                     Structure-                            Vector-                                                Graph-
                                       based                               based                                                  based




                    Position                   Length         Frequency             Similarity                    Degree     Pagerank              Similarity



                                                        LUHN
                                                                                                          LUHN_DEG*    LUHN_PR*
                                                         KEY
            POS_F                                                                                          KEY_DEG*     KEY_PR*
                                      LEN_W              COV
            POS_L
                                      LEN_CH              TF                Title          Document       COV_DEG*     COV_PR*             Title          Document
            POS_B                                                                                            DEG*         PR*
                                                        TFIISF
                                                                                                            GRASE*       ML_TR
                                                         SVD



                                                                 TITLE_O            D_COV_O*
                                                                                                                             TITLE_E_O*            D_COV_E_O*
                                                                 TITLE_J            D_COV_J*
                                                                                                                             TITLE_E_J*            D_COV_E_J*
                                                                 TITLE_C            D_COV_C*




                    Figure 1: Taxonomy of language-independent sentence scoring methods


                              Initialization                                                           empirically was proven as a good choice. Each
                                                                                                       gene is represented by a weighting vector vi =
                                     Selection                                                         w1 , . . . , wD having a fixed number of D ≤ 31 ele-
                                                                                                       ments. All elements are generated from a standard
                                      Mating
                                                                                                       normal distribution, with µ = 0 and σ 2 = 1, and
                      Reproduction




                                     Crossover           no                                            normalized to sum up to 1. For this solution rep-
                                                                                                       resentation, a negative weight, if it occurs, can be
                                     Mutation                                                          considered as a “penalty” for the associated met-
                                                                                                       ric.
                               Terminate?                                                                 Selection During each successive generation, a
                                          yes                                                          proportion of the existing population is selected to
                                       Best
                                       gene                                                            breed a new generation. We use a truncation se-
                                                                                                       lection method that rates the fitness of each so-
                                                                                                       lution and selects the best fifth (100 out of 500)
Figure 2: Simplified flowchart of a Genetic Algo-
                                                                                                       of the individual solutions, i.e., getting the maxi-
rithm
                                                                                                       mal ROUGE value. In such manner, we discard
                                                                                                       “bad” solutions and prevent them from reproduc-
for a linear combination of sentence scoring                                                           tion. Also, we use elitism—method that prevents
methods—real-valued numbers in the unlimited                                                           losing the best found solution in the population by
range normalized in such a way that they sum up                                                        copying it to the next generation.
to 1. The vector size is fixed and it equals to the                                                       Reproduction          In    this   stage,    new
number of methods used in the combination.                                                             genes/solutions are introduced into the popu-
   Defined over the genetic representation, the fit-                                                   lation, i.e., new points in the search space are
ness function measures the quality of the repre-                                                       explored. These new solutions are generated
sented solution. We use ROUGE-1 Recall (Lin                                                            from those selected through the following genetic
and Hovy, 2003) as a fitness function for mea-                                                         operators: mating, crossover, and mutation.
suring summarization quality, which is maximized                                                          In mating, a pair of “parent” solutions is ran-
during the optimization procedure.                                                                     domly selected, and a new solution is created us-
   Below we describe each phase of the optimiza-                                                       ing crossover and mutation, that are the most im-
tion procedure in detail.                                                                              portant part of a genetic algorithm. The GA per-
   Initialization GA will explore only a small part                                                    formance is influenced mainly by these two opera-
of the search space, if the population is too small,                                                   tors. New parents are selected for each new child,
whereas it slows down if there are too many solu-                                                      and the process continues until a new population
tions. We start from N = 500 randomly gener-                                                           of solutions of appropriate size N is generated.
ated genes/solutions as an initial population, that                                                       Crossover is performed under the assumption


                                                                                                 931


that new solutions can be improved by re-using                marization across two different languages.
the good parts of old solutions. However it is
good to keep some part of population from one                 4.2 Text preprocessing
generation to the next. Our crossover operator in-            Crucial to extractive summarization, proper sen-
cludes a probability (80%) that a new and different           tence segmentation contributes to the quality of
offspring solution will be generated by calculat-             summarization results. For English sentences,
ing the weighted average of two “parent” vectors              we used the sentence splitter provided with the
according to (Vignaux and Michalewicz, 1991).                 MEAD summarizer (Radev et al., 2001). A sim-
Formally, a new vector v will be created from                 ple splitter that can split the text at periods, excla-
two vectors v1 and v2 according to the formula                mation points, or question marks was used for the
v = λ ∗ v1 + (1 − λ) ∗ v2 (we set λ = 0.5). There             Hebrew text.7
is a probability of 20% that the offspring will be a
duplicate of one of its parents.                              4.3 Experiment design
   Mutation in GAs functions both to preserve the             The English text material we used in our experi-
existing diversity and to introduce new variation.            ments comprised the corpus of summarized doc-
It is aimed at preventing GA from falling into lo-            uments available to the single document summa-
cal extreme, but it should not be applied too often,          rization task at the Document Understanding Con-
because then GA will in fact change to random                 ference, 2002 (DUC, 2002). This benchmark
search. Our mutation operator includes a proba-               dataset contains 533 news articles, each accompa-
bility (3%) that an arbitrary weight in a vector will         nied by two to three human-generated abstracts of
be changed by a uniformly randomized factor in                approximately 100 words each.
the range of [−0.3, 0.3] from its original value.
                                                                 For the Hebrew language, however, to the best
   Termination The generational process is re-                of our knowledge, no summarization benchmarks
peated until a termination condition—a plateau of             exist. To generate a corpus of summarized Hebrew
solution/combination fitness such that successive             texts, therefore, we set up an experiment where
iterations no longer produce better results—has               human assessors were given 50 news articles of
been reached. The minimal improvement in our                  250 to 830 words each from the Website of the
experiments was set to ǫ = 1.0E − 21.                         Haaretz newspaper.8 All assessors were provided
                                                              with the Tool Assisting Human Assessors (TAHA)
4   Experiments
                                                              software tool9 that enables sentences to be easily
4.1 Overview                                                  selected and stored for later inclusion in the doc-
                                                              ument extract. In total, 70 undergraduate students
The MUSE summarization approach was eval-
                                                              from the Department of Information Systems En-
uated using a comparative experiment on two
                                                              gineering, Ben Gurion University of the Negev
monolingual corpora of English and Hebrew texts
                                                              participated in the experiment. Each student par-
and on a bilingual corpus of texts in both lan-
                                                              ticipant was randomly assigned ten different doc-
guages. We intentionally chose English and He-
                                                              uments and instructed to (1) spend at least five
brew, which belong to distinct language families
                                                              minutes on each document, (2) ignore dialogs and
(Indo-European and Semitic languages, respect-
                                                              quotations, (3) read the whole document before
fully), to ensure that the results of our evaluation
                                                              beginning sentence extraction, (4) ignore redun-
would be widely generalizable. The specific goals
                                                              dant, repetitive, and overly detailed information,
of the experiment are to:
                                                              and (5) remain within the minimal and maximal
- Evaluate the optimal sentence scoring models in-
                                                              summary length constraints (95 and 100 words, re-
duced from the corpora of summarized documents
                                                              spectively). Summaries were assessed for quality
in two different languages.
                                                              by comparing each student’s summary to those of
- Compare the performance of the GA-based mul-
                                                              all the other students using the ROUGE evalua-
tilingual summarization method proposed in this
work to the state-of-the-art approaches.                         7
                                                                    Although the same set of splitting rules may be used for
- Compare method performance on both lan-                     many different languages, separate splitters were used for En-
                                                              glish and Hebrew because the MEAD splitter tool is restricted
guages.                                                       to European languages.
- Determine whether the same sentence scoring                     8
                                                                    http://www.haaretz.co.il
                                                                  9
model can be efficiently used for extractive sum-                   TAHA can be provided upon request


                                                        932


tion toolkit adapted to Hebrew10 and the ROUGE-                      rizer, and (3) with the best single scoring method
1 metric (Lin and Hovy, 2003). We filtered all the                   in each corpus. As a baseline, we compiled sum-
summaries produced by assessors that received av-                    maries created from the initial sentences (denoted
erage ROUGE score below 0.5, i. e. agreed with                       by POS F). Table 4 shows the comparative re-
the rest of assessors in less than 50% of cases.                     sults (ROUGE mean values) for English, Hebrew,
Finally, our corpus of summarized Hebrew texts                       and bilingual corpora, with the best summarizers
was compiled from the summaries of about 60%                         on top. Pairwise comparisons between summa-
of the most consistent assessors, with an aver-                      rizers indicated that all methods (except POS F
age of seven extracts per single document11 . The                    and ML TR in the English and bilingual corpora
ROUGE scores of the selected assessors are dis-                      and D COV J and POS F in the Hebrew corpus)
tributed between 50 and 57 percents.                                 were significantly different at the 95% confidence
   The third, bilingual, experimental corpus was                     level. MUSE performed significantly better than
assembled from documents in both languages.                          TextRank in all three corpora and better than the
                                                                     best single methods COV DEG in English and
4.4 Experimental Results                                             D COV J in Hebrew corpora respectively.
We evaluated English and Hebrew summaries us-                           Two sets of features—the full set of 31 sen-
ing ROUGE-1, 2, 3, 4, L, SU and W metrics, de-                       tence scoring metrics and the 10 best bilingual
scribed in (2004). In agreement with Lin’s (2004)                    metrics determined in our previous work13 using
conclusion, our results for the different metrics                    a clustering analysis of the methods results on
were not statistically distinguishable. However,                     both corpora—were tested on the bilingual corpus.
ROUGE-1 showed the largest variation across the                      The experimental results show that the optimized
methods. In the following comparisons, all results                   combination of the 10 best metrics is not signif-
are presented in terms of the ROUGE-1 Recall                         icantly distinguishable from the best single met-
metric.                                                              ric in the multilingual corpus – COV DEG. The
   We estimated the ROUGE metric using 10-fold                       difference between the combination of all 31 met-
cross validation. The results of training and testing                rics and COV DEG is significant only with a one-
comprise the average ROUGE values obtained for                       tailed p-value of 0.0798 (considered not very sig-
English, Hebrew, and bilingual corpora (Table 3).                    nificant). Both combinations significantly outper-
Since we experimented with a different number of                     formed all the other summarizers that were com-
English and Hebrew documents (533 and 50, re-                        pared. Table 4 contains the results of MUSE-
spectively), we have created 10 balanced bilingual                   trained weights for all 31 metrics.
corpora, each with the same number of English                           Our experiments showed that the removal of
and Hebrew documents, by combining approxi-                          highly-correlated metrics (the metric with the
mately 50 randomly selected English documents                        lower ROUGE value out of each pair of highly-
with all 50 Hebrew documents. Each corpus was                        correlated metrics) from the linear combination
then subjected to 10-fold cross validation, and the                  slightly improved summarization quality, but the
average results for training and testing were calcu-                 improvement was not statistically significant. Dis-
lated.                                                               carding bottom ranked features (up to 50%), also,
   We compared our approach (1) with a                               did not affect the results significantly.
multilingual version of TextRank (denoted by                            Table 5 shows the best vectors generated from
ML TR) (Mihalcea, 2005) as the best known                            training MUSE on all the documents in the En-
multilingual summarizer, (2) with Microsoft                          glish, Hebrew, and multilingual (one of 10 bal-
Word’s Autosummarize function12 (denoted by                          anced) corpora and their ROUGE training scores
MS SUM) as a widely used commercial summa-                           and number of GA iterations.
   10
                                                                        While the optimal values of the weights are ex-
      The regular expressions specifying “word” were adapted
to Hebrew alphabet. The same toolkit was used for sum-
                                                                     pected to be nonnegative, among the actual re-
maries evaluation on Hebrew corpus.                                  sults are some negative values. Although there
   11
      Dataset is available at http://www.cs.bgu.ac.                  is no simple explanation for this outcome, it may
il/˜litvakm/research/
   12                                                                be related to a well-known phenomenon from Nu-
      We reported the following bug to Microsoft: Microsoft
Word’s Document.Autosummarize Method returns different               merical Analysis called over-relaxation (Friedman
results from the output of the AutoSummarize Dialog Box.
                                                                       13
In our experiments, the Method results were used.                           submitted to publication


                                                               933


and Kandel, 1994). For example, Laplace equa-
                                                             Table 5: Induced weights for the best linear com-
tion φxx + φyy = 0 is iteratively solved over a
                                                             bination of scoring metrics
grid of points as follows: At each grid point let
         (n)                                                       Metric          ENG      HEB     MULT
φ(n) , φ     denote the nth iteration as calculated                COV DEG         8.490   0.171    0.697
from the differential equation and its modified fi-                KEY DEG        15.774    0.218   -2.108
                                                                   KEY             4.734    0.471    0.346
nal value, respectively. The final value is chosen                 COV PR         -4.349    0.241   -0.462
                       (n−1)
as ωφ(n) + (1 − ω)φ          . While the sum of the                COV            10.016   -0.112    0.865
                                                                   D COV C        -9.499   -0.163    1.112
two weights is obviously 1, the optimal value of ω,                D COV J        11.337    0.710    2.814
which minimizes the number of iterations needed                    KEY PR          0.757    0.029   -0.326
for convergence, usually satisfies 1 < ω < 2                       LUHN DEG        6.970    0.211    0.113
                                                                   POS F           6.875    0.490    0.255
(i.e., the second weight 1 − ω is negative) and ap-                LEN CH          1.333   -0.002    0.214
proaches 2 the finer the grid gets. Though some-                   LUHN           -2.253   -0.060   0.411
what unexpected, this surprising result can be rig-                LUHN PR         1.878   -0.273   -2.335
                                                                   LEN W         -13.204   -0.006   1.596
orously proved (Varga, 1962).                                      ML TR           8.493    0.340    1.549
                                                                   TITLE E J      -5.551   -0.060   -1.210
                                                                   TITLE E O     -21.833    0.074   -1.537
    Table 3: Results of 10-fold cross validation                   D COV E J       1.629    0.302    0.196
                 ENG       HEB MULT                                D COV O         5.531   -0.475    0.431
                                                                   TFISF          -0.333   -0.503    0.232
        Train 0.4483 0.5993 0.5205                                 DEG             3.584   -0.218    0.059
        Test    0.4461 0.5936 0.5027                               D COV E O       8.557   -0.130   -1.071
                                                                   PR              5.891   -0.639    1.793
                                                                   TITLE J        -7.551    0.071    1.445
                                                                   TF              0.810    0.202   -0.650
                                                                   TITLE O       -11.996    0.179   -0.634
Table 4: Summarization performance.            Mean                SVD            -0.557    0.137    0.384
ROUGE-1                                                            TITLE C         5.536   -0.029    0.933
        Metric       ENG      HEB     MULT                         POS B          -5.350    0.347    1.074
        MUSE        0.4461   0.5921   0.4633                       GRASE          -2.197   -0.116   -1.655
        COV DEG     0.4363   0.5679   0.4588                       POS L         -22.521   -0.408   -3.531
        D COV J     0.4251   0.5748   0.4512                       Score          0.4549   0.6019   0.526
        POS F       0.4190   0.5678   0.4440                       Iterations       10        6        7
        ML TR       0.4138   0.5190   0.4288
        MS SUM      0.3097   0.4114   0.3184


   Assuming efficient implementation, most met-
rics have a linear computational complexity rela-
tive to the total number of words in a document
                                                             independent approach, in both Hebrew and En-
- O(n). As a result, MUSE total computation
                                                             glish using either monolingual or bilingual cor-
time, given a trained model, is also linear (at fac-
                                                             pora. Moreover, our results suggest that the same
tor of the number of metrics in a combination).
                                                             weighting model is applicable across multiple lan-
The training time is proportional to the number of
                                                             guages. In future work, one may:
GA iterations multiplied by the number of indi-
                                                             - Evaluate MUSE on additional languages and lan-
viduals in a population times the fitness evaluation
                                                             guage families.
(ROUGE) time. On average, in our experiments
                                                             - Incorporate threshold values for threshold-based
the GA performed 5 − 6 iterations—selection and
                                                             methods (Table 2) into the GA-based optimization
reproduction—before reaching convergence.
                                                             procedure.
5   Conclusions and future work                              - Improve performance of similarity-based metrics
                                                             in the multilingual domain.
In this paper we introduced MUSE, a new, GA-                 - Apply additional optimization techniques like
based approach to multilingual extractive sum-               Evolution Strategy (Beyer and Schwefel, 2002),
marization. We evaluated the proposed method-                which is known to perform well in a real-valued
ology on two languages from different language               search space.
families: English and Hebrew. The experimen-                 - Extend the search for the best summary to the
tal results showed that MUSE significantly out-              problem of multi-object optimization, combining
performed TextRank, the best known language-                 several summary quality metrics.


                                                       934


Acknowledgments                                                  M. Hassel and J. Sjobergh. 2006. Towards holistic
                                                                   summarization: Selecting summaries, not sentences.
We are grateful to Michael Elhadad and Galina                      In Proceedings of Language Resources and Evalua-
Volk from Ben-Gurion University for providing                      tion.
the ROUGE toolkit adapted to the Hebrew alpha-                   K. Ishikawa, S-I. ANDO, S-I. Doi, and A. Okumura.
bet, and to Slava Kisilevich from the University                   2002. Trainable automatic text summarization using
of Konstanz for the technical support in evaluation                segmentation of sentence. In Proceedings of 2002
experiments.                                                       NTCIR 3 TSC workshop.
                                                                 F. J. Kallel, M. Jaoua, L. B. Hadrich, and A. Ben
                                                                    Hamadou. 2004. Summarization at laris labora-
References                                                          tory. In Proceedings of the Document Understand-
                                                                    ing Conference.
P. B. Baxendale. 1958. Machine-made index for tech-
   nical literaturean experiment. IBM Journal of Re-             J.M. Kleinberg. 1999. Authoritative sources in a
   search and Development, 2(4):354–361.                            hyperlinked environment. Journal of the ACM
                                                                    (JACM), 46(5):604–632.
H.-G. Beyer and H.-P. Schwefel. 2002. Evolution
  strategies: A comprehensive introduction. Journal              J. Kupiec, J. Pedersen, and F Chen. 1995. A trainable
  Natural Computing, 1(1):3–52.                                     document summarizer. In Proceedings of the 18th
                                                                    annual international ACM SIGIR conference, pages
S. Brin and L. Page. 1998. The anatomy of a large-                  68–73.
   scale hypertextual web search engine. Computer
   networks and ISDN systems, 30(1-7):107–117.                   C.Y. Lin and E. Hovy. 1997. Identifying topics by po-
                                                                   sition. In Proceedings of the fifth conference on Ap-
DUC. 2002. Document understanding conference.                      plied natural language processing, pages 283–290.
  http://duc.nist.gov.
                                                                 Chin-Yew Lin and Eduard Hovy. 2003. Auto-
H. P. Edmundson. 1969. New methods in automatic                    matic evaluation of summaries using n-gram co-
  extracting. ACM, 16(2).                                          occurrence statistics. In NAACL ’03: Proceedings of
                                                                   the 2003 Conference of the North American Chapter
G. Erkan and D. R. Radev. 2004. Lexrank: Graph-
                                                                   of the Association for Computational Linguistics on
  based lexical centrality as salience in text summa-
                                                                   Human Language Technology, pages 71–78.
  rization. Journal of Artificial Intelligence Research,
  22:457–479.                                                    Chin-Yew Lin. 2004. Rouge: A package for auto-
                                                                   matic evaluation of summaries. In Proceedings of
K. Filippova, M. Surdeanu, M. Ciaramita, and
                                                                   the Workshop on Text Summarization Branches Out
  H. Zaragoza. 2009. Company-oriented extractive
                                                                   (WAS 2004), pages 25–26.
  summarization of financial news. In Proceedings
  of the 12th Conference of the European Chapter                 M. Litvak and M. Last. 2008. Graph-based keyword
  of the Association for Computational Linguistics,                extraction for single-document summarization. In
  pages 246–254.                                                   Proceedings of the Workshop on Multi-source Multi-
                                                                   lingual Information Extraction and Summarization,
M. Friedman and A. Kandel. 1994. Fundamentals of                   pages 17–24.
  Computer Numerical Analysis. CRC Press.
                                                                 D. Liu, Y. He, D. Ji, and H. Yang. 2006a. Genetic al-
D. E. Goldberg. 1989. Genetic algorithms in search,                gorithm based multi-document summarization. Lec-
  optimization and machine learning.      Addison-                 ture Notes in Computer Science, 4099:1140.
  Wesley.
                                                                 D. Liu, Y. Wang, C. Liu, and Z. Wang. 2006b. Mul-
J. Goldstein, M. Kantrowitz, V. Mittal, and J. Car-                tiple documents summarization based on genetic
   bonell. 1999. Summarizing text documents: Sen-                  algorithm. Lecture Notes in Computer Science,
   tence selection and evaluation metrics. In Proceed-             4223:355.
   ings of the 22nd Annual International ACM SIGIR
   Conference on Research and Development in Infor-              H. P. Luhn. 1958. The automatic creation of literature
   mation Retrieval, pages 121–128.                                abstracts. IBM Journal of Research and Develop-
                                                                   ment, 2:159–165.
Y. Gong and X. Liu. 2001. Generic text summarization
   using relevance measure and latent semantic analy-            Inderjeet Mani. 2001. Automatic Summarization. Nat-
   sis. In Proceedings of the 24th ACM SIGIR confer-                ural Language Processing, John Benjamins Publish-
   ence on Research and development in information                  ing Company.
   retrieval, pages 19–25.
                                                                 Rada Mihalcea. 2005. Language independent extrac-
A. Gulli and A. Signorini. 2005. The indexable web is              tive summarization. In AAAI’05: Proceedings of the
  more than 11.5 billion pages. http://www.cs.                     20th national conference on Artificial intelligence,
  uiowa.edu/˜asignori/web-size/.                                   pages 1688–1689.


                                                           935


J.L. Neto, A.D. Santos, C.A.A. Kaestner, and A.A. Fre-           G. A. Vignaux and Z. Michalewicz. 1991. A ge-
   itas. 2000. Generating text summaries through the               netic algorithm for the linear transportation problem.
   relative importance of topics. Lecture Notes in Com-            IEEE Transactions on Systems, Man and Cybernet-
   puter Science, pages 300–309.                                   ics, 21:445–452.

Constantin Orăsan, Richard Evans, and Ruslan Mitkov.            K.F. Wong, M. Wu, and W. Li. 2008. Extractive sum-
  2000. Enhancing preference-based anaphora res-                   marization using supervised and semi-supervised
  olution with genetic algorithms.       In Dimitris               learning. In Proceedings of the 22nd International
  Christodoulakis, editor, Proceedings of the Second               Conference on Computational Linguistics-Volume 1,
  International Conference on Natural Language Pro-                pages 985–992.
  cessing, volume 1835, pages 185 – 195, Patras,
  Greece, June 2– 4. Springer.

Dragomir Radev, Sasha Blair-Goldensohn, and Zhu
  Zhang. 2001. Experiments in single and multidoc-
  ument summarization using mead. First Document
  Understanding Conference.

Horacio Saggion, Kalina Bontcheva, and Hamish Cun-
  ningham. 2003. Robust generic and query-based
  summarisation. In EACL ’03: Proceedings of the
  tenth conference on European chapter of the Associ-
  ation for Computational Linguistics.

G. Salton, A. Singhal, M. Mitra, and C. Buckley. 1997.
   Automatic text structuring and summarization. In-
   formation Processing and Management, 33(2):193–
   207.

C. N. Satoshi, S. Satoshi, M. Murata, K. Uchimoto,
  M. Utiyama, and H. Isahara. 2001. Sentence ex-
  traction system assembling multiple evidence. In
  Proceedings of 2nd NTCIR Workshop, pages 319–
  324.

A. Schenker, H. Bunke, M. Last, and A. Kandel. 2004.
   Classification of web documents using graph match-
   ing. International Journal of Pattern Recognition
   and Artificial Intelligence, 18(3):475–496.

A. Schenker, H. Bunke, M. Last, and A. Kandel. 2005.
   Graph-theoretic techniques for web content mining.

J. Steinberger and K. Jezek. 2004. Text summarization
   and singular value decomposition. Lecture Notes in
   Computer Science, pages 245–254.

S. Teufel and M. Moens. 1997. Sentence extraction as
   a classification task. In Proceedings of the Workshop
   on Intelligent Scalable Summarization, ACL/EACL
   Conference, pages 58–65.

Peter D. Turney.     2000.        Learning algorithms
  for keyphrase extraction.     Information Retrieval,
  2(4):303–336.

L. Vanderwende, H. Suzuki, C. Brockett, and
  A. Nenkova. 2007. Beyond sumbasic: Task-
  focused summarization with sentence simplification
  and lexical expansion. Information processing and
  management, 43(6):1606–1618.

R.S. Varga. 1962. Matrix Iterative Methods. Prentice-
  Hall.


                                                           936

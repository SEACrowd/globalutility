         Modeling Norms of Turn-Taking in Multi-Party Conversation

                                             Kornel Laskowski
                                         Carnegie Mellon University
                                            Pittsburgh PA, USA
                                          kornel@cs.cmu.edu



                     Abstract                                     This state of affairs has resulted in the near-
    Substantial research effort has been in-                   exclusion from computational consideration and
    vested in recent decades into the com-                     from semantic analysis of a phenomenon which
    putational study and automatic process-                    occurs at the lowest level of speech exchange,
    ing of multi-party conversation. While                     namely the relative timing of the deployment of
    most aspects of conversational speech                      speech in arbitrary multi-party groups. This phe-
    have benefited from a wide availabil-                      nomenon, the implicit taking of turns at talk
    ity of analytic, computationally tractable                 (Sacks et al., 1974), is important because unless
    techniques, only qualitative assessments                   participants adhere to its general rules, a conver-
    are available for characterizing multi-party               sation would simply not take place. It is there-
    turn-taking. The current paper attempts to                 fore somewhat surprising that while most other
    address this deficiency by first proposing                 aspects of speech enjoy a large base of computa-
    a framework for computing turn-taking                      tional methodologies for their study, there are few
    model perplexity, and then by evaluat-                     quantitative techniques for assessing the flow of
    ing several multi-participant modeling ap-                 turn-taking in general multi-party conversation.
    proaches. Experiments show that direct                        The current work attempts to address this prob-
    multi-participant models do not general-                   lem by proposing a simple framework, which, at
    ize to held out data, and likely never will,               least conceptually, borrows quite heavily from the
    for practical reasons. In contrast, the                    standard language modeling paradigm. First, it de-
    Extended-Degree-of-Overlap model rep-                      fines the perplexity of a vector-valued Markov pro-
    resents a suitable candidate for future                    cess whose multi-participant states are a concate-
    work in this area, and is shown to success-                nation of the binary states of individual speakers.
    fully predict the distribution of speech in                Second, it presents some obvious evidence regard-
    time and across participants in previously                 ing the unsuitability of models defined directly
    unseen conversations.                                      over this space, under various assumptions of in-
                                                               dependence, for the inference of conversation-
1   Introduction
                                                               independent norms of turn-taking. Finally, it
Substantial research effort has been invested in               demonstrates that the extended-degree-of-overlap
recent decades into the computational study and                model of (Laskowski and Schultz, 2007), which
automatic processing of multi-party conversation.              models participants in an alternate space, achieves
Whereas sociolinguists might argue that multi-                 by far the best likelihood estimates for previ-
party settings provide for the most natural form               ously unseen conversations. This appears to be
of conversation, and that dialogue and monologue               because the model can learn across conversa-
are merely degenerate cases (Jaffe and Feldstein,              tions, regardless of the number of their partici-
1970), computational approaches have found it                  pants. Experimental results show that it yields
most expedient to leverage past successes; these               relative perplexity reductions of approximately
often involved at most one speaker. Consequently,              75% when compared to the ubiquitous single-
even in multi-party settings, automatic systems                participant model which ignores interlocutors, in-
generally continue to treat participants indepen-              dicating that it can learn and generalize aspects of
dently, fusing information across participants rel-            interaction which direct multi-participant models,
atively late in processing.                                    and merely single-participant models, cannot.


                                                         999
       Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 999–1008,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


2   Data                                               inter-pausal unit of (Koiso et al., 1998)1 , where
                                                       the threshold is 100 ms.
Analysis and experiments are performed using the          A consequence of this choice is that any model
ICSI Meeting Corpus (Janin et al., 2003; Shriberg      of turn-taking behavior inferred will effectively be
et al., 2004). The corpus consists of 75 meetings,     a model of the distribution of speech, in time and
held by various research groups at ICSI, which         across participants. If the parameters of such a
would have occurred even if they had not been          model are maximum likelihood (ML) estimates,
recorded. This is important for studying naturally     then that model will best account for what is most
occurring interaction, since any form of interven-     likely, or most “normal”; it will constitute a norm.
tion (including occurrence staging solely for the         Finally, an important aspect of this work is that
purpose of obtaining a record) may have an un-         it analyzes turn-taking behavior as independent of
known but consistent impact on the emergence of        the words spoken (and of the ways in which those
turn-taking behaviors. Each meeting was attended       words are spoken). As a result, strictly speaking,
by 3 to 9 participants, providing a wide variety of    what is modeled is not the distribution of speech in
possible interaction types.                            time and across participants but of binary speech
                                                       activity in time and across participants. Despite
3   Conceptual Framework                               this seemingly dramatic simplification, it will be
3.1 Definitions                                        seen that important aspects of turn-taking are suffi-
                                                       ciently rare to be problematic for modeling. Mod-
Turn-taking is a generally observed phenomenon         eling them jointly alongside lexical information,
in conversation (Sacks et al., 1974; Goodwin,          in multi-party scenarios, is likely to remain in-
1981; Schegloff, 2007); one party talks while the      tractable for the foreseeable future.
others listen. Its description and analysis is an
important problem, treated frequently as a sub-        3.2 The Vocal Interaction Record Q
domain of linguistic pragmatics (Levinson, 1983).      The notation used here, as in (Laskowski and
In spite of this, linguists tend to disagree about     Schultz, 2007), is a trivial extension of that pro-
what precisely constitutes a turn (Sacks et al.,       posed in (Rabiner, 1989) to vector-valued Markov
1974; Edelsky, 1981; Goodwin, 1981; Traum and          processes.
Heeman, 1997), or even a turn boundary. For ex-           At any instant t, each of K participants to a con-
ample, a “yeah” produced by a listener to indicate     versation is in a state drawn from Ψ ≡ {S0 , S1 } ≡
attentiveness, referred to as a backchannel (Yngve,    {, }, where S1 ≡  indicates speech (or, more
1970), is often considered to not implement a turn     precisely, “intra-talk-spurt instants”) and S0 ≡
(nor to delineate an ongoing turn of an interlocu-      indicates non-speech (or “inter-talk-spurt in-
tor), as it bears no propositional content and does    stants”). The joint state of all participants at time
not “take the floor” from the current speaker.         t is described using the K-length column vector
   To avoid being tied to any particular sociolin-
                                                           qt ∈ ΨK           ≡ Ψ × Ψ × ... × Ψ
guistic theory, the current work equates “turn”                                
with any contiguous interval of speech uttered by                            ≡ S0 , S1 , . . . , S2K −1          . (1)
the same participant. Such intervals are commonly      An entire conversation, from the point of view of
referred to as talk spurts (Norwine and Murphy,        this work, can be represented as the matrix
1938). Because Norwine and Murphy’s original
                                                                       Q ≡ [q1 , q2 , . . . , qT ]                  (2)
definition is somewhat ambiguous and non-trivial
                                                                                    K×T
to operationalize, this work relies on that proposed                        ∈ Ψ            .
by (Shriberg et al., 2001), in which spurts are “de-   Q is known as the (discrete) vocal interaction
fined as speech regions uninterrupted by pauses        (Dabbs and Ruback, 1987) record. T is the total
longer than 500 ms” (italics in the original). Here,   number of frames in the conversation, sampled at
a threshold of 300 ms is used instead, as recently     Ts = 100 ms intervals. This is approximately the
proposed in NIST’s Rich Transcription Meeting          duration of the shortest lexical productions in the
Recognition evaluations (NIST, 2002). The re-          ICSI Meeting Corpus.
sulting definition of talk spurt, it is important to      1
                                                            The inter-pausal unit differs from the pause unit of
note, is in quite common use but frequently un-        (Seligman et al., 1997) in that the latter is an intra-turn unit,
der different names. An oft-cited example is the       requiring prior turn segmentation


                                                   1000


3.3 Time-Independent First-Order Markov                              are often preferred (Jelinek, 1999). They are ubiq-
    Modeling of Q                                                    uitously used to compare the complexity of differ-
Given this definition of Q, a model Θ is sought                      ent word sequences (or corpora) w and w′ under
to account for it. Only time-independent models,                     the same model Θ, or the performance on a sin-
whose parameters do not change over the course                       gle word sequence (or corpus) w under competing
of the conversation, are considered in this work.                    models Θ and Θ′ .
   For simplicity, the state q0 = S0 =                                  Here, a similar metric is proposed, to be used
[, , . . . , ]∗ , in which no participant is speak-               for the same purposes, for the record Q.
ing (∗ indicates matrix transpose, to avoid con-                                             1
                                                                             NLL = −           log2 P ( Q | Θ )        (8)
fusion with conversation duration T ) is first                                              KT
prepended to Q. P0 = P ( q0 ) therefore repre-
                                                                             PPL = 2NLL
sents the unconditional probability of all partici-
                                                                                     = (P ( Q | Θ ))− /KT
                                                                                                         1
pants being silent just prior to the start of any con-                                                                 (9)
versation2 . Then
                                                                     are defined as measures of turn-taking perplex-
                        T
                        Y                                            ity. As can be seen in Equation 8, the negative
 P ( Q ) = P0 ·               P ( qt | q0 , q1 , · · · , qt−1 )      log-likelihood is normalized by the number K of
                        t=1                                          participants and the number T of frames in Q;
                         T                                           the latter renders the measure useful for making
             .          Y
             = P0 ·           P ( qt | qt−1 , Θ ) ,          (3)     duration-independent comparisons. The normal-
                        t=1                                          ization by K does not per se suggest that turn-
                                                                     taking in conversations with different K is nec-
where in the second line the history is truncated to
                                                                     essarily similar; it merely provides similar bounds
yield a standard first-order Markov form.
                                                                     on the magnitudes of these metrics.
   Each of the T factors in Equation 3 is indepen-
dent of the instant t,                                               4 Direct Estimation of Θ
       P ( qt | qt−1 , Θ )                                           Direct application of bigram modeling techniques,
              = P ( qt = Sj | qt−1 = Si , Θ )                (4)     defined over the states {S}, is treated as a baseline.
              ≡ aij ,                                        (5)     4.1 The Case of K = 2 Participants
                                                                     In contrast to multi-party conversation, dialogue
as per the notation in (Rabiner, 1989). In particu-
                                                                     has been extensively modeled in the ways de-
lar, each factor is a function only of the state Si in
                                                                     scribed in this paper. Beginning with (Brady,
which the conversation was at time t − 1 and the
                                                                     1969), Markov modeling techniques over the joint
state Sj in which the conversation is at time t, and
                                                                     speech activity of two interlocutors have been
not of the instants t − 1 or t. It may be expressed
                                                                     explored by both the sociolinguist and the psy-
as the scalar aij which forms the ith row and jth
                                                                     cholinguist community (Jaffe and Feldstein, 1970;
column entry of the matrix {aij } ≡ Θ.
                                                                     Dabbs and Ruback, 1987). The same models have
3.4 Perplexity                                                       also appeared in dialogue systems (Raux, 2008).
                                                                     Most recently, they have been augmented with du-
In language modeling practice, one finds the like-                   ration models in a study of the Switchboard corpus
lihood P ( w | Θ ), of a word sequence w of length                   (Grothendieck et al., 2009).
kwk under a model Θ, to be an inconvenient mea-
sure for comparison. Instead, the negative log-                      4.2 The Case of K > 2 Participants
likelihood (NLL) and perplexity (PPL), defined as                    In the general case beyond dialogue, such mod-
                            1                                        els have found less traction. This is partly due to
         NLL = −               loge P ( w | Θ )              (6)     the exponential growth in the number of states as
                           kwk
                                                                     K increases, and partly due to difficulties in in-
         PPL = 10NLL ,                                       (7)     terpretation. The only model for arbitrary K that
   2
                                                                     the author is familiar with is the GroupTalk model
    In reality, the instant t = 0 refers to the beginning of the
recording of a conversation, rather than the beginning of the        (Dabbs and Ruback, 1987), which is unsuitable
conversation itself; this detail is without consequence.             for the purposes here as it does not scale (with K,


                                                                  1001


                                                         instants following it. These halves are hereafter
                                                         referred to as A and B, respectively (the interval
  1.125
                                                         in Figure 1 falls entirely within the A half). Two
                                                         separate models ΘCD              CD
                                                                              A and ΘB are each trained
    1.1
                                                         on only one of the two halves, and then applied to
                                                         those same halves. As can be seen at the scale em-
  1.075
                                                         ployed, the matched A+B model, demonstrating
                                                         the effect of training data ablation, deviates from
   1.05                                    oracle
                                           A+B           the global oracle model only in the intervals [7, 11]
                                           B+A           seconds and [15, 18] seconds; otherwise it appears
                 10         15        20                 that more training data, from later in the conversa-
                                                         tion, does not affect model performance.
Figure 1: Perplexity (along y-axis) in time (along          Finally, the third trajectory, the continuous gray
x-axis, in minutes) for meeting Bmr024 under             line, is obtained when the two halves A and B
a conditionally dependent global oracle model,           of the meeting are scored using the mismatched
two “matched-half” models (A+B), and two                 models ΘCD              CD
                                                                    B and ΘA , respectively (this condi-
“mismatched-half” models (B+A).                          tion is henceforth referred to as the B+A condi-
                                                         tion). It can be seen that even when probabilities
                                                         are estimated from the same participants, in ex-
the number of participants) without losing track of      actly the same conversation, a direct conditionally
speakers when two or more participants speak si-         dependent model exposed to over 25 minutes of
multaneously (known as overlap).                         a conversation cannot predict the turn-taking pat-
                                                         terns observed later.
4.2.1 Conditionally Dependent Participants
In a particular conversation with K participants,        4.2.2 Conditionally Independent Participants
the state space of an ergodic process contains           A potential reason for the gross misestimation of
2K states, and the number of free parameters in          ΘCD under mismatched conditions is the size of
a model Θ which treats participant behavior as           the state space {S}. The number of parameters in
                                                  CD
conditionally dependent
            K      K
                           (CD), henceforth Θ ,         the model can be reduced by assuming that par-
scales as 2 · 2 − 1 . It should be immediately           ticipants behave independently at instant t, but are
obvious that many of the 2K states are likely to not     conditioned on their joint behavior at t − 1. The
occur within a conversation of duration T , leading      likelihood of Q under the resulting conditionally
to misestimation of the desired probabilities.           independent model ΘCI has the form
   To demonstrate this, three perplexity trajecto-
ries for a snippet of meeting Bmr024 are shown           P (Q)
in Figure 1, in the interval beginning 5 minutes                      T   K
                                                             .      YY
                                                                       P qt [k] | qt−1 , ΘCI
                                                                                             
into the meeting and ending 20 minutes later. (The           = P0 ·                       k    , (10)
meeting is actually just over 50 minutes long but                    t=1 k=1
only a snippet is shown to better appreciate small
                                                         where each factor is time-independent,
time-scale variation.) The depicted perplexities
are not unweighted averages over the whole meet-            P qt [k] | qt−1 , ΘCI
                                                                                    
                                                                               k
ing of duration T as in Equation 8, but over a 60-
                                                              = P qt [k] = Sn | qt−1 = Si , ΘCI
                                                                                                     
second Hamming window centered on each t.                                                    k           (11)
   The first trajectory, the dashed black line, is ob-        ≡ aCI
                                                                 k,in ,                                  (12)
tained when the entire meeting is used to estimate
ΘCD , and is then scored by that same model (an          with 0 ≤ i < 2K and 0 ≤ n < 2. The complete
“oracle” condition). Significant perplexity varia-       model {ΘCI           CI
                                                                   k } ≡ {{ak,in }} consists of K matrices
tion is observed throughout the depicted snippet.        of size 2K × 2 each. It therefore contains only
   The second trajectory, the continuous black           K·2K free parameters, a significant reduction over
line, is that obtained when the meeting is split into    the conditionally dependent model ΘCD .
two equal-duration halves, one consisting of all in-        Panel (a) of Figure 2 shows the performance
stants prior to the midpoint and the other of all        of this model on the same conversational snippet


                                                     1002


as in Figure 1. The oracle, dashed black line of
                                                             1.125                          1.4
the latter is reproduced as a reference. The con-
                                                               1.1                          1.3
tinuous black and gray lines show the smoothed
                                                             1.075                          1.2
perplexity for the matched (A+B) and the mis-
                                                              1.05                          1.1
matched (B+A) conditions, respectively. In the
matched condition, the CI model reproduces the                          10     15      20             10    15     20


oracle trajectory with relatively high fidelity, sug-                               ΘCI                          ΘCI
                                                                               
                                                                     (a) Θ =         k              (b) Θ =       any
gesting that participants’ behavior may in fact be
assumed to be conditionally independent in the
sense discussed. Furthermore, the failures of the            1.125                          1.125


CI model under mismatched conditions are less se-              1.1                            1.1


vere in magnitude than those of the CD model.                1.075                          1.075


   Panel (b) of Figure 2 demonstrates the trivial             1.05                           1.05


fact that a conditionally independent model ΘCI   any ,                 10     15      20              10   15      20

tying the statistics of all K participants into a sin-
                                                                                    ΘM I                         ΘM I
                                                                               
                                                                     (c) Θ =         k              (d) Θ =       any
gle model, is useless. This is of course because it
cannot predict the next state of a generic partici-
                                                          Figure 2: Perplexity (along y-axis) in time (along
pant for which the index k in qt−1 has been lost.
                                                          x-axis, in minutes) for meeting Bmr024 under a
4.2.3 Mutually Independent Participants                   conditionally dependent global oracle model, and
A further reduction in the complexity of Θ can be         various matched (A+B) and mismatched (B+A)
achieved by assuming that participants are mutu-          model pairs with relaxed dependence assump-
ally independent (MI), leading to the participant-        tions. Legend as in Figure 1.
specific ΘMk
             I model:


P (Q)                                                     5 Limitations and Desiderata
          T       K
.      YY
          P qt [k] | qt−1 [k] , ΘM I                      As the analyses in Section 4 reveal, direct es-
                                     
= P0 ·                           k     . (13)
         t=1 k=1                                          timation can be useful under oracle conditions,
                                                          namely when all of a conversation has been ob-
The factors are time-independent,                         served and the task is to find intervals where multi-
P qt [k] | qt−1 [k] , ΘM I
                                                         participant behavior deviates significantly from
                       k
                                                          its conversation-specific norm. The assumption
= P qt [k] = Sn | qt−1 [k] = Sm , ΘM I
                                               
                                   k               (14)   of conditional independence among participants
≡   aM I
     k,mn     ,                                    (15)   was argued to lead to negligible degradation in
                                                          the detectability of these intervals. However, the
where 0 ≤ m < 2 and 0 ≤ n < 2. This model                 assumption of mutual independence consistently
{ΘM   I           MI
    k } ≡ {{ak,mn }} consists of K matrices of            leads to higher surprise by the model.
size 2 × 2 each, with only K · 2 free parameters.
   Panel (c) of Figure 2 shows that the MI model
                                                          5.1 Predicting the Future Within
yields mismatched performance which is a much
                                                              Conversations
better approximation to its performance under
matched conditions. However, its matched perfor-          In the more interesting setting in which only a part
mance is worse than that of CD and CI models.             of a conversation has been seen and the task is to
When a single MI model ΘM       I
                              any is trained instead      limit the perplexity of what is still to come, direct
for all participants, as shown in panel (d), both of      estimation exhibits relatively large failures under
these effects are exaggerated. In fact, the perfor-       both conditionally dependent and conditionally in-
mance of ΘM     I
              any in matched and mismatched con-          dependent participant assumptions. This appears
ditions is almost identical. The consistently higher      to be due to the size of the state space, which
perplexity is obtained, as mentioned, by smooth-          scales as 2K with the number K of participants.
ing over 60-second windows, and therefore un-             In the case of general K, more conversational data
derestimates poor performance at specific instants        may be sought, from exactly the same group of
(which occur frequently).                                 participants, but that approach appears likely to be


                                                      1003


insufficient, and, for practical reasons3 , impossi-               tive and hence multi-participant phenomenon. It
ble. One would instead like to be able to use other                therefore cannot be said to rank conversations ac-
conversations, also exhibiting participant interac-                cording to their deviation from turn-taking norms.
tion, to limit the perplexity of speech occurrence
in the conversation under study.                                   5.3 Theoretical Limitations
   Unfortunately, there are two reasons why direct
                                                                   In addition to the concerns above, a funda-
estimation cannot be tractably deployed across
                                                                   mental limitation of the analyzed direct models,
conversations. The first is that the direct models
                                                                   whether for conversation-specific or conversation-
considered here, with the exception of ΘM      I
                                             any , are             independent use, is that they are theoretically cum-
K-specific. In particular, the number and the iden-
                                                                   bersome if not vacuous. Given a solution to the
tity of conditioning states are both functions of K,
                                                                   problem of R-specificity, the parameters {aCD    ij }
for ΘCD and {ΘCI    k }; the models may also con-                  may be robustly inferred, and the models may be
sist of K distinct submodels, as for {ΘCI   k } and                applied to yield useful estimates of turn-taking
{ΘM k
       I }. No techniques for computing the turn-
                                                                   perplexity. However, they cannot be said to di-
taking perplexity in conversations with K partici-
                                                                   rectly validate or dispute the vast qualitative ob-
pants, using models trained on conversations with
                                                                   servations of sociolinguistics, and of conversation
K ′ 6= K, are currently available.
                                                                   analysis in particular.
   The second reason is that these models, again
with the exception of ΘM      I
                            any , are R-specific, in-              5.4 Prospects for Smoothing
dependently of K-specificity. By this it is meant
that the models are sensitive to participant index                 To produce Figures 1 and 2, a small fraction of
permutation. Had a participant at index k in Q                     probability mass was reserved for unseen bigram
been assigned to another index k ′ 6=k, an alter-                  transitions (as opposed to backing off to unigram
nate representation of the conversation, namely                    probabilities). Furthermore, transitions into never-
Q′ = Rkk′ · Q, would have been obtained. (Here,                    observed states were assigned uniform probabili-
Rkk′ is a matrix rotation operator obtained by ex-                 ties. This policy is simplistic, and there is signifi-
changing columns k and k ′ of the K × K identity                   cant scope for more detailed back-off and interpo-
matrix I.) Since index assignment is entirely arbi-                lation. However, such techniques infer values for
trary, useful direct models cannot be inferred from                under-estimated probabilities from shorter trunca-
other conversations, even when their K ′ = K, un-                  tions of the conditioning history. As K-specificity
less K is small. The prospect of naively permuting                 and R-specificity suggest, what appears to be
every training conversation prior to parameter in-                 needed here are back-off and interpolation across
ference has complexity K!.                                         states. For example, in a conversation of K = 5
                                                                   participants, estimates of the likelihood of the state
5.2 Comparing Perplexity Across                                    qt = []∗ , which might have been unob-
    Conversations                                                  served in any training material, can be assumed
Until R-specificity is comprehensively addressed,                  to be related to those of q′t = []∗ and
the only model from among those discussed so                       q′′t = []∗ , as well as those of Rq′t and
far, which exhibits no K-dependence, is ΘM        I
                                                any ,
                                                                   Rq′′t , for arbitrary R.
namely that which treats participants identically
and independently. This model can be used to                       6 The Extended-Degree-of-Overlap
score the perplexity of any conversation, and facil-                 Model
itates the comparison of the distribution of speech
activity across conversations.                                     The limitations of direct models appear to be ad-
   Unfortunately, since the model captures only                    dressable by a form proposed by Laskowski and
durational aspects of one-participant speech and                   Schultz in (2006) and (2007). That form, the
non-speech intervals, it does not in any way en-                   Extended-Degree-of-Overlap (EDO) model, was
code a norm of turn-taking, an inherently interac-                 used to provide prior probabilities P ( Q | Θ ) of
                                                                   the speech states of multiple meeting participants
   3
     This pertains to the practicalities of re-inviting, instru-   simultaneously, for use in speech activity detec-
menting, recording and transcribing the same groups of
participants, with necessarily more conversations for large        tion. The model was trained on utterances (rather
groups than for small ones.                                        than talk spurts) from a different corpus than that


                                                               1004


used here, and the authors did not explore the turn-            in Equation 16 provides a deterministic map-
taking perplexities of their data sets.                         ping from the conversation-independent space
   Several of the equations in (Laskowski and                   (ni , [oij , nj ]) to the conversation-specific space
Schultz, 2007) are reproduced here for compar-                  {aij }. The mapping is deterministic because the
ison. The EDO model yields time-independent                     model assumes that all participants are identical.
transition probabilities which assume conditional               This places the EDO model at a disadvantage with
inter-participant dependence (cf. Equation 3),                  respect to the CD and CI models, as well as to
                                                                {ΘM    I
                                                                    k }, which allow each participant to be mod-
P ( qt+1 = Sj | qt = Si ) = αij ·                      (16)     eled differently.
P ( kqt+1 k = nj , kqt+1 · qt k = oij | kqt k = ni ) ,
                                                                7 Experiments
where ni ≡ kSi k and nj ≡ kSj k, with kSk yield-
                                                                This section describes the performance of the dis-
ing the number of participants in  in the multi-
                                                                cussed models on the entire ICSI Meeting Corpus.
participant state S. In other words, ni and nj are
the numbers of participants simultaneously speak-               7.1 Conversation-Specific Modeling
ing in states Si and Sj , respectively. The elements
                                                                First to be explored is the prediction of yet-
of the binary product S = S1 · S2 are given by
                                                                unobserved behavior in conversation-specific set-
              
                 , if S1 [k] = S2 [k] =                       tings. For each meeting, models are trained on
 S [k] ≡                                        (17)            portions of that meeting only, and then used to
                 , otherwise ,
                                                                score other portions of the same meeting. This
and oij is therefore the number of same partici-                is repeated over all meetings, and comprises the
pants speaking in Si and Sj . The discussion of                 mismatched condition of Section 4; for contrast,
the role of αij in Equation 16 is deferred to the               the matched condition is also evaluated.
end of this section.                                               Each meeting is divided into two halves, in two
   The EDO model mitigates R-specificity be-                    different ways. The first way is the A/B split of
cause it models each bigram (qt−1 , qt ) = (Si , Sj )           Section 4, representing the first and second halves
as the modified bigram (ni , [oij , nj ]), involving            of each meeting; as has been shown, turn-taking
three scalars each of which is a sum — a com-                   patterns may vary substantially from A to B. The
mutative (and therefore rotation-invariant) opera-              second split (C/D) places every even-numbered
tion. Because it sums across only those partici-                frame in one set and every odd-numbered frame
pants which are in the  state, completely ignor-               in the other. This yields a much easier setting, of
ing their -state interlocutors, it can also mitigate           two halves which are on average maximally simi-
K-specificity if one additionally redefines                     lar but still temporally disjoint.
                                                                   The perplexities (of Equation 9) in these experi-
         ni = min ( kSi k, Kmax )                      (18)     ments are shown in the second, fourth, sixth and
         nj    = min ( kSj k, Kmax )                   (19)     eighth columns of Table 1, under “all”. In the
         oij   = min ( kSi · Sj k, ni , nj ) ,         (20)     matched A+B and C+D conditions, the condition-
                                                                ally dependent model ΘCD provides topline ML
as in (Laskowski and Schultz, 2007). Kmax                       performance. Perplexities decrease as model com-
represents the maximum model-licensed degree                    plexities fall for direct models, as expected. How-
of overlap, or the maximum number of par-                       ever, in the more interesting mismatched B+A
ticipants allowed to be simultaneously speak-                   condition, the EDO model performs the best. This
ing. The EDO model therefore represents a                       shows that its ability to generalize to unseen data
viable conversation-independent, K-independent,                 is higher than that of direct models. However, in
and R-independent model of turn-taking for the                  the easier mismatched D+C condition, it is out-
purposes in the current work4 . The factor αij                  performed by the CI model due to behavior differ-
    4
                                                                ences among participants, which the EDO model
      There exists some empirical evidence to suggest that
conversations of K participants should not be used to train     small groups and large groups, represented in their study by
models for predicting turn-taking behavior in conversations     K = 5 and K = 10, and noted that there is a smooth transi-
of K ′ participants, for K ′ 6= K, because turn-taking is in-   tion between the two extremes; this provides some scope for
herently K-dependent. For example, (Fay et al., 2000) found     interpolating small- and large- group models, and the EDO
that qualitative differences in turn-taking patterns between    framework makes this possible.


                                                            1005


                         Hard split A/B (first/second halves)           Easy split C/D (odd/even frames)
           Model               A+B                     B+A                   C+D                 D+C
                          “all”   “sub”           “all”   “sub”         “all”   “sub”       “all”   “sub”
           ΘCD           1.0905 1.6444           1.1225 1.8395         1.0915 1.6555       1.0991 1.7403
           {ΘCI
             k }         1.0915 1.6576           1.1156 1.7809         1.0925 1.6695       1.0956 1.7028
           {ΘM
             k }
                I        1.0978 1.7236           1.1086 1.7950         1.0991 1.7381       1.0992 1.7398
           ΘM I          1.1046 1.8047           1.1047 1.8059         1.1046 1.8050       1.1046 1.8052
           ΘEDO          1.0977 1.7257           1.0985 1.7323         1.0977 1.7268       1.0982 1.7313

Table 1: Perplexities for conversation-specific turn-taking models on the entire ICSI Meeting Corpus.
Both “all” frames and the subset (“sub”) for which qt−1 6= qt are shown, for matched (A+B and C+D)
and mismatched (B+A and D+C) conditions on splits A/B and C/D.


does not capture.                                                                        PPL           ∆PPL (%)
                                                                     Model
   The numbers under the “all” columns in Table 1                                    “all”   “sub”    “all” “sub”
were computed using all of each meeting’s frames.                    ΘCD           1.0921 1.6616        —      —
For contrast, in the “sub” columns, perplexities                     ΘM I          1.1051 1.8170      14.1   23.5
are computed over only those frames for which                        ΘEDO    (6)   1.0992 1.7405       7.7   11.9
qt−1 6= qt . This is a useful subset because, for                    ΘEDO    (5)   1.0968 1.7127       5.1    7.7
the majority of time in conversations, one person                    ΘEDO    (4)   1.0953 1.6947       3.5    5.0
simply continues to talk while all others remain                     ΘEDO    (3)   1.1082 1.8502      17.5   28.5
silent5 . Excluding qt−1 = qt bigrams (leading to
0.32M frames from 2.39M frames in “all”) offers a                 Table 2: Perplexities for conversation-independent
glimpse of expected performance differences were                  turn-taking models on the entire ICSI Meeting
duration modeling to be included in the models.                   Corpus; the oracle ΘCD topline is included in the
Perplexities are much higher in these intervals, but              first row. Both “all” frames and the subset (“sub”)
the same general trend as for “all” is observed.                  for which qt−1 6= qt are shown; relative increases
                                                                  over the topline (less unity, representing no per-
7.2 Conversation-Independent Modeling                             plexity) are shown in columns 4 and 5. The value
The training of conversation-independent models,                  of Kmax (cf. Equations 18, 19, and 20) is shown
given a corpus of K-heterogeneous meetings, is                    in parentheses in the first column.
achieved by iterating over all meetings and testing
each using models trained on all of the other meet-
                                                                  ΘEDO by 78%.
ings. As discussed in the preceding section, ΘM    I
                                                 any
is the only one among the direct models which can
be used for this purpose. It also models exclu-                   8 Discussion
sively single-participant behavior, ignoring the in-              The model perplexities as reported above may
teractive setting provided by other participants. As              be somewhat different if the “talk spurt” were
shown in Table 2, when all time is scored the EDO                 replaced by a more sociolinguistically motivated
model with Kmax = 4 is the best model (in Sec-                    definition of “turn”, but the ranking of models and
tion 7.1, Kmax = K since the model was trained                    their relative performance differences are likely to
on the same meeting to which it was applied). Its                 remain quite similar. On the one hand, many inter-
perplexity gap to the oracle model is only a quarter              talk-spurt gaps might find themselves to be within-
of the gap exhibited by ΘM   I
                           any .                                  turn, leading to more  entries in the record Q
   The relative performance of EDO models is                      than observed in the current work. This would
even better when only those instants t are consid-                increase the apparent frequency and duration of
ered for which qt−1 6= qt . There, the perplex-                   intervals of overlap. On the other hand, alterna-
ity gap to the oracle model is smaller than that of               tive definitions of turn may exclude some speech
    5
      Retaining only qt−1 6=qt also retains instants of transi-   activity, such as that implementing backchannels.
tion into and out of intervals of silence.                        Since backchannels are often produced in overlap


                                                              1006


with the foreground speaker, their removal may          proved by considering variability across partic-
eliminate some overlap from Q. (However, as             ipants and in time. Participant dependence is
noted in (Shriberg et al., 2001), overlap rates in      likely to be related to speakers’ social character-
multi-party conversation remain high even after         istics and conversational roles, while time depen-
the exclusion of backchannels.) Both inter-talk-        dence may reflect opening and closing functions,
spurt gap inclusion and backchannel exclusion are       topic boundaries, and periodic turn exchange fail-
likely to yield systematic differences, and there-      ures. In the meantime, event types such as the lat-
fore to be exploitable by the investigated models       ter may be detectable as EDO perplexity depar-
in similar ways.                                        tures, potentially recommending the model’s use
   The results presented may also be perturbed          for localizing conversational “hot spots” (Wrede
by modifying the way in which a (manually               and Shriberg, 2003). The EDO model, and turn-
produced) talk spurt segmentation, with high-           taking models in general, may also find use in
precision boundary time-stamps, is discretized to       diagnosing turn-taking naturalness in spoken di-
yield Q. Two parameters have controlled the dis-        alogue systems.
cretization in this work: (1) the frame step Ts =
                                                        9 Conclusions
100 ms; and (2) the proportion ρ of Ts for which
a participant must be speaking within a frame in        This paper has presented a framework for quan-
order for that frame to be considered  rather than     tifying the turn-taking perplexity in multi-party
. ρ = 0.5 was chosen since this posits approx-         conversations. To begin with, it explored the con-
imately as much more speech (than in the high-          sequences of modeling participants jointly by con-
precision segmentation) as it eliminates. Higher        catenating their binary speech/non-speech states
values of ρ would lead to more , leading to more       into a single multi-participant vector-valued state.
overlap than observed in this work. Meanwhile, at       Analysis revealed that such models are particu-
constant ρ, choosing a Ts value larger than 100 ms      larly poor at generalization, even to subsequent
would occasionally miss the shortest talk spurts,       portions of the same conversation. This is due to
but it would allow the models, which are all 1st-       the size of their state space, which is factorial in
order Markovian, to learn temporally more dis-          the number of participants. Furthermore, because
tant dependencies. The trade-offs between these         such models are both specific to the number of
choices are currently under investigation.              participants and to the order in which participant
   From an operational, modeling perspective, it        states are concatenated together, it is generally in-
is important to recognize that the choices of the       tractable to train them on material from other con-
definition for “turn”, and of the way in which          versations. The only such model which may be
segmentations are discretized, are essentially ar-      trained on other conversations is that which com-
bitrary. The investigated modeling alternatives,        pletely ignores interlocutor interaction.
and the EDO model in particular, require only that         In contrast, the Extended-Degree-of-Overlap
the multi-participant vocal interaction record Q        (EDO) construction of (Laskowski and Schultz,
be binary-valued. This general applicability has        2007) may be trained on other conversations, re-
been demonstrated in past work, in which the EDO        gardless of their number of participants, and use-
model was trained on utterances for use in speech       fully applied to approximate the turn-taking per-
activity detection (Laskowski and Schultz, 2007),       plexity of an oracle model. This is achieved be-
as well as in (Laskowski and Burger, 2007) where        cause it models entry into and egress out of spe-
it was trained separately on talk spurts and laugh      cific degrees of overlap, and completely ignores
bouts, in the same data, to highlight the differences   the number of participants actually present or their
between speech and laughter deployment.                 modeled arrangement. In this sense, the EDO
                                                        model can be said to implement the qualitative
   Finally, it should be remembered that the EDO
                                                        findings of conversation analysis. In predicting the
model is both time-independent and participant-
                                                        distribution of speech in time and across partici-
independent. This makes it suitable for compar-
                                                        pants, it reduces the unseen data perplexity of a
ison of conversational genres, in much the same
                                                        model which ignores interaction by 75% relative
way as are general language models of words. Ac-
                                                        to an oracle model.
cordingly, as for language models, density esti-
mation in future turn-taking models may be im-


                                                    1007


References                                                Stephen C. Levinson. 1983. Pragmatics. Cambridge
                                                             University Press.
Paul T. Brady. 1969. A model for generating on-
  off patterns in two-way conversation. Bell Systems      National Institute of Standards and Technology.
  Technical Journal, 48(9):2445–2472.                       2002.      Rich Transcription Evaluation Project,
                                                            www.itl.nist.gov/iad/mig/tests/rt/
James M. Dabbs and R. Barry Ruback. 1987. Di-               (last accessed 15 February 2010 1217hrs GMT).
  mensions of group process: Amount and structure
  of vocal interaction. Advances in Experimental So-      A. C. Norwine and O. J. Murphy. 1938. Character-
  cial Psychology, 20:123–169.                              istic time intervals in telephonic conversation. Bell
                                                            System Technical Journal, 17:281-291.
Carole Edelsky. 1981. Who’s got the floor? Langauge
  in Society, 10:383–421.                                 Lawrence Rabiner. 1989. A tutorial on hidden Markov
                                                            models and selected applications in speech recogni-
Nicolas Fay, Simon Garrod, and Jean Carletta. 2000.         tion. Proc. IEEE, 77(2):257–286.
  Group discussion as interactive dialogue or as serial
  monologue: The influence of group size. Psycho-         Antoine Raux. 2008. Flexible turn-taking for spo-
  logical Science, 11(6):487–492.                           ken dialogue systems. PhD Thesis, Carnegie Mellon
                                                            University.
Charles Goodwin. 1981. Conversational Organiza-
  tion: Interaction Between Speakers and Hearers.         Harvey Sacks, Emanuel A. Schegloff, and Gail Jeffer-
  Academic Press, New York NY, USA.                         son. 1974. A simplest semantics for the organi-
                                                            zation of turn-taking for conversation. Language,
John Grothendieck, Allen Gorin, and Nash Borges.            50(4):696–735.
  2009. Social correlates of turn-taking behavior.
  Proc. ICASSP, Taipei, Taiwan, pp. 4745–4748.            Emanuel A. Schegloff. 2007. Sequence Organization
                                                            in Interaction. Cambridge University Press, Cam-
Joseph Jaffe and Stanley Feldstein. 1970. Rhythms of        bridge, UK.
   Dialogue. Academic Press, New York NY, USA.            Mark Seligman, Junko Hosaka, and Harald Singer.
                                                           1997. “Pause units” and analysis of spontaneous
Adam Janin, Don Baron, Jane Edwards, Dan Ellis,
                                                           Japanese dialogues: Preliminary studies. Dialogue
  David Gelbart, Nelson Morgan, Barbara Peskin,
                                                           Processing in Spoken Language Systems E. Maier,
  Thilo Pfau, Elizabeth Shriberg, Andreas Stolcke,
                                                           M. Mast, and S. LuperFoy, eds., Lecture Notes
  and Chuck Wooters. 2003. The ICSI Meeting Cor-
                                                           in Computer Science, 1236:100–112. Springer
  pus. Proc. ICASSP, Hong Kong, China, pp. 364–
                                                           Berlin/Heidelberg, Germany.
  367.
                                                          Elizabeth Shriberg, Andreas Stolcke, and Don Baron.
Frederick Jelinek. 1999. Statistical Methods for             2001. Observations on overlap: Findings and impli-
  Speech Recognition. MIT Press, Cambridge MA,               cations for automatic processing of multi-party con-
  USA.                                                       versation. Proc. EUROSPEECH, Genève, Switzer-
                                                             land, pp. 1359–1362.
Hanae Koiso, Yasui Horiuchi, Syun Tutiya, Akira
  Ichikawa, and Yasuharu Den. 1998. An analysis           Elizabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy
  of turn-taking and backchannels based on prosodic          Ang, and Hannah Carvey. 2004. The ICSI Meeting
  and syntactic features in Japanese Map Task dialogs.       Recorder Dialog Act (MRDA) Corpus. Proc. SIG-
  Language and Speech, 41(3-4):295–321.                      DIAL, Boston MA, USA, pp. 97–100.
Kornel Laskowski and Tanja Schultz. 2006. Unsu-           David Traum and Peeter Heeman. 1997. Utterance
  pervised learning of overlapped speech model pa-          units in spoken dialogue. Dialogue Processing in
  rameters for multichannel speech activity detection       Spoken Language Systems E. Maier, M. Mast, and
  in meetings. Proc. ICASSP, Toulouse, France, pp.          S. LuperFoy, eds., Lecture Notes in Computer Sci-
  993–996.                                                  ence, 1236:125–140. Springer Berlin/Heidelberg,
                                                            Germany.
Kornel Laskowski and Susanne Burger. 2007. Analy-
  sis of the occurrence of laughter in meetings. Proc.    Britta Wrede and Elizabeth Shriberg. 2003. Spot-
  INTERSPEECH, Antwerpen, Belgium, pp. 1258–                ting “hot spots” in meetings: Human judgments
  1261.                                                     and prosodic cues. Proc. EUROSPEECH, Aalborg,
                                                            Denmark, pp. 2805–2808.
Kornel Laskowski and Tanja Schultz. 2007. Mod-
  eling vocal interaction for segmentation in meet-       Victor H. Yngve. 1970. On getting a word in edgewise.
  ing recognition. Machine Learning for Multimodal          Papers from the Sixth Regional Meeting Chicago
  Interaction, A. Popescu-Belis, S. Renals, and H.          Linguistic Society, pp. 567–578. Chicago Linguis-
  Bourlard, eds., Lecture Notes in Computer Sci-            tic Society, Chicago IL, USA.
  ence, 4892:259–270, Springer Berlin/Heidelberg,
  Germany.


                                                      1008

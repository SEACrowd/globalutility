                               The Influence of Discourse on Syntax
                          A Psycholinguistic Model of Sentence Processing
                                                    Amit Dubey


                      Abstract                                attention from other authors. In the literature on
    Probabilistic models of sentence com-                     probabilistic modeling, though, the bulk of this
    prehension are increasingly relevant to                   work is focused on lexical semantics (e.g. Padó
    questions concerning human language                       et al., 2006; Narayanan and Jurafsky, 1998) or
    processing. However, such models are of-                  only considers syntactic decisions in the preceed-
    ten limited to syntactic factors. This paper              ing text (e.g. Dubey et al., 2009; Levy and Jaeger,
    introduces a novel sentence processing                    2007). This is the first model we know of which
    model that consists of a parser augmented                 introduces a broad-coverage sentence processing
    with a probabilistic logic-based model                    model which takes the effect of coreference and
    of coreference resolution, which allows                   discourse into account.
    us to simulate how context interacts with                    A major question concerning discourse-syntax
    syntax in a reading task. Our simulations                 interactions involves the strength of communica-
    show that a Weakly Interactive cognitive                  tion between discourse and syntactic information.
    architecture can explain data which had                   The Weakly Interactive (Altmann and Steed-
    been provided as evidence for the Strongly                man, 1988) hypothesis states that a discourse
    Interactive hypothesis.                                   context can reactively prune syntactic choices
                                                              that have been proposed by the parser, whereas
1   Introduction                                              the Strongly Interactive hypothesis posits that
Probabilistic grammars have been found to be                  context can proactively suggest choices to the
useful for investigating the architecture of the              syntactic processor.
human sentence processing mechanism (Jurafsky,                   Support for Weak Interaction comes from
1996; Crocker and Brants, 2000; Hale, 2003;                   experiments in which there are temporary ambi-
Boston et al., 2008; Levy, 2008; Demberg and                  guities, or garden paths, which cause processing
Keller, 2009). For example, probabilistic models              difficulty. The general finding is that supportive
shed light on so-called locality effects: contrast            contexts can reduce the effect of the garden path.
the non-probabilistic hypothesis that dependants              However, Grodner et al. (2005) found that sup-
which are far away from their head always cause               portive contexts even facilitate the processing of
processing difficulty for readers due to the cost             unambiguous sentences. As there are no incorrect
of storing the intervening material in memory                 analyses to prune in unambiguous structures, the
(Gibson, 1998), compared to the probabilistic                 authors claimed their results were not consistent
prediction that there are cases when faraway                  with the Weakly Interactive hypothesis, and
dependants facilitate processing, because readers             suggested that their results were best explained by
have more time to predict the head (Levy, 2008).              a Strongly Interactive processor.
Using a computational model to address funda-                    The model we present here implements the
mental questions about sentence comprehension                 Weakly Interactive hypothesis, but we will show
motivates the work in this paper.                             that it can nonetheless successfully simulate the
   So far, probabilistic models of sentence pro-              results of Grodner et al. (2005). There are three
cessing have been largely limited to syntactic                main parts of the model: a syntactic processor,
factors. This is unfortunate because many out-                a coreference resolution system, and a simple
standing questions in psycholinguistics concern               pragmatics processor which computes certain
interactions between different levels of process-             limited forms of discourse coherence. Following
ing. This paper addresses this gap by building                Hale (2001) and Levy (2008), among others, the
a computational model which simulates the                     syntactic processor uses an incremental proba-
influence of discourse on syntax.                             bilistic Earley parser to compute a metric which
   Going beyond the confines of syntax alone is a             correlates with increased reading difficulty. The
sufficiently important problem that it has attracted          coreference resolution system is implemented


                                                        1179
       Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1179–1188,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


in a probabilistic logic known as Markov Logic                 The target sentences, which were drawn from the
(Richardson and Domingos, 2006). Finally, the                  experiment of McRae et al. (1998), were either
pragmatics processing system contains a small set              the reduced or unreduced sentences similar to:
of probabilistic constraints which convey some
intuitive facts about discourse processing. The                (2)    The postman who was carried by the
three components form a pipeline, where each part                     paramedics was having trouble breathing.
is probabilistically dependent on the previous one.            The reduced version of the sentence is produced
This allows us to combine all three into a single              by removing the words who was. We measured
probability for each reading of an input sentence.             reading times in the underlined region, which is
   The rest of the paper is structured as follows. In          the first point at which there is evidence for the
Section 2, we discuss the details two experiments              relative clause interpretation. The key evidence is
showing support of the Weakly and Strongly In-                 given by the word ‘by’, but the previous word is in-
teractive hypotheses: we discuss Grodner et al.’s              cluded as readers often do not fixate on short func-
result on unambiguous syntactic structures and we              tion words, but rather process them while overtly
present a new experiment on involving a garden                 fixating on the previous word (Rayner, 1998).
path which was designed to be similar to the Grod-                The relative clauses in the target sentence act as
ner et al. experiment. Section 3 introduces techni-            restrictive relative clauses, selecting one referent
cal details of model, and Section 4 shows the pre-             from a larger set. The target sentences are there-
dictions of the model on the experiments discussed             fore more coherent in a context where a restricted
in Section 2. Finally, we discuss the theoretical              set and a contrast set are easily available, than one
consequences of these predictions in Section 5.                in which these sets are absent. This makes the
2     Cognitive Experiments                                    context in Example (1-a) supportive of a reduced
                                                               relative reading, and the context in Example (1-b)
2.1    Discourse and Ambiguity Resolution                      unsupportive of a reduced relative clause. Other
There is a fairly large literature on garden path              experiments, for instance Spivey and Tanenhaus
experiments involving context (Crain and Steed-                (1998), used an unsupportive context where only
man, 1985; Mitchell et al., 1992, ibid). The                   one postman was mentioned. Our experiments
experiments by Altmann and Steedman (1988)                     used a neutral context, where no postmen are
involved PP attachment ambiguity. Other authors                mentioned, to be more similar to the Grodner et
(e.g. Spivey and Tanenhaus, 1998) have used                    al. experiment, as described below.
reduced relative clause attachment ambiguity. In                  Overall, there were 28 items, and 28 partici-
order to be more consistent with the design of the             pants read these sentences using an EyeLink II
experiment in Section 2.2, however, we performed               eyetracker. Each participant read items one at a
our own reading-time experiment which partially                time, with fillers between subsequent items so as
replicated previous results.1                                  to obfuscate the nature of the experiment.
   The experimental items all had a target sen-                Results An ANOVA revealed that all conditions
tence containing a relative clause, and one of two             with a supportive context were read faster than one
possible context sentences, one of which supports              with a neutral context (i.e. a main effect of con-
the relative clause reading and the other which                text), and all conditions with unambiguous syntax
does not.                                                      were read faster than those with a garden path
   The context sentence was one of:                            (i.e. a main effect of ambiguity). Finally, there
                                                               was a statisically significant interaction between
(1)      a.   There were two postmen, one of
                                                               syntax and discourse whereby context decreases
              whom was injured and carried by
                                                               reading times much more when a garden path is
              paramedics, and another who was
                                                               present compared to an unambiguous structure. In
              unhurt.
                                                               other words, a supportive context helped reduce
         b.   Although there was a medical emer-
                                                               the effect of a garden path. This is the prediction
              gency at the post office earlier today,
                                                               made by both the Weakly Interactive and Strongly
              regular mail delivery was unaffected.
                                                               Interactive hypothesis. The pattern of results are
   1
     This experiment was previously reported by Dubey et al.   shown in Figure 2a in Section 4, where they are
(2010).                                                        directly compared to the model results.


                                                           1180


                                                                                                  S
2.2   Discourse and Unambiguous Syntax
As mentioned in the Introduction, Grodner et al.                               NP                                 VP
(2005) proposed an experiment with a supportive                                                                   ...
or unsupportive discourse followed by an unam-                        NP                   VP

biguous target sentence. In their experiment, the                The postman
                                                                                 VBD                  PP
target sentence was one of the following:                                       carried
                                                                                            IN             NP-LGS

(3)    a.   The director that the critics praised                                           by        The paramedics

            at a banquet announced that he was                             (a) Standard WSJ Tree
            retiring to make room for young                                                       S
            talent in the industry.
       b.   The director, who the critics praised                              NP                                   VP
            at a banquet, announced that he was                                                                   ...
            retiring to make room for young                         NPbase                VP-LGS

            talent in the industry.                              The postman
                                                                                VBD1                  PP:by

They also manipulated the context, which was                                    carried
                                                                                           IN:by            NPbase-LGS
either supportive of the target, or a null context.                                          by            The paramedics
The two supportive contexts are:                                      (b) Minimally Modified Tree

(4)    a.   A group of film critics praised a         Figure 1: A schematic representation of the smallest set of
            director at a banquet and another         grammar transformations which we found were required to
                                                      accurately parse the experimental items.
            director at a film premiere.
       b.   A group of film critics praised a
            director and a producer for lifetime      directly compared to the model results. Because
            achievement.                              these results are computed as regressions against a
                                                      baseline, a reading time of 0ms indicates average
The target sentence in (3-a) is a restrictive         difficulty, with negative numbers showing some
relative clause, as in the garden path exper-         facilitation has occured, and positive number
iments. However, the sentence in (3-b) is a           indicating reading difficulty.
non-restrictive relative clause, which does not
                                                      3     Model
assume the presence of a constrast set. Therefore,
the context (4-a) is only used with the restrictive   The model comprises three parts: a parser, a
relative clause, and the context (4-b), where only    coreference resolution system, and a pragmatics
one director is mentioned, is used as the context     subsystem. Let us look at each individually.
for the non-restrictive relative clause. In the       3.1    Parser
conditions with a null context, the target sentence
                                                      The parser is an incremental unlexicalized proba-
was not preceded by any contextual sentence.
                                                      bilistic Earley parser, which is capable of comput-
Results Grodner et al.           measured residual    ing prefix probabilities. A PCFG parser outputs
reading times, i.e. reading times compared to         the generative probability Pparser (w, t), where w is
a baseline in the embedded subject NP (‘the           the text and t is a parse tree. A probabilistic Earley
critics’). They found that the supportive contexts    parser can retrieve all possible derivations at word
decreased reading time, and that this effect was      i (Stolcke, 1995), allowingP us to compute the prob-
stronger for restrictive relatives compared to non-   ability P (wi . . . w0 ) = t Pparser (wi . . . w0 , t).
restricted relatives. As there was no garden path,       Using the prefix probability, we can compute
and hence no incorrect structure for the discourse    the word-by-word Surprisal (Hale, 2001), by
processor to prune, the authors conclude that this    taking the log ratio of the previous word’s prefix
must be evidence for the Strongly Interactive         probability against this word’s prefix probability:
hypothesis. Unlike the garden path experiment                                                 
above, these results do not appear to be consistent                         P (wi−1 . . . w0 )
                                                                     log                                    (1)
with a Weakly Interactive model. We plot their                                P (wi . . . w0 )
results in Figure 3a in Section 4, where they are         Higher Surprisal scores are interpreted as


                                                  1181


being correlated with more reading difficulty, and        Expression                Meaning
likewise lower scores with greater reading ease.          Coref (x , y)             x is coreferent with y.
For most of the remainder of the paper we will            First(x )                 x is a first mention.
simply refer to the prefix probability at word i as       Order (x , y)             x occurs before y.
P (w). While the prefix probability as presented                                    Do x and y share the
here is suitable for syntax-based computations, a         SameHead (x , y)
                                                                                    same syntactic head?
main technical contribution of our model, detailed        ExactMatch(x , y)         x and y are same string.
in Sections 3.2 and 3.3 below, is that we include         SameNumber (x , y)        x and y match in number.
non-syntactic probabilities in the computation of         SameGender (x , y)        x and y match in gender.
Surprisal.                                                SamePerson(x , y)         x and y match in person.
   As per Hale’s original suggestion, our parser                                    The distance between
can compute Surprisal using an exhaustive search,         Distance(x , y, d )
                                                                                    x and y, in sentences.
which entails summing over each licensed deriva-          Pronoun(x )               x is a pronoun.
tion. This can be done efficiently using the packed                                 x has entity type e
representation of an Earley chart. However, as            EntityType(x , e)
                                                                                    (person, organization, etc.)
the coreference processor takes trees as input, we
must therefore unpack parses before resolving              Table 1: Predicates used in the Markov Logic Network
referential ambiguity. Given the ambiguity of our
grammar, this is not tractable. Therefore, we only
consider an n-best list when computing Surprisal.      Markov Logic Network (MLN) we used for our
As other authors have found that a relatively small    system uses similar predicates as the MLN-based
set of analyses can give meaningful predictions        corference resolution system of Huang et al.
(Brants and Crocker, 2000; Boston et al., 2008),       (2009).2 Our MLN uses the predicates listed
we set n = 10.                                         in Table 1. Two of these predicates, Coref and
   The parser is trained on the Wall Street Journal    First, are the output of the MLN – they provide
(WSJ) section of the Penn treebank. Unfortu-           a labelling of coreference mentions into entity
nately, the standard WSJ grammar is not able to        classes. Note that, unlike Huang et al., we assume
give correct incremental parses to our experimen-      an ordering on x and y if Coref (x , y) is true: y
tal items. We found we could resolve this problem      must occur earlier in the document than x. The
by using four simple transformations, which are        remaining predicates in Table 1 are a subset of
shown in Figure 1: (i) adding valency information      features used by other coreference resolution
to verb POS tags (e.g. VBD1 represents a tran-         systems (cf. Soon et al., 2001). The predicates
sitive verb); (ii) we lexicalize ‘by’ prepositions;    we use involve matching strings (checking if two
(iii) VPs containing a logical subject (i.e. the       mentions share a head word or if they are exactly
agent), get the -LGS label; (iv) non-recursive         the same string), matching argreement features (if
NPs are renamed NPbase (the coreference system         the gender, number or person of pairs of NPs are
treats each NPbase as a markable).                     the same; especially important for pronouns), the
                                                       distance between mentions, and if mentions have
3.2   Discourse Processor
                                                       the same entity type (i.e. do they refer to a person,
The primary function of the discourse processing       organization, etc.) As our main focus is not to
module is to perform coreference resolution for        produce a state-of-the-art coreference system, we
each mention in an incrementally processed text.       do not include predicates which are irrevelant for
Because each mention in a coreference chains is        our simulations even if they have been shown to be
transitive, we cannot use a simple classifier, as      effective for coreference resolution. For example,
they cannot enforce global transitivity constraints.   we do not have predicates if two mentions are in
Therefore, this system is implemented in Markov        an apposition relationship, or if two mentions are
Logic (Richardson and Domingos, 2006), a               synonyms for each other.
probabilistic logic, which does allow us to include       Table 2 lists the actual logical formulae which
such constraints.                                      are used as features in the MLN. It should be
   Markov Logic attempts to combine logic                  2
                                                            As we are not interested in unsupervised inference, the
with probabilities by using a Markov random            system of Poon and Domingos (2008) was unsuitable for our
field where logical formulas are features. The         needs.


                                                   1182


               Description                                         Rule
                                    Coref (x , z ) ∧ Coref (y, z ) ∧ Order (x , y) ⇒ Coref (x , y)
               Transitivity                          Coref (x , y) ∧ Coref (y, z ) ⇒ Coref (x , z )
                                    Coref (x , y) ∧ Coref (x , z ) ∧ Order (y, z ) ⇒ Coref (y, z )
                                                     Coref (x , y) ⇒ ¬First(x )
               First Mentions
                                                        First(x ) ⇒ ¬Coref (x , y)
                                                  ExactMatch(x , y) ⇒ Coref (x , y)
               String Match
                                                   SameHead (x , y) ⇒ Coref (x , y)
                                Pronoun(x ) ∧ Pronoun(y) ∧ SameGender (x , y) ⇒ Coref (x , y)
               Pronoun          Pronoun(x ) ∧ Pronoun(y) ∧ SameNumber (x , y) ⇒ Coref (x , y)
                                 Pronoun(x ) ∧ Pronoun(y) ∧ SamePerson(x , y) ⇒ Coref (x , y)
                                     EntityType(x , e) ∧ EntityType(y, e) ⇒ Coref (x , y)
               Other
                                                         Distance(x , y, +d ) ⇒ Coref (x , y)

                                 Table 2: Rules used in the Markov Logic Network



noted that, because we are assuming an order
on the arguments of Coref (x , y), we need three                           XX
formulae to capture transivity relationships. To             P (w) =                   P (c, w, t)
                                                                             c     t
test that the coreference resolution system was                            XX
producing meaningful results, we evaluated our                        =                Pcoref (c|w, t)Pparser (w, t)
system on the test section of the ACE-2 dataset.                             c     t

Using b3 scoring (Bagga and Baldwin, 1998),                   Note that we only consider one possible as-
which computes the overlap of a proposed set with          signment of NPs to coreference entities per parse,
the gold set, the system achieves an F -score of           as we only retrieve the probabilities of the MAP
65.4%. While our results are not state-of-the-art,         solution.
they are reasonable considering the brevity of our         3.3   Pragmatics Processor
feature list.
                                                           The effect of context in the experiments described
                                                           in Section 2 cannot be fully explained using a
                                                           coreference resolution system alone. In the case
   The discourse model is run iteratively at each          of restrictive relative clauses, the referential ‘mis-
word. This allows us to find a globally best               match’ in the unsupported conditions is caused
assignment at each word, which can be reanalyzed           by an expectation elicited by a restrictive relative
at a later point in time. It assumes there is a            clause which is inconsistent with the previous
mention for each base NP outputted by the parser,          discourse when there is no salient restricted subset
and for all ordered pairs of mentions x, y, it             of a larger set. When the larger set is not found
outputs all the ‘observed’ predicates (i.e. ev-            in the discourse, the relative clause becomes
erything but First and Coref ), and feeds them             incoherent given the context, causing reading
to the Markov Logic system. At each step, we               difficulty. Modeling this coherence constraint is
compute both the maximum a posteriori (MAP)                essentially a pragmatics problem, and is under the
assignment of coreference relationships as well            purview of the pragmatics processor in our sys-
as the probability that each individual coreference        tem. The pragmatics processor is quite specialised
assignment is true. Taken together, they allow             and, although the information it encapsulates is
us to calculate, for a coreference assignment c,           quite intuitive, it nonetheless relies on hand-coded
Pcoref (c|w, t) where w is the text input (of the          expert knowledge.
entire document until this point), and t is the parse         The pragmatics processor takes as input an
of each tree in the document up to and including           incremental pragmatics configuration p and
the current incremental parse. As we have previ-           computes the probability Pprag (p|w, t, c). The
ously calculated Pparser (w, t), it is then possible       pragmatics configuration we consider is quite
to compute the joint probability P (c, w, t) at each       simple. It is a 3-tuple where one element is true
word, and therefore the prefix probability P (w)           if the current noun phrase being processed is a
due to syntax and coreference. Overall, we have:           discourse new definite noun phrase, the second


                                                      1183


element is true if the current NP is a discourse           ceding comma, it will be known to be restrictive
new indefinite noun phrase, and the final element          or nonrestrictive clause. In addition to the overall
is true if we encounter an unsupported restrictive         Surprisal values, we also compute syntactic
relative clause. We simply conjecture that there           Surprisal scores, to test if there is any benefit from
is little processing cost (and hence a high proba-         the discourse and pragmatics subsystems. As we
bility) if the entire vector is false; there is a small    are outputting n best lists for each parse, it is
processing cost for discourse new indefinites,             also straightforward to compute other measures
a slightly larger processing cost for discourse            which predict reading difficulty, including pruning
new definites and a large processing cost for an           (Jurafsky, 1996), whereby processing difficulty
incoherent reduced relative clause.                        is predicted when a parse is removed from the n
   The first two elements of the 3-tuple depend            best list, and attention shift (Crocker and Brants,
on the identity of the determiner as recovered by          2000), which predicts parsing difficulty at words
the parser, and on whether the coreference system          where the most highly ranked parse flips from one
adduces the predicate F irst for the current NP.           interpretation to another.
As the coreference system wasn’t designed to                  For the garden path experiment, the simulation
find anaphoric contrast sets, these sets were found        was run on each of the 28 experimental items in
using a simple post-processing check. This post-           each of the 4 conditions, resulting in a total of 112
processing approach worked well for our experi-            runs. For the Grodner et al. experiment, the sim-
mental items, but finding such sets is, in general,        ulation was run on each of the 20 items in each
quite a difficult problem (Modjeska et al., 2003).         of the 4 conditions, resulting in a total of 80 runs.
   The distribution Pprag (p|w, t, c) applies a            For each run, the model was reset, purging all dis-
processing penalty for an unsupported restrictive          course information gained while reading earlier
relative clause whenever a restrictive relative            items. As the system is not stochastic, two runs us-
clause is in the n best list. Because Surprisal            ing the exact same items in the same condition will
computes a ratio of probabilities, this in ef-             produce the same result. Therefore, we made no
fect means we only pay this penality when                  attempt to model by-subject variability, but we did
an unsupported restrictive relative clause first           perform by-item ANOVAs on the system output.
appears in the n best list (otherwise the effect is        4.2   Results
cancelled out). The penalty for discourse new
entities is applied on the first word (ignoring            Garden Path Experiment The simulated
punctuation) following the end of the NP. This             results of our experiment are shown in Figure 2.
spillover processing effect is simply a matter of          Comparing the full simulated results in Figure 2b
modeling convenience: without it, we would have            to the experimental results in Figure 2a, we find
to compute Surprisal probabilities over regions            that the simulation, like the actual experiment,
rather than individual words. Thus, the overall            finds both main effects and an interaction: there
prefix   probability can be computed as: P (w) =           is a main effect of context whereby a supportive
P                                                          context facilitates reading, a main effect of syntax
   p,c,t Pprag (p|w, t, c)Pcoref (c|w, t)Pparser (w, t),
which is then substituted in Equation (1) to get a         whereby the garden path slows down reading,
Surprisal prediction for the current word.                 and an interaction in that the effect of context is
                                                           strongest in the garden path condition. All these
4     Evaluation                                           effects were highly significant at p < 0.01. The
                                                           pattern of results between the full simulation and
4.1    Method
                                                           the experiment differed in two ways. First, the
When modeling the garden path experiment we                simulated results suggested a much larger reading
presented in Section 2.1, we compute Surprisal             difficulty due to ambiguity than the experimental
values on the word ‘by’, which is the earliest point       results. Also, in the unambiguous case, the model
at which there is evidence for a relative clause           predicted a null cost of an unsupportive context on
interpretation. For the Grodner et al. experiment,         the word ‘by’, because the model bears the cost
we compute Surprisal values on the relativiser             of an unsupportive context earlier in the sentence,
‘who’ or ‘that’. Again, this is the earliest point at      and assumes no spillover to the word ‘by’. Finally,
which there is evidence for a relative clause, and         we note that the syntax-only simulation, shown in
depending upon the presence or absence of a pre-           Figure 2c, only produced a main effect of ambigu-


                                                       1184


      (a) Results from our garden path      (b) Simulation of our garden path                    (c) Syntax-only simulation
                 experiment                 experiment

Figure 2: The simulated results predict the same interaction as the garden path experiment, but show a stronger main effect of
ambiguity, and no influence of discourse in the unambiguous condition on the word ‘by’.




(a) Results from the Grodner et al.         (b) Simulation of the Grodner et al.                 (c) Syntax-only simulation
experiment                                  experiment

                     Figure 3: The simulated results predict the outcome of the Grodner et al. experiment.


ity, and was not able to model the effect of context.            successfully simulate syntax-discourse interaction
                                                                 effects which have been shown in the literature.
Grodner et al. Experiment The simulated
                                                                 The difference between a Weakly Interactive
results of the Grodner et al. experiment are shown
                                                                 and Strongly Interactive model can be thought of
in Figure 3. In this experiment, the pattern of
                                                                 computationally in terms of a pipeline architecture
simulated results in Figure 3b showed a much
                                                                 versus joint inference. In a weaker sense, even
closer resemblance to the experimental results in
                                                                 a pipeline architecture where the discourse can
Figure 3a than the garden path experiment. There
                                                                 influence syntactic probabilities could be claimed
is a main effect of context, which is much stronger
                                                                 to be a Strongly Interactive model. However,
in the restrictive relative case compared to non-
                                                                 as our model uses a pipeline where syntactic
restrictive relatives. As with the garden path
                                                                 probabilities are independent of the discourse,
experiment, the ANOVA reported that all effects
                                                                 we claim that our model is Weakly Interactive.
were significant at the p < 0.01 level. Again, as
                                                                 Unlike Altmann and Steedman, who posited that
we can see from Figure 3c, there was no effect
                                                                 the discourse processor actually removes parsing
of context in the syntax-only simulation. The nu-
                                                                 hypotheses, we were able to simulate this pruning
merical trend did show a slight facilitation in the
                                                                 behaviour by simply re-weighting parses in our
unrestricted supported condition, with a Surprisal
                                                                 coreference and pragmatics modules.
of 4.39 compared to 4.41 in the supported case,
but this difference was not significant.                            The fact that a Weakly Interactive system can
                                                                 simulate the result of an experiment proposed in
4.3    Discussion
                                                                 support of the Strongly Interactive hypothesis is
We have shown that our incremental sentence pro-                 initially counter-intuitive. However, this naturally
cessor augmented with discourse processing can                   falls out from our decision to use a probabilistic


                                                            1185


                                  S
                                                                                    show processing difficulty on the word ‘by’ in
                                                                                    the garden path experiment. However, Figure 4
               NP                                 VP-LGS
                                                                                    (which shows the top three parses on the word
             NPbase
                                                                                    ‘by’) indicates that not only are there still main
           The postman       VBD1                    PP:by                 ...
                                                                                    clause interpretations present, but in fact, the
                             carried        IN:by              ...
                                                                                    top two parses are main clause interpretations.
                                                by
                                                                                    This is also true if we limit ourselves to syntactic
         (a) Best parse: p = 9.99 × 10−10 main
         clause, expecting more dependents
                                                                                    probabilities (which are the probabilities listed
                                                                                    in Figure 4). This suggests that neither Jurafsky
                                      S
                                                                                    (1996)’s notion of pruning as processing difficulty
                                                                                    nor Crocker and Brants (2000) notion of attention
                      NP                        VP-LGS
                                                                                    shifts would correctly predict higher reading times
                    NPbase
                                      VBD1                     PP:by
               The postman
                                                                                    on a region containing the word ‘by’. In fact, the
                                      carried         IN:by          ...
                                                                                    main clause interpretation remains the highest-
                                                          by
                                                                                    ranked interpretation until it is finally pruned at an
             (b) 2nd parse: p = 9.93 × 10−10                                        auxiliary of the main verb of the sentence (‘The
             main clause, no more dependents
                                                                                    postman carried by the paramedics was having’).
                                                      S                                This result is curious as our experimental items
                                                                                    closely match some of those simulated by Crocker
                             NP                                            ...      and Brants (2000). We conjecture that the differ-
                                                                                    ence between our attention shift prediction and
              NPbase                      VP-LGS
                                                                                    theirs is due to differences in the grammar. It is
           The postman
                              VBD1                    PP:by                         possible that using a more highly tuned grammar
                              carried           IN:by          ...                  would result in attention shift making the correct
                                                 by                                 prediction, but this possibly shows one benefit of
         (c) 3rd parse: p = 7.69×−10 relative                                       using Surprisal as a linking hypothesis. Because
         clause                                                                     Surprisal sums over several derivations, it is not
Figure 4: The top three parses on the word ‘by’ in the our                          as reliant upon the grammar as the attention shift
first experimental item.                                                            or pruning linking hypotheses.
                                                                                    5   Conclusions
model: a lower probability, even in an unambigu-                                    The main result of this paper is that it is possible
ous structure, is associated with increased reading                                 to produce a Surprisal-based sentence process-
difficulty. As an aside, we note that when using                                    ing model which can simulate the influence of
realistic computational grammars, even the struc-                                   discourse on syntax in both garden path and
tures used in the Grodner et al. experiment are                                     unambiguous sentences. Computationally, the
not unambiguous. In the restrictive relative clause                                 inclusion of Markov Logic allowed the discourse
condition, even though there was not any compe-                                     module to compute well-formed coreference
tition between a relative and main clause reading,                                  chains, and opens two avenues of future re-
our n best list was at all times filled with analyses.                              search. First, it ought to be possible to make the
For example, on the word ‘who’ in the restricted                                    probabilistic logic more naturally incremental,
relative clause condition, the parser is already                                    rather than re-running from scratch at each word.
predicting both the subject-relative (‘the postman                                  Second, we would like to make greater use of the
who was bit by the dog’) and object-relative (‘the                                  logical elements by applying it to problems where
postman who the dog bit’) readings.                                                 inference is necessary, such as resolving bridging
    Overall, these results are supportive of the                                    anaphora (Haviland and Clark, 1974).
growing importance of probabilistic reasoning as                                       Our primary cognitive finding that our model,
a model of human cognitive behaviour. Therefore,                                    which assumes the Weakly Interactive hypothesis
especially with respect to sentence processing,                                     (whereby discourse is influenced by syntax in a
it is necessary to have a proper understanding                                      reactive manner), is nonetheless able to simulate
of how probabilities are linked to real-world                                       the experimental results of Grodner et al. (2005),
behaviours. We note that Surprisal does indeed                                      which were claimed by the authors to be in


                                                                                 1186


support of the Strongly Interactive hypothesis.       Vera Demberg and Frank Keller. A computational
This suggests that the evidence is in favour of the     model of prediction in human parsing: Unifying
Strongly Interactive hypothesis may be weaker           locality and surprisal effects. In Proceedings
than thought.                                           of the 29th meeting of the Cognitive Science
   Finally, we found that the attention shift           Society (CogSci-09), 2009.
(Crocker and Brants, 2000) and pruning (Jurafsky,     Amit Dubey, Frank Keller, and Patrick Sturt.
1996) linking theories are unable to correctly         A probabilistic corpus-based model of paral-
simulate the results of the garden path experiment.    lelism. Cognition, 109(2):193–210, 2009.
Although our main results above underscore the
                                                      Amit Dubey, Patrick Sturt, and Frank Keller. The
usefulness of probabilistic modeling, this obser-
                                                       effect of discourse inferences on syntactic am-
vation emphasizes the importance of finding a
                                                       biguity resolution. In Proceedings of the 23rd
tenable link between probabilities and behaviours.
                                                       Annual CUNY Conference on Human Sentence
Acknowledgements                                       Processing (CUNY 2010), page 151, 2010.
We would like to thank Frank Keller, Patrick          Ted Gibson. Linguistic complexity: Locality of
Sturt, Alex Lascarides, Mark Steedman, Mirella          syntactic dependencies. Cognition, 68:1–76,
Lapata and the anonymous reviewers for their            1998.
insightful comments. We would also like to thank      Daniel J. Grodner, Edward A. F. Gibson, and
ESRC for their financial supporting on grant            Duane Watson. The influence of contextual
RES-062-23-1450.                                        constrast on syntactic processing: Evidence for
References                                              strong-interaction in sentence comprehension.
                                                        Cognition, 95(3):275–296, 2005.
Gerry Altmann and Mark Steedman.          Inter-
                                                      John T. Hale. A probabilistic earley parser as
  action with context during human sentence
                                                        a psycholinguistic model. In In Proceedings
  processing. Cognition, 30:191–238, 1988.
                                                        of the Second Meeting of the North American
Amit Bagga and Breck Baldwin. Algorithms for            Chapter of the Asssociation for Computational
 scoring coreference chains. In The First Inter-        Linguistics, 2001.
 national Conference on Language Resources            John T. Hale. The information conveyed by
 and Evaluation Workshop on Linguistics                 words in sentences. Journal of Psycholinguistic
 Coreference (LREC 98), 1998.                           Research, 32(2):101–123, 2003.
Marisa Ferrara Boston, John T. Hale, Reinhold         Susan E. Haviland and Herbert H. Clark. What’s
 Kliegl, and Shravan Vasisht. Surprising parser         new? acquiring new information as a process
 actions and reading difficulty. In Proceedings         in comprehension. Journal of Verbal Learning
 of ACL-08:HLT, Short Papers, pages 5–8, 2008.          and Verbal Behavior, 13:512–521, 1974.
Thorsten Brants and Matthew Crocker. Probabilis-      Shujian Huang, Yabing Zhang, Junsheng Zhou,
  tic parsing and psychological plausibility. In        and Jiajun Chen. Coreference resolution using
  Proceedings of 18th International Conference          markov logic. In Proceedings of the 2009
  on Computational Linguistics (COLING-2000),           Conference on Intelligent Text Processing and
  pages 111–117, 2000.                                  Computational Linguistics (CICLing 09), 2009.
Stephen Crain and Mark Steedman. On not being         D. Jurafsky. A probabilistic model of lexical and
  led down the garden path: the use of context          syntactic access and disambiguation. Cognitive
  by the psychological syntax processor. In             Science, 20:137–194, 1996.
  D. Dowty, L. Karttunen, and A. Zwicky, edi-         Roger Levy. Expectation-based syntactic compre-
  tors, Natural language parsing: Psychological,        hension. Cognition, 106(3):1126–1177, March
  computational, and theoretical perspectives.          2008.
  Cambridge University Press, 1985.                   Roger Levy and T. Florian Jaeger. Speakers
Matthew Crocker and Thorsten Brants. Wide               optimize information density through syntactic
 coverage probabilistic sentence processing.            reduction. In Proceedings of the Twentieth
 Journal of Psycholinguistic Research, 29(6):           Annual Conference on Neural Information
 647–669, 2000.                                         Processing Systems, 2007.


                                                  1187


Ken McRae, Michael J. Spivey-Knowlton, and                prefix probabilities. Computational Linguistics,
  Michael K. Tanenhaus. Modeling the influence            21(2):165–201, 1995.
  of thematic fit (and other constraints) in on-line
  sentence comprehension. Journal of Memory
  and Language, 38:283–312, 1998.
Don C. Mitchell, Martin M. B. Corley, and Alan
  Garnham. Effects of context in human sentence
  parsing: Evidence against a discourse-baed
  proposal mechanism. Journal of Experimental
  Psychology: Learning, Memory and Cognition,
  18(1):69–88, 1992.
Natalia N. Modjeska, Katja Markert, and Malvina
  Nissim. Using the web in machine learning for
  other-anaphora resolution. In Proceedings of
  the 2003 Conference on Empirical Methods in
  Natural Language Processing (EMNLP-2003),
  pages 176–183, Sapporo, Japan, 2003.
Shrini Narayanan and Daniel Jurafsky. Bayesian
  models of human sentence processing. In Pro-
  ceedings of the 20th Annual Conference of the
  Cognitive Science Society (CogSci 98), 1998.
Ulrike Padó, Matthew Crocker, and Frank Keller.
  Modelling semantic role plausability in human
  sentence processing. In Proceedings of the 28th
  Annual Conference of the Cognitive Science
  Society (CogSci 2006), pages 657–662, 2006.
Hoifung Poon and Pedro Domingos. Joint unsu-
  pervised coreference resolution with markov
  logic. In Proceedings of the 2008 Conference
  on Empirical Methods in Natural Language
  Processing (EMNLP-08), 2008.
Keith Rayner. Eye movements in reading and
  information processing: 20 years of research.
  Psychological Bulletin, 124(3):372–422, 1998.
Matthew Richardson and Pedro Domingos.
 Markov logic networks. Machine Learning, 62
 (1-2):107–136, 2006.
W. M. Soon, H. T. Ng, and D. C. Y. Lim. A
  machine learning approach to coreference
  resolution of noun phrases. Computational
  Linguistics, 27(4):521–544, 2001.
M. J. Spivey and M. K. Tanenhaus. Syntactic
 ambiguity resolution in discourse: Modeling
 the effects of referential context and lexical
 frequency. Journal of Experimental Psychol-
 ogy: Learning, Memory and Cognition, 24(6):
 1521–1543, 1998.
Andreas Stolcke.      An efficient probabilistic
  context-free parsing algorithm that computes


                                                   1188

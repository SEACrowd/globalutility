     Assessing the Role of Discourse References in Entailment Inference

          Shachar Mirkin, Ido Dagan                                   Sebastian Padó
              Bar-Ilan University                                   University of Stuttgart
              Ramat-Gan, Israel                                      Stuttgart, Germany
      {mirkins,dagan}@cs.biu.ac.il                             pado@ims.uni-stuttgart.de




                      Abstract                                that the Kennedy in question is President Kennedy.
                                                              However, the utilization of discourse information
    Discourse references, notably coreference
                                                              for such inferences has been so far limited mainly
    and bridging, play an important role in
                                                              to the substitution of nominal coreferents, while
    many text understanding applications, but
                                                              many aspects of the interface between discourse
    their impact on textual entailment is yet to
                                                              and semantic inference needs remain unexplored.
    be systematically understood. On the ba-
    sis of an in-depth analysis of entailment                    The recently held Fifth Recognizing Textual
    instances, we argue that discourse refer-                 Entailment (RTE-5) challenge (Bentivogli et al.,
    ences have the potential of substantially                 2009a) has introduced a Search task, where the
    improving textual entailment recognition,                 text sentences are interpreted in the context of their
    and identify a number of research direc-                  full discourse, as in Example 1 above. Accord-
    tions towards this goal.                                  ingly, TE constitutes an interesting framework –
                                                              and the Search task an adequate dataset – to study
1   Introduction                                              the interrelation between discourse and inference.
The detection and resolution of discourse refer-                 The goal of this study is to analyze the roles
ences such as coreference and bridging anaphora               of discourse references for textual entailment in-
play an important role in text understanding appli-           ference, to provide relevant findings and insights
cations, like question answering and information              to developers of both reference resolvers and en-
extraction. There, reference resolution is used for           tailment systems and to highlight promising direc-
the purpose of combining knowledge from multi-                tions for the better incorporation of discourse phe-
ple sentences. Such knowledge is also important               nomena into inference. Our focus is on a manual,
for Textual Entailment (TE), a generic framework              in-depth assessment that results in a classification
for modeling semantic inference. TE reduces the               and quantification of discourse reference phenom-
inference requirements of many text understand-               ena and their utilization for inference. On this ba-
ing applications to the problem of determining                sis, we develop an account of formal devices for
whether the meaning of a given textual assertion,             incorporating discourse references into the infer-
termed hypothesis (H), can be inferred from the               ence computation. An additional point of inter-
meaning of certain text (T ) (Dagan et al., 2006).            est is the interrelation between entailment knowl-
   Consider the following example:                            edge and coreference. E.g., in Example 1 above,
                                                              knowing that Kennedy was a president can alle-
(1) T: “Not only had he developed an aversion                 viate the need for coreference resolution. Con-
    to the President1 and politics in general,                versely, coreference resolution can often be used
    Oswald2 was also a failure with Marina, his               to overcome gaps in entailment knowledge.
    wife. [...] Their relationship was supposedly
    responsible for why he2 killed Kennedy1 .”                Structure of the paper. In Section 2, we pro-
                                                              vide background on the use of discourse refer-
    H: “Oswald killed President Kennedy.”
                                                              ences in natural language processing (NLP) in
The understanding that the second sentence of the             general and specifically in TE. Section 3 describes
text entails the hypothesis draws on two corefer-             the goals of this study, followed by our analy-
ence relationships, namely that he is Oswald, and             sis scheme (Section 4) and the required inference


                                                        1209
       Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1209–1219,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


mechanisms (Section 5). Section 6 presents quan-         event coreference and bridging.1 Another reason
titative findings and further observations. Conclu-      is uncertainty about their practical importance.
sions are discussed in Section 7.
                                                         2.2    Discourse in Textual Entailment
2     Background                                         Textual Entailment has been introduced in Sec-
                                                         tion 1 as a common-sense notion of inference.
2.1    Discourse in NLP
                                                         It has spawned interest in the computational lin-
Discourse information plays a role in a range            guistics community as a common denominator of
of NLP tasks. It is obviously central to dis-            many NLP tasks including IE, summarization and
course processing tasks such as text segmenta-           tutoring (Romano et al., 2006; Harabagiu et al.,
tion (Hearst, 1997). Reference information pro-          2007; Nielsen et al., 2009).
vided by discourse is also useful for text under-
standing tasks such as question answering (QA),          Architectures for Textual Entailment. Over
information extraction (IE) and information re-          the course of recent RTE challenges (Giampic-
trieval (IR) (Vicedo and Ferrndez, 2006; Zelenko         colo et al., 2007; Giampiccolo et al., 2008), the
et al., 2004; Na and Ng, 2009), as well as for the       main benchmark for TE technology, two archi-
acquisition of lexical-semantic “narrative schema”       tectures for modeling TE have emerged as dom-
knowledge (Chambers and Jurafsky, 2009). Dis-            inant: transformations and alignment. The goal
course references have been the subject of atten-        of transformation-based TE models is to deter-
tion in both the Message Understanding Confer-           mine the entailment relation T ⇒ H by find-
ence (Grishman and Sundheim, 1996) and the Au-           ing a “proof”, i.e., a sequence of consequents,
tomatic Content Extraction program (Strassel et          (T, T1 , . . . , Tn ), such that Tn =H (Bar-Haim et al.,
al., 2008).                                              2008; Harmeling, 2009), and that in each trans-
   The simplest form of information that discourse       formation, Ti → Ti+1 , the consequent Ti+1 is en-
provides is coreference, i.e., information that two      tailed by Ti . These transformations commonly in-
linguistic expressions refer to the same entity or       clude lexical modifications and the generation of
event. Coreference is particularly important for         syntactic alternatives. The second major approach
processing pronouns and other anaphoric expres-          constructs an alignment between the linguistic en-
sions, such as he in Example 1. Ability to re-           tities of the trees (or graphs) of T and H, which
solve this reference translates directly into, e.g., a   can represent syntactic structure, semantic struc-
QA system’s ability to answer questions like Who         ture, or non-hierarchical phrases (Zanzotto et al.,
killed Kennedy?.                                         2009; Burchardt et al., 2009; MacCartney et al.,
   A second, more complex type of information            2008). H is assumed to be entailed by T if its en-
stems from bridging references, such as in the fol-      tities are aligned “well” to corresponding entities
lowing discourse (Asher and Lascarides, 1998):           in T . Alignment quality is generally determined
                                                         based on features that assess the validity of the lo-
(2) “I’ve just arrived. The camel is outside.”           cal replacement of the T entity by the H entity.
                                                             While transformation- and alignment-based en-
While coreference indicates equivalence, bridging        tailment models look different at first glance, they
points to the existence of a salient semantic rela-      ultimately have the same goal, namely obtaining
tion between two distinct entities or events. Here,      a maximal coverage of H by T , i.e. to identify
it is (informally) ‘means of transport’, which           matches of as many elements of H within T as
would make the discourse (2) relevant for a ques-        possible.2 To do so, both architectures typically
tion like How did I arrive here?. Other types of         make use of inference rules such as ‘Y was pur-
bridging relations include set-membership, roles         chased by X → X paid for Y’, either by directly ap-
in events and consequence (Clark, 1975).                 plying them as transformations, or by using them
   Note, however, that text understanding systems           1
                                                               Some studies, e.g. (Markert et al., 2003; Poesio et al.,
are generally limited to the resolution of entity (or    2004), address the resolution of a few specific kinds of bridg-
even just pronoun) coreference, e.g. (Li et al.,         ing relations; yet, wide-scope systems for bridging resolution
2009; Dali et al., 2009). An important reason is the     are unavailable.
                                                             2
                                                               Clearly, the details of how the final entailment decision
unavailability of tools to resolve the more complex      is made based on the attained coverage differ substantially
(and difficult) forms of discourse reference such as     among models.


                                                     1210


to score alignments. Rules are generally drawn          sented; (2) the off-the-shelf coreference resolution
from external knowledge resources, such as Word-        systems which may have been not robust enough;
Net (Fellbaum, 1998) or DIRT (Lin and Pantel,           (3) the limitation to nominal coreference; and (4)
2001), although knowledge gaps remain a key ob-         overly simple integration of reference information
stacle (Bos, 2005; Balahur et al., 2008; Bar-Haim       into the inference engines.
et al., 2008).                                             The goal of this paper is to assess the impact of
                                                        discourse references on entailment with an anno-
Discourse in previous RTE challenges. The               tation study which removes these limitations. To
first two rounds of the RTE challenge used “self-       counteract (1), we use the recent RTE-5 Search
contained” texts and hypotheses, where discourse        dataset (details below). To avoid (2), we perform
considerations played virtually no role. A first step   a manual analysis, assuming discourse references
towards a more comprehensive notion of entail-          as predicted by an oracle. With regards to (3), our
ment was taken with RTE-3 (Giampiccolo et al.,          annotation scheme covers coreference and bridg-
2007), when paragraph-length texts were first in-       ing relations of all syntactic categories and classi-
cluded and constituted 17% of the texts in the test     fies them. As for (4), we suggest several opera-
set. Chambers et al. (2007) report that in a sample     tions necessary to integrate the discourse informa-
of T − H pairs drawn from the development set,          tion into an entailment engine.
25% involved discourse references.                         In contrast to the numerous existing datasets
   Using the concepts introduced above, the im-         annotated for discourse references (Hovy et al.,
pact of discourse references can be generally de-       2006; Strassel et al., 2008), we do not annotate ex-
scribed as a coverage problem, independent of the       haustively. Rather, we are interested specifically in
system’s architecture. In Example 1, the hypoth-        those references instances that impact inference.
esis word Oswald cannot be safely linked to the         Furthermore, we analyze each instance from an
text pronoun he without further knowledge about         entailment perspective, characterizing the relevant
he; the same is true for ‘Kennedy → President           factors that have an impact on inference. To our
Kennedy’ which involves a specialization that is        knowledge, this is the first such in-depth study.4
only warranted in the specific discourse.                  The results of our study are of twofold interest.
   A number of systems have tried to address the        First, they provide guidance for the developers of
question of coreference in RTE as a preprocessing       reference resolvers who might prioritize the scope
step prior to inference proper, with most systems       of their systems to make them more valuable for
using off-the-shelf coreference resolvers such as       inference. Second, they point out potential direc-
JavaRap (Qiu et al., 2004) or OpenNLP3 . Gen-           tions for the developers of inference systems by
erally, anaphoric expressions were textually re-        specifying what additional inference mechanisms
placed by their antecedents. Results were in-           are needed to utilize discourse information.
conclusive, however, with several reports about
errors introduced by automatic coreference res-         The RTE-5 Search dataset. We base our anno-
olution (Agichtein et al., 2008; Adams et al.,          tation on the Search task dataset, a new addition
2007). Specific evaluations of the contribution         to the recent Fifth RTE challenge (Bentivogli et
of coreference resolution yielded both small nega-      al., 2009a) that is motivated by the needs of NLP
tive (Bar-Haim et al., 2008) and insignificant pos-     applications and drawn from the TAC summariza-
itive (Chambers et al., 2007) results.                  tion track. In the Search task, TE systems are re-
                                                        quired to find all individual sentences in a given
3       Motivation and Goals                            corpus which entail the hypothesis – a setting that
                                                        is sensible not only for summarization, but also for
The results of recent studies, as reported in Sec-      information access tasks like QA. Sentences are
tion 2.2, seem to show that current resolution of       judged individually, but “are to be interpreted in
discourse references in RTE systems hardly af-          the context of the corpus as they rely on explicit
fects performance. However, our intuition is that       and implicit references to entities, events, dates,
these results can be attributed to four major lim-      places, etc., mentioned elsewhere in the corpus”
itations shared by these studies: (1) the datasets,     (Bentivogli et al., 2009b).
where discourse phenomena were not well repre-
                                                          4
                                                            The guidelines and the dataset are available at
    3
        http://opennlp.sourceforge.net                  http://www.cs.biu.ac.il/˜nlp/downloads/


                                                    1211


                                               Text                                                    Hypothesis
               0   Once the reform becomes law, Spain will join the Netherlands
           T
    i              and Belgium in allowing homosexual marriages.                       Massachusetts allows homosexual
                   Such unions are also legal in six Canadian provinces and the        marriages
           T
                   northeastern US state of Massachusetts.
           T0      The official name of 2003 UB313 has yet to be determined.
    ii             Brown said he expected to find a moon orbiting Xena because         2003 UB313 is in the Kuiper Belt
           T
                   many Kuiper Belt objects are paired with moons.
                   All seven aboard the AS-28 submarine appeared to be in satis-
           Ta0
                   factory condition, naval spokesman said.
    iii            British crews were working with Russian naval authorities to ma-    The AS-28 mini submarine was trapped
           Tb0
                   neuver the unmanned robotic vehicle and untangle the AS-28.         underwater
                   The Russian military was racing against time early Friday to res-
           T
                   cue a mini submarine trapped on the seabed.
           T0      China seeks solutions to its coal mine safety.                      A mining accident in China has killed
    iv     T       A recent accident has cost more than a dozen miners their lives.    several miners
                   A remote-controlled device was lowered to the stricken vessel to
           T 00
                   cut the cables in which the AS-28 vehicle is caught.
    v              The mini submarine was resting on the seabed at a depth of about    The AS-28 mini submarine was trapped
           T0
                   200 meters.                                                         underwater
                   Specialists said it could have become tangled up with a metal
           T
                   cable or in sunken nets from a fishing trawler.
                   . . . dried up lakes in Siberia, because the permafrost beneath     The ice is melting in the Arctic
    vi     T
                   them has begun to thaw.

Table 1: Examples for discourse-dependent entailment in the RTE-5 dataset, where the inference of H
depends on reference information from the discourse sentences T 0 / T 00 . Referring terms (in T ) and target
terms (in H) are shown in boldface.

4         Analysis Scheme                                             erence term needs to be found. We now define
                                                                      and illustrate these concepts on examples from
For annotating the RTE-5 data, we operationalize                      Table 1.5
reference relations that are relevant for entailment                     The target component is a tree component in
as those that improve coverage. Recall from Sec-                      H that cannot be covered by the “local” material
tion 2.2 that the concept of coverage is applicable                   from T . An example for a tree component is Ex-
to both transformation and alignment models, all                      ample (v), where the target component AS-28 mini
of which aim at maximizing coverage of H by T .                       submarine in H cannot be inferred from the pro-
   We represent T and H as syntactic trees, as                        noun it in T . Example (vi) demonstrates an edge
common in the RTE literature (Zanzotto et al.,                        as target component. In this case, the edge in H
2009; Agichtein et al., 2008). Specifically, we                       connecting melt with the modifier in the Arctic is
assume MINIPAR-style (Lin, 1993) dependency                           not found in T . Although each of the hypothesis’
trees where nodes represent text expressions and                      nodes can be covered separately via knowledge-
edges represent the syntactic relations between                       based rules (e.g. ‘Siberia → Arctic’, ‘permafrost
them. We use “term” to refer to text expressions,                     → ice’, ‘thaw ↔ melt’), the resulting fragments
and “components” to refer to nodes, edges, and                        in T are unconnected without the (intra-sentential)
subtrees. Dependency trees are a popular choice                       coreference between them and lakes in Siberia.
in RTE since they offer a fairly semantics-oriented                      For each target component, we identify its focus
account of the sentence structure that can still be                   term as the expression in T that does not cover the
constructed robustly. In an ideal case of entail-                     target component itself but participates in a refer-
ment, all nodes and dependency edges of H are                         ence relation that can help covering it.
covered by T .                                                           We follow the focus term’s reference chain to
   For each T − H pair, we annotate all relevant                      a reference term which can, either separately or
discourse references in terms of three items: the                     in combination with the focus term, help covering
target component in H, the focus term in T , and                      the target component. In Example (ii), where the
the reference term which stands in a reference re-                        5
                                                                           In our annotation, we assume throughout that some
lation to the focus term. By resolving this ref-                      knowledge about basic admissible transformations is avail-
                                                                      able, such as passive to active or derivational transformations;
erence, the target component can usually be in-                       for brevity, we ignore articles in the examples and treat named
ferred; sometimes, however, more than one ref-                        entities as single nodes.


                                                                 1212


target component in H is 2003 UB313, Xena is the         the focus/reference terms entailment status – does
focus term in T and the reference term is a men-         some kind of entailment relation hold between the
tion of 2003 UB313 in a previous sentence, T 0 . In      two terms? Fourth, the operation that should be
this case, the reference term covers the entire tar-     performed on the focus and reference terms to ob-
get component on its own.                                tain coverage of the target component (as specified
   An additional attribute that we record for each       in Section 5).
instance is whether resolving the discourse refer-
                                                         5   Integrating Discourse References into
ence is mandatory for determining entailment, or
                                                             Entailment Recognition
optional. In Example (v), it is mandatory: the in-
ference cannot be completed without the knowl-           In initial analysis we found that the standard sub-
edge provided by the discourse. In contrast, in          stitution operation applied by virtually all previous
Example (ii), inferring 2003 UB313 from Xena             studies for integrating coreference into entailment
is optional. It can be done either by identify-          is insufficient. We identified three distinct cases
ing their coreference relation, or by using back-        for the integration of discourse reference knowl-
ground knowledge in the form of an entailment            edge in entailment, which correspond to different
rule, ‘Xena ↔ 2003 UB313’, that is applicable            relations between the target component, the fo-
in the context of astronomy. Optional discourse          cus term and the reference term. This section de-
references represent instances where discourse in-       scribes the three cases and characterizes them in
formation and TE knowledge are interchange-              terms of tree transformations. An initial version of
able. As mentioned, knowledge gaps constitute            these transformations is described in (Abad et al.,
a major obstacle for TE systems, and we can-             2010). We assume a transformation-based entail-
not rely on the availability of any ceratin piece of     ment architecture (cf. Section 2.2), although we
knowledge to the inference process. Thus, in our         believe that the key points of our account are also
scheme, mandatory references provide a “lower            applicable to alignment-based architecture. Trans-
bound” with regards to the necessity to resolve          formations create revised trees that cover previ-
discourse references, even in the presence of com-       ously uncovered target components in H. The
plete knowledge; optional references, on the other       output of each transformation, T1 , is comprised
hand, set an “upper bound” for the contribution of       of copies of the components used to construct it,
discourse resolution to inference, when no knowl-        and is appended to the discourse forest, which in-
edge is available. At the same time, this scheme         cludes the dependency trees of all sentences and
allows investigating how much TE knowledge can           their generated consequents.
be replaced by (perfect) discourse processing.              We assume that we have access to a dependency
   When choosing a reference term, we search the         tree for H, a dependency forest for T and its dis-
reference chain of the focus term for the nearest        course context, as well as the output of a perfect
expression that is identical to the target component     discourse processor, i.e., a complete set of both
or a subcomponent of it. If we find such an expres-      coreference and bridging relations, including the
sion, covering the identical part of the target com-     type of bridging relation (e.g. part-of, cause).
ponent requires no entailment knowledge. If no              We use the following notation. We use x, y
identical reference term exists, we choose the se-       for tree nodes, and Sx to denote a (sub-)tree with
mantically ‘closest’ term from the reference chain,      root x. lab(x) is the label of the incoming edge
i.e. the term which requires the least knowledge to      of x (i.e., its grammatical function). We write
infer the target component. For instance, we may         C(x, y) for a coreference relation between Sx and
pick permafrost as the semantically closet term to       Sy , the corresponding trees of the focus and refer-
the target ice if the latter is not found in the focus   ence terms, respectively. We write Br (x, y) for a
term’s reference chain.                                  bridging relation, where r is its type.
   Finally, for each reference relation that we an-      (1) Substitution: This is the most intuitive and
notate, we record four additional attributes which       widely-used transformation, corresponding to the
we assumed to be informative in an evaluation.           treatment of discourse information in existing sys-
First, the reference type: Is the relation a coref-      tems. It applies to coreference relations, when an
erence or a bridging reference? Second, the syn-         expression found elsewhere in the text (the refer-
tactic type of the focus and reference terms. Third,     ence term) can cover all missing information (the


                                                     1213


      T’                 T                         T1                                                  T                           T1
                                                                             T’a
                         be                        be                                             submarine                      submarine
                              pred                      pred                 submarine           mod         pnmod                          pnmod
                                                                                                                            nn
                                                                                                                                   mod
                        legal                    legal                             nn
                                                          mod                                   mini       trapped       AS-28 mini   trapped
                 subj            mod      subj
                                                                              AS-28                            mod                    mod

                                                                                                             on                             on
  marriages    union            also   marriages               also
                                                                                                               pcomp-n            pcomp-n
       mod         pre                       mod                               T’b
  homosexual                           homosexual                                                          seabed                        seabed
               such                                                                     AS-28


Figure 1: The Substitution transformation, demon-                        Figure 2: The dependent-merge (Ta0 ) and head-
strated on the relevant subtrees of Example (i).                         merge (Tb0 ) transformations (Example (iii)).
The dashed line denotes a discourse reference.
                                                                         the target component, but modifiers from both of
target component) on its own. In such cases, the
                                                                         them are required to cover the target component’s
reference term can replace the entire focus term.
                                                                         dependents. The modifiers are therefore merged
Apparently (cf. Section 6), substitution applies
                                                                         as dependents of a single head node, to create
also to some types of bridging relations, such as
                                                                         a tree that covers the entire target component.
set-membership, when the member is sufficient for
                                                                         Dependent-merge is illustrated in Figure 2, using
representing the entire set for the necessary infer-
                                                                         Example (iii). The component we wish to cover in
ence. For example, in “I met two people yesterday.
                                                                         H is the noun phrase AS-28 mini submarine. Un-
The woman told me a story.” (Clark, 1975), sub-
                                                                         fortunately, the focus term in T , “mini submarine
stituting two people with woman results in a text
                                                                         trapped on the seabed”, covers only the modifier
which is entailed from the discourse, and which
                                                                         mini, but not AS-28. This modifier can however be
allows inferring “I met a woman yesterday.”
                                                                         provided by the coreferent term in Ta0 (left upper
   In a parse tree representation, given a corefer-
                                                                         corner). Once merged, the inference engine can,
ence relation C(x, y) (or Br (x, y)), the newly gen-
                                                                         e.g., employ the rule ‘on seabed → underwater’
erated tree, T1 , consists of a copy of T , where the
                                                                         to cover H completely.
entire tree Sx is replaced by a copy of Sy . In Fig-
                                                                            Formally, assume without loss of generality that
ure 1, which shows Example (i) from Table 1, such
                                                                         y, the reference term’s head, matches the root node
unions is substituted by homosexual marriages.
                                                                         of the target component. Given C(x, y), we define
   Head-substitution. Occasionally, substituting
                                                                         T1 as a copy of T , where (i) the subtree Sx is re-
only the head of the focus term is sufficient. In
                                                                         placed by Sy , and (ii) for all children c of x, a copy
such cases, only the root nodes x and y are sub-
                                                                         of Sc is placed under the copy of y in T1 with its
stituted. This is the case, for example, with syn-
                                                                         original edge label, lab(c).
onymous verbs with identical subcategorization
frames (like melt and thaw). As verbs typically                             (b) Head-merge. An alternative way to recover
constitute tree roots in dependency parses, sub-                         the missing information in Example (iii) is to find
stituting or merging (see below) their entire trees                      a reference term whose head word itself (rather
might be inappropriate or wasteful. In such cases,                       than one of its modifiers) matches the target com-
the simpler head-substitution may be applied.                            ponent’s missing dependent, as with AS-28 in Fig-
                                                                         ure 2 in the bottom left corner (Tb0 ). In terms of
(2) Merge: In contrast to substitution, where a                          parse trees, we need to add one tree as a depen-
match for the entire target component is found                           dent of the other. Formally, given C(x, y), simi-
elsewhere in the text, this transformation is re-                        larly to dependent-merge, T1 is created as a copy
quired when parts of the missing information are                         of T where the subtree Sx is replaced by either Sx
scattered among multiple locations in the text.                          or Sy , depending on whichever of x and y matches
We distinguish between two types of merge trans-                         the target component’s head. Assume it is x, for
formations: (a) dependent-merge, and (b) head-                           example. Then, a copy of Sy is added as a new
merge, depending on the syntactic roles of the                           child to x. In our sample, head-merge operations
merged components.                                                       correspond to internal coreferences within nomi-
   (a) Dependent-Merge. This operation is ap-                            nal target components (such as between AS-28 and
plicable when the head of either the focus or ref-                       mini submarine in this case). The appropriate la-
erence terms (of both) matches the head node of                          bel, lab(y), in these cases is nn (nominal modi-


                                                                      1214


         T’                         T                                 T1                  abovementioned interface; only the node to which
                                                                      cost
        seek                       cost
                                                                                          it is attached and the contents of the variable node
  obj          subj       subj            obj               subj                obj
                                 have                               have                  are determined at transformation-time.
Solution China          accident have more                accident have more                  As another example, consider the following
        mod
   to                      mod                  comp1     mod      mod      comp1         short text from (Clark, 1975): John was murdered
        pcomp-n
                        recent            than            recent in             than      yesterday. The knife lay nearby. Here, the bridg-
 safety
                                                pcomp-n     pcomp-n        pcomp-n        ing relation between the murder event and the in-
 gen               nn
              nn
                                          dozen                    China       dozen
                                                                                          strument, the knife (x), can be addressed by in-
   its coal mine
                                                                                          serting under x a subtree for the clause with which
Figure 3: The insertion transformation. Dotted                                            as Szr , with a variable which is instantiated by the
edges mark the newly inserted path (Ex. (iv)).                                            parse-tree (headed by murdered, y) of the entire
                                                                                          first sentence John was murdered yesterday.

fier). Further analysis is required to specify what                                       Transformation chaining. Since our transfor-
other dependencies can hold between such core-                                            mations are defined to be minimal, some cases re-
ferring heads.                                                                            quire the application of multiple transformations
                                                                                          to achieve coverage. Consider Example (v), Ta-
(3) Insertion: The last transformation, insertion,                                        ble 1. We wish to cover AS-28 mini submarine in
is used when a relation that is realized in H is                                          H from the coreferring it in T , mini submarine in
missing from T and is only implied via a bridg-                                           T 0 and AS-28 vehicle in T 00 . A substitution of it by
ing relation. In Example (iv), the location that is                                       either coreference does not suffice, since none of
explicitly mentioned in H can only be covered by                                          the antecedents contains all necessary modifiers. It
T by resolving a bridging reference with China                                            is therefore necessary to substitute it first by one of
in T 0 . To connect the bridging referents, a new                                         the coreferences and then merge it with the other.
tree component representing the bridging relation
is inserted into the consequent tree T1 . In this ex-                                     6   Results
ample, the component connects China and recent                                            We analyzed 120 sentence-hypothesis pairs of the
accident via the in preposition. Formally, given                                          RTE-5 development set (21 different hypotheses,
a bridging relation Br (x, y), we introduce a new                                         111 distinct sentences, 53 different documents).
subtree Szr into T1 , where z is a child of x and                                         Below, we summarize our findings, focusing on
lab(z) = labr . Szr must contain a variable node                                          the relation between our findings and the assump-
that is instantiated with a copy of S(y).                                                 tions of previous studies as discussed in Section 3.
   This transformation stands out from the others
                                                                                          General statistics. We found that 44% of the
in that it introduces new material. For each bridg-
                                                                                          pairs contained reference relations whose resolu-
ing relation, it adds a specific subtrees S r via an
                                                                                          tion was mandatory for inference. In another 28%,
edge labeled with labr . These two items form the
                                                                                          references could optionally support the inference
dependency representation of the bridging relation
                                                                                          of the hypothesis. In the remaining 28%, refer-
Br and must be provided by the interface between
                                                                                          ences did not contribute towards inference. The
the discourse and the inference systems. Clearly,
                                                                                          total number of relevant references was 137, and
their exact form depends on the set of bridging re-
                                                                                          37 pairs (27%) contained multiple relevant refer-
lations provided by the discourse resolver as well
                                                                                          ences. These numbers support our assumption that
as the details of the dependency parses.
                                                                                          discourse references play an important role in in-
   As shown in Figure 3, the bridging relation
                                                                                          ference.
located-in (r) is represented by inserting a subtree
Szr headed by in (z) into T1 and connecting it to                                         Reference types. 73% of the identified refer-
accident (x) as a modifier (labr ). The subtree Szr                                       ences are coreferences and 27% are bridging re-
consists of a variable node which is connected to                                         lations. The most common bridging relation was
in with a pcomp-n dependency (a nominal head of                                           the location of events (e.g. Arctic in ice melting
a prepositional phrase), and which is instantiated                                        events), generally assumed to be known through-
with the node China (y) when the transformation                                           out the document. Other bridging relations we en-
is applied. Note that the structure of Szr and the                                        countered include cause (e.g. between injured and
way it is inserted into T1 are predefined by the                                          attack), event participants and set membership.


                                                                                       1215


(%)                 Pronoun       NE       NP        VP        had to go to other documents to find reference
Focus term             9          19       49        23
Reference term         -          43       43        14        terms that, possibly in conjunction with the focus
                                                               term, could cover the target components. Interest-
 Table 2: Syntactic types of discourse references              ingly, all such cases involved coreference (about
(%)                Sub.         Merge           Insertion
                                                               equally divided between the merge transforma-
Coreference         62           38                 -          tions and substitutions), while bridging was al-
Bridging            30            -                70          ways “document-local”. This result reaffirms the
Total               54           28                18          usefulness of cross-document coreference resolu-
                                                               tion for inference (Huang et al., 2009).
  Table 3: Distribution of transformation types
                                                               Discourse resolution as preprocessing? In ex-
Syntactic types. Table 2 shows that 77% of all                 isting RTE systems, discourse references are typ-
focus terms and 86% of the reference terms were                ically resolved as a preprocessing step. While
nominal phrases, which justifies their prominent               our annotation was manual and cannot yield di-
position in work on anaphora and coreference res-              rect results about processing considerations, we
olution. However, almost a quarter of the focus                observed that discourse relations often hold be-
terms were verbal phrases. We found these focus                tween complex, and deeply embedded, expres-
terms to be frequently crucial for entailment since            sions, which makes their automatic resolution dif-
they included the main predicate of the hypothe-               ficult. Of course, many RTE systems attempt to
sis.6 This calls for an increased focus on the reso-           normalize and simplify H and T , e.g., by split-
lution of event references.                                    ting conjunctions or removing irrelevant clauses,
                                                               but these operations are usually considered a part
Transformations. Table 3 shows the relative                    of the inference rather the preprocessing phase (cf.
frequencies of all transformations. Again, we                  e.g., Bar-Haim et al. (2007)). Since the resolu-
found that the “default” transformation, substitu-             tion of discourse references is likely to profit from
tion, is the most frequent one, and is helpful for             these steps, it seems desirable to “postpone” it un-
both coreference and bridging relations. Substitu-             til after simplification. In transformation-based
tion is particularly useful for handling pronouns              systems, it might be natural to add discourse-based
(14% of all substitution instances), the replace-              transformations to the set of inference operations,
ment of named entities by synonymous names                     while in alignment-based systems, discourse ref-
(32%), the replacement of other NPs (38%), and                 erences can be integrated into the computation of
the substitution of verbal head nodes in event                 alignment scores.
coreference (16%). Yet, in nearly half the cases,
a different transformation had to be applied. In-              Discourse references vs. entailment knowledge.
sertion accounts for the majority of bridging cases.           We have stated before that even if a discourse ref-
Head-merge is necessary to integrate proper nouns              erence is not strictly necessary for entailment, it
as modifiers of other head nouns. Dependent-                   may be interesting because it represents an alter-
merge, responsible for 85% of the merge transfor-              native to the use of knowledge rules to cover the
mations, can be used to complete nominal focus                 hypothesis. Sometimes, these rules are generally
terms with missing modifiers (e.g., adjectives), as            applicable (e.g., ‘Alaska → Arctic’). However, of-
well as for merging other dependencies between                 ten they are context-specific. Consider the follow-
coreferring predicates. This result indicates the              ing sentence as T for the hypothesis H: “The ice
importance of incorporating other transformations              is melting in the Arctic”:
into inference systems.
                                                               (3) T : “The scene at the receding edge of the Exit
Distance of reference terms. The distance be-                      Glacier was part festive gathering, part nature
tween the focus and the reference terms varied                     tour with an apocalyptic edge.”
considerably, ranging from intra-sentential refer-
ence relations and up to several dozen sentences.              While it is possible to cover melting using a rule
For more than a quarter of the focus terms, we                 ‘melting ↔ receding’, this rule is only valid under
   6
                                                               quite specific conditions (e.g., for the subject ice).
    The lower proportion of VPs among reference terms
stems from bridging relations between VPs and nominal de-      Instead of determining the applicability of the rule,
pendents, such as the abovementioned “location” relation.      a discourse-aware system can take the next sen-


                                                            1216


tence into account, which contains a coreferring           Our manual analysis of the RTE-5 dataset
event to receding that can cover melting in H:          shows that while the majority of discourse refer-
                                                        ences that affect inference are nominal coreference
(4) T 0 : “. . . people moved closer to the rope line   relations, another substantial part is made up by
    near the glacier as it shied away, practically      verbal terms and bridging relations. Furthermore,
    groaning and melting before their eyes.”            we have demonstrated that substitution alone is in-
                                                        sufficient to extract all relevant information from
Discourse relations can in fact encode arbitrar-        the wide range of discourse references that are
ily complex world knowledge, as in the following        frequently relevant for inference. We identified
pair:                                                   three general cases, and suggested matching op-
                                                        erations to obtain the relevant inferences, formu-
(5) H: “The serial killer BTK was accused of at         lated as tree transformations. Furthermore, our ev-
    least 7 killings starting in the 1970’s.”           idence suggests that for practical reasons, the res-
    T: “Police say BTK may have killed as many          olution of discourse references should be tightly
    as 10 people between 1974 and 1991.”                integrated into entailment systems instead of treat-
                                                        ing it as a preprocessing step.
Here, the H modifier serial, which does not occur          A particularly interesting result concerns the
in T , can be covered either by world knowledge         interplay between discourse references and en-
(a person who killed 10 people is a serial killer),     tailment knowledge. While semantic knowledge
or by resolving the coreference of BTK to the term      (e.g., from WordNet or Wikipedia) has been used
the serial killer BTK which occurs in the discourse     beneficially for coreference resolution (Soon et al.,
around T . Our conclusion is that not only can          2001; Ponzetto and Strube, 2006), reference res-
discourse references often replace world knowl-         olution has, to our knowledge, not yet been em-
edge in principle, in practice it often seems easier    ployed to validate entailment rules’ applicability.
to resolve discourse references than to determine       Our analyses suggest that in the context of de-
whether a rule is applicable in a given context or      ciding textual entailment, reference resolution and
to formalize complex world knowledge as infer-          entailment knowledge can be seen as complemen-
ence rules. Our annotation provides further em-         tary ways of achieving the same goal, namely en-
pirical support to this claim: An entailment rela-      riching T with additional knowledge to allow the
tion exists between the focus and reference terms       inference of H. Given that both of the technolo-
in 60% of the focus-reference term pairs, and in        gies are still imperfect, we envisage the way for-
many of the remainder, entailment holds between         ward as a joint strategy, where reference resolution
the terms’ heads. Thus, discourse provides rela-        and entailment rules mutually fill each other’s gaps
tions which are many times equivalent to entail-        (cf. Example 3).
ment knowledge rules and can therefore be uti-             In sum, our study shows that textual entailment
lized in their stead.                                   can profit substantially from better discourse han-
                                                        dling. The next challenge is to translate the the-
7   Conclusions                                         oretical gain into practical benefit. Our analy-
                                                        sis demonstrates that improvements are necessary
This work has presented an analysis of the relation     both on the side of discourse reference resolution
between discourse references and textual entail-        systems, which need to cover more types of refer-
ment. We have identified a set of limitations com-      ences, as well as a better integration of discourse
mon to the handling of discourse relations in vir-      information in entailment systems, even for those
tually all entailment systems. They include the use     relations which are within the scope of available
of off-the-shelf resolvers that concentrate on nom-     resolvers.
inal coreference, the integration of reference in-
formation through substitution, and the RTE eval-       Acknowledgements
uation schemes, which played down the role of
discourse. Since in practical settings, discourse       This work was partially supported by the
plays an important role, our goal was to develop        PASCAL-2 Network of Excellence of the Eu-
an agenda for improving the handling of discourse       ropean Community FP7-ICT-2007-1-216886 and
references in entailment-based inference.               the Israel Science Foundation grant 1112/08.


                                                    1217


References                                                 Herbert H. Clark. 1975. Bridging. In R. C. Schank
                                                             and B. L. Nash-Webber, editors, Theoretical issues
Azad Abad, Luisa Bentivogli, Ido Dagan, Danilo Gi-           in natural language processing, pages 169–174. As-
  ampiccolo, Shachar Mirkin, Emanuele Pianta, and            sociation of Computing Machinery.
  Asher Stern. 2010. A resource for investigating the
  impact of anaphora and coreference on inference. In      Ido Dagan, Oren Glickman, and Bernardo Magnini.
  Proceedings of LREC.                                        2006. The PASCAL recognising textual entailment
Rod Adams, Gabriel Nicolae, Cristina Nicolae, and             challenge. In Machine Learning Challenges, vol-
  Sanda Harabagiu. 2007. Textual entailment through           ume 3944 of Lecture Notes in Computer Science,
  extended lexical overlap and lexico-semantic match-         pages 177–190. Springer.
  ing. In Proceedings of the ACL-PASCAL Workshop
  on Textual Entailment and Paraphrasing.                  Lorand Dali, Delia Rusu, Blaz Fortuna, Dunja
                                                             Mladenic, and Marko Grobelnik. 2009. Ques-
E. Agichtein, W. Askew, and Y. Liu. 2008. Combining          tion answering based on semantic graphs. In Pro-
   lexical, syntactic, and semantic evidence for textual     ceedings of the Workshop on Semantic Search (Sem-
   entailment classification. In Proceedings of TAC.         Search 2009).
Nicholas Asher and Alex Lascarides. 1998. Bridging.        Christiane Fellbaum, editor. 1998. WordNet: An Elec-
  Journal of Semantics, 15(1):83–113.                        tronic Lexical Database (Language, Speech, and
Alexandra Balahur, Elena Lloret, Óscar Ferrández,          Communication). The MIT Press.
  Andrés Montoyo, Manuel Palomar, and Rafael
  Muñoz. 2008. The DLSIUAES team’s participation          Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
  in the TAC 2008 tracks. In Proceedings of TAC.             and Bill Dolan. 2007. The third pascal recogniz-
                                                             ing textual entailment challenge. In Proceedings of
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal             the ACL-PASCAL Workshop on Textual Entailment
  Shnarch. 2007. Semantic inference at the lexical-          and Paraphrasing.
  syntactic level. In Proceedings of AAAI.
                                                           Danilo Giampiccolo, Hoa Trang Dang, Bernardo
Roy Bar-Haim, Jonathan Berant, Ido Dagan, Iddo               Magnini, Ido Dagan, and Bill Dolan. 2008. The
  Greental, Shachar Mirkin, and Eyal Shnarch amd             fourth pascal recognizing textual entailment chal-
  Idan Szpektor. 2008. Efficient semantic deduc-             lenge. In Proceedings of TAC.
  tion and approximate matching over compact parse
  forests. In Proceedings of TAC.                          Ralph Grishman and Beth Sundheim. 1996. Mes-
                                                             sage Understanding Conference-6: a brief history.
Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo
                                                             In Proceedings of the 16th conference on Computa-
  Giampiccolo, and Bernardo Magnini. 2009a. The
                                                             tional Linguistics.
  fifth pascal recognizing textual entailment chal-
  lenge. In Proceedings of TAC.
                                                           Sanda Harabagiu, Andrew Hickl, and Finley Lacatusu.
Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo          2007. Satisfying information needs with multi-
  Giampiccolo, Medea Lo Leggio, and Bernardo                 document summaries. Information Processing &
  Magnini. 2009b. Considering discourse references           Management, 43:1619–1642.
  in textual entailment annotation. In Proceedings of
  the 5th International Conference on Generative Ap-       Stefan Harmeling. 2009. Inferring textual entailment
  proaches to the Lexicon (GL2009).                           with a probabilistically sound calculus. Journal of
                                                              Natural Language Engineering, pages 459–477.
Johan Bos. 2005. Recognising textual entailment with
  logical inference. In Proceedings of EMNLP.              Marti A. Hearst. 1997. Segmenting text into multi-
                                                            paragraph subtopic passages. Computational Lin-
Aljoscha Burchardt, Marco Pennacchiotti, Stefan             guistics, 23(1):33–64.
  Thater, and Manfred Pinkal. 2009. Assessing
  the impact of frame semantics on textual entail-         Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance
  ment. Journal of Natural Language Engineering,             Ramshaw, and Ralph Weischedel. 2006. Ontonotes:
  15(4):527–550.                                             The 90% solution. In Proceedings of HLT-NAACL.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
  pervised learning of narrative schemas and their par-    Jian Huang, Sarah M. Taylor, Jonathan L. Smith, Kon-
  ticipants. In Proceedings of ACL-IJCNLP.                    stantinos A. Fotiadis, and C. Lee Giles. 2009. Pro-
                                                              file based cross-document coreference using kernel-
Nathanael Chambers, Daniel Cer, Trond Grenager,               ized fuzzy relational clustering. In Proceedings of
  David Hall, Chloe Kiddon, Bill MacCartney, Marie-           ACL-IJCNLP.
  Catherine de Marneffe, Daniel Ramage, Eric Yeh,
  and Christopher D. Manning. 2007. Learning align-        Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan
  ments and leveraging natural logic. In Proceedings         Zhu. 2009. Answering opinion questions with
  of the ACL-PASCAL Workshop on Textual Entail-              random walks on graphs. In Proceedings of ACL-
  ment and Paraphrasing.                                     IJCNLP.


                                                       1218


Dekang Lin and Patrick Pantel. 2001. Discovery of in-    Dmitry Zelenko, Chinatsu Aone, and Jason Tibbetts.
  ference rules for question answering. Natural Lan-      2004. Coreference resolution for information ex-
  guage Engineering, 4(7):343–360.                        traction. In Proceedings of the ACL Workshop on
                                                          Reference Resolution and its Applications.
Dekang Lin. 1993. Principle-based parsing without
  overgeneration. In Proceedings of ACL.

Bill MacCartney, Michel Galley, and Christopher D.
   Manning. 2008. A phrase-based alignment model
   for natural language inference. In Proceedings of
   EMNLP.

Katja Markert, Malvina Nissim, and Natalia N. Mod-
  jeska. 2003. Using the web for nominal anaphora
  resolution. In Proceedings of EACL Workshop on
  the Computational Treatment of Anaphora.

Seung-Hoon Na and Hwee Tou Ng. 2009. A 2-poisson
  model for probabilistic coreference of named enti-
  ties for improved text retrieval. In Proceedings of
  SIGIR.

Rodney D. Nielsen, Wayne Ward, and James H. Mar-
  tin. 2009. Recognizing entailment in intelligent
  tutoring systems. Natural Language Engineering,
  15(4):479–501.

Massimo Poesio, Rahul Mehta, Axel Maroudas, and
 Janet Hitzeman. 2004. Learning to resolve bridging
 references. In Proceedings of ACL.

Simone Paolo Ponzetto and Michael Strube. 2006.
  Exploiting semantic role labeling, WordNet and
  Wikipedia for coreference resolution. In Proceed-
  ings of HLT.

Long Qiu, Min-Yen Kan, and Tat-Seng Chua. 2004. A
  public reference implementation of the rap anaphora
  resolution algorithm. In Proceedings of LREC.

Lorenza Romano, Milen Kouylekov, Idan Szpektor,
  Ido Dagan, and Alberto Lavelli. 2006. Investigat-
  ing a generic paraphrase-based approach for relation
  extraction. In Proceedings of EACL.

Wee Meng Soon, Hwee Tou Ng, and Daniel
  Chung Yong Lim. 2001. A machine learning ap-
  proach to coreference resolution of noun phrases.
  Computational Linguistics, 27(4):521–544.

Stephanie Strassel, Mark Przybocki, Kay Peterson,
   Zhiyi Song, and Kazuaki Maeda. 2008. Linguistic
   resources and evaluation techniques for evaluation
   of cross-document automatic content extraction. In
   Proceedings of LREC.

Jose L. Vicedo and Antonio Ferrndez. 2006. Coref-
   erence in Q&A.      In Tomek Strzalkowski and
   Sanda M. Harabagiu, editors, Advances in Open Do-
   main Question Answering, pages 71–96. Springer.

Fabio Massimo Zanzotto, Marco Pennacchiotti, and
  Alessandro Moschitti. 2009. A machine learning
  approach to textual entailment recognition. Journal
  of Natural Language Engineering, 15(4):551–582.


                                                     1219

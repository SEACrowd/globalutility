      Multilingual Pseudo-Relevance Feedback: Performance Study of
                           Assisting Languages
             Manoj K. Chinnakotla Karthik Raman Pushpak Bhattacharyya
                      Department of Computer Science and Engineering
                          Indian Institute of Technology, Bombay,
                                       Mumbai, India
                      {manoj,karthikr,pb}@cse.iitb.ac.in

                      Abstract                                like morphological variations, polysemy and syn-
                                                              onymy. Relevance Feedback (RF) tries to over-
    In a previous work of ours Chinnakotla
                                                              come these problems by eliciting user feedback
    et al. (2010) we introduced a novel
                                                              on the relevance of documents obtained from the
    framework for Pseudo-Relevance Feed-
                                                              initial ranking and then uses it to automatically
    back (PRF) called MultiPRF. Given a
                                                              refine the query. Since user input is hard to ob-
    query in one language called Source, we
                                                              tain, Pseudo-Relevance Feedback (PRF) (Buckley
    used English as the Assisting Language to
                                                              et al., 1994; Xu and Croft, 2000; Mitra et al., 1998)
    improve the performance of PRF for the
                                                              is used as an alternative, wherein RF is performed
    source language. MulitiPRF showed re-
                                                              by assuming the top k documents from the initial
    markable improvement over plain Model
                                                              retrieval as being relevant to the query. Based on
    Based Feedback (MBF) uniformly for 4
                                                              the above assumption, the terms in the feedback
    languages, viz., French, German, Hungar-
                                                              document set are analyzed to choose the most dis-
    ian and Finnish with English as the as-
                                                              tinguishing set of terms that characterize the feed-
    sisting language. This fact inspired us
                                                              back documents and as a result the relevance of
    to study the effect of any source-assistant
                                                              a document. Query refinement is done by adding
    pair on MultiPRF performance from out
                                                              the terms obtained through PRF, along with their
    of a set of languages with widely differ-
                                                              weights, to the actual query.
    ent characteristics, viz., Dutch, English,
    Finnish, French, German and Spanish.                         Although PRF has been shown to improve re-
    Carrying this further, we looked into the                 trieval, it suffers from the following drawbacks:
    effect of using two assisting languages to-               (a) the type of term associations obtained for query
    gether on PRF.                                            expansion is restricted to co-occurrence based re-
                                                              lationships in the feedback documents, and thus
    The present paper is a report of these in-
                                                              other types of term associations such as lexical and
    vestigations, their results and conclusions
                                                              semantic relations (morphological variants, syn-
    drawn therefrom. While performance im-
                                                              onyms) are not explicitly captured, and (b) due to
    provement on MultiPRF is observed what-
                                                              the inherent assumption in PRF, i.e., relevance of
    ever the assisting language and whatever
                                                              top k documents, performance is sensitive to that
    the source, observations are mixed when
                                                              of the initial retrieval algorithm and as a result is
    two assisting languages are used simul-
                                                              not robust.
    taneously. Interestingly, the performance
    improvement is more pronounced when                          Multilingual Pseudo-Relevance Feedback
    the source and assisting languages are                    (MultiPRF) (Chinnakotla et al., 2010) is a novel
    closely related, e.g., French and Spanish.                framework for PRF to overcome both the above
                                                              limitations of PRF. It does so by taking the help of
1   Introduction                                              a different language called the assisting language.
The central problem of Information Retrieval (IR)             In MultiPRF, given a query in source language
is to satisfy the user’s information need, which is           L1 , the query is automatically translated into
typically expressed through a short (typically 2-3            the assisting language L2 and PRF performed
words) and often ambiguous query. The problem                 in the assisting language. The resultant terms
of matching the user’s query to the documents is              are translated back into L1 using a probabilistic
rendered difficult by natural language phenomena              bi-lingual dictionary. The translated feedback


                                                        1346
       Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1346–1356,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


model, is then combined with the original feed-         TREC Robust Track, is to use a large external col-
back model of L1 to obtain the final model which        lection like Wikipedia or the Web as a source of
is used to re-rank the corpus. MulitiPRF showed         expansion terms (Xu et al., 2009; Voorhees, 2006).
remarkable improvement on standard CLEF                 The intuition behind the above approach is that
collections over plain Model Based Feedback             if the query does not have many relevant docu-
(MBF) uniformly for 4 languages, viz., French,          ments in the collection then any improvements in
German, Hungarian and Finnish with English as           the modeling of PRF is bound to perform poorly
the assisting language. This fact inspired us to        due to query drift.
study the effect of any source-assistant pair on           Several approaches have been proposed for
PRF performance from out of a set of languages          including different types of lexically and se-
with widely different characteristics, viz., Dutch,     mantically related terms during query expansion.
English, Finnish, French, German and Spanish.           Voorhees (1994) use Wordnet for query expan-
Carrying this further, we looked into the effect of     sion and report negative results. Recently, random
using two assisting languages together on PRF.          walk models (Lafferty and Zhai, 2001; Collins-
   The present paper is a report of these in-           Thompson and Callan, 2005) have been used to
vestigations, their results and conclusions drawn       learn a rich set of term level associations by com-
therefrom. While performance improvement on             bining evidence from various kinds of information
PRF is observed whatever the assisting language         sources like WordNet, Web etc. Metzler and Croft
and whatever the source, observations are mixed         (2007) propose a feature based approach called la-
when two assisting languages are used simulta-          tent concept expansion to model term dependen-
neously. Interestingly, the performance improve-        cies.
ment is more pronounced when the source and as-
                                                           All the above mentioned approaches use the re-
sisting languages are closely related, e.g., French
                                                        sources available within the language to improve
and Spanish.
                                                        the performance of PRF. However, we make use of
   The paper is organized as follows: Section 2,
                                                        a second language to improve the performance of
discusses the related work. Section 3, explains the
                                                        PRF. Our proposed approach is especially attrac-
Language Modeling (LM) based PRF approach.
                                                        tive in the case of resource-constrained languages
Section 4, describes the MultiPRF approach. Sec-
                                                        where the original retrieval is bad due to poor cov-
tion 5 discusses the experimental set up. Section 6
                                                        erage of the collection and/or inherent complexity
presents the results, and studies the effect of vary-
                                                        of query processing (for example term conflation)
ing the assisting language and incorporates mul-
                                                        in those languages.
tiple assisting languages. Finally, Section 7 con-
cludes the paper by summarizing and outlining fu-          Jourlin et al. (1999) use parallel blind relevance
ture work.                                              feedback, i.e. they use blind relevance feedback on
                                                        a larger, more reliable parallel corpus, to improve
2   Related Work                                        retrieval performance on imperfect transcriptions
PRF has been successfully applied in various IR         of speech. Another related idea is by Xu et al.
frameworks like vector space models, probabilis-        (2002), where a statistical thesaurus is learned us-
tic IR and language modeling (Buckley et al.,           ing the probabilistic bilingual dictionaries of Ara-
1994; Jones et al., 2000; Lavrenko and Croft,           bic to English and English to Arabic. Meij et
2001; Zhai and Lafferty, 2001). Several ap-             al. (2009) tries to expand a query in a differ-
proaches have been proposed to improve the per-         ent language using language models for domain-
formance and robustness of PRF. Some of the rep-        specific retrieval, but in a very different setting.
resentative techniques are (i) Refining the feed-       Since our method uses a corpus in the assisting
back document set (Mitra et al., 1998; Sakai et         language from a similar time period, it can be
al., 2005), (ii) Refining the terms obtained through    likened to the work by Talvensaari et al. (2007)
PRF by selecting good expansion terms (Cao et           who used comparable corpora for Cross-Lingual
al., 2008) and (iii) Using selective query expan-       Information Retrieval (CLIR). Other work pertain-
sion (Amati et al., 2004; Cronen-Townsend et al.,       ing to document alignment in comparable corpora,
2004) and (iv) Varying the importance of docu-          such as Braschler and Schäuble (1998), Lavrenko
ments in the feedback set (Tao and Zhai, 2006).         et al. (2002), also share certain common themes
Another direction of work, often reported in the        with our approach. Recent work by Gao et al.


                                                    1347


(2008) uses English to improve the performance                             Query in L1                     Translated Query
                                                                                                                 to L2
over a subset of Chinese queries whose transla-                                   Initial Retrieval                       Initial Retrieval
                                                                                     Algorithm                               Algorithm
tions in English are unambiguous. They use inter-                                  (LM Based Query                           (LM Based Query
                                                                                      Likelihood)                               Likelihood)
document similarities across languages to improve
the ranking performance. However, cross lan-
guage document similarity measurement is in it-
                                                                L1 Index          Top ‘k’ Results                         Top ‘k’ Results           L2 Index
self known to be an hard problem and the scale of
their experimentation is quite small.
                                                                                         PRF                                      PRF
3   PRF in the LM Framework                                                          (Model Based                             (Model Based
                                                                                      Feedback)                                Feedback)

The Language Modeling (LM) Framework allows                                Feedback Model   θL1                  Feedback Model      θL2
PRF to be modelled in a principled manner. In the               Query               Feedback                             Relevance Model
                                                                Model           Model Interpolation        Translated       Translation
LM approach, documents and queries are modeled                                                             Feedback
                                                                 θQ
using multinomial distribution over words called                                                             Model
                                                                                                                                    Probabilistic
                                                                                   KL-Divergence
document language model P (w|D) and query lan-                                    Ranking Function
                                                                                                                                     Dictionary
                                                                                                                                      L2 → L1
guage model P (w|ΘQ ) respectively. For a given
query, the document language models are ranked                                                           Final Ranked List
                                                                                                        Of Documents in L1
based on their proximity to the query language
model, measured using KL-Divergence.                             Figure 1: Schematic of the Multilingual PRF Approach

                       X                     P (w|ΘQ )          Symbol         Description
        KL(ΘQ ||D) =       P (w|ΘQ ) · log
                       w
                                              P (w|D)
                                                                ΘQ             Query Language Model
                                                                ΘF             Feedback Language Model obtained from PRF in L1
Since the query length is short, it is difficult to es-          L
                                                                ΘF
                                                                    1
                                                                               Feedback Language Model obtained from PRF in L2
                                                                 L  2
timate ΘQ accurately using the query alone. In                  ΘTL1
                                                                    rans
                                                                               Feedback Model Translated from L2 to L1
PRF, the top k documents obtained through the ini-              t(f |e)        Probabilistic Bi-Lingual Dictionary from L2 to L1
                                                                β, γ           Interpolation coefficients coefficients used in MultiPRF
tial ranking algorithm are assumed to be relevant
and used as feedback for improving the estima-                  Table 2: Glossary of Symbols used in explaining MultiPRF
tion of ΘQ . The feedback documents contain both            to the above technique as Model Based Feedback
relevant and noisy terms from which the feedback            (MBF).
language model is inferred based on a Generative
Mixture Model (Zhai and Lafferty, 2001).
                                                            4        Multilingual PRF (MultiPRF)
   Let DF = {d1 , d2 , . . . , dk } be the top k docu-      The schematic of the MultiPRF approach is shown
ments retrieved using the initial ranking algorithm.        in Figure 1. Given a query Q in the source lan-
Zhai and Lafferty (Zhai and Lafferty, 2001) model           guage L1 , we automatically translate the query
the feedback document set DF as a mixture of two            into the assisting language L2 . We then rank the
distributions: (a) the feedback language model and          documents in the L2 collection using the query
(b) the collection model P (w|C). The feedback              likelihood ranking function (John Lafferty and
language model is inferred using the EM Algo-               Chengxiang Zhai, 2003). Using the top k doc-
rithm (Dempster et al., 1977), which iteratively            uments, we estimate the feedback model using
accumulates probability mass on the most distin-            MBF as described in the previous section. Simi-
guishing terms, i.e. terms which are more fre-              larly, we also estimate a feedback model using the
quent in the feedback document set than in the              original query and the top k documents retrieved
entire collection. To maintain query focus the fi-          from the initial ranking in L1 . Let the resultant
nal converged feedback model, ΘF is interpolated            feedback models be ΘFL2 and ΘFL1 respectively.
with the initial query model ΘQ to obtain the final         The feedback model estimated in the assisting lan-
query model ΘF inal .                                       guage ΘFL2 is translated back into language L1
                                                            using a probabilistic bi-lingual dictionary t(f |e)
             ΘF inal = (1 − α) · ΘQ + α · ΘF                from L2 → L1 as follows:
                                                                                     T rans
                                                                                                           X                               F
  ΘF inal is used to re-rank the corpus using the                           P (f |ΘL
                                                                                       1
                                                                                            )       =                t(f |e) · P (e|ΘL )
                                                                                                                                               2
                                                                                                                                                         (1)
                                                                                                         ∀ e in L2
KL-Divergence ranking function to obtain the fi-
nal ranked list of documents. Henceforth, we refer                The probabilistic bi-lingual dictionary t(f |e) is


                                                         1348


                    CLEF Collection                                                     No. of      No. of Unique   CLEF Topics
   Language                              Description
                    Identifier                                                          Documents   Terms           (No. of Topics)
                    EN-00+01+02          LA Times 94                                    113005      174669          -
   English          EN-03+05+06          LA Times 94, Glasgow Herald 95                 169477      234083          -
                    EN-02+03             LA Times 94, Glasgow Herald 95                 169477      234083          91-200 (67)
                    FR-00                Le Monde 94                                    44013       127065          1-40 (29)
                    FR-01+02             Le Monde 94, French SDA 94                     87191       159809          41-140 (88)
   French           FR-02+03             Le Monde 94, French SDA 94-95                  129806      182214          91-200 (67)
                    FR-03+05             Le Monde 94, French SDA 94-95                  129806      182214          141-200,251-300 (99)
                    FR-06                Le Monde 94-95, French SDA 94-95               177452      231429          301-350 (48)
                    DE-00                Frankfurter Rundschau 94, Der Spiegel 94-95    153694      791093          1-40 (33)
                                         Frankfurter Rundschau 94, Der Spiegel 94-95,
                    DE-01+02                                                            225371      782304          41-140 (85)
                                         German SDA 94
   German                                Frankfurter Rundschau 94, Der Spiegel 94-95,
                    DE-02+03                                                            294809      867072          91-200 (67)
                                         German SDA 94-95
                                         Frankfurter Rundschau 94, Der Spiegel 94-95,
                    DE-03                                                               294809      867072          141-200 (51)
                                         German SDA 94-95
                    FI-02+03+04          Aamulehti 94-95                                55344       531160          91-250 (119)
   Finnish
                    FI-02+03             Aamulehti 94-95                                55344       531160          91-200 (67)
                                         NRC Handelsblad 94-95, Algemeen Dagblad 94-
   Dutch            NL-02+03                                                            190604      575582          91-200 (67)
                                         95
   Spanish          ES-02+03             EFE 94, EFE 95                                 454045      340250          91-200 (67)


Table 1: Details of the CLEF Datasets used for Evaluating the MultiPRF approach. The number shown in brackets of the final
column CLEF Topics indicate the actual number of topics used during evaluation.

 Source Term       Top Aligned Terms in Target                                     back translation the feedback model in L2 is inter-
 French            English                                                         polated with the translated query before transla-
 américain        american, us, united, state, america
 nation            nation, un, united, state, country
                                                                                   tion of the L2 feedback model. The parameters β
 et́ude            study, research, assess, investigate, survey                    and γ control the relative importance of the orig-
 German            English
 flugzeug          aircraft, plane, aeroplane, air, flight                         inal query model, feedback model of L1 and the
 spiele            play, game, stake, role, player
 verhältnis       relationship, relate, balance, proportion
                                                                                   translated feedback model obtained from L1 and
                                                                                   are tuned based on the choice of L1 and L2 .
Table 3: Top Translation Alternatives for some sample words
in Probabilistic Bi-Lingual Dictionary                                             5     Experimental Setup
learned from a parallel sentence-aligned corpora                                   We evaluate the performance of our system us-
in L1 −L2 based on word level alignments. Tiede-                                   ing the standard CLEF evaluation data in six lan-
mann (Tiedemann, 2001) has shown that the trans-                                   guages, widely varying in their familial relation-
lation alternatives found using word alignments                                    ships - Dutch, German, English, French, Span-
could be used to infer various morphological and                                   ish and Finnish using more than 600 topics. The
semantic relations between terms. In Table 3,                                      details of the collections and their corresponding
we show the top translation alternatives for some                                  topics used for MultiPRF are given in Table 1.
sample words. For example, the French word                                         Note that, in each experiment, we choose assist-
américain (american) brings different variants of                                 ing collections such that the topics in the source
the translation like american, america, us, united,                                language are covered in the assisting collection so
state, america which are lexically and semanti-                                    as to get meaningful feedback terms. In all the top-
cally related. Hence, the probabilistic bi-lingual                                 ics, we only use the title field. We ignore the top-
dictionary acts as a rich source of morphologically                                ics which have no relevant documents as the true
and semantically related feedback terms. Thus,                                     performance on those topics cannot be evaluated.
during this step, of translating the feedback model                                   We demonstrate the performance of MultiPRF
as given in Equation 1, the translation model adds                                 approach with French, German and Finnish as
related terms in L1 which have their source as the                                 source languages and Dutch, English and Span-
term from feedback model ΘFL2 . The final Multi-                                   ish as the assisting language. We later vary the
PRF model is obtained by interpolating the above                                   assisting language, for each source language and
translated feedback model with the original query                                  study the effects. We use the Terrier IR platform
model and the feedback model of language L1 as                                     (Ounis et al., 2005) for indexing the documents.
given below:                                                                       We perform standard tokenization, stop word re-
                                                                                   moval and stemming. We use the Porter Stemmer
      ΘL
         M ulti
          1
                                                   F
                  = (1 − β − γ) · ΘQ + β · ΘL + γ · ΘL
                                                       1
                                                                  T rans
                                                                    1
                                                                           (2)     for English and the stemmers available through the
                                                                                   Snowball package for other languages. Other than
                                                                                   these, we do not perform any language-specific
  Since we want to retain the query focus during                                   processing on the languages. In case of French,


                                                                             1349


                Assist.             P@5                          P@10                         MAP                          GMAP
     Collection
                 Lang     MBF      MultiPRF % Impr.    MBF      MultiPRF % Impr.    MBF      MultiPRF % Impr.    MBF      MultiPRF   % Impr.
                  EN                 0.5241 11.76‡                0.4000     0.00              0.4393     4.10              0.3413     15.27
        FR-00     ES      0.4690     0.5034    7.35‡   0.4000     0.4103     2.59   0.4220     0.4418     4.69   0.2961     0.3382     14.22
                  NL                 0.5034     7.35              0.4103     2.59              0.4451     5.47              0.3445     16.34
                  EN                 0.4818     3.92              0.4386    7.82‡              0.4535    4.43‡              0.2721     13.61
      FR-01+02    ES      0.4636     0.4977    7.35‡   0.4068     0.4363    7.26‡   0.4342     0.4416     1.70   0.2395     0.2349      -1.92
                  NL                 0.4818     3.92              0.4409    8.38‡              0.4375     0.76              0.2534       5.80
                  EN                 0.4768    4.89‡              0.4202       4‡              0.3694    4.67‡              0.1411       6.57
      FR-03+05    ES      0.4545     0.4727     4.00   0.4040     0.4080     1.00   0.3529     0.3582     1.50   0.1324     0.1325       0.07
                  NL                 0.4525    -0.44              0.4010    -0.75              0.3513     0.45              0.1319      -0.38
                  EN                 0.5083     3.39              0.4729     2.25              0.4104     6.97              0.2810     29.25
        FR-06     ES      0.4917     0.5083     3.39   0.4625     0.4687     1.35   0.3837     0.3918     2.12   0.2174     0.2617     20.38
                  NL                 0.5083     3.39              0.4646     0.45              0.3864     0.71              0.2266       4.23
                  EN                 0.3212 39.47‡                0.2939 22.78‡                0.2273     5.31              0.0191    730.43
        DE-00     ES      0.2303     0.3212 39.47‡     0.2394     0.2818 17.71‡     0.2158     0.2376   10.09    0.0023     0.0123    434.78
                  NL                 0.3151 36.82‡                0.2818 17.71‡                0.2331     8.00              0.0122    430.43
                  EN                 0.6000 12.34‡                0.5318    9.35‡              0.4576     8.2‡              0.2721       9.19
     DE-01+02     ES      0.5341     0.5682    6.39‡   0.4864     0.5091    4.67‡   0.4229     0.4459     5.43   0.1765     0.2309     30.82
                  NL                 0.5773    8.09‡              0.5114    5.15‡              0.4498    6.35‡              0.2355     33.43
                  EN                 0.5412     6.15              0.4980     4.10              0.4355     1.91              0.1771     42.48
        DE-03     ES      0.5098     0.5647 10.77‡     0.4784     0.4980     4.10   0.4274     0.4568    6.89‡   0.1243     0.1645     32.34
                  NL                 0.5529    8.45‡              0.4941     3.27              0.4347     1.72              0.1490     19.87
                  EN                 0.4034    6.67‡              0.3319    8.52‡              0.4246    7.06‡              0.2272     69.05
    FI-02+03+04   ES      0.3782     0.3879     2.58   0.3059     0.3267     6.81   0.3966     0.3881    -2.15   0.1344     0.1755     30.58
                  NL                 0.3948     4.40              0.3301     7.92              0.4077     2.79              0.1839     36.83

Table 4: Results comparing the performance of MultiPRF over baseline MBF on CLEF collections with English (EN), Spanish
(ES) and Dutch (NL) as assisting languages. Results marked as ‡ indicate that the improvement was found to be statistically
significant over the baseline at 90% confidence level (α = 0.01) when tested using a paired two-tailed t-test.

since some function words like l’, d’ etc., occur as                     the baseline value on all metrics, namely MAP
prefixes to a word, we strip them off during index-                      (where significant improvements range from 4.4%
ing and query processing, since it significantly im-                     to 7.1%); P@5 (significant improvements range
proves the baseline performance. We use standard                         from 4.9% to 39.5% and P@10 (where MultiPRF
evaluation measures like MAP, P@5 and P@10                               has significant gains varying from 4% to 22.8%).
for evaluation. Additionally, for assessing robust-                      Additionally we also find MultiPRF to be more ro-
ness, we use the Geometric Mean Average Preci-                           bust than the baseline, as indicated by the GMAP
sion (GMAP) metric (Robertson, 2006) which is                            score, where improvements vary from 4.2% to
also used in the TREC Robust Track (Voorhees,                            730%. Furthermore we notice these trends hold
2006). The probabilistic bi-lingual dictionary used                      across different assisting languages, with Span-
in MultiPRF was learnt automatically by running                          ish and Dutch outperforming English as the as-
GIZA++: a word alignment tool (Och and Ney,                              sisting language on some of the French and Ger-
2003) on a parallel sentence aligned corpora. For                        man collections. On performing a more detailed
all the above language pairs we used the Europarl                        study of the results we identify the main reason
Corpus (Philipp, 2005). We use Google Trans-                             for improvements in our approach is the ability to
late as the query translation system as it has been                      obtain good feedback terms in the assisting lan-
shown to perform well for the task (Wu et al.,                           guage coupled with the introduction of lexically
2008). We use the MBF approach explained in                              and semantically related terms during the back-
Section 3 as a baseline for comparison. We use                           translation step.
two-stage Dirichlet smoothing with the optimal
                                                                            In Table 5, we see some examples, which illus-
parameters tuned based on the collection (Zhai and
                                                                         trates the feedback terms brought by the MultiPRF
Lafferty, 2004). We tune the parameters of MBF,
                                                                         method. As can be seen by these example, the
specifically λ and α, and choose the values which
                                                                         gains achieved by MultiPRF are primarily due to
give the optimal performance on a given collec-
                                                                         one of three reasons: (a) Good Feedback in As-
tion. We uniformly choose the top ten documents
                                                                         sisting Language: If the feedback model in the
for feedback. Table 4 gives the overall results.
                                                                         assisting language contains good terms, then the
6      Results and Discussion                                            back-translation process will introduce the corre-
                                                                         sponding feedback terms in the source language,
In Table 4, we see the performance of the Multi-                         thus leading to improved performance. As an
PRF approach for three assisting languages, and                          example of this phenomena, consider the French
how it compares with the baseline MBF meth-                              Query “Maladie de Creutzfeldt-Jakob”. In this
ods. We find MultiPRF to consistently outperform                         case the original feedback model also performs


                                                                   1350


                                                                                                        MBF- Top Representative Terms           MultiPRF- Top Representative
                ASSIST SOURCE LANGUAGE         TRANSLATED             QUERY           MBF       MPRF    (With Meaning) Excl. Query              Terms (With Meaning) Excl. Query
  TOPIC NO      LANG. QUERY                    QUERY                  MEANING         MAP       MAP     Terms                                   Terms
                                                                                                        exxon, million, ol (oil), tonn,         olverschmutz (oil pollution), ol,
  GERMAN '01:         Ölkatastrophe in                                Siberian Oil
                EN                             Oil Spill in Siberia                   0.618     0.812   russisch (russian), olp (oil),          russisch, erdol (petroleum), russland
  TOPIC 61            Sibirien                                        Catastrophe
                                                                                                        moskau (moscow), us                     (russia), olunfall(oil spill), olp
                                                                                                        chronisch (chronic), pet, athlet
                                                                                                                                                asthma, allergi, krankheit (disease),
                                                                                                        (athlete), ekrank (ill), gesund
  GERMAN '02:                                                         Bronchial                                                                 allerg (allergenic), chronisch,
                ES    Bronchialasthma          El asma bronquial                      0.062     0.636   (healthy), tuberkulos
  TOPIC 105                                                           Asthma                                                                    hauterkrank (illness of skin), arzt
                                                                                                        (tuberculosis), patient, reis (rice),
                                                                                                                                                (doctor), erkrank (ill)
                                                                                                        person
                                                                                                        développ (developed), évolu
  FRENCH '02:                                  Genetische             Genetic                                                                   genetic, gen, engineering, développ,
                NL    Ingénierie génétique                                            0.145     0.357   (evolved), product, produit
  TOPIC 107                                    Manipulatie            Engineering                                                               product
                                                                                                        (product), moléculair (molecular)
                                                                                                                                            malad, humain (human), bovin
                                                                                                        malad (illness), produit (product),
  FRENCH '06:         Maladie de                                      Creutzfeldt-                                                          (bovine), encéphalopath (suffering
                EN                             Creutzfeldt-Jakob                      0.507     0.688   animal (animal), hormon
  TOPIC 256           Creutzfeldt-Jakob                               Jakob Disease                                                         from encephalitis), scientif, recherch
                                                                                                        (hormone)
                                                                                                                                            (research)
                                                                                                        telefonbuch (phone book), sieg gross (large), verfecht (champion),
  GERMAN '03:         Siegerinnen von          Champions of           Wimbledon                         (victory), titelseit (front page),  sampra (sampras), 6, champion,
                EN                                                                    0.074     0.146
  TOPIC 157           Wimbledon                Wimbledon              Lady Winners                      telekom (telecommunication),        steffi, verteidigt (defendending),
                                                                                                        graf                                martina, jovotna, navratilova
                                                                                                        international, amnesty,
                                                                                                        strassenkind (street child),        karib (Caribbean), land, brasili,
  GERMAN '01:                                  La gripe aviar en      AI in Latin
                ES    AI in Lateinamerika                                             0.456     0.098   kolumbi (Columbian), land, brasili schuld (blame), amerika, kalt (cold),
  TOPIC 91                                     América Latina         America
                                                                                                        (Brazil), menschenrecht (human welt (world), forschung (research)
                                                                                                        rights), polizei (police)
                                                                                                                                            kernfusion (nuclear fusion),
  GERMAN '03:         Fusion japanischer       Fusion of Japanese Merger of                             daiwa, tokyo, filial (branch),      zentralbank (central bank), daiwa,
                EN                                                               0.572          0.264
  TOPIC 196           Banken                   banks              Japanese Banks                        zusammenschluss (merger)            weltbank (world bank),
                                                                                                                                            investitionsbank (investment bank)
                                                                                                        convent (convention), franc,        per (father), convent, franc, jurid
  FRENCH '03:                                  De rechten van het
                NL    Les droits de l'enfant                      Child Rights        0.479     0.284   international, onun (united         (legal), homm (man), cour (court),
  TOPIC 152                                    kind
                                                                                                        nations), réserv (reserve)          biolog


Table 5: Qualitative comparison of feedback terms given by MultiPRF and MBF on representative queries where positive and
negative results were observed in French and German collections.

quite strongly with a MAP score of 0.507. Al-                                                 nakotla et al., 2010), the MultiPRF approach is
though there is no significant topic drift in this                                            robust to suboptimal translation quality as well.
case, there are not many relevant terms apart from                                            To see how MultiPRF leads to improvements even
the query terms. However the same query per-                                                  with errors in query translation consider the Ger-
forms very well in English with all the documents                                             man Query “Siegerinnen von Wimbledon”. When
in the feedback set of the English corpus being rel-                                          this is translated to English, the term “Lady” is
evant, thus resulting in informative feedback terms                                           dropped, this causes only “Wimbledon Champi-
such as {bovin, scientif, recherch}. (b) Finding                                              ons” to remain. As can be observed, this causes
Synonyms/Morphological Variations: Another sit-                                               terms like sampras to come up in the MultiPRF
uation in which MultiPRF leads to large improve-                                              model. However, while the MultiPRF model has
ments is when it finds semantically/lexically re-                                             some terms pertaining to Men’s Winners of Wim-
lated terms to the query terms which the origi-                                               bledon as well, the original feedback model suf-
nal feedback model was unable to. For example,                                                fers from severe topic drift, with irrelevant terms
consider the French query “Ingénierie g´n´tique”.                                            such as {telefonbuch, telekom} also amongst the
While the feedback model was unable to find                                                   top terms. Thus we notice that despite the er-
any of the synonyms of the query terms, due to                                                ror in query translation MultiPRF still manages to
their lack of co-occurence with the query terms,                                              correct the drift of the original feedback model,
the MultiPRF model was able to get these terms,                                               while also introducing relevant terms such as
which are introduced primarily during the back-                                               {verfecht, steffi, martina, novotna, navratilova}
translation process. Thus terms like {genetic, gen,                                           as well. Thus as shown in (Chinnakotla et al.,
engineering}, which are synonyms of the query                                                 2010), having a better query translation system
words, are found thus resulting in improved per-                                              can only lead to better performance. We also
formance. (c) Combination of Above Factors:                                                   perform a detailed error analysis and found three
Sometimes a combination of the above two factors                                              main reasons for MultiPRF failing: (i) Inaccura-
causes improvements in the performance as in the                                              cies in query translation (including the presence of
German query “Ölkatastrophein Sibirien”. For                                                 out-of-vocabulary terms). This is seen in the Ger-
this query, MultiPRF finds good feedback terms                                                man Query AI in Lateinamerika, which wrongly
such as {russisch, russland} while also obtaining                                             translates to Avian Flu in Latin America in Span-
semantically related terms such as {olverschmutz,                                             ish thus affecting performance. (ii) Poor retrieval
erdol, olunfall}.                                                                             in Assisting Language. Consider the French query
   Although all of the previously described exam-                                             Les droits de l’enfant, for which due to topic drift
ples had good quality translations of the query                                               in English, MultiPRF performance reduces. (iii)
in the assisting language, as mentioned in (Chin-                                             In a few rare cases inaccuracy in the back transla-


                                                                                      1351


             (a) Source:French (FR-01+02) Assist:Spanish          (b) Source:German (DE-01+02) Assist:Dutch




                                    (c) Source:Finnish (FI-02+03+04) Assist:English
 Figure 2: Results showing the sensitivity of MultiPRF performance to parameters β and γ for French, German and Finnish.

tion affects performance as well.                             alyze the behaviour of MultiPRF in the following
                                                              two scenarios: (a) Using ideal query translation
6.1   Parameter Sensitivity Analysis
                                                              (b) Using Google Translate for query translation.
The MultiPRF parameters β and γ in Equation                   In ideal query translation setup, in order to elim-
2 control the relative importance assigned to the             inate its effect, we skip the query translation step
original feedback model in source language L1 ,               and use the corresponding original topics for each
the translated feedback model obtained from as-               target language instead. The results for both the
sisting language L2 and the original query terms.             above scenarios are given in Tables 6 and 7.
We varied the β and γ parameters for French, Ger-
man and Finnish collections with English, Dutch                  From the results, we firstly observe that besides
and Spanish as assisting languages and studied its            English, other languages such as French, Spanish,
effect on MAP of MultiPRF. The results are shown              German and Dutch act as good assisting languages
in Figure 2. The results show that, in all the three          and help in improving performance over mono-
collections, the optimal value of the parameters              lingual MBF. We also observe that the best as-
almost remains the same and lies in the range of              sisting language varies with the source language.
0.4-0.48. Due to the above reason, we arbitrarily             However, the crucial factors of the assisting lan-
choose the parameters in the above range and do               guage which influence the performance of Multi-
not use any technique to learn these parameters.              PRF are: (a) Monolingual PRF Performance: The
                                                              main motivation for using a different language was
6.2   Effect of Assisting Language Choice
                                                              to get good feedback terms, especially in case of
In this section, we discuss the effect of varying             queries which fail in the source language. Hence,
the assisting language. Besides, we also study                an assisting language in which the monolingual
the inter and intra familial behaviour of source-             feedback performance itself is poor, is unlikely
assisting language pairs. In order to ensure that             to give any performance gains. This observation
the results are comparable across languages, we               is evident in case of Finnish, which has the low-
indexed the collections from the years 2002, 2003             est Monolingual MBF performance. The results
and use common topics from the topic range 91-                show that Finnish is the least helpful of assist-
200 that have relevant documents across all the six           ing languages, with performance similar to those
languages. The number of such common topics                   of the baselines. We also observe that the three
were 67. For each source language, we use the                 best performing assistant languages, i.e. English,
other languages as assisting collections and study            French and Spanish, have the highest monolingual
the performance of MultiPRF. Since query trans-               performances as well, thus further validating the
lation quality varies across language pairs, we an-           claim. One possible reason for this is the relative


                                                           1352


   Source                                             Assisting Language                                                                    Source
    Lang.          English           German        Dutch             Spanish                       French                Finnish            Lang.MBF
          MAP                        0.4464 (-0.7%)0.4471 (-0.5%)    0.4566 (+1.6%)                0.4563 (+1.5%)        0.4545 (+1.1%)     0.4495
  English P@5              -         0.4925 (-0.6%)0.5045 (+1.8%) 0.5164 (+4.2%)                   0.5075 (+2.4%)        0.5194 (+4.8%)     0.4955
          P@10                       0.4343 (+0.4%)0.4373 (+1.0%) 0.4537 (+4.8%)                   0.4343 (+0.4%)        0.4373 (+1.0%)     0.4328
          MAP      0.4229 (+4.9%)                  0.4346 (+7.8%) 0.4314 (+7.0%)                   0.411 (+1.9%)         0.3863 (-4.2%)     0.4033
  German P@5       0.5851 (+14%)           -       0.5851 (+14%)     0.5791 (+12.8%)               0.594 (+15.7%)        0.5522 (+7.6%)     0.5134
          P@10     0.5284 (+11.3%)                 0.5209 (+9.8%) 0.5179 (+9.1%)                   0.5149 (+8.5%)        0.5075 (+6.9%)     0.4746
          MAP      0.4317 (+4%)    0.4453 (+7.2%)                    0.4275 (+2.9%)                0.4241 (+2.1%)        0.3971 (-4.4%)     0.4153
   Dutch P@5       0.5642 (+11.8%) 0.5731 (+13.6%)          -        0.5343 (+5.9%)                0.5582 (+10.6%)       0.5045 (0%)        0.5045
          P@10     0.5075 (+9%)    0.4925 (+5.8%)                    0.4896 (+5.1%)                0.5015 (+7.7%)        0.4806 (+3.2%)     0.4657
                                                                                                                         0.4311 (-
           MAP     0.4667 (-2.9%)    0.4749 (-1.2%)    0.4744 (-1.3%)                              0.4609 (-4.1%)        10.3%)             0.4805
  Spanish
           P@5     0.62 (-2.9%)      0.6418 (+0.5%)    0.6299 (-1.4%)              -               0.6269 (-1.6%)        0.6149 (-3.7%)     0.6388
           P@10    0.5625 (-1.8%)    0.5806 (+1.3%)    0.5851 (+2.1%)                              0.5627 (-1.8%)        0.5478 (-4.4%)     0.5731
           MAP     0.4658 (+6.9%)    0.4526 (+3.9%)    0.4374 (+0.4%)   0.4634 (+6.4%)                                   0.4451 (+2.2%)     0.4356
   French P@5      0.4925 (+3.1%)    0.4806 (+0.6%)    0.4567 (-4.4%)   0.4925 (+3.1%)                       -           0.4836 (+1.3%)     0.4776
           P@10    0.4358 (+3.9%)    0.4239 (+1%)      0.4224 (+0.7%)   0.4388 (+4.6%)                                   0.4209 (+0.4%)     0.4194
           MAP     0.3411 (-4.7%)    0.3796 (+6.1%)    0.3722 (+4%)     0.369 (+3.1%)              0.3553 (-0.7%)                           0.3578
   Finnish P@5     0.394 (+3.1%)     0.403 (+5.5%)     0.406 (+6.3%)    0.4119 (+7.8%)             0.397 (+3.9%)                -           0.3821
           P@10    0.3463 (+11.5%)   0.3582 (+15.4%)   0.3478 (+12%)    0.3448 (+11%)              0.3433 (+10.6%)                          0.3105

Table 6: Results showing the performance of MultiPRF with different source and assisting languages using Google Translate
for query translation step. The intra-familial affinity could be observed from the elements close to the diagonal.

ease of processing in these languages. (b) Familial                      Source
                                                                                                    Assisting Language
                                                                         Lang.
Similarity Between Languages: We observe that                                          FR     ES     DE     NL      EN    FI        MBF   MPRF

the performance of MultiPRF is good if the as-                           French        -      0.3686 0.3113 0.3366 0.4338 0.3011 0.4342 0.4535

sisting language is from the same language fam-                          Spanish       0.3647 -      0.3440 0.3476 0.3954 0.3036 0.5000 0.4892

ily. Birch et al. (2008) show that the language                          German 0.2729 0.2736 -             0.2951 0.2107 0.2266 0.4229 0.4576
family is a strong predictor of machine transla-                         Dutch         0.2663 0.2836 0.2902 -       0.2757 0.2372 0.3968 0.3989
tion performance. Hence, the query translation
and back translation quality improves if the source                 Table 8: Effect of Language Family on Back Translation
                                                                    Performance measured through MultiPRF MAP. 100 Topics
and assisting languages belong to the same family.                  from years 2001 and 2002 were used for all languages.
For example, in the Germanic family, the source-
assisting language pairs German-English, Dutch-                     is directly back translated from L2 into L1 and
English, Dutch-German and German-Dutch show                         finally documents are re-ranked using this trans-
good performance. Similarly, in Romance family,                     lated feedback model. Since the automatic query
the performance of French-Spanish confirms this                     translation and PRF steps have been eliminated,
behaviour. In some cases, we observe that Multi-                    the only factor which influences the MultiPRF per-
PRF scores decent improvements even when the                        formance is the back-translation step. This means
assisting language does not belong to the same                      that the source-assisting language pairs for which
language family as witnessed in French-English                      the back-translation is good will score a higher
and English-French. This is primarily due to their                  performance. The results of the above experiment
strong monolingual MBF performance.                                 is shown in Table 8. For each source language,
                                                                    the best performing assisting languages have been
6.3   Effect of Language Family on Back                             highlighted.
      Translation Performance
                                                                       The results show that the performance of
As already mentioned, the performance of Multi-                     closely related languages like French-Spanish and
PRF is good if the source and assisting languages                   German-Dutch is more when compared to other
belong to the same family. In this section, we ver-                 source-assistant language pairs. This shows that
ify the above intuition by studying the impact of                   in case of closely related languages, the back-
language family on back translation performance.                    translation step succeeds in adding good terms
The experiment designed is as follows: Given a                      which are relevant like morphological variants,
query in source language L1 , the ideal translation                 synonyms and other semantically related terms.
in assisting language L2 is used to compute the                     Hence, familial closeness of the assisting language
query model in L2 using only the query terms.                       helps in boosting the MultiPRF performance. An
Then, without performing PRF the query model                        exception to this trend is English as assisting lan-


                                                              1353


   Source                                                Assisting Language                                                               Source
    Lang.           English           German           Dutch            Spanish             French               Finnish                  Lang.MBF
          MAP                         0.4513 (+0.4%)   0.4475 (-0.4%) 0.4695 (+4.5%)        0.4665 (+3.8%)       0.4416 (-1.7%)           0.4495
  English P@5                 -       0.5104 (+3.0%)   0.5104 (+3.0%) 0.5343 (+7.8%)        0.5403 (+9.0%)       0.4806 (-3.0%)           0.4955
          P@10                        0.4373 (+1.0%)   0.4358 (+0.7%) 0.4597 (+6.2%)        0.4582 (+5.9%)       0.4164 (-3.8%)           0.4328
          MAP       0.4427 (+9.8%)                     0.4306 (+6.8%) 0.4404 (+9.2%)        0.4104 (+1.8%)       0.3993 (-1.0%)           0.4033
  German P@5        0.606 (+18%)             -         0.5672 (+10.5%) 0.594 (+15.7%)       0.5761 (+12.2%)      0.5552 (+8.1%)           0.5134
          P@10      0.5373 (+13.2%)                    0.503 (+6.0%)    0.5299 (+11.7%)     0.494 (+4.1%)        0.5 (+5.4%)              0.4746
          MAP       0.4361 (+5.0%)    0.4344 (+4.6%)                    0.4227 (+1.8%)      0.4304 (+3.6%)       0.4134 (-0.5%)           0.4153
   Dutch P@5        0.5761 (+14.2%)   0.5552 (+10%)             -       0.5403 (+7.1%)      0.5463 (+8.3%)       0.5433 (+7.7%)           0.5045
          P@10      0.5254 (+12.8%)   0.497 (+6.7%)                     0.4776 (+2.6%)      0.5134 (+10.2%)      0.4925 (+5.8%)           0.4657
          MAP       0.4665 (-2.9%)    0.4773 (-0.7%)   0.4733 (-1.5%)                       0.4839 (+0.7%)       0.4412 (-8.2%)           0.4805
  Spanish P@5       0.6507 (+1.8%)    0.6448 (+0.9%)   0.6507 (+1.8%)           -           0.6478 (+1.4%)       0.597 (-6.5%)            0.6388
          P@10      0.5791 (+1.0%)    0.5791 (+1.0%)   0.5761 (+0.5%)                       0.5866 (+2.4%)       0.5567 (-2.9%)           0.5731
          MAP       0.4591 (+5.4%)    0.4514 (+3.6%)   0.4409 (+1.2%) 0.4712 (+8.2%)                             0.4354 (0%)              0.4356
  French P@5        0.4925 (+3.1%)    0.4776 (0%)      0.4776 (0%)      0.4995 (+4.6%)                -          0.4955 (+3.8%)           0.4776
          P@10      0.4463 (+6.4%)    0.4313 (+2.8%)   0.4373 (+4.3%) 0.4448 (+6.1%)                             0.4209 (+0.3%)           0.4194
          MAP       0.3733 (+4.3%)    0.3559 (-0.5%)   0.3676 (+2.7%) 0.3594 (+0.4%)        0.371 (+3.7%)                                 0.3578
  Finnish P@5       0.4149 (+8.6%)    0.385 (+0.7%)    0.388 (+1.6%)    0.388 (+1.6%)       0.3911 (+2.4%)                -               0.3821
          P@10      0.3567 (+14.9%)   0.31 (-0.2%)     0.3253 (+4.8%) 0.32 (+3.1%)          0.3239 (+4.3%)                                0.3105

Table 7: Results showing the performance of MultiPRF without using automatic query translation i.e. by using corresponding
original queries in assisting collection. The results show the potential of MultiPRF by establishing a performance upper bound.

guage which shows good performance across both                             Source       Assisting Language Pairs with
                                                                           Language     Improvement >3%
families.                                                                  English      FR-DE (4.5%), FR-ES (4.8%), DE-NL (+3.1%)
                                                                           French       EN-DE (4.1%), DE-ES (3.4%), NL-FI (4.8%)
                                                                           German       None
6.4   Multiple Assisting Languages                                         Spanish      None
                                                                                        EN-DE (3.9%), DE-FR (4.1%), FR-ES (3.8%), DE-ES
So far, we have only considered a single assist-                           Dutch        (3.9%)
                                                                                        EN-ES (3.2%), FR-DE (4.6%), FR-ES (6.4%),
ing language. However, a natural extension to                              Finnish      DE-ES (11.2%), DE-NL (4.4%), ES-NL (5.9%)
the method which comes to mind, is using mul-                                           EN – 3 Pairs; FR – 6 Pairs; DE – 10 Pairs;
                                                                           Total - 16   ES - 8 Pairs; NL – 4 Pairs; FI – 1 Pair
tiple assisting languages. In other words, com-
bining the evidence from all the feedback mod-                     Table 9: Summary of MultiPRF Results with Two Assisting
                                                                   Languages. The improvements described above are with re-
els of more than one assisting language, to get a                  spect to maximum MultiPRF MAP obtained using either L1
feedback model which is better than that obtained                  or L2 alone as assisting language.
using a single assisting language. To check how                    lead to improvements. A more detailed study of
this simple extension works, we performed exper-                   this observation needs to be done to explain this.
iments using a pair of assisting languages. In these
experiments for a given source language (from                      7     Conclusion and Future Work
amongst the 6 previously mentioned languages)                      We studied the effect of different source-assistant
we tried using all pairs of assisting languages (for               pairs and multiple assisting languages on the per-
each source language, we have 10 pairs possible).                  formance of MultiPRF. Experiments across a wide
To obtain the final model, we simply interpolate all               range of language pairs with varied degree of fa-
the feedback models with the initial query model,                  milial relationships show that MultiPRF improves
in a similar manner as done in MultiPRF. The re-                   performance in most cases with the performance
sults for these experiments are given in Table 9.                  improvement being more pronounced when the
As we see, out of the 60 possible combinations                     source and assisting languages are closely related.
of source language and assisting language pairs,                   We also notice that the results are mixed when two
we obtain improvements of greater than 3% in 16                    assisting languages are used simultaneously. As
cases. Here the improvements are with respect to                   part of future work, we plan to vary the model
the best model amongst the two MultiPRF mod-                       interpolation parameters dynamically to improve
els corresponding to each of the two assisting lan-                the performance in case of multiple assisting lan-
guages, with the same source language. Thus we                     guages.
observe that a simple linear interpolation of mod-
                                                                   Acknowledgements
els is not the best way of combining evidence from
multiple assisting languages. We also observe than                 The first author was supported by a fellowship
                                                                   award from Infosys Technologies Ltd., India. We
when German or Spanish are used as one of the                      would like to thank Mr. Vishal Vachhani for his
two assisting languages, they are most likely to                   help in running the experiments.


                                                              1354


References                                                     John Lafferty and Chengxiang Zhai. 2003. Probabilistic Rel-
                                                                  evance Models Based on Document and Query Genera-
Giambattista Amati, Claudio Carpineto, and Giovanni Ro-           tion. Language Modeling for Information Retrieval, pages
  mano. 2004. Query Difficulty, Robustness, and Selec-            1–10. Kluwer International Series on IR.
  tive Application of Query Expansion. In ECIR ’04, pages
  127–137.                                                     K. Sparck Jones, S. Walker, and S. E. Robertson. 2000. A
                                                                  Probabilistic Model of Information Retrieval: Develop-
Alexandra Birch, Miles Osborne and Philipp Koehn. 2008.           ment and Comparative Experiments. Inf. Process. Man-
   Predicting Success in Machine Translation. In EMNLP            age., 36(6):779–808.
   ’08, pages 745-754, ACL.
                                                               John Lafferty and Chengxiang Zhai. 2001. Document Lan-
Martin Braschler and Carol Peters. 2004. Cross-Language
                                                                  guage Models, Query Models, and Risk Minimization for
  Evaluation Forum: Objectives, Results, Achievements.
                                                                  Information Retrieval. In SIGIR ’01, pages 111–119.
  Inf. Retr., 7(1-2):7–31.
                                                                  ACM.
Martin Braschler and Peter Schäuble. 1998. Multilingual In-
                                                               Victor Lavrenko and W. Bruce Croft. 2001. Relevance Based
  formation Retrieval based on Document Alignment Tech-
                                                                  Language Models. In SIGIR ’01, pages 120–127. ACM.
  niques. In ECDL ’98, pages 183–197, Springer-Verlag.

Chris Buckley, Gerald Salton, James Allan, and Amit Sing-      Victor Lavrenko, Martin Choquette, and W. Bruce Croft.
  hal. 1994. Automatic Query Expansion using SMART :              2002. Cross-Lingual Relevance Models. In SIGIR ’02,
  TREC 3. In TREC-3, pages 69–80.                                 pages 175–182, ACM.

Guihong Cao, Jian-Yun Nie, Jianfeng Gao, and Stephen           Edgar Meij, Dolf Trieschnigg, Maarten Rijke de, and Wessel
  Robertson. 2008. Selecting Good Expansion Terms for            Kraaij. 2009. Conceptual Language Models for Domain-
  Pseudo-Relevance Feedback. In SIGIR ’08, pages 243–            specific Retrieval. Information Processing & Manage-
  250. ACM.                                                      ment, 2009.

Manoj K. Chinnakotla, Karthik Raman, and Pushpak Bhat-         Donald Metzler and W. Bruce Croft. 2007. Latent Concept
  tacharyya. 2010. Multilingual PRF: English Lends a             Expansion Using Markov Random Fields. In SIGIR ’07,
  Helping Hand. In SIGIR ’10, ACM.                               pages 311–318. ACM.

Kevyn Collins-Thompson and Jamie Callan. 2005. Query           Mandar Mitra, Amit Singhal, and Chris Buckley. 1998. Im-
  Expansion Using Random Walk Models. In CIKM ’05,               proving Automatic Query Expansion. In SIGIR ’98, pages
  pages 704–711. ACM.                                            206–214. ACM.

Steve Cronen-Townsend, Yun Zhou, and W. Bruce Croft.           Franz Josef Och and Hermann Ney. 2003. A System-
   2004. A Framework for Selective Query Expansion. In            atic Comparison of Various Statistical Alignment Models.
   CIKM ’04, pages 236–237. ACM.                                  Computational Linguistics, 29(1):19–51.

Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two Lan-       I. Ounis, G. Amati, Plachouras V., B. He, C. Macdonald, and
   guages Are More Informative Than One. In ACL ’91,               Johnson. 2005. Terrier Information Retrieval Platform.
   pages 130–137. ACL.                                             In ECIR ’05, volume 3408 of Lecture Notes in Computer
                                                                   Science, pages 517–519. Springer.
A. Dempster, N. Laird, and D. Rubin. 1977. Maximum Like-
   lihood from Incomplete Data via the EM Algorithm. Jour-     Koehn Philipp. 2005. Europarl: A Parallel Corpus for Statis-
   nal of the Royal Statistical Society, 39:1–38.                tical Machine Translation. In MT Summit ’05.

T. Susan Dumais, A. Todd Letsche, L. Michael Littman, and      Stephen Robertson. 2006. On GMAP: and Other Transfor-
   K. Thomas Landauer. 1997. Automatic Cross-Language             mations. In CIKM ’06, pages 78–83. ACM.
   Retrieval Using Latent Semantic Indexing. In AAAI ’97,
   pages 18–24.                                                Tetsuya Sakai, Toshihiko Manabe, and Makoto Koyama.
                                                                  2005. Flexible Pseudo-Relevance Feedback Via Selective
Wei Gao, John Blitzer, and Ming Zhou. 2008. Using English         Sampling. ACM TALIP, 4(2):111–135.
  Information in Non-English Web Search. In iNEWS ’08,
  pages 17–24. ACM.                                            Tao Tao and ChengXiang Zhai. 2006. Regularized Esti-
                                                                 mation of Mixture Models for Robust Pseudo-Relevance
David Hawking, Paul Thistlewaite, and Donna Harman.              Feedback. In SIGIR ’06, pages 162–169. ACM.
  1999. Scaling Up the TREC Collection. Inf. Retr., 1(1-
  2):115–137.                                                  Tuomas Talvensaari, Jorma Laurikkala, Kalervo Järvelin,
                                                                 Martti Juhola, and Heikki Keskustalo. 2007. Creating and
Hieu Hoang, Alexandra Birch, Chris Callison-burch, Richard       Exploiting a Comparable Corpus in Cross-language Infor-
  Zens, Rwth Aachen, Alexandra Constantin, Marcello Fed-         mation Retrieval. ACM Trans. Inf. Syst., 25(1):4, 2007.
  erico, Nicola Bertoldi, Chris Dyer, Brooke Cowan, Wade
  Shen, Christine Moran, and Ondej Bojar. 2007. Moses:         Jrg Tiedemann. 2001. The Use of Parallel Corpora in Mono-
  Open Source Toolkit for Statistical Machine Translation.        lingual Lexicography - How word alignment can identify
  In ACL ’07, pages 177–180.                                      morphological and semantic relations. In COMPLEX ’01,
                                                                  pages 143–151.
P. Jourlin, S. E. Johnson, K. Spärck Jones and P. C. Wood-
   land. 1999. Improving Retrieval on Imperfect Speech         Ellen M. Voorhees. 1994. Query Expansion Using Lexical-
   Transcriptions (Poster Abstract). In SIGIR ’99, pages          Semantic Relations. In SIGIR ’94, pages 61–69. Springer-
   283–284. ACM.                                                  Verlag.


                                                           1355


Ellen Voorhees. 2006. Overview of the TREC 2005 Robust
   Retrieval Track. In TREC 2005, Gaithersburg, MD. NIST.

Dan Wu, Daqing He, Heng Ji, and Ralph Grishman. 2008.
  A Study of Using an Out-of-Box Commercial MT System
  for Query Translation in CLIR. In iNEWS ’08, pages 71–
  76. ACM.

Jinxi Xu and W. Bruce Croft. 2000. Improving the Effective-
   ness of Information Retrieval with Local Context Analy-
   sis. ACM Trans. Inf. Syst., 18(1):79–112.

Jinxi Xu, Alexander Fraser, and Ralph Weischedel. 2002.
   Empirical Studies in Strategies for Arabic Retrieval. In
   SIGIR ’02, pages 269–274. ACM.

Yang Xu, Gareth J.F. Jones, and Bin Wang.      2009.
  Query Dependent Pseudo-Relevance Feedback Based on
  Wikipedia. In SIGIR ’09, pages 59–66. ACM.

Chengxiang Zhai and John Lafferty. 2001. Model-based
  Feedback in the Language Modeling approach to Infor-
  mation Retrieval. In CIKM ’01, pages 403–410. ACM.

Chengxiang Zhai and John Lafferty. 2004. A Study of
  Smoothing Methods for Language Models applied to In-
  formation Retrieval. ACM Transactions on Information
  Systems, 22(2):179–214.




                                                          1356

       A Unified Graph Model for Sentence-based Opinion Retrieval



                     Binyang Li, Lanjun Zhou, Shi Feng, Kam-Fai Wong
                 Department of Systems Engineering and Engineering Management
                              The Chinese University of Hong Kong
                 {byli, ljzhou, sfeng, kfwong}@se.cuhk.edu.hk



                                                              tion, opinion extraction, opinion question ans-
                      Abstract                                wering, and opinion summarization, etc. are re-
                                                              ceiving growing attention (Wilson, et al., 2005;
    There is a growing research interest in opinion           Liu et al., 2005; Oard et al., 2006). However,
    retrieval as on-line users’ opinions are becom-           most existing works concentrate on analyzing
    ing more and more popular in business, social             opinions expressed in the documents, and none
    networks, etc. Practically speaking, the goal of          on how to represent the information needs re-
    opinion retrieval is to retrieve documents,
                                                              quired to retrieve opinionated documents. In this
    which entail opinions or comments, relevant to
    a target subject specified by the user’s query. A         paper, we focus on opinion retrieval, whose goal
    fundamental challenge in opinion retrieval is             is to find a set of documents containing not only
    information representation. Existing research             the query keyword(s) but also the relevant opi-
    focuses on document-based approaches and                  nions. This requirement brings about the chal-
    documents are represented by bag-of-word.                 lenge on how to represent information needs for
    However, due to loss of contextual information,           effective opinion retrieval.
    this representation fails to capture the associa-            In order to solve the above problem, previous
    tive information between an opinion and its               work adopts a 2-stage approach. In the first stage,
    corresponding target. It cannot distinguish dif-          relevant documents are determined and ranked
    ferent degrees of a sentiment word when asso-
                                                              by a score, i.e. tf-idf value. In the second stage,
    ciated with different targets. This in turn se-
    riously affects opinion retrieval performance.            an opinion score is generated for each relevant
    In this paper, we propose a sentence-based ap-            document (Macdonald and Ounis, 2007; Oard et
    proach based on a new information representa-             al., 2006). The opinion score can be acquired by
    tion, namely topic-sentiment word pair, to cap-           either machine learning-based sentiment classifi-
    ture intra-sentence contextual information be-            ers, such as SVM (Zhang and Yu, 2007), or a
    tween an opinion and its target. Additionally,            sentiment lexicons with weighted scores from
    we consider inter-sentence information to cap-            training documents (Amati et al., 2007; Hannah
    ture the relationships among the opinions on              et al., 2007; Na et al., 2009). Finally, an overall
    the same topic. Finally, the two types of infor-          score combining the two is computed by using a
    mation are combined in a unified graph-based
                                                              score function, e.g. linear combination, to re-rank
    model, which can effectively rank the docu-
    ments. Compared with existing approaches,                 the retrieved documents.
    experimental results on the COAE08 dataset                   Retrieval in the 2-stage approach is based on
    showed that our graph-based model achieved                document and document is represented by
    significant improvement.                                  bag-of-word. This representation, however, can
                                                              only ensure that there is at least one opinion in
1    Introduction                                             each relevant document, but it cannot determine
                                                              the relevance pairing of individual opinion to its
In recent years, there is a growing interest in               target. In general, by simply representing a
sharing personal opinions on the Web, such as                 document in bag-of-word, contextual informa-
product reviews, economic analysis, political                 tion i.e. the corresponding target of an opinion, is
polls, etc. These opinions cannot only help inde-             neglected. This may result in possible mismatch
pendent users make decisions, but also obtain                 between an opinion and a target and in turn af-
valuable feedbacks (Pang et al., 2008). Opinion               fects opinion retrieval performance. By the same
oriented research, including sentiment classifica-            token, the effect to documents consisting of mul-

                                                         1367
        Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1367–1375,
                  Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


tiple topics, which is common in blogs and               election). The topic of the document is not re-
on-line reviews, is also significant. In this setting,   quired to be the same as the target, but an opi-
even if a document is regarded opinionated, it           nion about the target has to be presented in the
cannot ensure that all opinions in the document          document or one of the comments to the docu-
are indeed relevant to the target concerned.             ment (Macdonald and Ounis, 2006). Therefore,
Therefore, we argue that existing information            in this paper we regard the information needs for
representation i.e. bag-of-word, cannot satisfy          opinion retrieval as relevant opinion.
the information needs for opinion retrieval.
   In this paper, we propose to handle opinion re-       2.2   Motivation of Our Approach
trieval in the granularity of sentence. It is ob-        In traditional information retrieval (IR)
served that a complete opinion is always ex-             bag-of-word representation is the most common
pressed in one sentence, and the relevant target         way to express information needs. However, in
of the opinion is mostly the one found in it.            opinion retrieval, information need target at re-
Therefore, it is crucial to maintain the associative     levant opinion, and this renders bag-of-word re-
information between an opinion and its target            presentation ineffective.
within a sentence. We define the notion of a top-           Consider the example in Figure 1. There are
ic-sentiment word pair, which is composed of a           three sentences A, B, and C in a document di.
topic term (i.e. the target) and a sentiment word        Now given an opinion-oriented query Q related
(i.e. opinion) of a sentence. Word pairs can             to ‘Avatar’. According to the conventional
maintain intra-sentence contextual information to        2-stage opinion retrieval approach, di is
express the potential relevant opinions. In addi-        represented by a bag-of-word. Among the words,
tion, inter-sentence contextual information is also      there is a topic term Avatar (t1) occurring twice,
captured by word pairs to represent the relation-        i.e. Avatar in A and Avatar in C, and two senti-
ship among opinions on the same topic. In prac-          ment words comfortable (o1) and favorite (o2)
tice, the inter-sentence information reflects the        (refer to Figure 2 (a)). In order to rank this doc-
degree of a word pair. Finally, we combine both          ument, an overall score of the document di is
intra-sentence and inter-sentence contextual in-         computed by a simple combination of the rele-
formation to construct a unified undirected graph        vant score (            ) and the opinion score
to achieve effective opinion retrieval.                  (        ), e.g. equal weighted linear combination,
   The rest of the paper is organized as follows.        as follows.
In Section 2, we describe the motivation of our
approach. Section 3 presents a novel unified             For simplicity, we let               , and
graph-based model for opinion retrieval. We                      be computed by using lexicon-based
evaluated our model and the results are presented        method:               ℎ           ℎ      .
in Section 4. We review related works on opi-
nion retrieval in Section 5. Finally, in Section 6,         A. 阿凡达明日将在中国上映。
the paper is concluded and future work is sug-              Tomorrow, Avatar will be shown in China.
gested.                                                     B. 我预订到了 IMAX 影院中最舒服的位子。
                                                            I’ve reserved a comfortable seat in IMAX.
2     Motivation                                            C. 阿凡达是我最喜欢的一部 3D 电影。
                                                            Avatar is my favorite 3D movie.
In this section, we start from briefly describing
the objective of opinion retrieval. We then illu-        Figure 1: A retrieved document di on the target
strate the limitations of current opinion retrieval      ‘Avatar’.
approaches, and analyze the motivation of our               Although bag-of-word representation achieves
method.                                                  good performance in retrieving relevant docu-
                                                         ments, our study shows that it cannot satisfy the
2.1    Formal Description of Problem                     information needs for retrieval of relevant opi-
Opinion retrieval was first presented in the             nion. It suffers from the following limitations:
TREC 2006 Blog track, and the objective is to               (1) It cannot maintain contextual information;
retrieve documents that express an opinion about         thus, an opinion may not be related to the target
a given target. The opinion target can be a “tradi-      of the retrieved document is neglected. In this
tional” named entity (e.g. a name of person, lo-         example, only the opinion favorite (o2) on Avatar
cation, or organization, etc.), a concept (e.g. a        in C is the relevant opinion. But due to loss of
type of technology), or an event (e.g. presidential      contextual information between the opinion and
                                                         its corresponding target, Avatar in A and com-

                                                     1368


fortable (o1) are also regarded as relevant opi-     Further, since the lexical scope of an opinion
nion mistakenly, creating a false positive. In re-   does not usually go beyond a sentence, we pro-
ality comfortable (o1) describes “the seats in       pose to handle opinion retrieval in the granularity
IMAX”, which is an irrelevant opinion, and sen-      of sentence.
tence A is a factual statement rather than an opi-       Without loss of generality, we assume that
nion statement.                                      there is a document set             , , , ,    , and
                                                     a specific query               , , , ,      , where
                                                        , , , ,      are query keywords. Opinion re-
                                                     trieval aims at retrieving documents from
                                                     with relevant opinion about the query . In ad-
                                                     dition, we construct a sentiment word lexicon
                                                     and a topic term lexicon         (see Section 4). To
              (a)                  (b)               maintain the associative information between the
Figure 2: Two kinds of information representa-       target and the opinion, we consider the document
tion of opinion retrieval. (t1=‘Avatar’ o1= ‘com-    set as a bag of sentences, and define a sentence
fortable’, o2=‘favorite’)                            set as         , , , ,      . For each sentence, we
   (1) Current approaches cannot capture the re-     capture the intra-sentence information through
lationship among opinions about the same topic.      the topic-sentiment word pair.
Suppose there is another document including          Definition 1. topic-sentiment word pair         con-
sentence C which expresses the same opinion on       sists of two elements, one is from , and the
Avatar. Existing information representation          other one is from .
simply does not cater for the two identical opi-                         ,     |       ,       .
nions from different documents. In addition, if          The topic term from        determines relevance
many documents contain opinions on Avatar, the       by the query term matching, and the sentiment
relationship among them is not clearly               word from       is used to express an opinion. We
represented by existing approaches.                  use the word pair to maintain the associative in-
   In this paper, we process opinion retrieval in    formation between the topic term and the opinion
the granularity of sentence as we observe that a     word (also referred to as sentiment word). The
complete opinion always exists within a sentence     word pair is used to identify a relevant opinion in
(refer to Figure 2 (b)). To represent a relevant     a sentence. In Figure 2 (b), t1, i.e. Avatar in C, is
opinion, we define the notion of topic-sentiment     a topic term relevant to the query, and o2 (‘favo-
word pair, which consists of a topic term and a      rite’) is supposed to be an opinion; and the word
sentiment word. A word pair maintains the asso-      pair < t1, o2> indicates sentence C contains a re-
ciative information between the two words, and       levant opinion. Similarly, we map each sentence
enables systems to draw up the relationship          in word pairs by the following rule, and express
among all the sentences with the same opinion        the intra-sentence information using word pairs.
on an identical target. This relationship informa-       For each sentiment word of a sentence, we
tion can identify all documents with sentences       choose the topic term with minimum distance as
including the sentiment words and to determine       the other element of the word pair:
the contributions of such words to the target                     ,    |    min        ,   for each
(topic term). Furthermore, based on word pairs,         According to the mapping rule, although a
we designed a unified graph-based method for         sentence may give rise to a number of word pairs,
opinion retrieval (see later in Section 3).          only the pair with the minimum word distance is
                                                     selected. We do not take into consideration of the
3     Graph-based model                              other words in a sentence as relevant opinions
3.1    Basic Idea                                    are generally formed in close proximity. A sen-
                                                     tence is regarded non-opinionated unless it con-
Different from existing approaches which simply      tains at least one word pair.
make use of document relevance to reflect the           In practice, not all word pairs carry equal
relevance of opinions embedded in them, our          weights to express a relevant opinion as the con-
approach concerns more on identifying the re-        tribution of an opinion word differs from differ-
levance of individual opinions. Intuitively, we      ent target topics, and vice versa. For example,
believed that the more relevant opinions appear      the word pair < t1, o2> should be more probable
in a document, the more relevant is that docu-       as a relevant opinion than < t1, o1>. To consider
ment for subsequent opinion analysis operations.

                                                 1369


that, inter-sentence contextual information is ex-    and sentiment words, which appear in one sen-
plored. This is achieved by assigning a weight to     tence.              is the set of documents.
each word pair to measure their associative de-                |       ,           corresponds to the
grees to different queries. We believe that the       connection between documents and top-
more a word pair appears the higher should be         ic-sentiment word pairs. Each edge         is asso-
the weight between the opinion and the target in      ciated with a weight            0,1 denoting the
the context.                                          contribution of        to the document       . The
  We will describe how to utilize intra-sentence      weight      is computed by the contribution of
contextual information to express relevant opi-       word pair      in all sentences of    as follows:
nion, and inter-sentence information to measure
the degree of each word pair through a                             |   |
                                                                           ∑           ·             ,          1     ,    1
graph-based model in the following section.               |   is the number of sentences in ;
                                                               |
3.2   HITS Model                                           is introduced as the trade-off parameter to
                                                          balance the         ,   and      , ;
We propose an opinion retrieval model based on                 ,    is computed to judge the relevance
HITS, a popular graph ranking algorithm                   of      in     which belongs to ;
(Kleinberg, 1999). By considering both in-                             ,        ,                   (2)
tra-sentence information and inter-sentence in-       where     ,   is the number of     appears in ,
formation, we can determine the weight of a           and
word pair and rank the documents.                                              log
   HITS algorithm distinguishes hubs and au-                                               .      (3)
thorities in objects. A hub object has links to       where      is the number of sentences that the
many authorities. An authority object, which has      word   appears in.
high-quality content, would have many hubs                    ,     is the contribution of    in
linking to it. The hub scores and authority scores        which belongs to .
are computed in an iterative way. Our proposed                                 ,
                                                                                                                ,

opinion retrieval model contains two layers. The                                                 ,        0.5   1.5       (4)
upper level contains all the topic-sentiment word     where          is the average number of sentences in
pairs            ,    |     ,        . The lower         ;     ,    is the number of       appears in (Al-
level contains all the documents to be retrieved.     lan et al., 2003; Otterbacher et al., 2005).
Figure 3 gives the bipartite graph representation        It is found that the contribution of a sentiment
of the HITS model.                                    word         will not decrease even if it appears in
                                                      all the sentences. Therefore in Equation 4, we
                                                      just use the length of a sentence instead of
                                                      to normalize long sentences which would likely
                                                      contain more sentiment words.
                                                         The authority score                            of
                                                      document           and a hub score
                                                      of         at the        1    iteration are computed
            Figure 3: Bipartite link graph.
                                                      based on the hub scores and authority scores in
   For our purpose, the word pairs layer is consi-
                                                      the        iteration as follows.
dered as hubs and the documents layer authori-
                                                                               ∑                        (5)
ties. If a word pair occurs in one sentence of a
                                                                                       ∑                                   (6)
document, there will be an edge between them.
In Figure 3, we can see that the word pair that        We let                  ,   |       | |   |       denote the adjacency
has links to many documents can be assigned a         matrix.
high weight to denote a strong associative degree                                                   (7)
between the topic term and a sentiment word,                                                        (8)
and it likely expresses a relevant opinion. On the    where                         | |  is the vector
other hand, if a document has links to many word      of authority scores for documents at the     ite-
pairs, the document is with many relevant opi-        ration and                         | |   is  the
nions, and it will result in high ranking.            vector of hub scores for the word pairs at
   Formally, the representation for the bipartite     iteration. In order to ensure convergence of the
graph is denoted as                , ,      , where   iterative form, and are normalized in each
           is the set of all pairs of topic words     iteration cycle.

                                                  1370


   For computation of the final scores, the initial   (2) The opinion word lexicon provided by Na-
scores of all documents are set to √ , and top-           tional Taiwan University which consists of
                                                          2,812 positive words and 8,276 negative
ic-sentiment word pairs are set to √        . The
                                                          words;
above iterative steps are then used to compute
                                                      (3) Sentiment word lexicon and comment word
the new scores until convergence. Usually the
                                                          lexicon from Hownet. It contains 1836 posi-
convergence of the iteration algorithm is
                                                          tive sentiment words, 3,730 positive com-
achieved when the difference between the scores
                                                          ments, 1,254 negative sentiment words and
computed at two successive iterations for any
                                                          3,116 negative comment words.
nodes falls below a given threshold (Wan et al.,
                                                         The different graphemes corresponding to
2008; Li et al., 2009; Erkan and Radev, 2004). In
                                                      Traditional Chinese and Simplified Chinese are
our model, we use the hub scores to denote the
                                                      both considered so that the sentiment lexicons
associative degree of each word pair and the au-
                                                      from different sources are applicable to process
thority scores as the total scores. The documents
                                                      Simplified Chinese text. The lexicon was ma-
are then ranked based on the total scores.
                                                      nually verified.
4     Experiment                                      4.1.3    Topic Term Collection
We performed the experiments on the Chinese           In order to acquire the collection of topic terms,
benchmark dataset to verify our proposed ap-          we adopt two expansion methods, dictio-
proach for opinion retrieval. We first tested the     nary-based method and pseudo relevance feed-
effect of the parameter       of our model. To        back method.
demonstrate the effectiveness of our opinion re-         The dictionary-based method utilizes Wikipe-
trieval model, we compared its performance with       dia (Popescu and Etzioni, 2005) to find an entry
the same of other approaches. In addition, we         page for a phrase or a single term in a query. If
studied each individual query to investigate the      such an entry exists, all titles of the entry page
influence of query to our model. Furthermore,         are extracted as synonyms of the query concept.
we showed the top-5 highest weight word pairs         For example, if we search “绿坝” (Green Tsu-
of 5 queries to further demonstrate the effect of     nami, a firewall) in Wikipedia, it is re-directed to
word pair.                                            an entry page titled “花季护航” (Youth Escort).
4.1     Experiment Setup                              This term is then added as a synonym of “绿坝”
                                                      (Green Tsunami) in the query. Synonyms are
4.1.1    Benchmark Datasets                           treated the same as the original query terms in a
Our experiments are based on the Chinese              retrieval process. The content words in the entry
benchmark dataset, COAE08 (Zhao et al., 2008).        page are ranked by their frequencies in the page.
COAE dataset is the benchmark data set for the        The top-k terms are returned as potential ex-
opinion retrieval track in the Chinese Opinion        panded topic terms.
Analysis Evaluation (COAE) workshop, consist-            The second query expansion method is a
ing of blogs and reviews. 20 queries are provided     web-based method. It is similar to the pseudo
in COAE08. In our experiment, we created re-          relevance feedback expansion but using web
levance judgments through pooling method,             documents as the document collection. The
where documents are ranked at different levels:       query is submitted to a web search engine, such
irrelevant, relevant but without opinion, and re-     as Google, which returns a ranked list of docu-
levant with opinion. Since polarity is not consi-     ments. In the top-n documents, the top-m topic
dered, all relevant documents with opinion are        terms which are highly correlated to the query
classified into the same level.                       terms are returned.

4.1.2    Sentiment Lexicon                            4.2     Performance Evaluation

In our experiment, the sentiment lexicon is           4.2.1    Parameter Tuning
composed by the following resources (Xu et al.,       We first studied how the parameter (see Equ-
2007):                                                ation 1) influenced the mean average precision
(1) The Lexicon of Chinese Positive Words,            (MAP) in our model. The result is given in Fig-
    which consists of 5,054 positive words and        ure 4.
    the Lexicon of Chinese Negative Words,
    which consists of 3,493 negative words;


                                                  1371


            0.4                                       COAE08            and Precision at 10 documents (P@10) were also
           0.35                                                         used. The evaluation results based on these me-
     MAP
            0.3                                                         trics are shown in Table 1.
           0.25                                                            Table 1 summarized the results obtained. We
            0.2                                                         found that GORM achieved the best performance
                  0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
                                                                        in all the evaluation metrics. Our baseline, ROSC
                                     λ                                  and GORM which were sentence-based ap-
 Figure 4: Performance of MAP with varying .                            proaches achieved better performance than the
  Best MAP performance was achieved in                                  document-based approaches by 20% in average.
COAE08 evaluation, when        was set between                          Moreover, our GORM approach did not use ma-
0.4 and 0.6. Therefore, in the following experi-                        chine learning techniques, but it could still
ments, we set     0.4.                                                  achieve outstanding performance.
                                                                           To study GORM influenced by different que-
4.2.2       Opinion Retrieval Model Comparison                          ries, the MAP from median average precision on
To demonstrate the effectiveness of our proposed                        individual topic was shown in Figure 5.
model, we compared it with the following mod-                                               Difference from Median Average Precision per
els using different evaluation metrics:                                                                       Topic
                                                                                      0.6
(1) IR: We adopted a classical information re-                                        0.5
trieval model, and further assumed that all re-                                       0.4
trieved documents contained relevant opinions.                                        0.3
                                                                        Difference

(2) Doc: The 2-stage document-based opinion                                           0.2
                                                                                      0.1
retrieval model was adopted. The model used                                             0
sentiment lexicon-based method for opinion                                           ‐0.1
identification and a conventional information                                        ‐0.2
                                                                                     ‐0.3
retrieval method for relevance detection.                                            ‐0.4   1 2 3 4 5 6 7 8 9 1011121314151617181920
(3) ROSC: This was the model which achieved
                                                                                                             Topic
the best run in TREC Blog 07. It employed ma-
chine learning method to identify opinions for                          Figure 5: Difference of MAP from Median on
each sentence, and to determine the target topic                        COAE08 dataset. (MAP of Median is 0.3724)
by a NEAR operator.                                                        As shown in Figure 5, the MAP performance
(4) ROCC: This model was similar to ROSC,                               was very low on topic 8 and topic 11. Topic 8, i.e.
but it considered the factor of sentence and re-                        ‘成龙’ (Jackie Chan), it was influenced by topic
garded the count of relevant opinionated sen-                           7, i.e. ‘李连杰’ (Jet Lee) as there were a number
tence to be the opinion score (Zhang and Yu,                            of similar relevant targets for the two topics, and
2007). In our experiment, we treated this model                         therefore many word pairs ended up the same.
as the evaluation baseline.                                             As a result, documents belonging to topic 7 and
(5) GORM: our proposed graph-based opinion                              topic 8 could not be differentiated, and they both
retrieval model.                                                        performed badly. In order to solve this problem,
                                   COAE08                               we extracted the topic term with highest relevant
 Approach
                               Evaluation metrics                       weight in the sentence to form word pairs so that
 Run id            MAP          R-pre     bPref             P@10        it reduce the impact on the topic terms in com-
 IR                0.2797       0.3545       0.2474         0.4868
                                                                        mon. 24% and 30% improvement were achieved,
 Doc               0.3316       0.3690       0.3030         0.6696
 ROSC              0.3762       0.4321       0.4162         0.7089      respectively.
 Baseline          0.3774       0.4411       0.4198         0.6931         As to topic 11, i.e. ‘指环王’ (Lord of King),
 GORM              0.3978       0.4835       0.4265         0.7309      there were only 8 relevant documents without
Table 1: Comparison of different approaches on                          any opinion and 14 documents with relevant
COAE08 dataset, and the best is highlighted.                            opinions. As a result, the graph constructed by
   Most of the above models were originally de-                         insufficient documents worked ineffectively.
signed for opinion retrieval in English, and                               Except for the above queries, GORM per-
re-designed them to handle Chinese opinionated                          formed well in most of the others. To further in-
documents. We incorporated our own Chinese                              vestigate the effect of word pair, we summarized
sentiment lexicon for this purpose. In our expe-                        the top-5 word pairs with highest weight of 5
riments, in addition to MAP, other metrics such                         queries in Table 2.
as R-precision (R-prec), binary Preference (bPref)


                                                                     1372


                                                   Top-5 MAP
           陈凯歌                  国六条                  宏观调控                  周星驰                  Vista
         Chen Kaige            Six States         Macro-regulation      Stephen Chow            Vista
       <陈凯歌 支持>               <房价 上涨>               <经济 平稳>              <电影 喜欢>              <价格 贵>
      Chen Kaige Support     Room rate Rise       Economics Steady        Movie Like       Price Expensive
       <陈凯歌 最佳>               <调控 加强>               <价格 上涨>            <周星驰 喜欢>             <微软 喜欢>
       Chen Kaige Best     Regulate Strengthen       Price Rise       Stephen Chow Like     Microsoft Like
       <《无极》 骂>               <中央 加强>               <发展 平稳>              <主角 最佳>             <Vista 推荐>
       Limitless Revile      CCP Strengthen      Development Steady    Protagonist Best   Vista Recommend
        <影片 优秀>               <房价 平稳>               <消费 上涨>               <喜剧 好>            <问题 重要>
       Movie Excellent      Room rate Steady       Consume Rise         Comedy Good         Problem Vital
       <阵容 强大的>               <住房 保障>               <社会 保障>              <作品 精彩>              <性能 不>
         Cast Strong        Housing Security       Social Security      Works Splendid     Performance No
               Table 2: Top-5 highest weight word pairs for 5 queries in COAE08 dataset.
   Table 2 showed that most word pairs could               documents. Similarly, a pseudo opinionated
represent the relevant opinions about the corres-          word composed of all opinion words was first
ponding queries. This showed that inter-sentence           created, and then used to estimate the opinion
information was very helpful to identify the as-           score of a document (Na et al., 2009). This me-
sociative degree of a word pair. Furthermore,              thod was shown to be very effective in TREC
since word pairs can indicate relevant opinions            evaluations (Lee et al., 2008). More recently,
effectively, it is worth further study on how they         Huang and Croft (2009) proposed an effective
could be applied to other opinion oriented appli-          relevance model, which integrated both
cations, e.g. opinion summarization, opinion               query-independent and query-dependent senti-
prediction, etc.                                           ment words into a mixture model.
                                                              In our approach, we also adopt sentiment lex-
5     Related Work                                         icon-based method for opinion identification.
                                                           Unlike the above methods, we generate a weight
Our research focuses on relevant opinion rather
                                                           to a sentiment word for each target (associated
than on relevant document retrieval. We, there-
                                                           topic term) rather than assign a unified weight or
fore, review related works in opinion identifica-
                                                           an equal weight to the sentiment word for the
tion research. Furthermore, we do not support the
                                                           whole topics. Besides, in our model no training
conventional 2-stage opinion retrieval approach.
                                                           data is required. We just utilize the structure of
We conducted literature review on unified opi-
                                                           our graph to generate a weight to reflect the as-
nion retrieval models and related work in this
                                                           sociative degree between the two elements of a
area is presented in the section.
                                                           word pair in different context.
5.1    Lexicon-based Opinion Identification
                                                           5.2    Unified Opinion Retrieval Model
Different from traditional IR, opinion retrieval
                                                           In addition to conventional 2-stage approach,
focuses on the opinion nature of documents.
                                                           there has been some research on unified opinion
During the last three years, NTICR and TREC
                                                           retrieval models.
evaluations have shown that sentiment lex-
                                                              Eguchi and Lavrenko proposed an opinion re-
icon-based methods led to good performance in
                                                           trieval model in the framework of generative
opinion identification.
                                                           language modeling (Eguchi and Lavrenko, 2006).
   A lightweight lexicon-based statistical ap-
                                                           They modeled a collection of natural language
proach was proposed by Hannah et al. (2007). In
                                                           documents or statements, each of which con-
this method, the distribution of terms in relevant
                                                           sisted of some topic-bearing and some senti-
opinionated documents was compared to their
                                                           ment-bearing words. The sentiment was either
distribution in relevant fact-based documents to
                                                           represented by a group of predefined seed words,
calculate an opinion weight. These weights were
                                                           or extracted from a training sentiment corpus.
used to compute opinion scores for each re-
                                                           This model was shown to be effective on the
trieved document. A weighted dictionary was
                                                           MPQA corpus.
generated from previous TREC relevance data
                                                              Mei et al. tried to build a fine-grained opinion
(Amati et al., 2007). This dictionary was submit-
                                                           retrieval system for consumer products (Mei et
ted as a query to a search engine to get an initial
                                                           al., 2007). The opinion score for a product was a
query-independent opinion score of all retrieved
                                                           mixture of several facets. Due to the difficulty in

                                                       1373


associating sentiment with products and facets,       Experimental results show that our proposed
the system was only tested using small scale text     model performs well on COAE08 dataset.
collections.                                             The novelty of our work lies in using word
   Zhang and Ye proposed a generative model to        pairs to represent the information needs for opi-
unify topic relevance and opinion generation          nion retrieval. On the one hand, word pairs can
(Zhang and Ye, 2008). This model led to satis-        identify the relevant opinion according to in-
factory performance, but an intensive computa-        tra-sentence contextual information. On the other
tion load was inevitable during retrieval, since      hand, word pairs can measure the degree of a
for each possible candidate document, an opinion      relevant opinion by taking inter-sentence con-
score was summed up from the generative prob-         textual information into consideration. With the
ability of thousands of sentiment words.              help of word pairs, the information needs for
   Huang and Croft proposed a unified opinion         opinion retrieval can be represented appropriate-
retrieval model according to the Kullback-Leib-       ly.
ler divergence between the two probability dis-          In the future, more research is required in the
tributions of opinion relevance model and docu-       following directions:
ment model (Huang and Croft, 2009). They di-          (1) Since word pairs can indicate relevant opi-
vided the sentiment words into query-dependent             nions effectively, it is worth further study on
and query-independent by utilizing several sen-            how they could be applied to other opinion
timent expansion techniques, and integrated them           oriented applications, e.g. opinion summa-
into a mixed model. However, in this model, the            rization, opinion prediction, etc.
contribution of a sentiment word was its corres-      (2) The characteristics of blogs will be taken
ponding incremental mean average precision                 into consideration, i.e., the post time, which
value. This method required that large amount of           could be helpful to create a more time sensi-
training data and manual labeling.                         tivity graph to filter out fake opinions.
   Different from the above opinion retrieval ap-     (3) Opinion holder is another important role of
proaches, our proposed graph-based model                   an opinion, and the identification of opinion
processes opinion retrieval in the granularity of          holder is a main task in NTCIR. It would be
sentence. Instead of bag-of-word, the sentence is          interesting to study opinion holders, e.g. its
split into word pairs which can maintain the               seniority, for opinion retrieval.
contextual information. On the one hand, word
pair can identify the relevant opinion according         Acknowledgements: This work is partially
to intra-sentence contextual information. On the      supported by the Innovation and Technology
other hand, it can measure the degree of a rele-      Fund of Hong Kong SAR (No. ITS/182/08) and
vant opinion by considering the inter-sentence        National 863 program (No. 2009AA01Z150).
contextual information.                               Special thanks to Xu Hongbo for providing the
                                                      Chinese sentiment resources. We also thank Bo
6    Conclusion and Future Work                       Chen, Wei Gao, Xu Han and anonymous re-
                                                      viewers for their helpful comments.
In this work we focus on the problem of opinion
retrieval. Different from existing approaches,
                                                      References
which regard document relevance as the key in-
dicator of opinion relevance, we propose to ex-       James Allan, Courtney Wade, and Alvaro Bolivar.
plore the relevance of individual opinion. To do        2003. Retrieval and novelty detection at the sen-
that, opinion retrieval is performed in the granu-      tence level. In SIGIR ’03: Proceedings of the 26th
larity of sentence. We define the notion of word        annual international ACM SIGIR conference on
                                                        Research and development in information retrieval,
pair, which can not only maintain the association
                                                        pages 314-321. ACM.
between the opinion and the corresponding target      Giambattista Amati, Edgardo Ambrosi, Marco Bianc-
in the sentence, but it can also build up the rela-     hi, Carlo Gaibisso, and Giorgio Gambosi. 2007.
tionship among sentences through the same word          FUB, IASI-CNR and University of Tor Vergata at
pair. Furthermore, we convert the relationships         TREC 2007 Blog Track. In Proceedings of the 15th
between word pairs and sentences into a unified         Text Retrieval Conference.
graph, and use the HITS algorithm to achieve          Koji Eguchi and Victor Lavrenko. Sentiment retrieval
document ranking for opinion retrieval. Finally,        using generative models. 2006. In EMNLP ’06,
we compare our approach with existing methods.          Proceedings of 2006 Conference on Empirical Me-
                                                        thods in Natural Language Processing, page
                                                        345-354.


                                                  1374


Gunes Erkan and Dragomir R. Radev. 2004. Lexpa-            and Dagbert Soergel. 2006. TREC-2006 at Mary-
  gerank: Prestige in multi-document text summariza-       land: Blog, Enterprise, Legal and QA Tracks. In
  tion. In EMNLP ’04, Proceedings of 2004 Confe-           Proceedings of the 15th Text Retrieval Conference.
  rence on Empirical Methods in Natural Language         Jahna Otterbacher, Gunes Erkan, and Dragomir R.
  Processing.                                              Radev. 2005. Using random walks for ques-
David Hannah, Craig Macdonald, Jie Peng, Ben He,           tion-focused sentence retrieval. In EMNLP ’05,
  and Iadh Ounis. 2007. University of Glasgow at           Proceedings of 2005 Conference on Empirical Me-
  TREC 2007: Experiments in Blog and Enterprise            thods in Natural Language Processing.
  Tracks with Terrier. In Proceedings of the 15th Text   Larry Page, Sergey Brin, Rajeev Motwani, and Terry
  Retrieval Conference.                                    Winograd. 1998. The pagerank citation ranking:
Xuanjing Huang, William Bruce Croft. 2009. A Uni-          Bringing order to the web. Technical report, Stan-
  fied Relevance Model for Opinion Retrieval. In           ford University.
  Proceedings of CIKM.                                   Bo Pang and Lillian Lee. 2008. Opinion mining and
Jon M. Kleinberg. 1999. Authoritative sources in a         sentiment analysis. Foundations and Trends in In-
  hyperlinked environment. J. ACM, 46(5): 604-632.         formation Retrieval, 2(1-2): 1-135.
Yeha Lee, Seung-Hoon Na, Jungi Kim, Sang-Hyob            Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
  Nam, Hun-young Jung, Jong-Hyeok Lee. 2008.               ing product features and opinion s from reviews. In
  KLE at TREC 2008 Blog Track: Blog Post and Feed          EMNLP ’05, Proceedings of 2005 Conference on
  Retrieval. In Proceedings of the 15th Text Retrieval     Empirical Methods in Natural Language
  Conference.                                              Processing.
Fangtao Li, Yang Tang, Minlie Huang, and Xiaoyan         Xiaojun Wan and Jianwu Yang. 2008. Mul-
  Zhu. 2009. Answering Opinion Questions with              ti-document summarization using cluster-based link
  Random Walks on Graphs. In ACL ’09, Proceedings          analysis. In SIGIR ’08: Proceedings of the 31th an-
  of the 48th Annual Meeting of the Association for        nual international ACM SIGIR conference on Re-
  Computational Linguistics.                               search and development in information retrieval,
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.            pages 299-306. ACM.
  Opinion observer: Analyzing and comparing opi-         Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
  nion s on the web. In WWW ’05: Proceedings of the        2005. Recognizing contextual polarity in
  14th International Conference on World Wide Web.         phrase-level sentiment analysis. In EMNLP ’05,
Craig Macdonald and Iadh Ounis. 2007. Overview of          Proceedings of 2005 Conference on Empirical Me-
  the TREC-2007 Blog Track. In Proceedings of the          thods in Natural Language Processing.
  15th Text Retrieval Conference.                        Ruifeng Xu, Kam-Fai Wong and Yunqing Xia. 2007.
Craig Macdonald and Iadh Ounis. 2006. Overview of          Opinmine - Opinion Analysis System by CUHK for
  the TREC-2006 Blog Track. In Proceedings of the          NTCIR-6 Pilot Task. In Proceedings of NTCIR-6.
  14th Text Retrieval Conference.                        Min Zhang and Xingyao Ye. 2008. A generation
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,             model to unify topic relevance and lexicon-based
  and Chengxiang Zhai. 2007. Topic sentiment mix-          sentiment for opinion retrieval. In SIGIR ’08: Pro-
  ture: Modeling facets and opinions in weblogs. In        ceedings of the 31st Annual International ACM SI-
  WWW ’07: Proceedings of the 16 International             GIR conference on Research and Development in
  Conference on World Wide Web.                            Information Retrieval, pages 411-418. ACM.
Seung-Hoon Na, Yeha Lee, Sang-Hyob Nam, and              Wei Zhang and Clement Yu. 2007. UIC at TREC
  Jong-Hyeok Lee. 2009. Improving opinion retrieval        2007 Blog Track. In Proceedings of the 15th Text
  based on query-specific sentiment lexicon. In            Retrieval Conference.
  ECIR ’09: Proceedings of the 31st annual European      Jun Zhao, Hongbo Xu, Xuanjing Huang, Songbo Tan,
  Conference on Information Retrieval, pages               Kang Liu, and Qi Zhang. 2008. Overview of Chi-
  734-738.                                                 nese Opinion Analysis Evaluation 2008. In Pro-
Douglas Oard, Tamer Elsayed, Jianqiang Wang, Ye-           ceedings of the First Chinese Opinion Analysis
  jun Wu, Pengyi Zhang, Eileen Abels, Jimmy Lin,           Evaluation.




                                                     1375

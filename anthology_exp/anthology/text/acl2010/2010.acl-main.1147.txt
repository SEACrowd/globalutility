    Discriminative Modeling of Extraction Sets for Machine Translation

                                    John DeNero and Dan Klein
                                     Computer Science Division
                                   University of California, Berkeley
                               {denero,klein}@cs.berkeley.edu



                      Abstract                                two-stage pipeline into a single step. We present a
                                                              discriminative model that directly predicts which
    We present a discriminative model that di-                set of phrasal translation rules should be extracted
    rectly predicts which set of phrasal transla-             from a sentence pair. Our model predicts extrac-
    tion rules should be extracted from a sen-                tion sets: combinatorial objects that include the
    tence pair. Our model scores extraction                   set of all overlapping phrasal translation rules con-
    sets: nested collections of all the overlap-              sistent with an underlying word-level alignment.
    ping phrase pairs consistent with an under-               This approach provides additional discriminative
    lying word alignment. Extraction set mod-                 power relative to word aligners because extraction
    els provide two principle advantages over                 sets are scored based on the phrasal rules they con-
    word-factored alignment models. First,                    tain in addition to word-to-word alignment links.
    we can incorporate features on phrase                     Moreover, the structure of our model directly re-
    pairs, in addition to word links. Second,                 flects the purpose of alignment models in general,
    we can optimize for an extraction-based                   which is to discover translation rules.
    loss function that relates directly to the                   We address several challenges to training and
    end task of generating translations. Our                  applying an extraction set model. First, we would
    model gives improvements in alignment                     like to leverage existing word-level alignment re-
    quality relative to state-of-the-art unsuper-             sources. To do so, we define a deterministic map-
    vised and supervised baselines, as well                   ping from word alignments to extraction sets, in-
    as providing up to a 1.4 improvement in                   spired by existing extraction procedures. In our
    BLEU score in Chinese-to-English trans-                   mapping, possible alignment links have a precise
    lation experiments.                                       interpretation that dictates what phrasal translation
                                                              rules can be extracted from a sentence pair. This
1   Introduction                                              mapping allows us to train with existing annotated
In the last decade, the field of statistical machine          data sets and use the predictions from word-level
translation has shifted from generating sentences             aligners as features in our extraction set model.
word by word to systems that recycle whole frag-                 Second, our model solves a structured predic-
ments of training examples, expressed as transla-             tion problem, and the choice of loss function dur-
tion rules. This general paradigm was first pur-              ing training affects model performance. We opti-
sued using contiguous phrases (Och et al., 1999;              mize for a phrase-level F-measure in order to fo-
Koehn et al., 2003), and has since been general-              cus learning on the task of predicting phrasal rules
ized to a wide variety of hierarchical and syntactic          rather than word alignment links.
formalisms. The training stage of statistical sys-               Third, our discriminative approach requires that
tems focuses primarily on discovering translation             we perform inference in the space of extraction
rules in parallel corpora.                                    sets. Our model does not factor over disjoint word-
   Most systems discover translation rules via a              to-word links or minimal phrase pairs, and so ex-
two-stage pipeline: a parallel corpus is aligned at           isting inference procedures do not directly apply.
the word level, and then a second procedure ex-               However, we show that the dynamic program for
tracts fragment-level rules from word-aligned sen-            a block ITG aligner can be augmented to score ex-
tence pairs. This paper offers a model-based alter-           traction sets that are indexed by underlying ITG
native to phrasal rule extraction, which merges this          word alignments (Wu, 1997). We also describe a


                                                        1453
       Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1453–1463,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


                            σ(ei )                                                     (a) 1:Type
                                                                                      Type        1: Language-specific
                                                                                              Language-specific           function
                                                                                                                   function
                  σ(ei )
                                                                                            words omitted
                                                                                      words omitted         in thelanguage
                                                                                                     in the other  other language

                                                                  2010年2010年                                                     Distribution
                                                                                                                                        over over
                                                                                                              过 [go过over]
                                                                                                                      [go over]
                                                                                                                           Distribution
                                                                                                                                 possible  link types
                                                                                                                           possible link types
 过去 [past]
ast]       σ(fj )           σ(fj )                                      2月                                        地球
                                                                                                              地球 [Earth][Earth]
                                                                  2月
 两       [two]
                                                                                         over theover Earth
                                                                                                         the Earth                    65% 65%
wo]
                                                                  15日 15日
 年                                                                                    Type 2:Type   2: Role-equivalent
                                                                                                Role-equivalent          word pairs
                                                                                                                  pairs that
ear]
         [year]
                                                                                      are not that are equivalents
                                                                                               lexical not lexical equivalents        31% 31%
                                             On February 15   2010
                                        On February 15   2010                                               被 [passive marker]
n]中
         [in]                                                                                          被 [passive marker]
                                                                                                           发现 [discover]
                           Figure 1: A word alignment A (shaded grid cells)                            发现 [discover]
                           defines projections σ(ei ) and σ(fj ), shown as dot-              was discovered
                                                                                        was discovered
                           ted lines for each word in each sentence. The ex-
                           traction set R3 (A) includes all bispans licensed by        (b)                σ(e1 )
                           these projections, shown as rounded rectangles.         Figure 2: Examples of two types of possible align-
                                                                                            σ(e1 )
                                                                                   ment links (striped). These types account for  96%
                                                                                                                               2010年
                                                                                   of the possible alignment links in our data set.
                           coarse-to-fine inference approach that allows us to          σ(f2 )                                2010年
                                                                                                                              2月
                           scale our method to long sentences.
                                                                                alignment links A = {(i, j)} to an extraction set
                              Our extraction set model outperforms both un- σ(f2 )                                            2月
                                                                                of bispans Rn (A) = {[g, h) ⇔ [k, `)}, 15日     where
                           supervised and supervised word aligners at pre-
                                                                                each bispan links target span [g, h) to source span
                           dicting word alignments and extraction sets. We                                                    15日
                                                                                [k, `).1 The maximumOn February    15
                                                                                                          phrase length 2010
                                                                                                                        n ensures that
                           also demonstrate that extraction sets are useful for
                                                                                max(h − g, ` − k) ≤ n.
       [after]             end-to-end machine translation. Our model im-
                                                                                   We canOndescribe
                                                                                                 Februarythis
                                                                                                           15 mapping
                                                                                                                2010 PDT via word-to-
                           proves translation quality relative to state-of-the-
饭      [dinner]                                                                 phrase projections, as illustrated in Figure 1. Let
                           art Chinese-to-English baselines across two pub-
                                                                                word ei project to the phrasal span σ(ei ), where
                           licly available systems, providing total BLEU im-
       [after]             provements of 1.2 in Moses, a phrase-based sys-                                                
                           tem, and 1.4 in a Joshua, a hierarchical system                 σ(ei ) = min j , max j + 1              (1)
       [I]                                                                                             j∈Ji     j∈Ji
                           (Koehn et al., 2007; Li et al., 2009)
                                                                                               Ji = {j : (i, j) ∈ A}
       [sleep]
                           2     Extraction Set Models
                                                                                   and likewise each word fj projects to a span of e.
       [past tense]        The input to our model is an unaligned sentence         Then, Rn (A) includes a bispan [g, h) ⇔ [k, `) iff
                           pair, and the output is an extraction set of phrasal
                           translation rules. Word-level alignments are gen-                    σ(ei ) ⊆ [k, `)             ∀i ∈ [g, h)
                           erated as a byproduct of inference. We first spec-                  σ(fj ) ⊆ [g, h)              ∀j ∈ [k, `)
                           ify the relationship between word alignments and
                           extraction sets, then define our model.                 That is, every word in one of the phrasal spans
                                                                                   must project within the other. This mapping is de-
                           2.1       Extraction Sets from Word Alignments          terministic, and so we can interpret a word-level
                                                                                   alignment A as also specifying the phrasal rules
                           Rule extraction is a standard concept in machine
                                                                                   that should be extracted from a sentence pair.
                           translation: word alignment constellations license
                           particular sets of overlapping rules, from which        2.2       Possible and Null Alignment Links
                           subsets are selected according to limits on phrase
                                                                                   We have not yet accounted for two special cases
                           length (Koehn et al., 2003), number of gaps (Chi-
                                                                                   in annotated corpora: possible alignments and null
                           ang, 2007), count of internal tree nodes (Galley et
                                                                                   alignments. To analyze these annotations, we con-
                           al., 2006), etc. In this paper, we focus on phrasal
                                                                                   sider a particular data set: a hand-aligned portion
                           rule extraction (i.e., phrase pair extraction), upon
                                                                                       1
                           which most other extraction procedures are based.             We use the fencepost indexing scheme used commonly
                                                                                   for parsing. Words are 0-indexed. Spans are inclusive on the
                              Given a sentence pair (e, f), phrasal rule extrac-   lower bound and exclusive on the upper bound. For example,
                           tion defines a mapping from a set of word-to-word       the span [0, 2) includes the first two words of a sentence.


                                                                               1454


                                                                                                     发现 [discover]

                                                                                       was discovered



            of the NIST MT02 Chinese-to-English test set,                                   σ(e1 )
            which has been used in previous alignment experi-
            ments (Ayan et al., 2005; DeNero and Klein, 2007;                                                                    2010年
            Haghighi et al., 2009).
               Possible links account for 22% of all alignment                    σ(f2 )
                                                                                                                                 2月
            links in these data, and we found that most of
            these links fall into two categories. First, possible                                                                15日
            links are used to align function words that have no
在  [after]  equivalent in the other language, but colocate with                               On February 15     2010    PDT
            aligned content words, such as English determin-
晚饭 [dinner]
            ers. Second, they are used to mark pairs of words
                                                                               Figure 3: Possible links constrain the word-to-
            or short phrases that are not lexical equivalents,
后  [after]                                                                     phrase projection of otherwise unaligned words,
            but which play equivalent roles in each sentence.
                                                                               which in turn license overlapping phrases. In this
我  [I]      Figure 2 shows examples of these two use cases,
                                                                               example, σ(f2 ) = [1, 2) does not include the
            along with their corpus frequencies.2
                                                                               possible link at (1, 0) because of the sure link at
睡  [sleep]     On the other hand, null alignments are used
                                                                               (1, 1), but σ(e1 ) = [1, 2) does use the possible
            sparingly in our annotated data. More than 90%
了  (past)   of words participate in some alignment link. The
                                                                               link because it would otherwise be unaligned. The
                                                                               word “PDT” is null aligned, and so its projection
            unaligned words typically express content in one
                                                                               σ(e4 ) = [−1, 4) extends beyond the bounds of the
            sentence that is absent in its translation.
                                                                               sentence, excluding “PDT” from all phrase pairs.
               Figure 3 illustrates how we interpret possible
            and null links in our projection. Possible links are
            typically not included in extraction procedures be-                herent extraction sets Rn (A), those that are li-
            cause most aligners predict only sure links. How-                  censed by an underlying word alignment A with
            ever, we see a natural interpretation for possible                 sure alignments A(s) ⊆ A. Conditioned on a
            links in rule extraction: they license phrasal rules               sentence pair (e, f) and maximum phrase length
            that both include and exclude them. We exclude                     n, we score extraction sets via a feature vec-
            null alignments from extracted phrases because                     tor φ(A(s) , Rn (A)) that includes features on sure
            they often indicate a mismatch in content.                         links (i, j) ∈ A(s) and features on the bispans in
               We achieve these effects by redefining the pro-                 Rn (A) that link [g, h) in e to [k, `) in f :
            jection operator σ. Let A(s) be the subset of A
            that are sure links, then let the index set Ji used                φ(A(s) , Rn (A)) =
                                                                                    X                                X
            for projection σ in Equation 1 be                                               φa (i, j) +                   φb (g, h, k, `)
                   
                                     (s)                                             (i,j)∈A(s)            [g,h)⇔[k,`)∈Rn (A)
                    j : (i, j) ∈ A
                                            if ∃j : (i, j) ∈ A(s)
             Ji = {−1, |f|}                  if @j : (i, j) ∈ A                Because the projection operator Rn (·) is a
                                                                               deterministic function, we can abbreviate
                   
                     {j : (i, j) ∈ A}        otherwise
                   
                                                                               φ(A(s) , Rn (A)) as φ(A) without loss of infor-
              Here, Ji is a set of integers, and σ(ei ) for null               mation, although we emphasize that A is a set
              aligned ei will be [−1, |f| + 1) by Equation 1.                  of sure and possible alignments, and φ(A) does
                 Of course, the characteristics of our aligned cor-            not decompose as a sum of vectors on individual
              pus may not hold for other annotated corpora or                  word-level alignment links. Our model is param-
              other language pairs. However, we hope that the                  eterized by a weight vector θ, which scores an
              overall effectiveness of our modeling approach                   extraction set Rn (A) as θ · φ(A).
              will influence future annotation efforts to build                   To further limit the space of extraction sets we
              corpora that are consistent with this interpretation.            are willing to consider, we restrict A to block
                                                                               inverse transduction grammar (ITG) alignments,
              2.3   A Linear Model of Extraction Sets                          a space that allows many-to-many alignments
              We now define a linear model that scores extrac-                 through phrasal terminal productions, but other-
              tion sets. We restrict our model to score only co-               wise enforces at-most-one-to-one phrase match-
                  2
                    We collected corpus frequencies of possible alignment      ings with ITG reordering patterns (Cherry and Lin,
              link types ourselves on a sample of the hand-aligned data set.   2007; Zhang et al., 2008). The ITG constraint


                                                                           1455


                              On February      15     2010
n]                                                                                                 被 [passive marker]

                                                                                                   发现 [discover]

                                                                                       was discovered
                                                                        model class. Hence, we update toward the ex-
                                                                        traction set for a pseudo-gold alignment Ag ∈
                                                                                            σ(e )
                                                                        ITG (e, f) with minimal1distance from the true ref-
                                                                        erence alignment At .
                                                                            Ag = arg minA∈ITG(e,f) |A ∪ At − A ∩ At | (3)         2010年

                                                                        Inference   2)
                                                                                  details
                                                                                σ(f       appear in Section 4.3.
                                                                                                                                  2月
                                                                           Given Ag and Am , we update the model param-
                                                                        eters away from Am and toward Ag .
                 Figure 4: Above, we show a representative sub-                                                                   15日
                 set of the block alignment patterns that serve as                 θ ← θ + τ · (φ(Ag ) − φ(Am ))
     [after]     terminal productions of the ITG that restricts the
                                                                                             On step
                                                                        where τ is the minimal     February  15 will2010
                                                                                                      size that       ensurePDT
                 output space of our model. These terminal pro-
                                                                        we prefer Ag to Am by a margin greater than
饭    [dinner]    ductions cover up to n = 3 words in each sentence
                                                                        the loss L(Am ; Ag ), capped at some maximum
                 and include a mixture of sure (filled) and possible
                                                                        update size C to provide regularization. We use
                 (striped) word-level alignment links.
     [after]                                                            C = 0.01 in experiments. The step size is a closed
                                                                        form function of the loss and feature vectors: τ =
     [I]          is more computationally convenient than arbitrar-
                                                                                                                        
                                                                                  L(Am ; Ag ) − θ · (φ(Ag ) − φ(Am ))
                  ily ordered phrase matchings (Wu, 1997; DeNero         min C,
                                                                                          ||φ(Ag ) − φ(Am )||22
     [sleep]      and Klein, 2008). However, the space of block
                  ITG alignments is expressive enough to include           We train the model for 30 iterations over the
     [past tense] the vast majority of patterns observed in hand-
                                                                        training set, shuffling the order each time, and we
                  annotated parallel corpora (Haghighi et al., 2009).   average the weight vectors observed after each it-
                     In summary, our model scores all Rn (A) for        eration to estimate our final model.
                  A ∈ ITG(e, f) where A can include block termi-        3.1    Extraction Set Loss Function
                  nals of size up to n. In our experiments, n = 3.
                                                                        In order to focus learning on predicting the
                  Unlike previous work, we allow possible align-
                                                                        right bispans, we use an extraction-level loss
                  ment links to appear in the block terminals, as de-
                                                                        L(Am ; Ag ): an F-measure of the overlap between
                  picted in Figure 4.
                                                                        bispans in Rn (Am ) and Rn (Ag ). This measure
                 3    Model Estimation                                  has been proposed previously to evaluate align-
                                                                        ment systems (Ayan and Dorr, 2006). Based
                 We estimate the weights θ of our extraction set        on preliminary translation results during develop-
                 model discriminatively using the margin-infused        ment, we chose bispan F5 as our loss:
                 relaxed algorithm (MIRA) of Crammer and Singer
                 (2003)—a large-margin, perceptron-style, online               Pr(Am ) = |Rn (Am ) ∩ Rn (Ag )|/|Rn (Am )|
                 learning algorithm. MIRA has been used suc-                  Rc(Am ) = |Rn (Am ) ∩ Rn (Ag )|/|Rn (Ag )|
                 cessfully in MT to estimate both alignment mod-                         (1 + 52 ) · Pr(Am ) · Rc(Am )
                 els (Haghighi et al., 2009) and translation models        F5 (Am ; Ag ) =
                                                                                           52 · Pr(Am ) + Rc(Am )
                 (Chiang et al., 2008).                                    L(Am ; Ag ) = 1 − F5 (Am ; Ag )
                    For each training example, MIRA requires that
                 we find the alignment Am corresponding to the          F5 favors recall over precision. Previous align-
                 highest scoring extraction set Rn (Am ) under the      ment work has shown improvements from adjust-
                 current model,                                         ing the F-measure parameter (Fraser and Marcu,
                                                                        2006). In particular, Lacoste-Julien et al. (2006)
                          Am = arg maxA∈ITG(e,f) θ · φ(A)         (2)   also chose a recall-biased objective.
                                                                           Optimizing for a bispan F-measure penalizes
                 Section 4 describes our approach to solving this       alignment mistakes in proportion to their rule ex-
                 search problem for model inference.                    traction consequences. That is, adding a word
                   MIRA updates away from Rn (Am ) and to-              link that prevents the extraction of many correct
                 ward a gold extraction set Rn (Ag ). Some hand-        phrasal rules, or which licenses many incorrect
                 annotated alignments are outside of the block ITG      rules, is strongly discouraged by this loss.


                                                                    1456


                                                                                                                                   σ(ei )                                       Type 1:
3.2   Features on Extraction Sets                                                                                                                                               words o
                                                                 or
The discriminative power of our model is driven                                                                                                                       2010年
by the features on sure word alignment links
φa (i, j) and bispans φb (g, h, k, `). In both cases,                                                       过去 [past]              σ(fj )                             2月
the most important features come from the pre-
                                                                                                            两    [two]                                                             over
dictions of unsupervised models trained on large                                                                                                                      15日
parallel corpora, which provide frequency and co-                                                                                                                               Type 2:
                                                                                                            年    [year]                                                         are not l
occurrence information.
   To score word-to-word links, we use the poste-                                                                                           On February   15   2010
                                                                                                            中    [in]
rior predictions of a jointly trained HMM align-
ment model (Liang et al., 2006). The remaining                            In     the   past     two years
features include a dictionary feature, an identical                                                                                                                                was
word feature, an absolute position distortion fea-         Figure 5: gBoth possible
                                                                               h     ITG decompositions of
ture, and features for numbers and punctuation.            this example alignment will split one of the two
   To score phrasal translation rules in an extrac-        highlighted bispans across constituents.
                                                               k
tion set, we use a mixture of feature types. Ex-
traction set models allow us to incorporate the
same phrasal relative frequency statistics that drive      4     Model Inference
                                                                 l                                                                                                            σ(f2 )
phrase-based translation performance (Koehn et             Equation 2 asks for the highest scoring extraction
al., 2003). To implement these frequency features,         set under our model, Rn (Am ), which we also re-
we extract a phrase table from the alignment pre-          quire at test time. Although we have restricted
dictions of a jointly trained unsupervised HMM             Am ∈ ITG(e, f), our extraction set model does not
model using Moses (Koehn et al., 2007), and score                                                       在
                                                           factor over ITG productions, and so the dynamic    [after]
bispans using the resulting features. We also in-          program for a vanilla block ITG will not suffice to
                                                                   k =2                                 晚饭 [dinner]
clude indicator features on lexical templates for          find Rn (Am ). To see this, consider the extraction
the 50 most common words in each language, as              set in Figure 5. An ITG decomposition of the 后 un-[after]
in Haghighi et al. (2009). We include indicators           derlying alignment imposes a hierarchical brack-
for the number of words and Chinese characters             eting onl =4                                 我 ex-[I]
                                                                     each sentence, and some bispan in the
in rules. One useful indicator feature exploits the        traction set for this alignment will cross any such
fact that capitalized terms in English tend to align                        g =1the score of
                                                           bracketing. Hence,             h =3          睡 bis-[sleep]
                                                                                             some licensed
to Chinese words with three or more characters.            pan will be non-local to the ITG decomposition.
On 1-by-n or n-by-1 phrasal rules, we include in-                                                               了         [past tense]

dicator features of fertility for common words.3           4.1       A Dynamic Program for Extraction Sets
                                                                               After   dinner     I     slept
   We also include monolingual phrase features             If we treat the maximum phrase length n as a fixed
that expose useful information to the model. For           constant, then we can define a dynamic program to
instance, English bigrams beginning with “the”             search the space of extraction sets. An ITG deriva-
are often extractable phrases. English trigrams            tion for some alignment A decomposes into two
with a hyphen as the second word are typically ex-         sub-derivations for AL and AR .4 The model score
tractable, meaning that the first and third words          of A, which scores extraction set Rn (A), decom-
align to consecutive Chinese words. When any               poses over AL and AR , along with any phrasal
conjugation of the word “to be” is followed by a           bispans licensed by adjoining AL and AR .
verb, indicating passive voice or progressive tense,
the two words tend to align together.                       θ · φ(A) = θ · φ(AL ) + θ · φ(AR ) + I(AL , AR )
   Our feature set also includes bias features on          where I(AL , AR ) is θ ·
                                                                                     P
                                                                                        φ(g, h, k, l) summed
phrasal rules and links, which control the num-            over licensed bispans [g, h) ⇔ [k, `) that overlap
ber of null-aligned words and number of rules li-          the boundary between AL and AR .5
censed. In total, our final model includes 4,249               4
                                                                 We abuse notation in conflating an alignment A with its
individual features, dominated by various instanti-        derivation. All derivations of the same alignment receive the
ations of lexical templates.                               same score, and we only compute the max, not the sum.
                                                               5
                                                                 We focus on the case of adjoining two aligned bispans.
   3
     Limiting lexicalized features to common words helps   Our algorithm easily extends to include null alignments, but
prevent overfitting.                                       we focus on the non-null setting for simplicity.


                                                       1457


                                                                                     On February      15     2010
                                             中     [in]                                                                                       被 [passive marker]

                                                                                                                                              发现 [discover]
             In   the    past   two years
                                                                                                                                was discovered

         g           h                                             alignment model (Ney and Vogel, 1996). We dis-
                                                                   card all states corresponding to bispans that are                 σ(e1 )
 k                                                                 incompatible with 3 or more alignment links un-
                                                                   der an intersected HMM—a proven approach to
                                                                   pruning the space of ITG alignments (Zhang and                                                        2010年
                                                                   Gildea, 2006; Haghighi et al., 2009). Pruning in
  l                                                                                                                        σ(f2 )
                                                                   this way reduces the search space dramatically, but                                                   2月
                                                                   only rarely prohibits correct alignments. The ora-
                                                                   cle alignment error rate for the block ITG model                                                      15日
Figure 6: Augmenting the ITG grammar states                        class is 1.4%; the oracle alignment error rate for
with the alignment configuration in an n − 1在deep [after]          this pruned subset of ITG is 2.0%.                                  On February 15       2010   PDT
perimeter of the bispan allows us to score all over-                  To take advantage of the sparsity that results
      k =2phrasal rules introduced by adjoining
lapping                                               晚饭 two [dinner]
                                                                   from pruning, we use an agenda-based parser that
bispans. The state must encode whether a sure link                 orders search states from small to large, where we
appears in each edge column or row, but the           后spe- [after]define the size of a bispan as the total number of
cific location of edge links is not required.                      words contained within it. For each size, we main-
       l =4                                           我        [I] tain a separate agenda. Only when the agenda for
                                                                   size k is exhausted does the parser proceed to pro-
    In order to gcompute
                   =1         I(AhL=3, AR ), we need  睡 cer- [sleep]
                                                                   cess the agenda for size k + 1.
tain information about the alignment configura-
                                                                      We also employ coarse-to-fine search to speed
tions of AL and AR where they adjoin at a corner.     了        (past)
The state must represent (a) the specific alignment                up  inference (Charniak and Caraballo, 1998). In
                  − 1 deep
links in the nAfter       dinner            sleptA, and (b)
                              cornerI of each                      the coarse pass, we search over the space of ITG
whether any sure alignments appear in the rows or                  alignments, but score only features on alignment
columns extending from those corners.6 With this                   links and bispans that are local to terminal blocks.
information, we can infer the bispans licensed by                  This simplification eliminates the need to augment
adjoining AL and AR , as in Figure 6.                              grammar symbols, and so we can exhaustively ex-
    Applying our score recurrence yields a                         plore the (pruned) space. We then compute out-
polynomial-time dynamic program. This dynamic                      side scores for bispans under a max-sum semir-
program is an instance of ITG bitext parsing,                      ing (Goodman, 1996). In the fine pass with the
where the grammar uses symbols to encode                           full extraction set model, we impose a maximum
the alignment contexts described above. This                       size of 10,000 for each agenda. We order states on
context-as-symbol augmentation of the grammar                      agendas by the sum of their inside score under the
is similar in character to augmenting symbols with                 full model and the outside score computed in the
lexical items to score language models during                      coarse pass, pruning all states not within the fixed
hierarchical decoding (Chiang, 2007).                              agenda beam size.
                                                                      Search states that are popped off agendas are
4.2 Coarse-to-Fine Inference and Pruning                           indexed by their corner locations for fast look-
                                                                   up when constructing new states. For each cor-
Exhaustive inference under an ITG requires O(k 6 )
                                                                   ner and size combination, built states are main-
time in sentence length k, and is prohibitively slow
                                                                   tained in sorted order according to their inside
when there is no sparsity in the grammar. Main-
                                                                   score. This ordering allows us to stop combin-
taining the context necessary to score non-local
                                                                   ing states early when the results are falling off the
bispans further increases running time. That is,
                                                                   agenda beams. Similar search and beaming strate-
ITG inference is organized around search states
                                                                   gies appear in many decoders for machine trans-
associated with a grammar symbol and a bispan;
                                                                   lation (Huang and Chiang, 2007; Koehn and Had-
augmenting grammar symbols also augments this
                                                                   dow, 2009; Moore and Quirk, 2007).
state space.
    To parse quickly, we prune away search states
                                                                   4.3 Finding Pseudo-Gold ITG Alignments
using predictions from the more efficient HMM
    6
                                                                   Equation 3 asks for the block ITG alignment
      The number of configuration states does not depend on
the size of A because corners have fixed size, and because the     Ag that is closest to a reference alignment At ,
position of links within rows or columns is not needed.            which may not lie in ITG(e,f). We search for


                                                          1458


                                                                                                                                                          2010年

l                                                                                                                  σ(f2 )
                                                                                                                                                          2月

                                                                                                                                                          15日


                                              在    [after]        explored area. Most work has focused on pre-
                                                                                                                            On February 15   2010   PDT
    k =1
                                                                  dicting word alignments via partial matching in-
                                              晚饭   [dinner]       ference algorithms (Melamed, 2000; Taskar et al.,
                                                                  2005; Moore, 2005; Lacoste-Julien et al., 2006).
                                              后    [after]
                                                                  Work in semi-supervised estimation has also con-
                                                                  tributed evidence that hand-annotations are useful
                                              我    [I]
    l =4                                                          for training alignment models (Fraser and Marcu,
           g =0                    h =3       睡    [sleep]        2006; Fraser and Marcu, 2007). The ITG gram-
                                                                  mar formalism, the corresponding word alignment
                                              了    [past tense]   class, and inference procedures for the class have
                                                                  also been explored extensively (Wu, 1997; Zhang
              After   dinner   I      slept
                                                                  and Gildea, 2005; Cherry and Lin, 2007; Zhang
                                                                  et al., 2008). At the intersection of these lines of
    Figure 7: A* search for pseudo-gold ITG align-                work, discriminative ITG models have also been
    ments uses an admissible heuristic for bispans that           proposed, including one-to-one alignment mod-
    counts the number of gold links outside of [k, `)             els (Cherry and Lin, 2006) and block models
    but within [g, h). Above, the heuristic is 1, which           (Haghighi et al., 2009). Our model directly ex-
    is also the minimal number of alignment errors                tends this research agenda with first-class possi-
    that an ITG alignment will incur using this bispan.           ble links, overlapping phrasal rule features, and an
                                                                  extraction-level loss function.
    Ag using A* bitext parsing (Klein and Manning,                   Kääriäinen (2009) trains a translation model
    2003). Search states, which correspond to bispans             discriminatively using features on overlapping
    [g, h) ⇔ [k, `), are scored by the number of errors           phrase pairs. That work differs from ours in
    within the bispan plus the number of (i, j) ∈ At              that it uses fixed word alignments and focuses on
    such that j ∈ [k, `) but i ∈/ [g, h) (recall errors).         translation model estimation, while we focus on
    As an admissible heuristic for the future cost of             alignment and translate using standard relative fre-
    a bispan [g, h) ⇔ [k, `), we count the number of              quency estimators.
    (i, j) ∈ At such that i ∈ [g, h) but j ∈ / [k, `), as            Deng and Zhou (2009) present an alignment
    depicted in Figure 7. These links will become re-             combination technique that uses phrasal features.
    call errors eventually. A* search with this heuristic         Our approach differs in two ways. First, their ap-
    makes no errors, and the time required to compute             proach is tightly coupled to the input alignments,
    pseudo-gold alignments is negligible.                         while we perform a full search over the space of
                                                                  ITG alignments. Also, their approach uses greedy
    5      Relationship to Previous Work                          search, while our search is optimal aside from
                                                                  pruning and beaming. Despite these differences,
    Our model is certainly not the first alignment ap-            their strong results reinforce our claim that phrase-
    proach to include structures larger than words.               level information is useful for alignment.
    Model-based phrase-to-phrase alignment was pro-
    posed early in the history of phrase-based trans-             6    Experiments
    lation as a method for training translation models
                                                                  We evaluate our extraction set model by the bis-
    (Marcu and Wong, 2002). A variety of unsuper-
                                                                  pans it predicts, the word alignments it generates,
    vised models refined this initial work with priors
                                                                  and the translations generated by two end-to-end
    (DeNero et al., 2008; Blunsom et al., 2009) and
                                                                  systems. Table 1 compares the five systems de-
    inference constraints (DeNero et al., 2006; Birch
                                                                  scribed below, including three baselines. All su-
    et al., 2006; Cherry and Lin, 2007; Zhang et al.,
                                                                  pervised aligners were optimized for bispan F5 .
    2008). These models fundamentally differ from
    ours in that they stipulate a segmentation of the             Unsupervised Baseline: GIZA++. We trained
    sentence pair into phrases, and only align the min-           GIZA++ (Och and Ney, 2003) using the default
    imal phrases in that segmentation. Our model                  parameters included with the Moses training script
    scores the larger overlapping phrases that result             (Koehn et al., 2007). The designated regimen con-
    from composing these minimal phrases.                         cludes by Viterbi aligning under Model 4 in both
       Discriminative alignment is also a well-                   directions. We combined these alignments with


                                                              1459


the grow-diag heuristic (Koehn et al., 2003).            Our end-to-end translation experiments were
                                                      tuned and evaluated on sentences up to length 40
Unsupervised Baseline: Joint HMM. We
                                                      from the NIST MT04 and MT05 test sets. For
trained and combined two HMM alignment mod-
                                                      these experiments, we trained on a 22.1 million
els (Ney and Vogel, 1996) using the Berkeley
                                                      word parallel corpus consisting of sentences up to
Aligner.7 We initialized the HMM model pa-
                                                      length 40 of newswire data from the GALE pro-
rameters with jointly trained Model 1 param-
                                                      gram, subsampled from a larger data set to pro-
eters (Liang et al., 2006), combined word-to-
                                                      mote overlap with the tune and test sets. This cor-
word posteriors by averaging (soft union), and de-
                                                      pus also includes a bilingual dictionary. To im-
coded with the competitive thresholding heuristic
                                                      prove performance, we retrained our aligner on a
of DeNero and Klein (2007), yielding a state-of-
                                                      retokenized version of the hand-annotated data to
the-art unsupervised baseline.
                                                      match the tokenization of our corpus.8 We trained
Supervised Baseline: Block ITG. We discrimi-          a language model with Kneser-Ney smoothing
natively trained a block ITG aligner with only sure   on 262 million words of newswire using SRILM
links, using block terminal productions up to 3       (Stolcke, 2002).
words by 3 words in size. This supervised base-
line is a reimplementation of the MIRA-trained        6.2    Word and Phrase Alignment
model of Haghighi et al. (2009). We use the same      The first panel of Table 1 gives a word-level eval-
features and parser implementation for this model     uation of all five aligners. We use the alignment
as we do for our extraction set model to ensure a     error rate (AER) measure: precision is the frac-
clean comparison. To remain within the alignment      tion of sure links in the system output that are sure
class, MIRA updates this model toward a pseudo-       or possible in the reference, and recall is the frac-
gold alignment with only sure links. This model       tion of sure links in the reference that the system
does not score any overlapping bispans.               outputs as sure. For this evaluation, possible links
                                                      produced by our extraction set models are ignored.
Extraction Set Coarse Pass. We add possible
                                                      The full extraction set model performs the best by
links to the output of the block ITG model by
                                                      a small margin, although it was not tuned for word
adding the mixed terminal block productions de-
                                                      alignment.
scribed in Section 2.3. This model scores over-
                                                         The second panel gives a phrasal rule-level
lapping phrasal rules contained within terminal
                                                      evaluation, which measures the degree to which
blocks that result from including or excluding pos-
                                                      these aligners matched the extraction sets of hand-
sible links. However, this model does not score
                                                      annotated alignments, R3 (At ).9 To compete
bispans that cross bracketing of ITG derivations.
                                                      fairly, all models were evaluated on the full ex-
Full Extraction Set Model. Our full model in-         traction sets induced by the word alignments they
cludes possible links and features on extraction      predicted. Again, the extraction set model outper-
sets for phrasal bispans with a maximum size of       formed the baselines, particularly on the F5 mea-
3. Model inference is performed using the coarse-     sure for which these systems were trained.
to-fine scheme described in Section 4.2.                 Our coarse pass extraction set model performed
                                                      nearly as well as the full model. We believe
6.1     Data                                          these models perform similarly for two reasons.
In this paper, we focus exclusively on Chinese-to-    First, most of the information needed to predict
English translation. We performed our discrimi-       an extraction set can be inferred from word links
native training and alignment evaluations using a     and phrasal rules contained within ITG terminal
hand-aligned portion of the NIST MT02 test set,       productions. Second, the coarse-to-fine inference
which consists of 150 training and 191 test sen-      may be constraining the full phrasal model to pre-
tences (Ayan and Dorr, 2006). We trained the          dict similar output to the coarse model. This simi-
baseline HMM on 11.3 million words of FBIS            larity persists in translation experiments.
newswire data, a comparable dataset to those used        8
                                                            All alignment results are reported under the annotated
in previous alignment evaluations on our test set     data set’s original tokenization.
(DeNero and Klein, 2007; Haghighi et al., 2009).          9
                                                            While pseudo-gold approximations to the annotation
                                                      were used for training, the evaluation is always performed
  7
      http://code.google.com/p/berkeleyaligner        relative to the original human annotation.


                                                  1460


                                        Word                       Bispan                 BLEU
                                 Pr     Rc      AER       Pr     Rc    F1     F5      Joshua Moses
      Baseline     GIZA++        72.5   71.8    27.8      69.4   45.4 54.9    46.0     33.8   32.6
      models       Joint HMM     84.0   76.9    19.6      69.5   59.5 64.1    59.9     34.5   33.2
                   Block ITG     83.4   83.8    16.4      75.8   62.3 68.4    62.8     34.7   33.6
      Extraction   Coarse Pass   82.2   84.2    16.9      70.0   72.9 71.4    72.8     35.7   34.2
      set models   Full Model    84.7   84.0    15.6      69.0   74.2 71.6    74.0     35.9   34.4

Table 1: Experimental results demonstrate that the full extraction set model outperforms supervised and
unsupervised baselines in evaluations of word alignment quality, extraction set quality, and translation.
In word and bispan evaluations, GIZA++ did not have access to a dictionary while all other methods
did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The
BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate
for parse failures.


6.3    Translation Experiments                         over the best unsupervised baseline and 0.8 over
We evaluate the alignments predicted by our            the block ITG supervised baseline (Papineni et al.,
model using two publicly available, open-source,       2002).
state-of-the-art translation systems. Moses is a          In Joshua, hierarchical rule extraction is based
phrase-based system with lexicalized reordering        upon phrasal rule extraction, but abstracts away
(Koehn et al., 2007). Joshua (Li et al., 2009) is      sub-phrases to create a grammar. Hence, the ex-
an implementation of Hiero (Chiang, 2007) using        traction sets we predict are closely linked to the
a suffix-array-based grammar extraction approach       representation that this system uses to translate.
(Lopez, 2007).                                         The extraction model again outperformed both un-
   Both of these systems take word alignments as       supervised and supervised baselines, by 1.4 BLEU
input, and neither of these systems accepts possi-     and 1.2 BLEU respectively.
ble links in the alignments they consume. To inter-
                                                       7    Conclusion
face with our extraction set models, we produced
three sets of sure-only alignments from our model      Our extraction set model serves to coordinate the
predictions: one that omitted possible links, one      alignment and translation model components of a
that converted all possible links to sure links, and   statistical translation system by unifying their rep-
one that includes each possible link with 0.5 prob-    resentations. Moreover, our model provides an ef-
ability. These three sets were aggregated and rules    fective alternative to phrase alignment models that
were extracted from all three.                         choose a particular phrase segmentation; instead,
   The training set we used for MT experiments         we predict many overlapping phrases, both large
is quite heterogenous and noisy compared to our        and small, that are mutually consistent. In future
alignment test sets, and the supervised aligners       work, we look forward to developing extraction
did not handle certain sentence pairs in our par-      set models for richer formalisms, including hier-
allel corpus well. In some cases, pruning based        archical grammars.
on consistency with the HMM caused parse fail-
ures, which in turn caused training sentences to be    Acknowledgments
skipped. To account for these issues, we added         This project is funded in part by BBN under
counts of phrasal rules extracted from the baseline    DARPA contract HR0011-06-C-0022 and by the
HMM to the counts produced by supervised align-        NSF under grant 0643742. We thank the anony-
ers.                                                   mous reviewers for their helpful comments.
   In Moses, our extraction set model predicts the
set of phrases extracted by the system, and so the
estimation techniques for the alignment model and      References
translation model both share a common underly-         Necip Fazil Ayan and Bonnie J. Dorr. 2006. Going
ing representation: extraction sets. Empirically,        beyond AER: An extensive analysis of word align-
we observe a BLEU score improvement of 1.2               ments and their impact on MT. In Proceedings of


                                                   1461


  the Annual Conference of the Association for Com-           John DeNero, Alexandre Bouchard-Cote, and Dan
  putational Linguistics.                                       Klein. 2008. Sampling alignment structure under
                                                                a bayesian translation model. In Proceedings of the
Necip Fazil Ayan, Bonnie J. Dorr, and Christof Monz.            Conference on Empirical Methods in Natural Lan-
  2005. Neuralign: combining word alignments us-                guage Processing.
  ing neural networks. In Proceedings of the Confer-
  ence on Human Language Technology and Empiri-               Yonggang Deng and Bowen Zhou. 2009. Optimizing
  cal Methods in Natural Language Processing.                   word alignment combination for phrase table train-
                                                                ing. In Proceedings of the Annual Conference of the
Alexandra Birch, Chris Callison-Burch, and Miles Os-            Association for Computational Linguistics: Short
  borne. 2006. Constraining the phrase-based, joint             Paper Track.
  probability statistical translation model. In Proceed-
  ings of the Conference for the Association for Ma-          Alexander Fraser and Daniel Marcu. 2006. Semi-
  chine Translation in the Americas.                            supervised training for statistical word alignment. In
                                                                Proceedings of the Annual Conference of the Asso-
Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Os-            ciation for Computational Linguistics.
  borne. 2009. A Gibbs sampler for phrasal syn-
  chronous grammar induction. In Proceedings of the           Alexander Fraser and Daniel Marcu. 2007. Getting
  Annual Conference of the Association for Computa-             the structure right for word alignment: Leaf. In Pro-
  tional Linguistics.                                           ceedings of the Joint Conference on Empirical Meth-
                                                                ods in Natural Language Processing and Computa-
Eugene Charniak and Sharon Caraballo. 1998. New                 tional Natural Language Learning.
  figures of merit for best-first probabilistic chart pars-
  ing. In Computational Linguistics.                          Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
                                                                Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Colin Cherry and Dekang Lin. 2006. Soft syntactic               Thayer. 2006. Scalable inference and training of
  constraints for word alignment through discrimina-            context-rich syntactic translation models. In Pro-
  tive training. In Proceedings of the Annual Confer-           ceedings of the Annual Conference of the Associa-
  ence of the Association for Computational Linguis-            tion for Computational Linguistics.
  tics.
                                                              Joshua Goodman. 1996. Parsing algorithms and met-
Colin Cherry and Dekang Lin. 2007. Inversion trans-              rics. In Proceedings of the Annual Meeting of the
  duction grammar for joint phrasal translation mod-             Association for Computational Linguistics.
  eling. In Proceedings of the Annual Conference of           Aria Haghighi, John Blitzer, John DeNero, and Dan
  the North American Chapter of the Association for             Klein. 2009. Better word alignments with super-
  Computational Linguistics Workshop on Syntax and              vised ITG models. In Proceedings of the Annual
  Structure in Statistical Translation.                         Conference of the Association for Computational
                                                                Linguistics.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
  Online large-margin training of syntactic and struc-        Liang Huang and David Chiang. 2007. Forest rescor-
  tural translation features. In Proceedings of the Con-        ing: Faster decoding with integrated language mod-
  ference on Empirical Methods in Natural Language              els. In Proceedings of the Annual Conference of the
  Processing.                                                   Association for Computational Linguistics.
David Chiang. 2007. Hierarchical phrase-based trans-          Matti Kääriäinen. 2009. Sinuhe—statistical machine
  lation. Computational Linguistics.                           translation using a globally trained conditional ex-
                                                               ponential family translation model. In Proceedings
Koby Crammer and Yoram Singer. 2003. Ultracon-                 of the Conference on Empirical Methods in Natural
  servative online algorithms for multiclass problems.         Language Processing.
  Journal of Machine Learning Research, 3:951–991.
                                                              Dan Klein and Chris Manning. 2003. A* parsing: Fast
John DeNero and Dan Klein. 2007. Tailoring word                 exact Viterbi parse selection. In Proceedings of the
  alignments to syntactic machine translation. In Pro-          Conference of the North American Chapter of the
  ceedings of the Annual Conference of the Associa-             Association for Computational Linguistics.
  tion for Computational Linguistics.
                                                              Philipp Koehn and Barry Haddow. 2009. Edinburghs
John DeNero and Dan Klein. 2008. The complexity of              submission to all tracks of the WMT2009 shared
  phrase alignment problems. In Proceedings of the              task with reordering and speed improvements to
  Annual Conference of the Association for Computa-             Moses. In Proceedings of the Workshop on Statis-
  tional Linguistics: Short Paper Track.                        tical Machine Translation.
John DeNero, Dan Gillick, James Zhang, and Dan                Philipp Koehn, Franz Josef Och, and Daniel Marcu.
  Klein. 2006. Why generative phrase models un-                 2003. Statistical phrase-based translation. In Pro-
  derperform surface heuristics. In Proceedings of the          ceedings of the Conference of the North American
  NAACL Workshop on Statistical Machine Transla-                Chapter of the Association for Computational Lin-
  tion.                                                         guistics.


                                                          1462


Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris          Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
  Callison-Burch, Marcello Federico, Nicola Bertoldi,        Jing Zhu. 2002. BLEU: A method for automatic
  Brooke Cowan, Wade Shen, Christine Moran,                  evaluation of machine translation. In Proceedings of
  Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra          the Annual Conference of the Association for Com-
  Constantin, and Evan Herbst. 2007. Moses: Open             putational Linguistics.
  source toolkit for statistical machine translation. In
  Proceedings of the Annual Conference of the Associ-      Andreas Stolcke. 2002. Srilm an extensible language
  ation for Computational Linguistics: Demonstration         modeling toolkit. In Proceedings of the Interna-
  track.                                                     tional Conference on Spoken Language Processing.

Simon Lacoste-Julien, Ben Taskar, Dan Klein, and           Ben Taskar, Simon Lacoste-Julien, and Dan Klein.
  Michael I. Jordan. 2006. Word alignment via                2005. A discriminative matching approach to word
  quadratic assignment. In Proceedings of the Annual         alignment. In Proceedings of the Conference on Em-
  Conference of the North American Chapter of the            pirical Methods in Natural Language Processing.
  Association for Computational Linguistics.
                                                           Dekai Wu. 1997. Stochastic inversion transduction
Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Gan-       grammars and bilingual parsing of parallel corpora.
  itkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren          Computational Linguistics, 23:377–404.
  Thornton, Jonathan Weese, and Omar Zaidan. 2009.
                                                           Hao Zhang and Daniel Gildea. 2005. Stochastic lex-
  Joshua: An open source toolkit for parsing-based
                                                             icalized inversion transduction grammar for align-
  machine translation. In Proceedings of the Work-
                                                             ment. In Proceedings of the Annual Conference of
  shop on Statistical Machine Translation.
                                                             the Association for Computational Linguistics.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-       Hao Zhang and Daniel Gildea. 2006. Efficient search
  ment by agreement. In Proceedings of the Annual            for inversion transduction grammar. In Proceedings
  Conference of the North American Chapter of the            of the Conference on Empirical Methods in Natural
  Association for Computational Linguistics.                 Language Processing.
Adam Lopez. 2007. Hierarchical phrase-based trans-         Hao Zhang, Chris Quirk, Robert C. Moore, and
  lation with suffix arrays. In Proceedings of the Con-      Daniel Gildea. 2008. Bayesian learning of non-
  ference on Empirical Methods in Natural Language           compositional phrases with synchronous parsing. In
  Processing.                                                Proceedings of the Annual Conference of the Asso-
                                                             ciation for Computational Linguistics.
Daniel Marcu and Daniel Wong. 2002. A phrase-
  based, joint probability model for statistical machine
  translation. In Proceedings of the Conference on
  Empirical Methods in Natural Language Process-
  ing.

I. Dan Melamed. 2000. Models of translational equiv-
   alence among words. Computational Linguistics.

Robert Moore and Chris Quirk.          2007.  Faster
  beam-search decoding for phrasal statistical ma-
  chine translation. In Proceedings of MT Summit XI.

Robert C. Moore. 2005. A discriminative framework
  for bilingual word alignment. In Proceedings of the
  Conference on Empirical Methods in Natural Lan-
  guage Processing.

Hermann Ney and Stephan Vogel. 1996. HMM-based
  word alignment in statistical translation. In Pro-
  ceedings of the Conference on Computational lin-
  guistics.

Franz Josef Och and Hermann Ney. 2003. A sys-
  tematic comparison of various statistical alignment
  models. Computational Linguistics, 29:19–51.

Franz Josef Och, Christoph Tillmann, and Hermann
  Ney. 1999. Improved alignment models for statisti-
  cal machine translation. In Proceedings of the Con-
  ference on Empirical Methods in Natural Language
  Processing.


                                                       1463

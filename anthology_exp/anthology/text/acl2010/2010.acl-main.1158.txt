         Plot Induction and Evolutionary Search for Story Generation

                               Neil McIntyre and Mirella Lapata
                           School of Informatics, University of Edinburgh
                           10 Crichton Street, Edinburgh, EH8 9AB, UK
                        n.d.mcintyre@sms.ed.ac.uk, mlap@inf.ed.ac.uk



                      Abstract                                   The broader appeal of computational story gen-
                                                              eration lies in its application potential. Examples
    In this paper we develop a story genera-                  include the entertainment industry and the devel-
    tor that leverages knowledge inherent in                  opment of tools that produce large numbers of
    corpora without requiring extensive man-                  plots automatically that might provide inspiration
    ual involvement. A key feature in our ap-                 to professional screen writers (Agudo et al., 2004);
    proach is the reliance on a story planner                 rendering video games more interesting by allow-
    which we acquire automatically by record-                 ing the plot to adapt dynamically to the players’
    ing events, their participants, and their                 actions (Barros and Musse, 2007); and assisting
    precedence relationships in a training cor-               teachers to create or personalize stories for their
    pus. Contrary to previous work our system                 students (Riedl and Young, 2004).
    does not follow a generate-and-rank archi-                   A major stumbling block for the widespread use
    tecture. Instead, we employ evolutionary                  of computational story generators is their reliance
    search techniques to explore the space of                 on expensive, manually created resources. A typi-
    possible stories which we argue are well                  cal story generator will make use of a knowledge
    suited to the story generation task. Experi-              base for providing detailed domain-specific infor-
    ments on generating simple children’s sto-                mation about the characters and objects involved
    ries show that our system outperforms pre-                in the story and their relations. It will also have a
    vious data-driven approaches.                             story planner that specifies how these characters
                                                              interact, what their goals are and how their ac-
1   Introduction
                                                              tions result in different story plots. Finally, a sen-
Computer story generation has met with fasci-                 tence planner (coupled with a surface realizer) will
nation since the early days of artificial intelli-            render an abstract story specification into natural
gence. Indeed, over the years, several genera-                language text. Traditionally, most of this knowl-
tors have been developed capable of creating sto-             edge is created by hand, and the effort must be re-
ries that resemble human output. To name only                 peated for new domains, new characters and plot
a few, TALE -S PIN (Meehan, 1977) generates sto-              elements.
ries through problem solving, M INSTREL (Turner,                 Fortunately, recent work in natural language
1992) relies on an episodic memory scheme, es-                processing has taken significant steps towards de-
sentially a repository of previous hand-coded sto-            veloping algorithms that learn some of this knowl-
ries, to solve the problems in the current story,             edge automatically from natural language cor-
and M AKEBELIEVE (Liu and Singh, 2002) uses                   pora. Chambers and Jurafsky (2009, 2008) pro-
commonsense knowledge to generate short stories               pose an unsupervised method for learning narra-
from an initial seed story (supplied by the user). A          tive schemas, chains of events whose arguments
large body of more recent work views story gener-             are filled with participant semantic roles defined
ation as a form of agent-based planning (Swartjes             over words. An example schema is {X arrest, X
and Theune, 2008; Pizzi et al., 2007). The agents             charge, X raid, X seize, X confiscate, X detain, X
act as characters with a list of goals. They form             deport}, where X stands for the argument types
plans of action and try to fulfill them. Interesting          {police, agent, authority, government}. Their ap-
stories emerge as plans interact and cause failures           proach relies on the intuition that in a coherent
and possible replanning.                                      text events that are about the same participants are


                                                        1562
       Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1562–1572,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


likely to be part of the same story or narrative.       teractive context: the user supplies the topic of the
Their model extracts narrative chains, essentially      story and its desired length (number of sentences).
events that share argument slots and merges them        The generator creates a story following a pipeline
into schemas. The latter could be used to construct     architecture typical of natural language generation
or enrich the knowledge base of a story generator.      systems (Reiter and Dale, 2000) consisting of con-
   In McIntyre and Lapata (2009) we presented a         tent selection, sentence planning, and surface real-
story generator that leverages knowledge inherent       ization.
in corpora without requiring extensive manual in-          The content of a story is determined by consult-
volvement. The generator operates over predicate-       ing a data-driven knowledge base that records the
argument and predicate-predicate co-occurrence          entities (i.e., nouns) appearing in a corpus and the
tuples gathered from training data. These are used      actions they perform. These are encoded as depen-
to produce a large set of candidate stories which       dency relations (e.g., subj-verb, verb-obj). In order
are subsequently ranked based on their interest-        to promote between-sentence coherence the gen-
ingness and coherence. The approach is unusual          erator also make use of an action graph that con-
in that it does not involve an explicit story plan-     tains action-role pairs and the likelihood of tran-
ning component. Stories are created stochastically      sitioning from one to another. The sentence plan-
by selecting entities and the events they are most      ner aggregates together entities and their actions
frequently attested with.                               into a sentence using phrase structure rules. Fi-
   In this work we develop a story generator that       nally, surface realization is performed by interfac-
is also data-driven but crucially relies on a story     ing RealPro (Lavoie and Rambow, 1997) with a
planner for creating meaningful stories. Inspired       language model. The system searches for the best
by Chambers and Jurafsky (2009) we acquire story        story overall as well as the best sentences that can
plots automatically by recording events, their par-     be generated from the knowledge base. Unlikely
ticipants, and their precedence relationships as at-    stories are pruned using beam search. In addition,
tested in a training corpus. Entities give rise to      stories are reranked using two scoring functions
different potential plots which in turn generate        based on coherence and interest. These are learnt
multiple stories. Contrary to our previous work         from training data, i.e., stories labeled with nu-
(McIntyre and Lapata, 2009), we do not follow a         meric values for interest and coherence.
generate-and-rank architecture. Instead, we search         Evolutionary search techniques have been pre-
the space of possible stories using Genetic Algo-       viously employed in natural language generation,
rithms (GAs) which we argue are advantageous            especially in the context of document planning.
in the story generation setting, as they can search     Structuring a set of facts into a coherent text is ef-
large fitness landscapes while greatly reducing the     fectively a search problem that may lead to com-
risk of getting stuck in local optima. By virtue of     binatorial explosion for large domains. Mellish
exploring the search space more broadly, we are         et al. (1998) (and subsequently Karamanis and
able to generate creative stories without an explicit   Manurung 2002) advocate genetic algorithms as
interest scoring module.                                an alternative to exhaustively searching for the op-
   In the remainder of this paper we give a brief       timal ordering of descriptions of museum arte-
overview of the system described in McIntyre and        facts. Rather than requiring a global optimum to
Lapata (2009) and discuss previous applications of      be found, the genetic algorithm selects an order
GAs in natural language generation (Section 2).         (based on coherence) that is good enough for peo-
Next, we detail our approach, specifically how          ple to understand. Cheng and Mellish (2000) focus
plots are created and used in conjunction with ge-      on the interaction of aggregation and text planning
netic search (Sections 3 and 4). Finally, we present    and use genetic algorithms to search for the best
our experimental results (Sections 6 and 7) and         aggregated document that satisfies coherence con-
conclude the paper with discussion of future work.      straints.
                                                           The application of genetic algorithms to story
2   Related Work                                        generation is novel to our knowledge. Our work
Our work builds on and extends the story genera-        also departs from McIntyre and Lapata (2009) in
tor developed in McIntyre and Lapata (2009). The        two important ways. Firstly, our generator does
system creates simple children’s stories in an in-      not rely on a knowledge base of seemingly un-
                                                        related entities and relations. Rather, we employ


                                                    1563


a document planner to create and structure a plot               purpose. We also assume that the actions associ-
for a story. The planner is built automatically from            ated with a given entity are ordered and that lin-
a training corpus and creates plots dynamically                 ear order corresponds to temporal order. This is a
depending on the protagonists of the story. Sec-                gross simplification as it is well known that tem-
ondly, our search procedure is simpler and more                 poral relationships between events are not limited
global; instead of searching for the best story twice           to precedence, they may overlap, occur simultane-
(i.e., by first finding the n-best stories and then             ously, or be temporally unrelated. We could have
subsequently reranking them based on coherence                  obtained a more accurate ordering using a tempo-
and interest), our genetic algorithm explores the               ral classifier (see Chambers and Jurafsky 2008),
space of possible stories once.                                 however we leave this to future work.
                                                                   For each entity e in the corpus we build a di-
3    Plot Generation                                            rected graph G = (V, E) whose nodes V denote
Following previous work (e.g., Shim and Kim                     predicate argument relationships, and edges E rep-
2002; McIntyre and Lapata 2009) we assume that                  resent transitions from node Vi to node V j . As
the user supplies a sentence (e.g., the princess                an example of our schema construction process,
loves the prince) from which the system creates                 consider a very small corpus consisting of the
a story. Each entity in this sentence (e.g., princess,          two documents shown in Figure 1. The schema
prince) is associated with its own narrative                    for princess after processing the first document is
schema, a set of key events and actors co-                      given on the left hand side. Each node in this graph
occurring with it in the training corpus. Our nar-              corresponds to an action attested with princess (we
rative schemas differ slightly from Chambers and                also record who performs it and where or how).
Jurafsky (2009). They acquire schematic represen-               Nodes are themselves dependency trees (see Fig-
tations of situations akin to FrameNet (Fillmore                ure 4a), but are linearized in the figure for the
et al., 2003): schemas consists of semantically                 sake of brevity. Edges in the graph indicate order-
similar predicates and the entities evoked by them.             ing and are weighted using the mutual informa-
In our setting, every entity has its own schema, and            tion metric proposed in Lin (1998) (the weights
predicates associated with it are ordered. Plots are            are omitted from the example).3 The first sentence
generated by merging the entity-specific narrative              in the text gives rise to the first node in the graph,
schemas which subsequently serve as the input to                the second sentence to the second node, and so on.
the genetic algorithm. In the following we describe             Note that the third sentence is not present in the
how the narrative schemas are extracted and plots               graph as it is not about the princess.
merged, and then discuss our evolutionary search                   When processing the second document, we sim-
procedure.                                                      ply expand this graph. Before inserting a new
                                                                node, we check if it can be merged with an al-
Entity-based Schema Extraction Before we                        ready existing one. Nodes are merged only if they
can generate a plot for a story we must have an                 have the same verb and similar arguments, with
idea of the actions associated with the entities in             the focal entity (i.e., princess) appearing in the
the story, the order in which these actions are per-            same argument slot. In our example, the nodes
formed and also which other entities can partici-               “prince marry princess in castle” and “prince
pate. This information is stored in a directed graph            marry princess in temple” can be merged as they
which we explain below. Our algorithm processes                 contain the same verb and number of similar ar-
each document at a time, it operates over depen-                guments. The nodes “princess have influence”
dency structures and assumes that entity mentions               and “princess have baby” cannot be merged as
have been resolved. In our experiments we used                  influence and baby are semantically unrelated.
Rasp (Briscoe and Carroll, 2002), a broad cover-                We compute argument similarity using WordNet
age dependency parser, and the OpenNLP1 coref-                  (Fellbaum, 1998) and the measure proposed by
erence resolution engine.2 However, any depen-                  Wu and Palmer (1994) which is based on path
dency parser or coreference tool could serve our                length. We merge nodes with related arguments
    1 Seehttp://opennlp.sourceforge.net/.                       only if their similarity exceeds a threshold (deter-
    2 The  coreference resolution tool we employ is not         mined empirically).
error-free and on occasion will fail to resolve a pronoun. We
map unresolved pronouns to the generic labels person or ob-         3 We use mutual information to identify event sequences
ject.                                                           strongly associated with the graph entity.


                                                            1564


                                                            The dragon holds the princess in a
  The goblin holds the princess in a lair.                  cave. The prince slays the dragon. The
  The prince rescues the princess and                       princess loves the prince. The prince
  marries her in a castle. The ceremony                     asks the king’s permission. The prince
  is beautiful. The princess has influence                  marries the princess in the temple. The
  as the prince rules the country.                          princess has a baby.
                                                                                                                   
                                                                      goblin                               lair
           goblin hold princess in lair                                            hold princess in
                                                                      dragon                              cave



             prince rescue princess                           prince rescue princess       princess love prince


                                                                                                                 
                                                                                                     castle
         prince marry princess in castle                             prince marry princess in
                                                                                                    temple



             princess have influence                         princess have influence        princess have baby



                      Figure 1: Example of schema construction for the entity princess


  The schema construction algorithm terminates           princess in [castle, temple], prince rule country),
when graphs like the ones shown in Figure 1 (right       and (princess love prince, prince ask king’s per-
hand side) have been created for all entities in the     mission prince marry princess in [castle, temple]).
corpus.                                                  Each of these plots represents two different stories
                                                         one with castle and one with temple in it.
Building a Story Plot Our generator takes an in-
put sentence and uses it to instantiate several plots.   Sentence Planning The sentence planner is in-
We achieve this by merging the schemas associ-           terleaved with the story planner and influences
ated with the entities in the sentence into a plot       the final structure of each sentence in the story.
graph. As an example, consider again the sentence        To avoid generating short sentences — note that
the princess loves the prince which requires comb-       nodes in the plot graph consist of a single ac-
ing the schemas representing prince and princess         tion and would otherwise correspond to a sentence
shown in Figures 2 and 1 (right hand side), re-          with a single clause — we combine pairs of nodes
spectively. Again, we look for nodes that can be         within the same graph by looking at intrasenten-
merged based on the identity of the actions in-          tial verb-verb co-occurrences in the training cor-
volved and the (WordNet) similarity of their ar-         pus. For example, the nodes (prince have prob-
guments. However, we disallow the merging of             lem, prince keep secret) could become the sen-
nodes with focal entities appearing in the same ar-      tence the prince has a problem keeping a secret.
gument slot (e.g., “[prince, princess] cries”).          We leave it up to the sentence planner to decide
   Once the plot graph is created, a depth first         how the two actions should be combined.4 The
search starting from the node corresponding to           sentence planner will also insert adverbs and ad-
the input sentence, finds all paths with length          jectives, using co-occurrence likelihoods acquired
matching the desired story length (cycles are dis-       from the training corpus. It is essentially a phrase
allowed). Assuming we wish to generate a story           structure grammar compiled from the lexical re-
consisting of three sentences, the graph in Figure 3     sources made available by Korhonen and Briscoe
would create four plots. These are (princess love        (2006) and Grishman et al. (1994). The grammar
prince, prince marry princess in [castle, temple],       rules act as templates for combining clauses and
princess have influence), (princess love prince,         filling argument slots.
prince marry princess in [castle, temple], princess          4 We only turn an action into a subclause if its subject en-
have baby), (princess love prince, prince marry          tity is same as that of the previous action.


                                                     1565


                                                                                                                   
    princess love prince             prince slay dragon                  goblin                               lair
                                                                                      hold princess in                    prince slay dragon
                                                                         dragon                              cave


prince rescue princess         prince ask king’s permission          prince rescue princess                          princess love prince


                                                  
                                          castle
                                                                                                                         
          prince marry princess in                                                                            castle
                                         temple                            prince marry princess in
                                                                                                             temple


                    prince rule country                                                                                       prince ask king’s
                                                                                                                              permission

Figure 2: Narrative schema for the entity prince.                         princess have influence                    prince rule country
                                                                                               princess have baby
4      Genetic Algorithms
The example shown in Figure 3 is a simplified ver-
sion of a plot graph. The latter would normally                  Figure 3: Plot graph for the input sentence the
contain hundreds of nodes and give rise to thou-                 princess loves the prince.
sands of stories once lexical variables have been
expanded. Searching the story space is a difficult               obtained is considered optimal. This process leads
optimization problem, that must satisfy several                  to the evolution of a population in which the in-
constraints: the story should be of a certain length,            dividuals are more and more suited to their envi-
overall coherent, creative, display some form of                 ronment, just as natural adaptation. We describe
event progression, and generally make sense. We                  below how we developed a genetic algorithm for
argue that evolutionary search is appealing here, as             our story generation problem.
it can find global optimal solutions in a more effi-
cient way than traditional optimization methods.                 Initial Population Rather than start with a ran-
   In this study we employ genetic algorithms                    dom population, we seed the initial population
(GAs) a well-known search technique for finding                  with story plots generated from our plot graph.
approximate (or exact) solutions to optimization                 For an input sentence, we generate all possible
problems. The basic idea behind GAs is based                     plots. The latter are then randomly sampled until a
on “natural selection” and the Darwinian princi-                 population of the desired size is created. Contrary
ple of the survival of the fittest (Mitchell, 1998).             to McIntyre and Lapata (2009), we initialize the
An initial population is randomly created contain-               search with complete stories, rather than generate
ing a predefined number of individuals (or solu-                 one sentence at a time. The genetic algorithm will
tions), each represented by a genetic string (e.g., a            thus avoid the pitfall of selecting early on a solu-
population of chromosomes). Each individual is                   tion that will later prove detrimental.
evaluated according to an objective function (also               Crossover Each plot is represented as an or-
called a fitness function). A number of individu-                dered graph of dependency trees (corresponding
als are then chosen as parents from the population               to sentences). We have decided to use crossover of
according to their fitness, and undergo crossover                a single point between two selected parents. The
(also called recombination) and mutation in order                children will therefore contain sentences up to the
to develop the new population. Offspring with bet-               crossover point of the first parent and sentences
ter fitness are then inserted into the population,               after that point of the second. Figure 4a shows
replacing the inferior individuals in the previous               two parents (prince rescue princess, prince marry
generation.                                                      princess in castle, princess have baby) and (prince
   The algorithm thus identifies the individuals                 rescue princess, prince love princess, princess kiss
with the optimizing fitness values, and those with               prince) and how two new plots are created by
lower fitness will naturally get discarded from the              swapping their last nodes.
population. This cycle is repeated for a given num-
ber of generations, or stopped when the solution


                                                              1566


 a)                rescue                            rescue                         rescue                             rescue
          prince       princess             prince        princess         prince       princess              prince        princess
                   marry in                        love              =⇒             marry in                          love
      prince      princess      castle       prince princess          prince      princess       castle         prince princess
                 have                              kiss                              kiss                            have
           princess baby                    princess prince                    prince princess                 princess baby



 b)                   marry                                               c)                 rescue                                 rescue
                                                           hall                     prince       princess                  prince        princess
                                                         temple                             marry in
       prince        princess      castle                                                                                             kiss
                                                          forest
                                                        kingdom                prince      princess    castle                   prince princess
                                                                                              kiss                                   marry in
                                                                                        prince princess                prince      princess      castle
 d)                rescue                                                 e)                knows
          prince       princess
                                                                                  prince
                   marry in                      hold                                                                                escape
                                       =⇒                                                             loves           =⇒
      prince      princess      castle    prince    princess
                                                                                           princess           child         princess          dragon
                     kiss
               prince princess



Figure 4: Example of genetic algorithm operators as they are applied to plot structures: a) crossover of
two plots on a single point, indicated by the dashed line, resulting in two children which are a recombi-
nation of the parents; b) mutation of a lexical node, church can be replaced from a list of semantically
related candidates; c) sentences can be switched under mutation to create a potentially more coherent
structure; d) if the matrix verb undergoes mutation then, a random sentence is generated to replace it; e)
if the verb chosen for mutation is the head of a subclause, then a random subclause replaces it.


Mutation Mutation can occur on any verb,                                   Selection To choose the plots for the next gener-
noun, adverb, or adjective in the plot. If a noun,                         ation, we used fitness proportional selection (also
adverb or adjective is chosen to undergo mutation,                         know as roulette-wheel selection, Goldberg 1989)
then we simply substitute it with a new lexical item                       which chooses candidates randomly but with a
that is sufficiently similar (see Figure 4b for an                         bias towards those with a larger proportion of the
example). Verbs, however, have structural impor-                           population’s combined fitness. We do not want to
tance in the stories and we cannot simply replace                          always select the fittest candidates as there may
them without taking account of their arguments.                            be valid partial solutions held within less fit mem-
If a matrix verb is chosen to undergo mutation,                            bers of the population. However, we did employ
then a new random sentence is generated to re-                             some elitism by allowing the top 1% of solutions
place the entire sentence (see Figure 4d). If it is                        to be copied straight from one generation to the
a subclause, then it is replaced with a randomly                           next. Note that our candidates may also represent
generated clause, headed by a verb that has been                           invalid solutions. For instance, through crossover
seen in the corpus to co-occur with the matrix verb                        it is possible to create a plot in which all or some
(Figure 4e). The sentence planner selects and fills                        nodes are identical. If any such candidates are
template trees for generating random clauses. Mu-                          identified, they are assigned a low fitness, without
tation may also change the order of any two nodes                          however being eliminated from the population as
in the graph in the hope that this will increase the                       some could be used to create fitter solutions.
story’s coherence or create some element of sur-                               In a traditional GA, the fitness function deals
prise (see Figure 4c).                                                     with one optimization objective. It is possible to
                                                                           optimize several objectives either using a vot-


                                                                      1567


ing model or more sophisticated methods such as         parameters (such as the population size for the GA
Pareto ranking (Goldberg, 1989). Following previ-       search), the baselines used for comparison, and ex-
ous work (Mellish et al., 1998) we used a single fit-   plain how our system output was evaluated.
ness function that scored candidates based on their
                                                        Corpus The generator was trained on the same
coherence. Our function was learned from training
                                                        corpus used in McIntyre and Lapata (2009), 437
data using the Entity Grid document representa-
                                                        stories from the Andrew Lang fairy tales collec-
tion proposed in Barzilay and Lapata (2007). An
                                                        tion.5 The average story length is 125.18 sen-
entity grid is a two-dimensional array in which
                                                        tences. The corpus contains 15,789 word tokens.
columns correspond to entities and rows to sen-
                                                        Following McIntyre and Lapata, we discarded to-
tences. Each cell indicates whether an entity ap-
                                                        kens that did not appear in the Children’s Printed
pears in a given sentence or not and whether it is a
                                                        Word Database6 , a database of printed word fre-
subject, object or neither. For training, this repre-
                                                        quencies as read by children aged between five
sentation is converted into a feature vector of en-
                                                        and nine. From this corpus we extracted narrative
tity transition sequences and a model is learnt from
                                                        schemas for 667 entities in total. We disregarded
examples of coherent and incoherent stories. The
                                                        any graph that contained less than 10 nodes as too
latter can be easily created by permuting the sen-
                                                        small. The graphs had on average 61.04 nodes,
tences of coherent stories (assuming that the orig-
                                                        with an average clustering rate7 of 0.027 which in-
inal story is more coherent than its permutations).
                                                        dicates that they are substantially connected.
   In addition to coherence, in McIntyre and La-
pata (2009) we used a scoring function based on         Parameter Setting Considerable latitude is
interest which we approximated with lexical and         available when selecting parameters for the GA.
syntactic features such as the number of noun/verb      These involve the population size, crossover, and
tokens/types, the number of subjects/objects, the       mutation rates. To evaluate which setting was best,
number of letters, word familiarity, imagery, and       we asked two human evaluators to rate (on a 1–5
so on. An interest-based scoring function made          scale) stories produced with a population size
sense in our previous setup as a means of selecting     ranging from 1,000 to 10,000, crossover rate of 0.1
unusual stories. However, in the context of genetic     to 0.6 and mutation rate of 0.001 to 0.1. For each
search such a function seems redundant as inter-        run of the system a limit was set to 5,000 genera-
esting stories emerge naturally through the opera-      tions. The human ratings revealed that the best sto-
tions of crossover and mutation.                        ries were produced for a population size of 10,000,
                                                        a crossover rate of 0.1% and a mutation rate
5   Surface Realization                                 of 0.1%. Compared to previous work (e.g., Kara-
Once the final generation of the population has         manis and Manurung 2002) our crossover rate
been reached, the fittest story is selected for sur-    may seem low and the mutation rate high. How-
face realization. The realizer takes each sentence      ever, it makes intuitively sense, as high crossover
in the story and reformulates it into input com-        may lead to incoherence by disrupting canonical
patible with the RealPro (Lavoie and Rambow,            action sequences found in the plots. On the other
1997) text generation engine. Realpro creates sev-      hand, a higher mutation will raise the likelihood of
eral variants of the same story differing in the        a lexical item being swapped for another and may
choice of determiners, number (singular or plural),     improve overall coherence and interest. The fit-
and prepositions. A language model is then used         ness function was trained on 200 documents from
to select the most probable realization (Knight         the fairy tales collection using Joachims’s (2002)
and Hatzivassiloglou, 1995). Ideally, the realizer      SVMlight package and entity transition sequences
should also select an appropriate tense for the sen-    of length 2. The realizer was interfaced with a tri-
tence. However, we make the simplifying assump-         gram language model trained on the British Na-
tion that all sentences are in the present tense.       tional Corpus with the SRI toolkit.
                                                            5 Available from http://homepages.inf.ed.ac.uk/
6   Experimental Setup                                  s0233364/McIntyreLapata09/.
                                                            6 http://www.essex.ac.uk/psychology/cpwd/
In this section we present our experimental set-up          7 Clustering rate (or transitivity) is the number of triangles
for assessing the performance of our story genera-      in the graph — sets of three vertices each of which is con-
tor. We give details on our training corpus, system,    nected to each of the others.



                                                    1568


Evaluation We compared the stories gener-                     System      Fluency     Coherence     Interest
ated by the GA against those produced by the                GA-based        3.09        2.48           2.36
rank-based system described in McIntyre and La-             Plot-based      3.03        2.36          2.14∗
pata (2009) and a system that creates stories from          Rank-based      1.96∗∗      1.65∗         1.85∗
the plot graph, without any stochastic search.              Random          3.10        2.23∗         2.20∗
Since plot graphs are weighted, we can simply se-
lect the graph with the highest weight. After ex-        Table 1: Human evaluation results: mean story
panding all lexical variables, the chosen plot graph     ratings for four story generators; ∗ : p < 0.05,
will give rise to different stories (e.g., castle or     ∗∗ : p < 0.01,  significantly different from
temple in the example above). We select the story        GA-based system.
ranked highest according to our coherence func-
tion. In addition, we included a baseline which
                                                         nificantly better than the Rank-based, Plot-based
randomly selects sentences from the training cor-
                                                         and Random ones (using a Post-hoc Tukey test,
pus provided they contain either of the story pro-
                                                         α < 0.05). With regard to fluency, the Rank-
tagonists (i.e., entities in the input sentence). Sen-
                                                         based system is significantly worse than the rest
tence length was limited to 12 words or less as this
                                                         (α < 0.01). Interestingly, the sentences generated
was on average the length of the sentences gener-
                                                         by the GA and Plot-based systems are as fluent as
ated by our GA system.
                                                         those created by humans. Recall that the Random
   Each system created stories for 12 input sen-
                                                         system, simply selects sentences from the train-
tences, resulting in 48 (4×12) stories for eval-
                                                         ing corpus. Finally, the GA system is significantly
uation. The sentences used commonly occurring
                                                         more coherent than the Rank-based and Random
entities in the fairy tales corpus (e.g., The child
                                                         systems (α < 0.05), but not the Plot-based one.
watches the bird, The emperor rules the kingdom.,
                                                         This is not surprising, the GA and Plot-based sys-
The wizard casts the spell.). The stories were split
                                                         tems rely on similar plots to create a coherent
into three sets containing four stories from each
                                                         story. The performance of the Random system is
system but with only one story from each input
                                                         also inferior as it does not have any explicit coher-
sentence. All stories had the same length, namely
                                                         ence enforcing mechanism. The Rank-based sys-
five sentences. Human judges were presented with
                                                         tem is perceived overall worse. As this system is
one of the three sets and asked to rate the stories
                                                         also the least fluent, we conjecture that partici-
on a scale of 1 to 5 for fluency (was the sentence
                                                         pants are influenced in their coherence judgments
grammatical?), coherence (does the story make
                                                         by the grammaticality of the stories.
sense overall?) and interest (how interesting is the
                                                            Overall our results indicate that an explicit story
story?). The stories were presented in random or-
                                                         planner improves the quality of the generated sto-
der and participants were told that all of them
                                                         ries, especially when coupled with a search mech-
were generated by a computer program. They were
                                                         anism that advantageously explores the search
instructed to rate more favorably interesting sto-
                                                         space. It is worth noting that the Plot-based sys-
ries, stories that were comprehensible and overall
                                                         tem is relatively simple, however the explicit use
grammatical. The study was conducted over the
                                                         of a story plot, seems to make up for the lack of
Internet using WebExp (Keller et al., 2009) and
                                                         sophisticated search and more elaborate linguis-
was completed by 56 volunteers, all self reported
                                                         tic information. Example stories generated by the
native English speakers.
                                                         four systems are shown in Table 2 for the input
7   Results                                              sentences The emperor rules the kingdom and The
                                                         child watches the bird.
Our results are summarized in Table 1 which lists           Possible extensions and improvements to the
the average human ratings for the four systems.          current work are many and varied. Firstly, we
We performed an Analysis of Variance (A NOVA)            could improve the quality of our plot graphs by
to examine the effect of system type on the story        taking temporal knowledge into account and mak-
generation task. Statistical tests were carried out      ing use of knowledge bases such as WordNet
on the mean of the ratings shown in Table 1 for          and ConceptNet (Liu and Davenport, 2004), a
fluency, coherence, and interest.                        freely available commonsense knowledge base.
   In terms of interest, the GA-based system is sig-     Secondly, our fitness function optimizes one ob-


                                                     1569


            The emperor rules the kingdom. The kingdom         The child watches the bird. The bird weeps
   PlotGA
            holds on to the emperor. The emperor rides         for the child. The child begs the bird to lis-
            out of the kingdom. The kingdom speaks out         ten.The bird dresses up the child. The child
            against the emperor. The emperor lies.             grows up.
            The emperor rules the kingdom. The emperor         The child watches the bird. The bird comes
            takes over. The emperor goes on to feel for the    to eat away at the child. The child does thor-
   Plot




            kingdom. Possibly the emperor sleeps. The          oughly. The bird sees the child. The child sits
            emperor steals.                                    down.
            The emperor rules the kingdom. The kingdom         The child watches the bird. The bird lives
            lives from the reign to the emperor. The em-       from the reign to the child. The child thanks
            peror feels that the brothers tempt a beauty       the victory for blessing the thought. The child
   Rank




            into the game. The kingdom saves the life          loves to hate the sun with the thought. The
            from crumbling the earth into the bird. The        child hopes to delay the duty from the happi-
            kingdom forces the whip into wiping the tears      ness.
            on the towel.
            Exclaimed the emperor when Petru had put           They cried, “what a beautiful child!” “No,
            his question. In the meantime, mind you take       that I cannot do, my child” he said at last.
   Random




            good care of our kingdom. At first the em-         “What is the matter, dear child?” “You wicked
            peror felt rather distressed. The dinner of an     child,” cried the Witch. Well, I will watch till
            emperor! Thus they arrived at the court of the     the bird comes.
            emperor.

Table 2: Stories generated by a system that uses plots and genetic search (PlotGA), a system that uses
only plots (Plot), McIntyre and Lapata (2009)’s rank-based system (Rank) and a system that randomly
pastes together sentences from the training corpus (Random).


jective, namely coherence. In the future we plan to             ing approach to story plot generation. In
explore multiple objectives, such as whether the                Proceedings of the 7th European Conference
story is verbose, readable (using existing readabil-            on Case-Based Reasoning. Springer, Madrid,
ity metrics), has two many or two few protago-                  Spain, pages 142–156.
nists, and so on.                                             Barros, Leandro Motta and Soraia Raupp Musse.
    Thirdly, our stories would benefit from some ex-            2007. Planning algorithms for interactive story-
plicit modeling of discourse structure. Although                telling. In Computers in Entertainment (CIE),
the plot graph captures the progression of the ac-              Association for Computing Machinery (ACM),
tions in a story, we would also like to know where              volume 5.
in the story these actions are likely to occur—
                                                              Barzilay, Regina and Mirella Lapata. 2007. Mod-
some tend to appear in the beginning and others in
                                                                eling local coherence: An entity-based ap-
the end. Such information would allow us to struc-
                                                                proach. Computational Linguistics 34(1):1–34.
ture the stories better and render them more natu-
ral sounding. For example, an improvement would               Briscoe, E. and J. Carroll. 2002. Robust accurate
be the inclusion of proper endings, as the stories              statistical annotation of general text. In Pro-
are currently cut off at an arbitrary point when the            ceedings of the 3rd International Conference on
desired maximum length is reached.                              Language Resources and Evaluation. Las Pal-
    Finally, the fluency of the stories would bene-             mas, Gran Canaria, pages 1499–1504.
fit from generating referring expressions, multiple           Chambers, Nathanael and Dan Jurafsky. 2008.
tense forms, indirect speech, aggregation and gen-              Unsupervised learning of narrative event chains.
erally more elaborate syntactic structure.                      In Proceedings of 46th Annual Meeting of the
                                                                Association for Computational Linguistics: Hu-
References                                                      man Language Technologies. Columbus, Ohio,
Agudo, Belén Diáz, Pablo Gervás, and Fred-                   pages 789–797.
  erico Peinado. 2004. A case based reason-                   Chambers, Nathanael and Dan Jurafsky. 2009.


                                                       1570


  Unsupervised learning of narrative schemas and     Korhonen, Y. Krymolowski, A. and E.J. Briscoe.
  their participants. In Proceedings of the Joint      2006. A large subcategorization lexicon for nat-
  Conference of the 47th Annual Meeting of the         ural language processing applications. In Pro-
  ACL and the 4th International Joint Conference       ceedings of the 5th LREC. Genova, Italy.
  on Natural Language Processing of the AFNLP.       Lavoie, Benoit and Owen Rambow. 1997. A fast
  Singapore, pages 602–610.                            and portable realizer for text generation sys-
Cheng, Hua and Chris Mellish. 2000. Captur-            tems. In Proceedings of the 5th Conference on
  ing the interaction between aggregation and text     Applied Natural Language Processing. Wash-
  planning in two generation systems. In Pro-          ington, D.C., pages 265–268.
  ceedings of the 1st International Conference on    Lin, Dekang. 1998. Automatic retrieval and clus-
  Natural Language Generation. Mitzpe Ramon,           tering of similar words. In Proceedings of
  Israel, pages 186–193.                               the 17th International Conference on Compu-
Fellbaum. 1998. WordNet: An Electronic Lexi-           tational Linguistic. Montreal, Quebec, pages
  cal Database (Language, Speech, and Commu-           768–774.
  nication). The MIT Press, Cambridge, Mas-
                                                     Liu, Hugo and Glorianna Davenport. 2004. Con-
  sachusetts.
                                                       ceptNet: a practical commonsense reasoning
Fillmore, Charles J., Christopher R. Johnson, and      toolkit. BT Technology Journal 22(4):211–226.
   Miriam R. L. Petruck. 2003. Background to
                                                     Liu, Hugo and Push Singh. 2002. Using com-
   FrameNet. International Journal of Lexicogra-
                                                       monsense reasoning to generate stories. In Pro-
   phy 16:235–250.
                                                       ceedings of the 18th National Conference on Ar-
Goldberg, David E. 1989. Genetic Algorithms            tificial Intelligence. Edmonton, Alberta, pages
  in Search, Optimization and Machine Learning.        957–958.
  Addison-Wesley Longman Publishing Co., Inc.,
                                                     McIntyre, Neil and Mirella Lapata. 2009. Learn-
  Boston, Massachusetts.
                                                      ing to tell tales: A data-driven approach to story
Grishman, Ralph, Catherine Macleod, and Adam          generation. In Proceedings of the Joint Confer-
  Meyers. 1994. COMLEX syntax: Building a             ence of the 47th Annual Meeting of the ACL and
  computational lexicon. In Proceedings of the        the 4th International Joint Conference on Natu-
  15th COLING. Kyoto, Japan, pages 268–272.           ral Language Processing of the AFNLP. Singa-
Joachims, Thorsten. 2002. Optimizing search en-       pore, pages 217–225.
  gines using clickthrough data. In Proceed-         Meehan, James. 1977. An interactive program that
  ings of the 8th Proceedings of the eighth ACM       writes stories. In Proceedings of the 5th In-
  SIGKDD international conference on Knowl-           ternational Joint Conference on Artificial Intel-
  edge discovery and data mining. Edmonton, Al-       ligence. Cambridge, Massachusetts, pages 91–
  berta, pages 133–142.                               98.
Karamanis, Nikiforos and Hisar Maruli Manu-
                                                     Mellish, Chris, Alisdair Knott, Jon Oberlander,
  rung. 2002. Stochastic text structuring using
                                                      and Mick O’Donnell. 1998. Experiments using
  the principle of continuity. In Proceedings of
                                                      stochastic search for text planning. In Proceed-
  the 2nd International Natural Language Gener-
                                                      ings of the 9th International Conference on Nat-
  ation Conference (INLG’02). pages 81–88.
                                                      ural Language Generation. New Brunswick,
Keller, Frank, Subahshini Gunasekharan, Neil          New Jersey, pages 98–107.
  Mayo, and Martin Corley. 2009. Timing accu-
                                                     Mitchell, Melanie. 1998. An Introduction to Ge-
  racy of web experiments: A case study using the
                                                      netic Algorithms. MIT Press, Cambridge, Mas-
  WebExp software package. Behavior Research
                                                      sachusetts.
  Methods 41(1):1–12.
                                                     Pizzi, David, Fred Charles, Jean-Luc Lugrin, and
Knight, Kevin and Vasileios Hatzivassiloglou.
                                                       Marc Cavazza. 2007. Interactive storytelling
  1995. Two-level, many-paths generation. In
                                                       with literary feelings. In Proceedings of the 2nd
  Proceedings of the 33rd Annual Meeting of
                                                       International Conference on Affective Comput-
  the Association for Computational Linguistics
                                                       ing and Intelligent Interaction. Lisbon, Portu-
  (ACL’95). Cambridge, Massachusetts, pages
                                                       gal, pages 630–641.
  252–260.


                                                 1571


Reiter, E and R Dale. 2000. Building Natural-
  Language Generation Systems. Cambridge
  University Press, Cambridge, UK.
Riedl, Mark O. and R. Michael Young. 2004. A
  planning approach to story generation and his-
  tory education. In Proceedings of the 3rd In-
  ternational Conference on Narrative and Inter-
  active Learning Environments. Edinburgh, UK,
  pages 41–48.
Shim, Yunju and Minkoo Kim. 2002. Automatic
  short story generator based on autonomous
  agents. In Proceedings of the 5th Pacific Rim In-
  ternational Workshop on Multi Agents. Tokyo,
  pages 151–162.
Swartjes, I.M.T. and M. Theune. 2008. The vir-
  tual storyteller: story generation by simulation.
  In Proceedings of the 20th Belgian-Netherlands
  Conference on Artificial Intelligence, BNAIC
  2008. Enschede, the Netherlands, pages 257–
  264.
Turner, Scott R. 1992. Ministrel: A Computer
  Model of Creativity and Sotrytelling. University
  of California, Los Angeles, California.
Wu, Zhibiao and Martha Palmer. 1994. Verb se-
 mantics and lexical selection. In Proceedings
 of the 32nd Annual Meeting of the Associa-
 tion for Computational Linguistics. Las Cruces,
 New Mexico, pages 133–138.




                                                  1572

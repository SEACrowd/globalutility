           The impact of interpretation problems on tutorial dialogue
                      Myroslava O. Dzikovska and Johanna D. Moore
          School of Informatics, University of Edinburgh, Edinburgh, United Kingdom
                          {m.dzikovska,j.moore}@ed.ac.uk

                      Natalie Steinhauser and Gwendolyn Campbell
            Naval Air Warfare Center Training Systems Division, Orlando, FL, USA
            {natalie.steihauser,gwendolyn.campbell}@navy.mil

                    Abstract                                et al., 2004). However, limiting the range of pos-
                                                            sible input limits the contentful talk that the stu-
    Supporting natural language input may                   dents are expected to produce, and therefore may
    improve learning in intelligent tutoring                limit the overall effectiveness of the system.
    systems. However, interpretation errors                    Most of the existing tutoring systems that accept
    are unavoidable and require an effective                unrestricted language input use classifiers based
    recovery policy. We describe an evaluation              on statistical text similarity measures to match
    of an error recovery policy in the B EE -               student answers to open-ended questions with
    TLE II tutorial dialogue system and dis-                pre-authored anticipated answers (Graesser et al.,
    cuss how different types of interpretation              1999; Jordan et al., 2004; McCarthy et al., 2008).
    problems affect learning gain and user sat-             While such systems are robust to unexpected ter-
    isfaction. In particular, the problems aris-            minology, they provide only a very coarse-grained
    ing from student use of non-standard ter-               assessment of student answers. Recent research
    minology appear to have negative conse-                 aims to develop methods that produce detailed
    quences. We argue that existing strategies              analyses of student input, including correct, in-
    for dealing with terminology problems are               correct and missing parts (Nielsen et al., 2008;
    insufficient and that improving such strate-            Dzikovska et al., 2008), because the more detailed
    gies is important in future ITS research.               assessments can help tailor tutoring to the needs of
                                                            individual students.
1   Introduction
                                                               While the detailed assessments of answers to
There is a mounting body of evidence that student           open-ended questions are intended to improve po-
self-explanation and contentful talk in human-              tential learning, they also increase the probabil-
human tutorial dialogue are correlated with in-             ity of misunderstandings, which negatively impact
creased learning gain (Chi et al., 1994; Purandare          tutoring and therefore negatively impact student
and Litman, 2008; Litman et al., 2009). Thus,               learning (Jordan et al., 2009). Thus, appropri-
computer tutors that understand student explana-            ate error recovery strategies are crucially impor-
tions have the potential to improve student learn-          tant for tutorial dialogue applications. We describe
ing (Graesser et al., 1999; Jordan et al., 2006;            an evaluation of an implemented tutorial dialogue
Aleven et al., 2001; Dzikovska et al., 2008). How-          system which aims to accept unrestricted student
ever, understanding and correctly assessing the             input and limit misunderstandings by rejecting low
student’s contributions is a difficult problem due          confidence interpretations and employing a range
to the wide range of variation observed in student          of error recovery strategies depending on the cause
input, and especially due to students’ sometimes            of interpretation failure.
vague and incorrect use of domain terminology.                 By comparing two different system policies, we
   Many tutorial dialogue systems limit the range           demonstrate that with less restricted language in-
of student input by asking short-answer questions.          put the rate of non-understanding errors impacts
This provides a measure of robustness, and previ-           both learning gain and user satisfaction, and that
ous evaluations of ASR in spoken tutorial dialogue          problems arising from incorrect use of terminol-
systems indicate that neither word error rate nor           ogy have a particularly negative impact. A more
concept error rate in such systems affect learning          detailed analysis of the results indicates that, even
gain (Litman and Forbes-Riley, 2005; Pon-Barry              though we based our policy on an approach ef-


                                                       43
                        Proceedings of the ACL 2010 Conference Short Papers, pages 43–48,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


fective in task-oriented dialogue (Hockey et al.,            word sense assigned to an ambiguous word, or an
2003), many of our strategies were not success-              incorrectly resolved referential expression.
ful in improving learning gain. At the same time,               Our approach to selecting an error recovery pol-
students appear to be aware that the system does             icy is to prefer non-understandings to misunder-
not fully understand them even if it accepts their           standings. There is a known trade-off in spoken di-
input without indicating that it is having interpre-         alogue systems between allowing misunderstand-
tation problems, and this is reflected in decreased          ings, i.e., cases in which a system accepts and
user satisfaction. We argue that this indicates that         acts on an incorrect interpretation of an utterance,
we need better strategies for dealing with termi-            and non-understandings, i.e., cases in which a sys-
nology problems, and that accepting non-standard             tem rejects an utterance as uninterpretable (Bo-
terminology without explicitly addressing the dif-           hus and Rudnicky, 2005). Since misunderstand-
ference in acceptable phrasing may not be suffi-             ings on the part of a computer tutor are known
cient for effective tutoring.                                to negatively impact student learning, and since
   In Section 2 we describe our tutoring system,             in human-human tutorial dialogue the majority of
and the two tutoring policies implemented for the            student responses using unexpected terminology
experiment. In Section 3 we present experimen-               are classified as incorrect (Jordan et al., 2009),
tal results and an analysis of correlations between          it would be a reasonable approach for a tutorial
different types of interpretation problems, learning         dialogue system to deal with potential interpreta-
gain and user satisfaction. Finally, in Section 4 we         tion problems by treating low-confidence interpre-
discuss the implications of our results for error re-        tations as non-understandings and focusing on an
covery policies in tutorial dialogue systems.                effective non-understanding recovery policy.1
                                                                We implemented two different policies for com-
2   Tutorial Dialogue System and Error                       parison. Our baseline policy does not attempt any
    Recovery Policies                                        remediation or error recovery. All student utter-
                                                             ances are passed through the standard interpreta-
This work is based on evaluation of B EETLE II               tion pipeline, so that the results can be analyzed
(Dzikovska et al., 2010), a tutorial dialogue sys-           later. However, the system does not attempt to ad-
tem which provides tutoring in basic electricity             dress the student content. Instead, regardless of
and electronics. Students read pre-authored mate-            the answer analysis, the system always uses a neu-
rials, experiment with a circuit simulator, and then         tral acceptance and bottom out strategy, giving the
are asked to explain their observations. B EETLE II          student the correct answer every time, e.g., “OK.
uses a deep parser together with a domain-specific           One way to phrase the correct answer is: the open
diagnoser to process student input, and a deep gen-          switch creates a gap in the circuit”. Thus, the stu-
erator to produce tutorial feedback automatically            dents are never given any indication of whether
depending on the current tutorial policy. It also            they have been understood or not.
implements an error recovery policy to deal with                The full policy acts differently depending on the
interpretation problems.                                     analysis of the student answer. For correct an-
   Students currently communicate with the sys-              swers, it acknowledges the answer as correct and
tem via a typed chat interface. While typing                 optionally restates it (see (Dzikovska et al., 2008)
removes the uncertainty and errors involved in               for details). For incorrect answers, it restates the
speech recognition, expected student answers are             correct portion of the answer (if any) and provides
considerably more complex and varied than in                 a hint to guide the student towards the completely
a typical spoken dialogue system. Therefore, a               correct answer. If the student’s utterance cannot be
significant number of interpretation errors arise,           interpreted, the system responds with a help mes-
primarily during the semantic interpretation pro-            sage indicating the cause of the problem together
cess. These errors can lead to non-understandings,           with a hint. In both cases, after 3 unsuccessful at-
when the system cannot produce a syntactic parse             tempts to address the problem the system uses the
(or a reasonable fragmentary parse), or when it              bottom out strategy and gives away the answer.
does not know how to interpret an out-of-domain
                                                                 1
word; and misunderstandings, where a system ar-                    While there is no confidence score from a speech recog-
                                                             nizer, our system uses a combination of a parse quality score
rives at an incorrect interpretation, due to either          assigned by the parser and a set of consistency checks to de-
an incorrect attachment in the parse, an incorrect           termine whether an interpretation is sufficiently reliable.


                                                        44


The content of the bottom out is the same as in              they were frustrated when the system said that it
the baseline, except that the full system indicates          did not understand them. However, some students
clearly that the answer was incorrect or was not             in BASE also mentioned that they sometimes were
understood, e.g., “Not quite. Here is the answer:            not sure if the system’s answer was correcting a
the open switch creates a gap in the circuit”.               problem with their answer, or simply phrasing it
   The help messages are based on the Targeted-              in a different way.
Help approach successfully used in spoken dia-                  We used mean frequency of non-interpretable
logue (Hockey et al., 2003), together with the error         utterances (out of all student utterances in
classification we developed for tutorial dialogue            each session) to evaluate the effectiveness of
(Dzikovska et al., 2009). There are 9 different er-          the two different policies. On average, 14%
ror types, each associated with a different targeted         of utterances in both conditions resulted in
help message. The goal of the help messages is to            non-understandings.2 The frequency of non-
give the student as much information as possible             understandings was negatively correlated with
as to why the system failed to understand them but           learning gain in FULL: r = −0.47, p < 0.005,
without giving away the answer.                              but not significantly correlated with learning gain
   In comparing the two policies, we would expect            in BASE: r = −0.09, p = 0.59. However, in both
that the students in both conditions would learn             conditions the frequency of non-understandings
something, but that the learning gain and user sat-          was negatively correlated with user satisfaction:
isfaction would be affected by the difference in             FULL r = −0.36, p = 0.03, BASE r = −0.4, p =
policies. We hypothesized that students who re-              0.01. Thus, even though in BASE the system
ceive feedback on their errors in the full condition         did not indicate non-understanding, students were
would learn more compared to those in the base-              negatively affected. That is, they were not satis-
line condition.                                              fied with the policy that did not directly address
                                                             the interpretation problems. We discuss possible
3   Evaluation                                               reasons for this below.
                                                                We investigated the effect of different types of
We collected data from 76 subjects interacting               interpretation errors using two criteria. First, we
with the system. The subjects were randomly as-              checked whether the mean frequency of errors was
signed to either the baseline (BASE) or the full             reduced between BASE and FULL for each individ-
(FULL) policy condition. Each subject took a pre-            ual strategy. The reduced frequency means that
test, then worked through a lesson with the system,          the recovery strategy for this particular error type
and then took a post-test and filled in a user satis-        is effective in reducing the error frequency. Sec-
faction survey. Each session lasted approximately            ond, we looked for the cases where the frequency
4 hours, with 232 student language turns in FULL             of a given error type is negatively correlated with
(SD = 25.6) and 156 in BASE (SD = 2.02). Ad-                 either learning gain or user satisfaction. This is
ditional time was taken by reading and interact-             provides evidence that such errors are negatively
ing with the simulation environment. The students            impacting the learning process, and therefore im-
had little prior knowledge of the domain. The sur-           proving recovery strategies for those error types is
vey consisted of 63 questions on the 5-point Lik-            likely to improve overall system effectiveness,
ert scale covering the lesson content, the graphical            The results, shown in Table 1, indicate that the
user interface, and tutor’s understanding and feed-          majority of interpretation problems are not sig-
back. For purposes of this study, we are using an            nificantly correlated with learning gain. How-
averaged tutor score.                                        ever, several types of problems appear to be
   The average learning gain was 0.57 (SD =                  particularly significant, and are all related to
0.23) in FULL, and 0.63 (SD = 0.26) in BASE.                 improper use of domain terminology. These
There was no significant difference in learning              were irrelevant answer, no appr terms, selec-
gain between conditions. Students liked BASE bet-            tional restriction failure and program error.
ter: the average tutor evaluation score for FULL                An irrelevant answer error occurs when the stu-
was 2.56 out of 5 (SD = 0.65), compared to 3.32              dent makes a statement that uses domain termi-
(SD = 0.65) in BASE. These results are signif-                  2
                                                                 We do not know the percentage of misunderstandings or
icantly different (t-test, p < 0.05). In informal            concept error rate as yet. We are currently annotating the data
comments after the session many students said that           with the goal to evaluate interpretation correctness.


                                                        45


                                                 full                                        baseline
                              mean freq.        satisfac-          gain      mean freq         satisfac-   gain
 error type
                              (std. dev)        tion r             r         (std. dev)        tion r      r
 irrelevant answer            0.008 (0.01)      -0.08              -0.19     0.012 (0.01)      -0.07       -0.47**
 no appr terms                0.005 (0.01)      -0.57**            -0.42**   0.003 (0.01)      -0.38**     -0.01
 selectional restr failure    0.032 (0.02)      -0.12              -0.55**   0.040 (0.03)      0.13        0.26*
 program error                0.002 (0.003)     0.02               0.26      0.003 (0.003)     0           -0.35**
 unknown word                 0.023 (0.01)      0.05               -0.21     0.024 (0.02)      -0.15       -0.09
 disambiguation failure       0.013 (0.01)      -0.04              0.02      0.007 (0.01)      -0.18       0.19
 no parse                     0.019 (0.01)      -0.14              -0.08     0.022(0.02)       -0.3*       0.01
 partial interpretation       0.004 (0.004)     -0.11              -0.01     0.004 (0.005)     -0.19       0.22
 reference failure            0.012 (0.02)      -0.31*             -0.09     0.017 (0.01)      -0.15       -0.23
 Overall                      0.134 (0.05)      -0.36**            -0.47**   0.139 (0.04)      -0.4**      -0.09

Table 1: Correlations between frequency of different error types and student learning gain and satisfac-
tion. ** - correlation is significant with p < 0.05, * - with p <= 0.1.


nology but does not appear to answer the system’s              tem’s domain knowledge. For example, the sys-
question directly. For example, the expected an-               tem can reason about damaged bulbs and batter-
swer to “In circuit 1, which components are in a               ies, and open and closed paths. So if the stu-
closed path?” is “the bulb”. Some students mis-                dent says “The path is damaged”, the FULL sys-
read the question and say “Circuit 1 is closed.” If            tem would respond with “I am sorry, I am having
that happens, in FULL the system says “Sorry, this             trouble understanding. Paths cannot be damaged.
isn’t the form of answer that I expected. I am look-           Only bulbs and batteries can be damaged.”
ing for a component”, pointing out to the student                 Program error were caused by faults in the un-
the kind of information it is looking for. The BASE            derlying network software, but usually occurred
system for this error, and for all other errors dis-           when the student was using extremely long and
cussed below, gives away the correct answer with-              complicated utterances.
out indicating that there was a problem with in-                  Out of the four important error types described
terpreting the student’s utterance, e.g., “OK, the             above, only the strategy for irrelevant answer was
correct answer is the bulb.”                                   effective: the frequency of irrelevant answer er-
   The no appr terms error happens when the stu-               rors is significantly higher in BASE (t-test, p <
dent is using terminology inappropriate for the les-           0.05), and it is negatively correlated with learning
son in general. Students are expected to learn to              gain in BASE. The frequencies of other error types
explain everything in terms of connections and ter-            did not significantly differ between conditions.
minal states. For example, the expected answer to                 However, one other finding is particularly in-
“What is voltage?” is “the difference in states be-            teresting: the frequency of no appr terms errors
tween two terminals”. If instead the student says              is negatively correlated with user satisfaction in
“Voltage is electricity”, FULL responds with “I am             BASE . This indicates that simply accepting the stu-
sorry, I am having trouble understanding. I see no             dent’s answer when they are using incorrect termi-
domain concepts in your answer. Here’s a hint:                 nology and exposing them to the correct answer is
your answer should mention a terminal.” The mo-                not the best strategy, possibly because the students
tivation behind this strategy is that in general, it is        are noticing the unexplained lack of alignment be-
very difficult to reason about vaguely used domain             tween their utterance and the system’s answer.
terminology. We had hoped that by telling the stu-
dent that the content of their utterance is outside            4   Discussion and Future Work
the domain as understood by the system, and hint-
ing at the correct terms to use, the system would              As discussed in Section 1, previous studies of
guide students towards a better answer.                        short-answer tutorial dialogue systems produced a
   Selectional restr failure errors are typically due          counter-intuitive result: measures of interpretation
to incorrect terminology, when the students                    accuracy were not correlated with learning gain.
phrased answers in a way that contradicted the sys-            With less restricted language, misunderstandings


                                                          46


negatively affected learning. Our study provides             conceivably be accepted by a system using seman-
further evidence that interpretation quality signif-         tic similarity as a metric (e.g., using LSA with pre-
icantly affects learning gain in tutorial dialogue.          authored answers). However, our results also indi-
Moreover, while it has long been known that user             cate that simply accepting the incorrect terminol-
satisfaction is negatively correlated with interpre-         ogy may not be the best strategy. Users appear to
tation error rates in spoken dialogue, this is the           be sensitive when the system’s language does not
first attempt to evaluate the impact of different            align with their terminology, as reflected in the de-
types of interpretation errors on task success and           creased satisfaction ratings associated with higher
usability of a tutoring system.                              rates of incorrect terminology problems in BASE.
   Our results demonstrate that different types of           Moreover, prior analysis of human-human data
errors may matter to a different degree. In our              indicates that tutors use different restate strate-
system, all of the error types negatively correlated         gies depending on the “quality” of the student an-
with learning gain stem from the same underlying             swers, even if they are accepting them as correct
problem: the use of incorrect or vague terminol-             (Dzikovska et al., 2008). Together, these point at
ogy by the student. With the exception of the ir-            an important unaddressed issue: existing systems
relevant answer strategy, the targeted help strate-          are often built on the assumption that only incor-
gies we implemented were not effective in reduc-             rect and missing parts of the student answer should
ing error frequency or improving learning gain.              be remediated, and a wide range of terminology
Additional research is needed to understand why.             should be accepted (Graesser et al., 1999; Jordan
One possibility is that irrelevant answer was eas-           et al., 2006). While it is obviously important for
ier to remediate compared to other error types. It           the system to accept a range of different phrasings,
usually happened in situations where there was a             our analysis indicates that this may not be suffi-
clear expectation of the answer type (e.g., a list of        cient by itself, and students could potentially ben-
component names, a yes/no answer). Therefore,                efit from addressing the terminology issues with a
it was easier to design an effective prompt. Help            specifically devised strategy.
messages for other error types were more frequent               Finally, it could also be possible that some
when the expected answer was a complex sen-                  differences between strategy effectiveness were
tence, and multiple possible ways of phrasing the            caused by incorrect error type classification. Man-
correct answer were acceptable. Therefore, it was            ual examination of several dialogues suggests that
more difficult to formulate a prompt that would              most of the errors are assigned to the appropri-
clearly describe the problem in all contexts.                ate type, though in some cases incorrect syntac-
                                                             tic parses resulted in unexpected interpretation er-
   One way to improve the help messages may be
                                                             rors, causing the system to give a confusing help
to have the system indicate more clearly when user
                                                             message. These misclassifications appear to be
terminology is a problem. Our system apologized
                                                             evenly split between different error types, though
each time there was a non-understanding, leading
                                                             a more formal evaluation is planned in the fu-
students to believe that they may be answering cor-
                                                             ture. However from our initial examination, we
rectly but the answer is not being understood. A
                                                             believe that the differences in strategy effective-
different approach would be to say something like
                                                             ness that we observed are due to the actual differ-
“I am sorry, you are not using the correct termi-
                                                             ences in the help messages. Therefore, designing
nology in your answer. Here’s a hint: your answer
                                                             better prompts would be the key factor in improv-
should mention a terminal”. Together with an ap-
                                                             ing learning and user satisfaction.
propriate mechanism to detect paraphrases of cor-
rect answers (as opposed to vague answers whose
                                                             Acknowledgments
correctness is difficult to determine), this approach
could be more beneficial in helping students learn.          This work has been supported in part by US Office
We are considering implementing and evaluating               of Naval Research grants N000140810043 and
this as part of our future work.                             N0001410WX20278. We thank Katherine Harri-
   Some of the errors, in particular instances of            son, Leanne Taylor, Charles Callaway, and Elaine
no appr terms and selectional restr failure, also            Farrow for help with setting up the system and
stemmed from unrecognized paraphrases with                   running the evaluation. We would like to thank
non-standard terminology. Those answers could                anonymous reviewers for their detailed feedback.


                                                        47


References                                                     Pamela Jordan, Diane Litman, Michael Lipschultz, and
                                                                 Joanna Drummond. 2009. Evidence of misunder-
V. Aleven, O. Popescu, and K. R. Koedinger. 2001.                standings in tutorial dialogue and their impact on
   Towards tutorial dialog to support self-explanation:          learning. In Proceedings of the 14th International
   Adding natural language understanding to a cogni-             Conference on Artificial Intelligence in Education
   tive tutor. In Proceedings of the 10th International          (AIED), Brighton, UK, July.
   Conference on Artificial Intelligence in Education
   (AIED ’01)”.                                                Diane Litman and Kate Forbes-Riley. 2005. Speech
Dan Bohus and Alexander Rudnicky. 2005. Sorry,                   recognition performance and learning in spoken di-
  I didn’t catch that! - An investigation of non-                alogue tutoring. In Proceedings of EUROSPEECH-
  understanding errors and recovery strategies. In               2005, page 1427.
  Proceedings of SIGdial-2005, Lisbon, Portugal.               Diane Litman, Johanna Moore, Myroslava Dzikovska,
Michelene T. H. Chi, Nicholas de Leeuw, Mei-Hung                 and Elaine Farrow. 2009. Generalizing tutorial dia-
  Chiu, and Christian LaVancher. 1994. Eliciting                 logue results. In Proceedings of 14th International
  self-explanations improves understanding. Cogni-               Conference on Artificial Intelligence in Education
  tive Science, 18(3):439–477.                                   (AIED), Brighton, UK, July.

Myroslava O. Dzikovska, Gwendolyn E. Campbell,                 Philip M. McCarthy, Vasile Rus, Scott Crossley,
 Charles B. Callaway, Natalie B. Steinhauser, Elaine             Arthur C. Graesser, and Danielle S. McNamara.
 Farrow, Johanna D. Moore, Leslie A. Butler, and                 2008. Assessing forward-, reverse-, and average-
 Colin Matheson. 2008. Diagnosing natural lan-                   entailment indeces on natural language input from
 guage answers to support adaptive tutoring. In                  the intelligent tutoring system, iSTART. In Proceed-
 Proceedings 21st International FLAIRS Conference,               ings of the 21st International FLAIRS conference,
 Coconut Grove, Florida, May.                                    pages 165–170.

Myroslava O. Dzikovska, Charles B. Callaway, Elaine            Rodney D. Nielsen, Wayne Ward, and James H. Mar-
 Farrow, Johanna D. Moore, Natalie B. Steinhauser,               tin. 2008. Learning to assess low-level conceptual
 and Gwendolyn C. Campbell. 2009. Dealing with                   understanding. In Proceedings 21st International
 interpretation errors in tutorial dialogue. In Pro-             FLAIRS Conference, Coconut Grove, Florida, May.
 ceedings of SIGDIAL-09, London, UK, Sep.
                                                               Heather Pon-Barry, Brady Clark, Elizabeth Owen
Myroslava O. Dzikovska, Johanna D. Moore, Natalie                Bratt, Karl Schultz, and Stanley Peters. 2004. Eval-
 Steinhauser, Gwendolyn Campbell, Elaine Farrow,                 uating the effectiveness of SCoT: A spoken conver-
 and Charles B. Callaway. 2010. Beetle II: a sys-                sational tutor. In J. Mostow and P. Tedesco, editors,
 tem for tutoring and computational linguistics ex-              Proceedings of the ITS 2004 Workshop on Dialog-
 perimentation. In Proceedings of ACL-2010 demo                  based Intelligent Tutoring Systems, pages 23–32.
 session.
                                                               Amruta Purandare and Diane Litman. 2008. Content-
A. C. Graesser, P. Wiemer-Hastings, P. Wiemer-                  learning correlations in spoken tutoring dialogs at
  Hastings, and R. Kreuz. 1999. Autotutor: A simula-            word, turn and discourse levels. In Proceedings 21st
  tion of a human tutor. Cognitive Systems Research,            International FLAIRS Conference, Coconut Grove,
  1:35–51.                                                      Florida, May.
Beth Ann Hockey, Oliver Lemon, Ellen Campana,
  Laura Hiatt, Gregory Aist, James Hieronymus,
  Alexander Gruenstein, and John Dowding. 2003.
  Targeted help for spoken dialogue systems: intelli-
  gent feedback improves naive users’ performance.
  In Proceedings of the tenth conference on European
  chapter of the Association for Computational Lin-
  guistics, pages 147–154, Morristown, NJ, USA.
Pamela W. Jordan, Maxim Makatchev, and Kurt Van-
  Lehn. 2004. Combining competing language under-
  standing approaches in an intelligent tutoring sys-
  tem. In James C. Lester, Rosa Maria Vicari, and
  Fábio Paraguaçu, editors, Intelligent Tutoring Sys-
  tems, volume 3220 of Lecture Notes in Computer
  Science, pages 346–357. Springer.
Pamela Jordan, Maxim Makatchev, Umarani Pap-
  puswamy, Kurt VanLehn, and Patricia Albacete.
  2006. A natural language tutorial dialogue system
  for physics. In Proceedings of the 19th International
  FLAIRS conference.


                                                          48

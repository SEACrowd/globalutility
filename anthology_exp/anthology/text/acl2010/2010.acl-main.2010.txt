               The Prevalence of Descriptive Referring Expressions
                             in News and Narrative
                   Raquel Hervás                                  Mark Alan Finlayson
             Departamento de Ingenieria                            Computer Science and
         del Software e Inteligencı́a Artificial             Artificial Intelligence Laboratory
         Universidad Complutense de Madrid                  Massachusetts Institute of Technology
                 Madrid, 28040 Spain                           Cambridge, MA, 02139 USA
             raquelhb@fdi.ucm.es                                    markaf@mit.edu

                     Abstract                               tify their intended referent. Referring expres-
                                                            sions, however, may be more than distinctive. It
    Generating referring expressions is a key               is widely acknowledged that they can be used to
    step in Natural Language Generation. Re-                achieve multiple goals, above and beyond distinc-
    searchers have focused almost exclusively               tion. Here we focus on descriptive referring ex-
    on generating distinctive referring expres-             pressions, that is, referring expressions that are not
    sions, that is, referring expressions that              only distinctive, but provide additional informa-
    uniquely identify their intended referent.              tion not required for identifying their intended ref-
    While undoubtedly one of their most im-                 erent. Consider the following text, in which some
    portant functions, referring expressions                of the referring expressions have been underlined:
    can be more than distinctive. In particular,
    descriptive referring expressions – those                 Once upon a time there was a man, who had
    that provide additional information not re-               three daughters. They lived in a house and
    quired for distinction – are critical to flu-             their dresses were made of fabric.
    ent, efficient, well-written text. We present
    a corpus analysis in which approximately                   While a bit strange, the text is perfectly well-
    one-fifth of 7,207 referring expressions in             formed. All the referring expressions are distinc-
    24,422 words of news and narrative are de-              tive, in that we can properly identify the referents
    scriptive. These data show that if we are               of each expression. But the real text, the opening
    ever to fully master natural language gen-              lines to the folktale The Beauty and the Beast, is
    eration, especially for the genres of news              actually much more lyrical:
    and narrative, researchers will need to de-
    vote more attention to understanding how                  Once upon a time there was a rich merchant,
    to generate descriptive, and not just dis-                who had three daughters. They lived in a
    tinctive, referring expressions.                          very fine house and their gowns were made
                                                              of the richest fabric sewn with jewels.
1   A Distinctive Focus
                                                               All the boldfaced portions – namely, the choice
Generating referring expressions is a key step in           of head nouns, the addition of adjectives, the use
Natural Language Generation (NLG). From early               of appositive phrases – serve to perform a descrip-
treatments in seminal papers by Appelt (1985)               tive function, and, importantly, are all unneces-
and Reiter and Dale (1992) to the recent set                sary for distinction! In all of these cases, the au-
of Referring Expression Generation (REG) Chal-              thor is using the referring expressions as a vehi-
lenges (Gatt et al., 2009) through different corpora        cle for communicating information about the ref-
available for the community (Eugenio et al., 1998;          erents. This descriptive information is sometimes
van Deemter et al., 2006; Viethen and Dale, 2008),          new, sometimes necessary for understanding the
generating referring expressions has become one             text, and sometimes just for added flavor. But
of the most studied areas of NLG.                           when the expression is descriptive, as opposed to
   Researchers studying this area have, almost              distinctive, this additional information is not re-
without exception, focused exclusively on how               quired for identifying the referent of the expres-
to generate distinctive referring expressions, that         sion, and it is these sorts of referring expressions
is, referring expressions that unambiguously iden-          that we will be concerned with here.


                                                       49
                        Proceedings of the ACL 2010 Conference Short Papers, pages 49–54,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


   Although these sorts of referring expression                      museum labels, Cheng et al. (2001) noted that de-
have been mostly ignored by researchers in this                      scriptive information is often integrated into refer-
area1 , we show in this corpus study that descrip-                   ring expressions using modifiers to the head noun.
tive expressions are in fact quite prevalent: nearly                 To study this, and to allow our results to be more
one-fifth of referring expressions in news and nar-                  closely compared with Cheng’s, we had our an-
rative are descriptive. In particular, our data,                     notators split referring expressions into their con-
the trained judgments of native English speakers,                    stituents, portions called either nuclei or modifiers.
show that 18% of all distinctive referring expres-                   The nuclei were the portions of the referring ex-
sions in news and 17% of those in narrative folk-                    pression that performed the ‘core’ referring func-
tales are descriptive. With this as motivation, we                   tion; the modifiers were those portions that could
argue that descriptive referring expressions must                    be varied, syntactically speaking, independently of
be studied more carefully, especially as the field                   the nuclei. Annotators then assigned a distinctive
progresses from referring in a physical, immedi-                     or descriptive function to each constituent, rather
ate context (like that in the REG Challenges) to                     than the referring expression as a whole.
generating more literary forms of text.                                 Normally, the nuclei corresponded to the head
                                                                     of the noun phrase. In (1), the nucleus is the token
2    Corpus Annotation                                               king, which we have here surrounded with square
                                                                     brackets. The modifiers, surrounded by parenthe-
This is a corpus study; our procedure was there-
                                                                     ses, are The and old.
fore to define our annotation guidelines (Sec-
tion 2.1), select texts to annotate (2.2), create an                 (1) (The) (old) [king] was wise.
annotation tool for our annotators (2.3), and, fi-
nally, train annotators, have them annotate refer-                      Phrasal modifiers were marked as single modi-
ring expressions’ constituents and function, and                     fiers, for example, in (2).
then adjudicate the double-annotated texts into a
gold standard (2.4).                                                 (2)   (The) [roof] (of the house) collapsed.

2.1 Definitions                                                         It is significant that we had our annotators mark
                                                                     and tag the nuclei of referring expressions. Cheng
We wrote an annotation guide explaining the dif-
                                                                     and colleagues only mentioned the possibility that
ference between distinctive and descriptive refer-
                                                                     additional information could be introduced in the
ring expressions. We used the guide when train-
                                                                     modifiers. However, O’Donnell et al. (1998) ob-
ing annotators, and it was available to them while
                                                                     served that often the choice of head noun can also
annotating. With limited space here we can only
                                                                     influence the function of a referring expression.
give an outline of what is contained in the guide;
                                                                     Consider (3), in which the word villain is used to
for full details see (Finlayson and Hervás, 2010a).
                                                                     refer to the King.
    Referring Expressions We defined referring
expressions as referential noun phrases and their                    (3) The King assumed the throne today.
coreferential expressions, e.g., “John kissed Mary.
                                                                           I don’t trust (that) [villain] one bit.
She blushed.”. This included referring expressions
to generics (e.g., “Lions are fierce”), dates, times,                   The speaker could have merely used him to re-
and numbers, as well as events if they were re-                      fer to the King–the choice of that particular head
ferred to using a noun phrase. We included in each                   noun villain gives us additional information about
referring expression all the determiners, quan-                      the disposition of the speaker. Thus villain is de-
tifiers, adjectives, appositives, and prepositional                  scriptive.
phrases that syntactically attached to that expres-                     Function: Distinctive vs. Descriptive As al-
sion. When referring expressions were nested, all                    ready noted, instead of tagging the whole re-
the nested referring expressions were also marked                    ferring expression, annotators tagged each con-
separately.                                                          stituent (nuclei and modifiers) as distinctive or de-
    Nuclei vs. Modifiers In the only previous cor-                   scriptive.
pus study of descriptive referring expressions, on                      The two main tests for determining descriptive-
    1
      With the exception of a small amount of work, discussed        ness were (a) if presence of the constituent was
in Section 4.                                                        unnecessary for identifying the referent, or (b) if


                                                                50


the constituent was expressed using unusual or os-          program that, among other things, includes the
tentatious word choice. If either was true, the con-        ability to annotate referring expressions and coref-
stituent was considered descriptive; otherwise, it          erential relationships. We added the ability to an-
was tagged as distinctive. In cases where the con-          notate nuclei, modifiers, and their functions by
stituent was completely irrelevant to identifying           writing a workbench “plugin” in Java that could
the referent, it was tagged as descriptive. For ex-         be installed in the application.
ample, in the folktale The Princess and the Pea,               The Story Workbench is not yet available to the
from which (1) was extracted, there is only one             public at large, being in a limited distribution beta
king in the entire story. Thus, in that story, the          testing phase. The developers plan to release it as
king is sufficient for identification, and therefore        free software within the next year. At that time,
the modifier old is descriptive. This points out the        we also plan to release our plugin as free, down-
importance of context in determining distinctive-           loadable software.
ness or descriptiveness; if there had been a room-
ful of kings, the tags on those modifiers would             2.4 Annotation & Adjudication
have been reversed.
   There is some question as to whether copular             The main task of the study was the annotation of
predicates, such as the plumber in (4), are actually        the constituents of each referring expression, as
referring expressions.                                      well as the function (distinctive or descriptive) of
                                                            each constituent. The system generated a first pass
(4) John is the plumber                                     of constituent analysis, but did not mark functions.
                                                            We hired two native English annotators, neither of
Our annotators marked and tagged these construc-            whom had any linguistics background, who cor-
tions as normal referring expressions, but they             rected these automatically-generated constituent
added an additional flag to identify them as cop-           analyses, and tagged each constituent as descrip-
ular predicates. We then excluded these construc-           tive or distinctive. Every text was annotated by
tions from our final analysis. Note that copular            both annotators. Adjudication of the differences
predicates were treated differently from apposi-            was conducted by discussion between the two an-
tives: in appositives the predicate was included in         notators; the second author moderated these dis-
the referring expression, and in most cases (again,         cussions and settled irreconcilable disagreements.
depending on context) was marked descriptive                We followed a “train-as-you-go” paradigm, where
(e.g., John, the plumber, slept.).                          there was no distinct training period, but rather
                                                            adjudication proceeded in step with annotation,
2.2 Text Selection                                          and annotators received feedback during those ses-
Our corpus comprised 62 texts, all originally writ-         sions.
ten in English, from two different genres, news                We calculated two measures of inter-annotator
and folktales. We began with 30 folktales of dif-           agreement: a kappa statistic and an f-measure,
ferent sizes, totaling 12,050 words. These texts            shown in Table 1. All of our f-measures indicated
were used in a previous work on the influence of            that annotators agreed almost perfectly on the lo-
dialogues on anaphora resolution algorithms (Ag-            cation of referring expressions and their break-
garwal et al., 2009); they were assembled with an           down into constituents. These agreement calcu-
eye toward including different styles, different au-        lations were performed on the annotators’ original
thors, and different time periods. Following this,          corrected texts.
we matched, approximately, the number of words                 All the kappa statistics were calculated for two
in the folktales by selecting 32 texts from Wall            tags (nuclei vs. modifier for the constituents, and
Street Journal section of the Penn Treebank (Mar-           distinctive vs. descriptive for the functions) over
cus et al., 1993). These texts were selected at ran-        both each token assigned to a nucleus or modifier
dom from the first 200 texts in the corpus.                 and each referring expression pair. Our kappas in-
                                                            dicate moderate to good agreement, especially for
2.3 The Story Workbench                                     the folktales. These results are expected because
We used the Story Workbench application (Fin-               of the inherent subjectivity of language. During
layson, 2008) to actually perform the annotation.           the adjudication sessions it became clear that dif-
The Story Workbench is a semantic annotation                ferent people do not consider the same information


                                                       51


as obvious or descriptive for the same concepts,                                    Tales    Articles    Total
and even the contexts deduced by each annotators                Nuclei              3,666     3,502      7,168
from the texts were sometimes substantially dif-                Max. Nuc/Ref          1         1          1
ferent.                                                         Dist. Nuc.          95%       97%        96%
                                                                Desc. Nuc.           5%        3%         4%
                           Tales    Articles    Total           Modifiers           2,277     3,627      5,904
 Ref. Exp. (F1 )           1.00      0.99       0.99            Avg. Mod/Ref         0.6       1.0        0.8
 Constituents (F1 )        0.99      0.98       0.98            Max. Mod/Ref          4         6          6
 Nuc./Mod. (κ)             0.97      0.95       0.96            Dist. Mod.          78%       81%        80%
 Const. Func. (κ)          0.61      0.48       0.54            Desc. Mod.          22%       19%        20%
 Ref. Exp. Func. (κ)       0.65      0.54       0.59
                                                                  Table 3: Breakdown of Constituent Tags
    Table 1: Inter-annotator agreement measures

                                                             are three. First is the general study of aggregation
3     Results                                                in the process of referring expression generation.
Table 2 lists the primary results of the study. We           Second and third are corpus studies by Cheng et al.
considered a referring expression descriptive if             (2001) and Jordan (2000a) that bear on the preva-
any of its constituents were descriptive. Thus,              lence of descriptive referring expressions.
18% of the referring expressions in the corpus                  The NLG subtask of aggregation can be used
added additional information beyond what was re-             to imbue referring expressions with a descriptive
quired to unambiguously identify their referent.             function (Reiter and Dale, 2000, §5.3). There is a
The results were similar in both genres.                     specific kind of aggregation called embedding that
                                                             moves information from one clause to another in-
                         Tales     Articles     Total        side the structure of a separate noun phrase. This
    Texts                 30          32          62         type of aggregation can be used to transform two
    Words               12,050     12,372      24,422        sentences such as “The princess lived in a castle.
    Sentences             904        571       1,475         She was pretty” into “The pretty princess lived in
    Ref. Exp.            3,681      3,526       7,207        a castle”. The adjective pretty, previously a cop-
    Dist. Ref. Exp.     3,057       2,830      5,887         ular predicate, becomes a descriptive modifier of
    Desc. Ref. Exp.       609        672       1,281         the reference to the princess, making the second
    % Dist. Ref.         83%        81%         82%          text more natural and fluent. This kind of ag-
    % Desc. Ref.         17%        19%         18%          gregation is widely used by humans for making
                                                             the discourse more compact and efficient. In or-
                Table 2: Primary results.                    der to create NLG systems with this ability, we
                                                             must take into account the caveat, noted by Cheng
   Table 3 contains the percentages of descriptive           (1998), that any non-distinctive information in a
and distinctive tags broken down by constituent.             referring expression must not lead to confusion
Like Cheng’s results, our analysis shows that de-            about the distinctive function of the referring ex-
scriptive referring expressions make up a signif-            pression. This is by no means a trivial problem
icant fraction of all referring expressions. Al-             – this sort of aggregation interferes with refer-
though Cheng did not examine nuclei, our results             ring and coherence planning at both a local and
show that the use of descriptive nuclei is small but         global level (Cheng and Mellish, 2000; Cheng et
not negligible.                                              al., 2001). It is clear, from the current state of the
                                                             art of NLG, that we have not yet obtained a deep
4     Relation to the Field                                  enough understanding of aggregation to enable us
Researchers working on generating referring ex-              to handle these interactions. More research on the
pressions typically acknowledge that referring ex-           topic is needed.
pressions can perform functions other than distinc-             Two previous corpus studies have looked at
tion. Despite this widespread acknowledgment,                the use of descriptive referring expressions. The
researchers have, for the most part, explicitly ig-          first showed explicitly that people craft descrip-
nored these functions. Exceptions to this trend              tive referring expressions to accomplish different


                                                        52


goals. Jordan and colleagues (Jordan, 2000b; Jor-            judicated into a gold-standard a corpus of 24,422
dan, 2000a) examined the use of referring expres-            words. We marked all referring expressions,
sions using the COCONUT corpus (Eugenio et                   coreferential relations, and referring expression
al., 1998). They tested how domain and discourse             constituents, and tagged each constituent as hav-
goals can influence the content of non-pronominal            ing a descriptive or distinctive function. We wrote
referring expressions in a dialogue context, check-          an annotation guide and created software that al-
ing whether or not a subject’s goals led them to in-         lows the annotation of this information in free text.
clude non-referring information in a referring ex-           The corpus and the guide are available on-line in a
pression. Their results are intriguing because they          permanent digital archive (Finlayson and Hervás,
point toward heretofore unexamined constraints,              2010a; Finlayson and Hervás, 2010b). The soft-
utilities and expectations (possibly genre- or style-        ware will also be released in the same archive
dependent) that may underlie the use of descriptive          when the Story Workbench annotation application
information to perform different functions, and are          is released to the public. This corpus will be useful
not yet captured by aggregation modules in partic-           for the automatic generation and analysis of both
ular or NLG systems in general.                              descriptive and distinctive referring expressions.
   In the other corpus study, which partially in-            Any kind of system intended to generate text as
spired this work, Cheng and colleagues analyzed              humans do must take into account that identifica-
a set of museum descriptions, the GNOME cor-                 tion is not the only function of referring expres-
pus (Poesio, 2004), for the pragmatic functions of           sions. Many analysis applications would benefit
referring expressions. They had three functions              from the automatic recognition of descriptive re-
in their study, in contrast to our two. Their first          ferring expressions.
function (marked by their uniq tag) was equiv-                  Second, we demonstrated that descriptive refer-
alent to our distinctive function. The other two             ring expressions comprise a substantial fraction
were specializations of our descriptive tag, where           (18%) of the referring expressions in news and
they differentiated between additional information           narrative. Along with museum descriptions, stud-
that helped to understand the text (int), or ad-             ied by Cheng, it seems that news and narrative are
ditional information not necessary for understand-           genres where authors naturally use a large num-
ing (attr). Despite their annotators seeming to              ber of descriptive referring expressions. Given that
have trouble distinguishing between the latter two           so little work has been done on descriptive refer-
tags, they did achieve good overall inter-annotator          ring expressions, this indicates that the field would
agreement. They identified 1,863 modifiers to                be well served by focusing more attention on this
referring expressions in their corpus, of which              phenomenon.
47.3% fulfilled a descriptive (attr or int) func-
tion. This is supportive of our main assertion,              Acknowledgments
namely, that descriptive referring expressions, not
only crucial for efficient and fluent text, are ac-          This work was supported in part by the Air
tually a significant phenomenon. It is interest-             Force Office of Scientific Research under grant
ing, though, that Cheng’s fraction of descriptive            number A9550-05-1-0321, as well as by the
referring expression was so much higher than ours            Office of Naval Research under award number
(47.3% versus our 18%). We attribute this sub-               N00014091059. Any opinions, findings, and con-
stantial difference to genre, in that Cheng stud-            clusions or recommendations expressed in this pa-
ied museum labels, in which the writer is space-             per are those of the authors and do not necessarily
constrained, having to pack a lot of information             reflect the views of the Office of Naval Research.
into a small label. The issue bears further study,           This research is also partially funded the Span-
and perhaps will lead to insights into differences           ish Ministry of Education and Science (TIN2009-
in writing style that may be attributed to author or         14659-C03-01) and Universidad Complutense de
genre.                                                       Madrid (GR58/08). We also thank Whitman
                                                             Richards, Ozlem Uzuner, Peter Szolovits, Patrick
5   Contributions                                            Winston, Pablo Gervás, and Mark Seifter for their
                                                             helpful comments and discussion, and thank our
We make two contributions in this paper.                     annotators Saam Batmanghelidj and Geneva Trot-
 First, we assembled, double-annotated, and ad-              ter.


                                                        53


References                                                      European Workshop on Natural Language Genera-
                                                                tion, pages 174–182, Morristown, NJ, USA. Associ-
Alaukik Aggarwal, Pablo Gervás, and Raquel Hervás.            ation for Computational Linguistics.
  2009. Measuring the influence of errors induced by
  the presence of dialogues in reference clustering of        Pamela W. Jordan. 2000a. Can nominal expressions
  narrative text. In Proceedings of ICON-2009: 7th              achieve multiple goals?: an empirical study. In ACL
  International Conference on Natural Language Pro-             ’00: Proceedings of the 38th Annual Meeting on As-
  cessing, India. Macmillan Publishers.                         sociation for Computational Linguistics, pages 142–
                                                                149, Morristown, NJ, USA. Association for Compu-
Douglas E. Appelt. 1985. Planning English referring             tational Linguistics.
  expressions. Artificial Intelligence, 26:1–33.
                                                              Pamela W. Jordan. 2000b. Influences on attribute se-
Hua Cheng and Chris Mellish. 2000. Capturing the in-            lection in redescriptions: A corpus study. In Pro-
  teraction between aggregation and text planning in            ceedings of CogSci2000, pages 250–255.
  two generation systems. In INLG ’00: First interna-
  tional conference on Natural Language Generation            Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
  2000, pages 186–193, Morristown, NJ, USA. Asso-               Beatrice Santorini. 1993. Building a large anno-
  ciation for Computational Linguistics.                        tated corpus of english: the penn treebank. Compu-
                                                                tational Linguistics, 19(2):313–330.
Hua Cheng, Massimo Poesio, Renate Henschel, and
  Chris Mellish. 2001. Corpus-based np modifier               Michael O’Donnell, Hua Cheng, and Janet Hitze-
  generation. In NAACL ’01: Second meeting of                   man. 1998. Integrating referring and informing in
  the North American Chapter of the Association for             NP planning. In Proceedings of COLING-ACL’98
  Computational Linguistics on Language technolo-               Workshop on the Computational Treatment of Nom-
  gies 2001, pages 1–8, Morristown, NJ, USA. Asso-              inals, pages 46–56.
  ciation for Computational Linguistics.
                                                              Massimo Poesio. 2004. Discourse annotation and
Hua Cheng. 1998. Embedding new information into                semantic annotation in the GNOME corpus. In
  referring expressions. In ACL-36: Proceedings of             DiscAnnotation ’04: Proceedings of the 2004 ACL
  the 36th Annual Meeting of the Association for Com-          Workshop on Discourse Annotation, pages 72–79,
  putational Linguistics and 17th International Con-           Morristown, NJ, USA. Association for Computa-
  ference on Computational Linguistics, pages 1478–            tional Linguistics.
  1480, Morristown, NJ, USA. Association for Com-
  putational Linguistics.                                     Ehud Reiter and Robert Dale. 1992. A fast algorithm
                                                                for the generation of referring expressions. In Pro-
Barbara Di Eugenio, Johanna D. Moore, Pamela W.                 ceedings of the 14th conference on Computational
  Jordan, and Richmond H. Thomason. 1998. An                    linguistics, Nantes, France.
  empirical investigation of proposals in collabora-
  tive dialogues. In Proceedings of the 17th inter-           Ehud Reiter and Robert Dale. 2000. Building Natural
  national conference on Computational linguistics,             Language Generation Systems. Cambridge Univer-
  pages 325–329, Morristown, NJ, USA. Association               sity Press.
  for Computational Linguistics.
                                                              Kees van Deemter, Ielka van der Sluis, and Albert Gatt.
Mark A. Finlayson and Raquel Hervás. 2010a. Anno-              2006. Building a semantically transparent corpus
 tation guide for the UCM/MIT indications, referring            for the generation of referring expressions. In Pro-
 expressions, and coreference corpus (UMIREC cor-               ceedings of the 4th International Conference on Nat-
 pus). Technical Report MIT-CSAIL-TR-2010-025,                  ural Language Generation (Special Session on Data
 MIT Computer Science and Artificial Intelligence               Sharing and Evaluation), INLG-06.
 Laboratory. http://hdl.handle.net/1721.1/54765.
                                                              Jette Viethen and Robert Dale. 2008. The use of spa-
Mark A. Finlayson and Raquel Hervás.       2010b.               tial relations in referring expressions. In Proceed-
 UCM/MIT         indications,    referring expres-               ings of the 5th International Conference on Natural
 sions,     and coreference corpus (UMIREC                       Language Generation.
 corpus).     Work product, MIT Computer Sci-
 ence and Artificial Intelligence Laboratory.
 http://hdl.handle.net/1721.1/54766.
Mark A. Finlayson. 2008. Collecting semantics in
 the wild: The Story Workbench. In Proceedings of
 the AAAI Fall Symposium on Naturally-Inspired Ar-
 tificial Intelligence, pages 46–53, Menlo Park, CA,
 USA. AAAI Press.
Albert Gatt, Anja Belz, and Eric Kow. 2009. The
  TUNA-REG challenge 2009: overview and evalu-
  ation results. In ENLG ’09: Proceedings of the 12th


                                                         54

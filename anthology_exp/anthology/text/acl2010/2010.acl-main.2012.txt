         Cognitively Plausible Models of Human Language Processing
                                            Frank Keller
                           School of Informatics, University of Edinburgh
                            10 Crichton Street, Edinburgh EH8 9AB, UK
                                      keller@inf.ed.ac.uk


                     Abstract                                linguistics (CL). To test their theories, psycholin-
                                                             guists construct computational models of hu-
    We pose the development of cognitively                   man language processing, but these models of-
    plausible models of human language pro-                  ten fall short of the engineering standards that
    cessing as a challenge for computational                 are generally accepted in the CL community
    linguistics. Existing models can only deal               (e.g., broad coverage, robustness, efficiency): typ-
    with isolated phenomena (e.g., garden                    ical psycholinguistic models only deal with iso-
    paths) on small, specifically selected data              lated phenomena and fail to scale to realistic data
    sets. The challenge is to build models that              sets. A particular issue is evaluation, which is typ-
    integrate multiple aspects of human lan-                 ically anecdotal, performed on a small set of hand-
    guage processing at the syntactic, seman-                crafted examples (see Sections 3).
    tic, and discourse level. Like human lan-                   In this paper, we propose a challenge that re-
    guage processing, these models should be                 quires the combination of research efforts in com-
    incremental, predictive, broad coverage,                 putational linguistics and psycholinguistics: the
    and robust to noise. This challenge can                  development of cognitively plausible models of
    only be met if standardized data sets and                human language processing. This task can be de-
    evaluation measures are developed.                       composed into a modeling challenge (building
                                                             models that instantiate known properties of hu-
1   Introduction                                             man language processing) and a data and evalu-
                                                             ation challenge (accounting for experimental find-
In many respects, human language processing is
                                                             ings and evaluating against standardized data sets),
the ultimate goldstandard for computational lin-
                                                             which we will discuss in turn.
guistics. Humans understand and generate lan-
guage with amazing speed and accuracy, they are              2     Modeling Challenge
able to deal with ambiguity and noise effortlessly
and can adapt to new speakers, domains, and reg-             2.1    Key Properties
isters. Most surprisingly, they achieve this compe-          The first part of the challenge is to develop a model
tency on the basis of limited training data (Hart            that instantiates key properties of human language
and Risley, 1995), using learning algorithms that            processing, as established by psycholinguistic ex-
are largely unsupervised.                                    perimentation (see Table 1 for an overview and
   Given the impressive performance of humans                representative references).1 A striking property of
as language processors, it seems natural to turn             the human language processor is its efficiency and
to psycholinguistics, the discipline that studies hu-        robustness. For the vast majority of sentences, it
man language processing, as a source of informa-             will effortlessly and rapidly deliver the correct
tion about the design of efficient language pro-             analysis, even in the face of noise and ungrammat-
cessing systems. Indeed, psycholinguists have un-            icalities. There is considerable experimental evi-
covered an impressive array of relevant facts (re-               1 Here an in the following, we will focus on sentence
viewed in Section 2), but computational linguists            processing, which is often regarded as a central aspect of
are often not aware of this literature, and results          human language processing. A more comprehensive answer
                                                             to our modeling challenge should also include phonological
about human language processing rarely inform                and morphological processing, semantic inference, discourse
the design, implementation, or evaluation of artifi-         processing, and other non-syntactic aspects of language pro-
cial language processing systems.                            cessing. Furthermore, established results regarding the inter-
                                                             face between language processing and non-linguistic cogni-
   At the same time, research in psycholinguis-              tion (e.g., the sensorimotor system) should ultimately be ac-
tics is often oblivious of work in computational             counted for in a fully comprehensive model.


                                                        60
                        Proceedings of the ACL 2010 Conference Short Papers, pages 60–67,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


                                                                                                          Model
 Property                            Evidence
                                                                                              Rank     Surp Pred        Stack
 Efficiency and robustness           Ferreira et al. (2001); Sanford and Sturt (2002)          −        −     −           +
 Broad coverage                      Crocker and Brants (2000)                                 +        +     −           +
 Incrementality and connectedness    Tanenhaus et al. (1995); Sturt and Lombardo (2005)        +        +     +           +
 Prediction                          Kamide et al. (2003); Staub and Clifton (2006)            −        ±     +           −
 Memory cost                         Gibson (1998); Vasishth and Lewis (2006)                  −        −     +           +
Table 1: Key properties of human language processing and their instantiation in various models of sentence processing (see
Section 2 for details)


dence that shallow processing strategies are used               model properties).2
to achieve this. The processor also achieves broad                 The earliest approaches were ranking-based
coverage: it can deal with a wide variety of syntac-            models (Rank), which make psycholinguistic pre-
tic constructions, and is not restricted by the do-             dictions based on the ranking of the syntactic
main, register, or modality of the input.                       analyses produced by a probabilistic parser. Ju-
   Human language processing is also word-by-                   rafsky (1996) assumes that processing difficulty
word incremental. There is strong evidence that                 is triggered if the correct analysis falls below a
a new word is integrated as soon as it is avail-                certain probability threshold (i.e., is pruned by
able into the representation of the sentence thus               the parser). Similarly, Crocker and Brants (2000)
far. Readers and listeners experience differential              assume that processing difficulty ensures if the
processing difficulty during this integration pro-              highest-ranked analysis changes from one word to
cess, depending on the properties of the new word               the next. Both approaches have been shown to suc-
and its relationship to the preceding context. There            cessfully model garden path effects. Being based
is evidence that the processor instantiates a strict            on probabilistic parsing techniques, ranking-based
form of incrementality by building only fully con-              models generally achieve a broad coverage, but
nected trees. Furthermore, the processor is able                their efficiency and robustness has not been evalu-
to make predictions about upcoming material on                  ated. Also, they are not designed to capture syntac-
the basis of sentence prefixes. For instance, listen-           tic prediction or memory effects (other than search
ers can predict an upcoming post-verbal element                 with a narrow beam in Brants and Crocker 2000).
based on the semantics of the preceding verb. Or                   The ranking-based approach has been gener-
they can make syntactic predictions, e.g., if they              alized by surprisal models (Surp), which pre-
encounter the word either, they predict an upcom-               dict processing difficulty based on the change in
ing or and the type of complement that follows it.              the probability distribution over possible analy-
   Another key property of human language pro-                  ses from one word to the next (Hale, 2001; Levy,
cessing is the fact that it operates with limited               2008; Demberg and Keller, 2008a; Ferrara Boston
memory, and that structures in memory are subject               et al., 2008; Roark et al., 2009). These models
to decay and interference. In particular, the pro-              have been successful in accounting for a range of
cessor is known to incur a distance-based memory                experimental data, and they achieve broad cover-
cost: combining the head of a phrase with its syn-              age. They also instantiate a limited form of predic-
tactic dependents is more difficult the more depen-             tion, viz., they build up expectations about the next
dents have to be integrated and the further away                word in the input. On the other hand, the efficiency
they are. This integration process is also subject              and robustness of these models has largely not
to interference from similar items that have to be              been evaluated, and memory costs are not mod-
held in memory at the same time.                                eled (again except for restrictions in beam size).
                                                                   The prediction model (Pred) explicitly predicts
2.2   Current Models                                            syntactic structure for upcoming words (Demberg
                                                                and Keller, 2008b, 2009), thus accounting for ex-
The challenge is to develop a computational model
                                                                perimental results on predictive language process-
that captures the key properties of human language
                                                                ing. It also implements a strict form of incre-
processing outlined in the previous section. A
number of relevant models have been developed,                     2 We   will not distinguish between model and linking the-
mostly based on probabilistic parsing techniques,               ory, i.e., the set of assumptions that links model quantities
                                                                to behavioral data (e.g., more probably structures are easier
but none of them instantiates all the key proper-               to process). It is conceivable, for instance, that a stack-based
ties discussed above (Table 1 gives an overview of              model is combined with a linking theory based on surprisal.


                                                           61


 Factor            Evidence                                     the development of language processing models
 Word senses       Roland and Jurafsky (2002)
 Selectional re-   Garnsey et al. (1997); Pickering and         that combine syntactic processing with semantic
 strictions        Traxler (1998)                               and discourse processing. So far, this challenge is
 Thematic roles    McRae et al. (1998); Pickering et al.        largely unmet: there are some examples of models
                   (2000)
 Discourse ref-    Altmann and Steedman (1988); Grod-           that integrate semantic processes such as thematic
 erence            ner and Gibson (2005)                        role assignment into a parsing model (Narayanan
 Discourse         Stewart et al. (2000); Kehler et al.
 coherence         (2008)
                                                                and Jurafsky, 2002; Padó et al., 2009). However,
                                                                other semantic factors are not accounted for by
 Table 2: Semantic factors in human language processing
                                                                these models, and incorporating non-lexical as-
                                                                pects of semantics into models of sentence pro-
mentality by building fully connected trees. Mem-               cessing is a challenge for ongoing research. Re-
ory costs are modeled directly as a distance-based              cently, Dubey (2010) has proposed an approach
penalty that is incurred when a prediction has to be            that combines a probabilistic parser with a model
verified later in the sentence. However, the current            of co-reference and discourse inference based on
implementation of the prediction model is neither               probabilistic logic. An alternative approach has
robust and efficient nor offers broad coverage.                 been taken by Pynte et al. (2008) and Mitchell
   Recently, a stack-based model (Stack) has been               et al. (2010), who combine a vector-space model
proposed that imposes explicit, cognitively mo-                 of semantics (Landauer and Dumais, 1997) with a
tivated memory constraints on the parser, in ef-                syntactic parser and show that this results in pre-
fect limiting the stack size available to the parser            dictions of processing difficulty that can be vali-
(Schuler et al., 2010). This delivers robustness, ef-           dated against an eye-tracking corpus.
ficiency, and broad coverage, but does not model
syntactic prediction. Unlike the other models dis-              2.4   Acquisition and Crosslinguistics
cussed here, no psycholinguistic evaluation has
been conducted on the stack-based model, so its                 All models of human language processing dis-
cognitive plausibility is preliminary.                          cussed so far rely on supervised training data. This
                                                                raises another aspect of the modeling challenge:
2.3   Beyond Parsing                                            the human language processor is the product of
There is strong evidence that human language pro-               an acquisition process that is largely unsupervised
cessing is driven by an interaction of syntactic, se-           and has access to only limited training data: chil-
mantic, and discourse processes (see Table 2 for                dren aged 12–36 months are exposed to between
an overview and references). Considerable exper-                10 and 35 million words of input (Hart and Ris-
imental work has focused on the semantic prop-                  ley, 1995). The challenge therefore is to develop
erties of the verb of the sentence, and verb sense,             a model of language acquisition that works with
selectional restrictions, and thematic roles have all           such small training sets, while also giving rise to
been shown to interact with syntactic ambiguity                 a language processor that meets the key criteria
resolution. Another large body of research has elu-             in Table 1. The CL community is in a good posi-
cidated the interaction of discourse processing and             tion to rise to this challenge, given the significant
syntactic processing. The most-well known effect                progress in unsupervised parsing in recent years
is probably that of referential context: syntactic              (starting from Klein and Manning 2002). How-
ambiguities can be resolved if a discourse con-                 ever, none of the existing unsupervised models has
text is provided that makes one of the syntactic                been evaluated against psycholinguistic data sets,
alternatives more plausible. For instance, in a con-            and they are not designed to meet even basic psy-
text that provides two possible antecedents for a               cholinguistic criteria such as incrementality.
noun phrase, the processor will prefer attaching a                 A related modeling challenge is the develop-
PP or a relative clause such that it disambiguates              ment of processing models for languages other
between the two antecedents; garden paths are re-               than English. There is a growing body of ex-
duced or disappear. Other results point to the im-              perimental research investigating human language
portance of discourse coherence for sentence pro-               processing in other languages, but virtually all ex-
cessing, an example being implicit causality.                   isting psycholinguistic models only work for En-
   The challenge facing researchers in compu-                   glish (the only exceptions we are aware of are
tational and psycholinguistics therefore includes               Dubey et al.’s (2008) and Ferrara Boston et al.’s


                                                           62


(2008) parsing models for German). Again, the                ena can it account for) and its accuracy (how well
CL community has made significant progress in                does it fit the behavioral data) can be assessed.
crosslinguistic parsing, especially using depen-                Experimental test sets should be complemented
dency grammar (Hajič, 2009), and psycholinguis-             by test sets based on corpus data. In order to as-
tic modeling could benefit from this in order to             sess the efficiency, robustness, and broad cover-
meet the challenge of developing crosslinguisti-             age of a model, a corpus of unrestricted, naturally
cally valid models of human language processing.             occurring text is required. The use of contextual-
                                                             ized language data makes it possible to assess not
3     Data and Evaluation Challenge                          only syntactic models, but also models that capture
                                                             discourse effects. These corpora need to be anno-
3.1    Test Sets
                                                             tated with behavioral measures, e.g., eye-tracking
The second key challenge that needs to be ad-                or reading time data. Some relevant corpora have
dressed in order to develop cognitively plausible            already been constructed, see the overview in Ta-
models of human language processing concerns                 ble 3, and various authors have used them for
test data and model evaluation. Here, the state of           model evaluation (Demberg and Keller, 2008a;
the art in psycholinguistic modeling lags signif-            Pynte et al., 2008; Frank, 2009; Ferrara Boston
icantly behind standards in the CL community.                et al., 2008; Patil et al., 2009; Roark et al., 2009;
Most of the models discussed in Section 2 have not           Mitchell et al., 2010).
been evaluated rigorously. The authors typically                However, the usefulness of the psycholinguis-
describe their performance on a small set of hand-           tic corpora in Table 3 is restricted by the absence
picked examples; no attempts are made to test on             of gold-standard linguistic annotation (though the
a range of items from the experimental literature            French part of the Dundee corpus, which is syn-
and determine model fit directly against behavioral          tactically annotated). This makes it difficult to test
measures (e.g., reading times). This makes it very           the accuracy of the linguistic structures computed
hard to obtain a realistic estimate of how well the          by a model, and restricts evaluation to behavioral
models achieve their aim of capturing human lan-             predictions. The challenge is therefore to collect
guage processing behavior.                                   a standardized test set of naturally occurring text
   We therefore suggest the development of stan-             or speech enriched not only with behavioral vari-
dard test sets for psycholinguistic modeling, simi-          ables, but also with syntactic and semantic anno-
lar to what is commonplace for tasks in computa-             tation. Such a data set could for example be con-
tional linguistics: parsers are evaluated against the        structed by eye-tracking section 23 of the Penn
Penn Treebank, word sense disambiguation sys-                Treebank (which is also part of Propbank, and thus
tems against the SemEval data sets, co-reference             has both syntactic and thematic role annotation).
systems against the Tipster or ACE corpora, etc.                In computational linguistics, the development
Two types of test data are required for psycholin-           of new data sets is often stimulated by competi-
guistic modeling. The first type of test data con-           tions in which systems are compared on a stan-
sists of a collection of representative experimental         dardized task, using a data set specifically de-
results. This collection should contain the actual           signed for the competition. Examples include the
experimental materials (sentences or discourse               CoNLL shared task, SemEval, or TREC in com-
fragments) used in the experiments, together with            putational syntax, semantics, and discourse, re-
the behavioral measurements obtained (reading                spectively. A similar competition could be devel-
times, eye-movement records, rating judgments,               oped for computational psycholinguistics – maybe
etc.). The experiments included in this test set             along the lines of the model comparison chal-
would be chosen to cover a wide range of ex-                 lenges that held at the International Conference
perimental phenomena, e.g., garden paths, syntac-            on Cognitive Modeling. These challenges provide
tic complexity, memory effects, semantic and dis-            standardized task descriptions and data sets; par-
course factors. Such a test set will enable the stan-        ticipants can enter their cognitive models, which
dardized evaluation of psycholinguistic models by            were then compared using a pre-defined evalua-
comparing the model predictions (rankings, sur-              tion metric.3
prisal values, memory costs, etc.) against behav-               3 The
                                                                    ICCM 2009 challenge was the Dynamic Stock and
ioral measures on a large set of items. This way             Flows Task, for more information see http://www.hss.
both the coverage of a model (how many phenom-               cmu.edu/departments/sds/ddmlab/modeldsf/.


                                                        63


 Corpus              Language          Words     Participants    Method               Reference
 Dundee Corpus       English, French   50,000             10     Eye-tracking         Kennedy and Pynte (2005)
 Potsdam Corpus      German             1,138            222     Eye-tracking         Kliegl et al. (2006)
 MIT Corpus          English            3,534             23     Self-paced reading   Bachrach (2008)
Table 3: Test corpora that have been used for psycholinguistic modeling of sentence processing; note that the Potsdam Corpus
consists of isolated sentences, rather than of continuous text


3.2   Behavioral and Neural Data                                    Further issues arise from the fact that we of-
As outlined in the previous section, a number of                 ten want to compare model fit for multiple experi-
authors have evaluated psycholinguistic models                   ments (ideally without reparametrizing the mod-
against eye-tracking or reading time corpora. Part               els), and that various mutually dependent mea-
of the data and evaluation challenge is to extend                sures are used for evaluation, e.g., processing ef-
this evaluation to neural data as provided by event-             fort at the sentence, word, and character level. An
related potential (ERP) or brain imaging studies                 important open challenge is there to develop eval-
(e.g., using functional magnetic resonance imag-                 uation measures and associated statistical proce-
ing, fMRI). Neural data sets are considerably more               dures that can deal with these problems.
complex than behavioral ones, and modeling them
is an important new task that the community is
                                                                 4   Conclusions
only beginning to address. Some recent work has                  In this paper, we discussed the modeling and
evaluated models of word semantics against ERP                   data/evaluation challenges involved in developing
(Murphy et al., 2009) or fMRI data (Mitchell et al.,             cognitively plausible models of human language
2008).4 This is a very promising direction, and the              processing. Developing computational models is
challenge is to extend this approach to the sentence             of scientific importance in so far as models are im-
and discourse level (see Bachrach 2008). Again,                  plemented theories: models of language process-
it will again be necessary to develop standardized               ing allow us to test scientific hypothesis about the
test sets of both experimental data and corpus data.             cognitive processes that underpin language pro-
                                                                 cessing. This type of precise, formalized hypoth-
3.3   Evaluation Measures
                                                                 esis testing is only possible if standardized data
We also anticipate that the availability of new test             sets and uniform evaluation procedures are avail-
data sets will facilitate the development of new                 able, as outlined in the present paper. Ultimately,
evaluation measures that specifically test the va-               this approach enables qualitative and quantitative
lidity of psycholinguistic models. Established CL                comparisons between theories, and thus enhances
evaluation measures such as Parseval are of lim-                 our understanding of a key aspect of human cog-
ited use, as they can only test the linguistic, but not          nition, language processing.
the behavioral or neural predictions of a model.                    There is also an applied side to the proposed
    So far, many authors have relied on qualita-                 challenge. Once computational models of human
tive evaluation: if a model predicts a difference                language processing are available, they can be
in (for instance) reading time between two types                 used to predict the difficulty that humans experi-
of sentences where such a difference was also                    ence when processing text or speech. This is use-
found experimentally, then that counts as a suc-                 ful for a number applications: for instance, nat-
cessful test. In most cases, no quantitative evalu-              ural language generation would benefit from be-
ation is performed, as this would require model-                 ing able to assess whether machine-generated text
ing the reading times for individual item and in-                or speech is easy to process. For text simplifica-
dividual participants. Suitable procedures for per-              tion (e.g., for children or impaired readers), such a
forming such tests do not currently exist; linear                model is even more essential. It could also be used
mixed effects models (Baayen et al., 2008) pro-                  to assess the readability of text, which is of interest
vide a way of dealing with item and participant                  in educational applications (e.g., essay scoring). In
variation, but crucially do not enable direct com-               machine translation, evaluating the fluency of sys-
parisons between models in terms of goodness of                  tem output is crucial, and a model that predicts
fit.                                                             processing difficulty could be used for this, or to
   4 These data sets were released as part of the NAACL-         guide the choice between alternative translations,
2010 Workshop on Computational Neurolinguistics.                 and maybe even to inform human post-editing.


                                                            64


References                                                  2008. Parsing costs as predictors of reading dif-
                                                            ficulty: An evaluation using the Potsdam Sen-
Altmann, Gerry T. M. and Mark J. Steedman.
                                                            tence Corpus. Journal of Eye Movement Re-
  1988. Interaction with context during human
                                                            search 2(1):1–12.
  sentence processing. Cognition 30(3):191–238.
Baayen, R. H., D. J. Davidson, and D. M. Bates.           Ferreira, Fernanda, Kiel Christianson, and An-
  2008. Mixed-effects modeling with crossed ran-            drew Hollingworth. 2001. Misinterpretations of
  dom effects for subjects and items. Journal of            garden-path sentences: Implications for models
  Memory and Language to appear.                            of sentence processing and reanalysis. Journal
                                                            of Psycholinguistic Research 30(1):3–20.
Bachrach, Asaf. 2008. Imaging Neural Correlates
  of Syntactic Complexity in a Naturalistic Con-          Frank, Stefan L. 2009. Surprisal-based compar-
  text. Ph.D. thesis, Massachusetts Institute of            ison between a symbolic and a connectionist
  Technology, Cambridge, MA.                                model of sentence processing. In Niels Taat-
                                                            gen and Hedderik van Rijn, editors, Proceed-
Brants, Thorsten and Matthew W. Crocker. 2000.
                                                            ings of the 31st Annual Conference of the Cog-
  Probabilistic parsing and psychological plau-
                                                            nitive Science Society. Cognitive Science Soci-
  sibility. In Proceedings of the 18th Interna-
                                                            ety, Amsterdam, pages 1139–1144.
  tional Conference on Computational Linguis-
  tics. Saarbrücken/Luxembourg/Nancy, pages              Garnsey, Susan M., Neal J. Pearlmutter, Elisa-
  111–117.                                                  beth M. Myers, and Melanie A. Lotocky. 1997.
Crocker, Matthew W. and Thorsten Brants. 2000.              The contributions of verb bias and plausibility
  Wide-coverage probabilistic sentence process-             to the comprehension of temporarily ambiguous
  ing.   Journal of Psycholinguistic Research               sentences. Journal of Memory and Language
  29(6):647–669.                                            37(1):58–93.
Demberg, Vera and Frank Keller. 2008a. Data               Gibson, Edward. 1998. Linguistic complexity:
  from eye-tracking corpora as evidence for theo-           locality of syntactic dependencies. Cognition
  ries of syntactic processing complexity. Cogni-           68:1–76.
  tion 101(2):193–210.                                    Grodner, Dan and Edward Gibson. 2005. Conse-
Demberg, Vera and Frank Keller. 2008b. A psy-               quences of the serial nature of linguistic input.
  cholinguistically motivated version of TAG. In            Cognitive Science 29:261–291.
  Proceedings of the 9th International Workshop
                                                          Hajič, Jan, editor. 2009. Proceedings of the 13th
  on Tree Adjoining Grammars and Related For-
                                                            Conference on Computational Natural Lan-
  malisms. Tübingen, pages 25–32.
                                                            guage Learning: Shared Task. Association for
Demberg, Vera and Frank Keller. 2009. A com-                Computational Linguistics, Boulder, CO.
  putational model of prediction in human pars-
                                                          Hale, John. 2001. A probabilistic Earley parser as
  ing: Unifying locality and surprisal effects. In
                                                            a psycholinguistic model. In Proceedings of the
  Niels Taatgen and Hedderik van Rijn, editors,
                                                            2nd Conference of the North American Chapter
  Proceedings of the 31st Annual Conference of
                                                            of the Association for Computational Linguis-
  the Cognitive Science Society. Cognitive Sci-
                                                            tics. Association for Computational Linguistics,
  ence Society, Amsterdam, pages 1888–1893.
                                                            Pittsburgh, PA, volume 2, pages 159–166.
Dubey, Amit. 2010. The influence of discourse on
  syntax: A psycholinguistic model of sentence            Hart, Betty and Todd R. Risley. 1995. Meaning-
  processing. In Proceedings of the 48th Annual             ful Differences in the Everyday Experience of
  Meeting of the Association for Computational              Young American Children. Paul H. Brookes,
  Linguistics. Uppsala.                                     Baltimore, MD.
Dubey, Amit, Frank Keller, and Patrick Sturt.             Jurafsky, Daniel. 1996. A probabilistic model of
  2008. A probabilistic corpus-based model of               lexical and syntactic access and disambigua-
  syntactic parallelism. Cognition 109(3):326–              tion. Cognitive Science 20(2):137–194.
  344.                                                    Kamide, Yuki, Gerry T. M. Altmann, and Sarah L.
Ferrara Boston, Marisa, John Hale, Reinhold                 Haywood. 2003. The time-course of prediction
  Kliegl, Umesh Patil, and Shravan Vasishth.                in incremental sentence processing: Evidence


                                                     65


  from anticipatory eye movements. Journal of               Language Processing. Singapore, pages 619–
  Memory and Language 49:133–156.                           627.
Kehler, Andrew, Laura Kertz, Hannah Rohde, and            Narayanan, Srini and Daniel Jurafsky. 2002. A
  Jeffrey L. Elman. 2008. Coherence and coref-              Bayesian model predicts human parse prefer-
  erence revisited. Journal of Semantics 25(1):1–           ence and reading time in sentence processing. In
  44.                                                       Thomas G. Dietterich, Sue Becker, and Zoubin
                                                            Ghahramani, editors, Advances in Neural In-
Kennedy, Alan and Joel Pynte. 2005. Parafoveal-
                                                            formation Processing Systems 14. MIT Press,
  on-foveal effects in normal reading. Vision Re-
                                                            Cambridge, MA, pages 59–65.
  search 45:153–168.
                                                          Padó, Ulrike, Matthew W. Crocker, and Frank
Klein, Dan and Christopher Manning. 2002. A
                                                            Keller. 2009. A probabilistic model of semantic
  generative constituent-context model for im-
                                                            plausibility in sentence processing. Cognitive
  proved grammar induction. In Proceedings of
                                                            Science 33(5):794–838.
  the 40th Annual Meeting of the Association for
  Computational Linguistics. Philadelphia, pages          Patil, Umesh, Shravan Vasishth, and Reinhold
  128–135.                                                  Kliegl. 2009. Compound effect of probabilis-
                                                            tic disambiguation and memory retrievals on
Kliegl, Reinhold, Antje Nuthmann, and Ralf Eng-
                                                            sentence processing: Evidence from an eye-
  bert. 2006. Tracking the mind during reading:
                                                            tracking corpus. In A. Howes, D. Peebles,
  The influence of past, present, and future words
                                                            and R. Cooper, editors, Proceedings of 9th In-
  on fixation durations. Journal of Experimental
                                                            ternational Conference on Cognitive Modeling.
  Psychology: General 135(1):12–35.
                                                            Manchester.
Landauer, Thomas K. and Susan T. Dumais. 1997.            Pickering, Martin J. and Martin J. Traxler. 1998.
  A solution to Plato’s problem: The latent se-             Plausibility and recovery from garden paths: An
  mantic analysis theory of acquisition, induction          eye-tracking study. Journal of Experimental
  and representation of knowledge. Psychologi-              Psychology: Learning Memory and Cognition
  cal Review 104(2):211–240.                                24(4):940–961.
Levy, Roger. 2008. Expectation-based syntactic            Pickering, Martin J., Matthew J. Traxler, and
  comprehension. Cognition 106(3):1126–1177.                Matthew W. Crocker. 2000. Ambiguity reso-
McRae, Ken, Michael J. Spivey-Knowlton, and                 lution in sentence processing: Evidence against
 Michael K. Tanenhaus. 1998. Modeling the in-               frequency-based accounts. Journal of Memory
 fluence of thematic fit (and other constraints)            and Language 43(3):447–475.
 in on-line sentence comprehension. Journal of            Pynte, Joel, Boris New, and Alan Kennedy. 2008.
 Memory and Language 38(3):283–312.                         On-line contextual influences during reading
Mitchell, Jeff, Mirella Lapata, Vera Demberg, and           normal text: A multiple-regression analysis. Vi-
 Frank Keller. 2010. Syntactic and semantic fac-            sion Research 48(21):2172–2183.
 tors in processing difficulty: An integrated mea-        Roark, Brian, Asaf Bachrach, Carlos Cardenas,
 sure. In Proceedings of the 48th Annual Meet-              and Christophe Pallier. 2009. Deriving lex-
 ing of the Association for Computational Lin-              ical and syntactic expectation-based measures
 guistics. Uppsala.                                         for psycholinguistic modeling via incremental
Mitchell, Tom M., Svetlana V. Shinkareva, An-               top-down parsing. In Proceedings of the Con-
 drew Carlson, Kai-Min Chang, Vicente L.                    ference on Empirical Methods in Natural Lan-
 Malave, Robert A. Mason, and Marcel Adam                   guage Processing. Singapore, pages 324–333.
 Just3. 2008. Predicting human brain activity as-         Roland, Douglas and Daniel Jurafsky. 2002. Verb
 sociated with the meanings of nouns. Science               sense and verb subcategorization probabilities.
 320(5880):1191–1195.                                       In Paola Merlo and Suzanne Stevenson, editors,
Murphy, Brian, Marco Baroni, and Massimo Poe-               The Lexical Basis of Sentence Processing: For-
 sio. 2009. EEG responds to conceptual stimuli              mal, Computational, and Experimental Issues,
 and corpus semantics. In Proceedings of the                John Bejamins, Amsterdam, pages 325–346.
 Conference on Empirical Methods in Natural               Sanford, Anthony J. and Patrick Sturt. 2002.


                                                     66


  Depth of processing in language comprehen-
  sion: Not noticing the evidence. Trends in Cog-
  nitive Sciences 6:382–386.
Schuler, William, Samir AbdelRahman, Tim
  Miller, and Lane Schwartz. 2010. Broad-
  coverage parsing using human-like mem-
  ory constraints. Computational Linguistics
  26(1):1–30.
Staub, Adrian and Charles Clifton. 2006. Syntac-
  tic prediction in language comprehension: Evi-
  dence from either . . . or. Journal of Experimen-
  tal Psychology: Learning, Memory, and Cogni-
  tion 32:425–436.
Stewart, Andrew J., Martin J. Pickering, and An-
  thony J. Sanford. 2000. The time course of the
  influence of implicit causality information: Fo-
  cusing versus integration accounts. Journal of
  Memory and Language 42(3):423–443.
Sturt, Patrick and Vincenzo Lombardo. 2005.
  Processing coordinated structures: Incremen-
  tality and connectedness. Cognitive Science
  29(2):291–305.
Tanenhaus, Michael K., Michael J. Spivey-
  Knowlton, Kathleen M. Eberhard, and Julie C.
  Sedivy. 1995. Integration of visual and linguis-
  tic information in spoken language comprehen-
  sion. Science 268:1632–1634.
Vasishth, Shravan and Richard L. Lewis. 2006.
  Argument-head distance and processing com-
  plexity: Explaining both locality and antilocal-
  ity effects. Language 82(4):767–794.




                                                      67

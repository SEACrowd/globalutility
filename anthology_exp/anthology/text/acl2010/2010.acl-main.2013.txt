                      The Manually Annotated Sub-Corpus:
                   A Community Resource For and By the People
                    Nancy Ide                                          Collin Baker
           Department of Computer Science                International Computer Science Institute
                   Vassar College                               Berkeley, California USA
              Poughkeepsie, NY, USA                       collinb@icsi.berkeley.edu
              ide@cs.vassar.edu

                Christiane Fellbaum                               Rebecca Passonneau
                 Princeton University                              Columbia University
             Princeton, New Jersey USA                          New York, New York USA
           fellbaum@princeton.edu                              becky@cs.columbia.edu
                    Abstract                                teen million word Open American National Cor-
                                                            pus annotations are largely unvalidated. The most
    The Manually Annotated Sub-Corpus
                                                            well-known multiply-annotated and validated cor-
    (MASC) project provides data and annota-
                                                            pus of English is the one million word Wall Street
    tions to serve as the base for a community-
                                                            Journal corpus known as the Penn Treebank (Mar-
    wide annotation effort of a subset of the
                                                            cus et al., 1993), which over the years has been
    American National Corpus. The MASC
                                                            fully or partially annotated for several phenomena
    infrastructure enables the incorporation of
                                                            over and above the original part-of-speech tagging
    contributed annotations into a single, us-
                                                            and phrase structure annotation. The usability of
    able format that can then be analyzed as
                                                            these annotations is limited, however, by the fact
    it is or ported to any of a variety of other
                                                            that many of them were produced by independent
    formats. MASC includes data from a
                                                            projects using their own tools and formats, mak-
    much wider variety of genres than exist-
                                                            ing it difficult to combine them in order to study
    ing multiply-annotated corpora of English,
                                                            their inter-relations. More recently, the OntoNotes
    and the project is committed to a fully
                                                            project (Pradhan et al., 2007) released a one mil-
    open model of distribution, without re-
                                                            lion word English corpus of newswire, broadcast
    striction, for all data and annotations pro-
                                                            news, and broadcast conversation that is annotated
    duced or contributed. As such, MASC
                                                            for Penn Treebank syntax, PropBank predicate ar-
    is the first large-scale, open, community-
                                                            gument structures, coreference, and named enti-
    based effort to create much needed lan-
                                                            ties. OntoNotes comes closest to providing a cor-
    guage resources for NLP. This paper de-
                                                            pus with multiple layers of annotation that can be
    scribes the MASC project, its corpus and
                                                            analyzed as a unit via its representation of the an-
    annotations, and serves as a call for con-
                                                            notations in a “normal form”. However, like the
    tributions of data and annotations from the
                                                            Wall Street Journal corpus, OntoNotes is limited
    language processing community.
                                                            in the range of genres it includes. It is also limited
1   Introduction                                            to only those annotations that may be produced by
                                                            members of the OntoNotes project. In addition,
The need for corpora annotated for multiple phe-
                                                            use of the data and annotations with software other
nomena across a variety of linguistic layers is
                                                            than the OntoNotes database API is not necessar-
keenly recognized in the computational linguistics
                                                            ily straightforward.
community. Several multiply-annotated corpora
exist, especially for Western European languages                The sparseness of reliable multiply-annotated
and for spoken data, but, interestingly, broad-             corpora can be attributed to several factors. The
based English language corpora with robust anno-            greatest obstacle is the high cost of manual pro-
tation for diverse linguistic phenomena are rela-           duction and validation of linguistic annotations.
tively rare. The most widely-used corpus of En-             Furthermore, the production and annotation of
glish, the British National Corpus, contains only           corpora, even when they involve significant scien-
part-of-speech annotation; and although it con-             tific research, often do not, per se, lead to publish-
tains a wider range of annotation types, the fif-           able research results. It is therefore understand-


                                                       68
                        Proceedings of the ACL 2010 Conference Short Papers, pages 68–73,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


able that many research groups are unwilling to                     Genre                   No. texts     Total words
                                                                    Email                           2             468
get involved in such a massive undertaking for rel-                 Essay                           4           17516
atively little reward.                                              Fiction                         4           20413
                                                                    Gov’t documents                 1            6064
   The      Manually      Annotated     Sub-Corpus                  Journal                       10            25635
(MASC) (Ide et al., 2008) project has been                          Letters                       31            10518
established to address many of these obstacles                      Newspaper/newswire            41            17951
                                                                    Non-fiction                     4           17118
to the creation of large-scale, robust, multiply-                   Spoken                        11            25783
annotated corpora. The project is providing                         Debate transcript               2           32325
appropriate data and annotations to serve as the                    Court transcript                1           20817
                                                                    Technical                       3           15417
base for a community-wide annotation effort,                        Travel guides                   4           12463
together with an infrastructure that enables the                    Total                        118          222488
representation of internally-produced and con-
tributed annotations in a single, usable format                     Table 1: MASC Composition (first 220K)
that can then be analyzed as it is or ported to any
of a variety of other formats, thus enabling its
                                                            or otherwise free of usage and redistribution re-
immediate use with many common annotation
                                                            strictions.
platforms as well as off-the-shelf concordance
                                                               Where licensing permits, data for inclusion in
and analysis software. The MASC project’s aim is
                                                            MASC is drawn from sources that have already
to offset some of the high costs of producing high
                                                            been heavily annotated by others. So far, the
quality linguistic annotations via a distribution of
                                                            first 80K increment of MASC data includes a
effort, and to solve some of the usability problems
                                                            40K subset consisting of OANC data that has
for annotations produced at different sites by
                                                            been previously annotated for PropBank predi-
harmonizing their representation formats.
                                                            cate argument structures, Pittsburgh Opinion an-
   The MASC project provides a resource that is
                                                            notation (opinions, evaluations, sentiments, etc.),
significantly different from OntoNotes and simi-
                                                            TimeML time and events2 , and several other lin-
lar corpora. It provides data from a much wider
                                                            guistic phenomena. It also includes a handful of
variety of genres than existing multiply-annotated
                                                            small texts from the so-called Language Under-
corpora of English, and all of the data in the cor-
                                                            standing (LU) Corpus3 that has been annotated by
pus are drawn from current American English so
                                                            multiple groups for a wide variety of phenomena,
as to be most useful for NLP applications. Per-
                                                            including events and committed belief. All of the
haps most importantly, the MASC project is com-
                                                            first 80K increment is annotated for Penn Tree-
mitted to a fully open model of distribution, with-
                                                            bank syntax. The second 120K increment includes
out restriction, for all data and annotations. It is
                                                            5.5K words of Wall Street Journal texts that have
also committed to incorporating diverse annota-
                                                            been annotated by several projects, including Penn
tions contributed by the community, regardless of
                                                            Treebank, PropBank, Penn Discourse Treebank,
format, into the corpus. As such, MASC is the
                                                            TimeML, and the Pittsburgh Opinion project. The
first large-scale, open, community-based effort to
                                                            composition of the 220K portion of the corpus an-
create a much-needed language resource for NLP.
                                                            notated so far is shown in Table 1. The remain-
This paper describes the MASC project, its corpus
                                                            ing 280K of the corpus fills out the genres that are
and annotations, and serves as a call for contribu-
                                                            under-represented in the first portion and includes
tions of data and annotations from the language
                                                            a few additional genres such as blogs and tweets.
processing community.

2       MASC: The Corpus                                    3       MASC Annotations

MASC is a balanced subset of 500K words of                  Annotations for a variety of linguistic phenomena,
written texts and transcribed speech drawn pri-             either manually produced or corrected from output
marily from the Open American National Corpus               of automatic annotation systems, are being added
(OANC)1 . The OANC is a 15 million word (and                    2
                                                                  The TimeML annotations of the data are not yet com-
growing) corpus of American English produced                pleted.
                                                                3
since 1990, all of which is in the public domain                  MASC contains about 2K words of the 10K LU corpus,
                                                            eliminating non-English and translated LU texts as well as
    1
        http://www.anc.org                                  texts that are not free of usage and redistribution restrictions.


                                                       69


  Annotation type       Method        No. texts    No. words             graph-analytic algorithms such as common sub-
  Token                 Validated          118       222472
  Sentence              Validated          118       222472              tree detection.
  POS/lemma             Validated          118       222472                 The layering of annotations over MASC texts
  Noun chunks           Validated          118       222472
  Verb chunks           Validated          118       222472              dictates the use of a stand-off annotation repre-
  Named entities        Validated          118       222472              sentation format, in which each annotation is con-
  FrameNet frames       Manual              21         17829             tained in a separate document linked to the pri-
  HSPG                  Validated          40*         30106
  Discourse             Manual             40*         30106             mary data. Each text in the corpus is provided in
  Penn Treebank         Validated           97         87383             UTF-8 character encoding in a separate file, which
  PropBank              Validated           92         50165             includes no annotation or markup of any kind.
  Opinion               Manual              97         47583
  TimeBank              Validated           34          5434             Each file is associated with a set of GrAF standoff
  Committed belief      Manual              13          4614             files, one for each annotation type, containing the
  Event                 Manual              13          4614
  Coreference           Manual                2         1877
                                                                         annotations for that text. In addition to the anno-
                                                                         tation types listed in Table 2, a document contain-
                                                                         ing annotation for logical structure (titles, head-
Table 2: Current MASC Annotations (* projected)                          ings, sections, etc. down to the level of paragraph)
                                                                         is included. Each text is also associated with
                                                                         (1) a header document that provides appropriate
to MASC data in increments of roughly 100K                               metadata together with machine-processable in-
words. To date, validated or manually produced                           formation about associated annotations and inter-
annotations for 222K words have been made avail-                         relations among the annotation layers; and (2) a
able.                                                                    segmentation of the primary data into minimal re-
   The MASC project is itself producing annota-                          gions, which enables the definition of different to-
tions for portions of the corpus for WordNet senses                      kenizations over the text. Contributed annotations
and FrameNet frames and frame elements. To de-                           are also included in their original format, where
rive maximal benefit from the semantic informa-                          available.
tion provided by these resources, the entire cor-
pus is also annotated and manually validated for                         3.1   WordNet Sense Annotations
shallow parses (noun and verb chunks) and named
entities (person, location, organization, date and                       A focus of the MASC project is to provide corpus
time). Several additional types of annotation have                       evidence to support an effort to harmonize sense
either been contracted by the MASC project or                            distinctions in WordNet and FrameNet (Baker and
contributed from other sources. The 220K words                           Fellbaum, 2009), (Fellbaum and Baker, to appear).
of MASC I and II include seventeen different types                       The WordNet and FrameNet teams have selected
of linguistic annotation4 , shown in Table 2.                            for this purpose 100 common polysemous words
   All MASC annotations, whether contributed or                          whose senses they will study in detail, and the
produced in-house, are transduced to the Graph                           MASC team is annotating occurrences of these
Annotation Framework (GrAF) (Ide and Suder-                              words in the MASC. As a first step, fifty oc-
man, 2007) defined by ISO TC37 SC4’s Linguistic                          currences of each word are annotated using the
Annotation Framework (LAF) (Ide and Romary,                              WordNet 3.0 inventory and analyzed for prob-
2004). GrAF is an XML serialization of the LAF                           lems in sense assignment, after which the Word-
abstract model of annotations, which consists of                         Net team may make modifications to the inven-
a directed graph decorated with feature structures                       tory if needed. The revised inventory (which will
providing the annotation content. GrAF’s primary                         be released as part of WordNet 3.1) is then used to
role is to serve as a “pivot” format for transducing                     annotate 1000 occurrences. Because of its small
among annotations represented in different for-                          size, MASC typically contains less than 1000 oc-
mats. However, because the underlying data struc-                        currences of a given word; the remaining occur-
ture is a graph, the GrAF representation itself can                      rences are therefore drawn from the 15 million
serve as the basis for analysis via application of                       words of the OANC. Furthermore, the FrameNet
                                                                         team is also annotating one hundred of the 1000
    4
      This includes WordNet sense annotations, which are not             sentences for each word with FrameNet frames
listed in Table 2 because they are not applied to full texts; see
Section 3.1 for a description of the WordNet sense annota-               and frame elements, providing direct comparisons
tions in MASC.                                                           of WordNet and FrameNet sense assignments in


                                                                    70


attested sentences.5                                                4       MASC Availability and Distribution
   For convenience, the annotated sentences are
                                                                    Like the OANC, MASC is distributed without
provided as a stand-alone corpus, with the Word-
                                                                    license or other restrictions from the American
Net and FrameNet annotations represented in
                                                                    National Corpus website7 . It is also available
standoff files. Each sentence in this corpus is
                                                                    from the Linguistic Data Consortium (LDC)8 for
linked to its occurrence in the original text, so that
                                                                    a nominal processing fee.
the context and other annotations associated with
                                                                       In addition to enabling download of the entire
the sentence may be retrieved.
                                                                    MASC, we provide a web application that allows
                                                                    users to select some or all parts of the corpus and
3.2   Validation                                                    choose among the available annotations via a web
Automatically-produced annotations for sentence,                    interface (Ide et al., 2010). Once generated, the
token, part of speech, shallow parses (noun and                     corpus and annotation bundle is made available to
verb chunks), and named entities (person, lo-                       the user for download. Thus, the MASC user need
cation, organization, date and time) are hand-                      never deal directly with or see the underlying rep-
validated by a team of students. Each annotation                    resentation of the stand-off annotations, but gains
set is first corrected by one student, after which it               all the advantages that representation offers. The
is checked (and corrected where necessary) by a                     following output formats are currently available:
second student, and finally checked by both auto-
                                                                        1. in-line XML (XCES9 ), suitable for use with
matic extraction of the annotated data and a third
                                                                           the BNCs XAIRA search and access inter-
pass over the annotations by a graduate student
                                                                           face and other XML-aware software;
or senior researcher. We have performed inter-
annotator agreement studies for shallow parses in                       2. token / part of speech, a common input for-
order to establish the number of passes required to                        mat for general-purpose concordance soft-
achieve near-100% accuracy.                                                ware such as MonoConc10 , as well as the
                                                                           Natural Language Toolkit (NLTK) (Bird et
   Annotations produced by other projects and
                                                                           al., 2009);
the FrameNet and Penn Treebank annotations
                                                                        3. CONLL IOB format, used in the Confer-
produced specifically for MASC are semi-
                                                                           ence on Natural Language Learning shared
automatically and/or manually produced by those
                                                                           tasks.11
projects and subjected to their internal quality con-
trols. No additional validation is performed by the
                                                                    5       Tools
ANC project.
   The WordNet sense annotations are being used                     The ANC project provides an API for GrAF an-
as a base for an extensive inter-annotator agree-                   notations that can be used to access and manip-
ment study, which is described in detail in (Pas-                   ulate GrAF annotations directly from Java pro-
sonneau et al., 2009), (Passonneau et al., 2010).                   grams and render GrAF annotations in a format
All inter-annotator agreement data and statistics                   suitable for input to the open source GraphViz12
are published along with the sense tags. The re-                    graph visualization application.13 Beyond this, the
lease also includes documentation on the words                      ANC project does not provide specific tools for
annotated in each round, the sense labels for each                  use of the corpus, but rather provides the data in
word, the sentences for each word, and the anno-                    formats suitable for use with a variety of available
tator or annotators for each sense assignment to                    applications, as described in section 4, together
each word in context. For the multiply annotated                    with means to import GrAF annotations into ma-
data in rounds 2-4, we include raw tables for each                  jor annotation software platforms. In particular,
word in the form expected by Ron Artstein’s cal-                    the ANC project provides plugins for the General
culate alpha.pl perl script6 , so that the agreement                    7
                                                                           http://www.anc.org
numbers can be regenerated.                                             8
                                                                           http://www.ldc.upenn.edu
                                                                         9
                                                                           XML Corpus Encoding Standard, http://www.xces.org
                                                                        10
    5
      Note that several MASC texts have been fully annotated               http://www.athel.com/mono.html
                                                                        11
for FrameNet frames and frame elements, in addition to the                 http://ifarm.nl/signll/conll
                                                                        12
WordNet-tagged sentences.                                                  http://www.graphviz.org/
    6                                                                   13
      http://ron.artstein.org/resources/calculate-alpha.perl               http://www.anc.org/graf-api


                                                               71


Architecture for Text Engineering (GATE) (Cun-                  users may contribute evaluations and error reports
ningham et al., 2002) to input and/or output an-                for the various annotations on the ANC/MASC
notations in GrAF format; a “CAS Consumer”                      wiki17 .
to enable using GrAF annotations in the Un-                        Contributions of unvalidated annotations for
structured Information Management Architecture                  MASC and OANC data are also welcomed and are
(UIMA) (Ferrucci and Lally, 2004); and a corpus                 distributed separately. Contributions of unencum-
reader for importing MASC data and annotations                  bered texts in any genre, including stories, papers,
into NLTK14 .                                                   student essays, poetry, blogs, and email, are also
   Because the GrAF format is isomorphic to in-                 solicited via the ANC web site and the ANC Face-
put to many graph-analytic tools, existing graph-               Book page18 , and may be uploaded at the contri-
analytic software can also be exploited to search               bution page cited above.
and manipulate MASC annotations. Trivial merg-
ing of GrAF-based annotations involves simply                   7        Conclusion
combining the graphs for each annotation, after
which graph minimization algorithms15 can be ap-                MASC is already the most richly annotated corpus
plied to collapse nodes with edges to common                    of English available for widespread use. Because
subgraphs to identify commonly annotated com-                   the MASC is an open resource that the commu-
ponents. Graph-traversal and graph-coloring al-                 nity can continually enhance with additional an-
gorithms can also be applied in order to iden-                  notations and modifications, the project serves as a
tify and generate statistics that could reveal in-              model for community-wide resource development
teractions among linguistic phenomena that may                  in the future. Past experience with corpora such
have previously been difficult to observe. Other                as the Wall Street Journal shows that the commu-
graph-analytic algorithms — including common                    nity is eager to annotate available language data,
sub-graph analysis, shortest paths, minimum span-               and we anticipate even greater interest in MASC,
ning trees, connectedness, identification of artic-             which includes language data covering a range of
ulation vertices, topological sort, graph partition-            genres that no existing resource provides. There-
ing, etc. — may also prove to be useful for mining              fore, we expect that as MASC evolves, more and
information from a graph of annotations at multi-               more annotations will be contributed, thus creat-
ple linguistic levels.                                          ing a massive, inter-linked linguistic infrastructure
                                                                for the study and processing of current American
6        Community Contributions                                English in its many genres and varieties. In addi-
The ANC project solicits contributions of anno-                 tion, by virtue of its WordNet and FrameNet anno-
tations of any kind, applied to any part or all of              tations, MASC will be linked to parallel WordNets
the MASC data. Annotations may be contributed                   and FrameNets in languages other than English,
in any format, either inline or standoff. All con-              thus creating a global resource for multi-lingual
tributed annotations are ported to GrAF standoff                technologies, including machine translation.
format so that they may be used with other MASC
annotations and rendered in the various formats                 Acknowledgments
the ANC tools generate. To accomplish this, the                 The MASC project is supported by National
ANC project has developed a suite of internal tools             Science Foundation grant CRI-0708952. The
and methods for automatically transducing other                 WordNet-FrameNet alignment work is supported
annotation formats to GrAF and for rapid adapta-                by NSF grant IIS 0705155.
tion of previously unseen formats.
   Contributions     may      be    emailed      to
anc@cs.vassar.edu or uploaded via the                           References
ANC website16 . The validity of annotations
and supplemental documentation (if appropriate)                 Collin F. Baker and Christiane Fellbaum. 2009. Word-
                                                                  Net and FrameNet as complementary resources for
are the responsibility of the contributor. MASC
                                                                  annotation. In Proceedings of the Third Linguistic
    14
      Available in September, 2010.
    15                                                              17
      Efficient algorithms for graph merging exist; see,            http://www.anc.org/masc-wiki
e.g., (Habib et al., 2000).                                         18
                                                                    http://www.facebook.com/pages/American-National-
   16
      http://www.anc.org/contributions.html                     Corpus/42474226671


                                                           72


  Annotation Workshop, pages 125–129, Suntec, Sin-             Rebecca Passonneau, Ansaf Salleb-Aouissi, Vikas
  gapore, August. Association for Computational Lin-             Bhardwaj, and Nancy Ide. 2010. Word sense an-
  guistics.                                                      notation of polysemous words by multiple annota-
                                                                 tors. In Proceedings of the Seventh International
Steven Bird, Ewan Klein, and Edward Loper.                       Conference on Language Resources and Evaluation
   2009. Natural Language Processing with Python.                (LREC), Valletta, Malta.
   O’Reilly Media, 1st edition.
                                                               Sameer S. Pradhan, Eduard Hovy, Mitch Mar-
Hamish Cunningham, Diana Maynard, Kalina                         cus, Martha Palmer, Lance Ramshaw, and Ralph
  Bontcheva, and Valentin Tablan. 2002. GATE: A                  Weischedel. 2007. OntoNotes: A unified relational
  framework and graphical development environment                semantic representation. In ICSC ’07: Proceed-
  for robust nlp tools and applications. In Proceedings          ings of the International Conference on Semantic
  of ACL’02.                                                     Computing, pages 517–526, Washington, DC, USA.
                                                                 IEEE Computer Society.
Christiane Fellbaum and Collin Baker. to appear.
  Aligning verbs in WordNet and FrameNet. Linguis-
  tics.

David Ferrucci and Adam Lally. 2004. UIMA: An
  architectural approach to unstructured information
  processing in the corporate research environment.
  Natural Language Engineering, 10(3-4):327–348.

Michel Habib, Christophe Paul, and Laurent Viennot.
  2000. Partition refinement techniques: an interest-
  ing algorithmic tool kit. International Journal of
  Foundations of Computer Science, 175.

Nancy Ide and Laurent Romary. 2004. International
  standard for a linguistic annotation framework. Nat-
  ural Language Engineering, 10(3-4):211–225.

Nancy Ide and Keith Suderman. 2007. GrAF: A graph-
  based format for linguistic annotations. In Proceed-
  ings of the Linguistic Annotation Workshop, pages
  1–8, Prague, Czech Republic, June. Association for
  Computational Linguistics.

Nancy Ide, Collin Baker, Christiane Fellbaum, Charles
  Fillmore, and Rebecca Passonneau. 2008. MASC:
  The Manually Annotated Sub-Corpus of American
  English. In Proceedings of the Sixth International
  Conference on Language Resources and Evaluation
  (LREC), Marrakech, Morocco.

Nancy Ide, Keith Suderman, and Brian Simms. 2010.
  ANC2Go: A web application for customized cor-
  pus creation. In Proceedings of the Seventh Interna-
  tional Conference on Language Resources and Eval-
  uation (LREC), Valletta, Malta, May. European Lan-
  guage Resources Association.

Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
  Beatrice Santorini. 1993. Building a large anno-
  tated corpus of English: the Penn Treebank. Com-
  putational Linguistics, 19(2):313–330.

Rebecca J. Passonneau, Ansaf Salleb-Aouissi, and
  Nancy Ide. 2009. Making sense of word sense
  variation. In SEW ’09: Proceedings of the Work-
  shop on Semantic Evaluations: Recent Achieve-
  ments and Future Directions, pages 2–9, Morris-
  town, NJ, USA. Association for Computational Lin-
  guistics.


                                                          73

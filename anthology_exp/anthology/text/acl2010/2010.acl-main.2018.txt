                       A Structured Model for Joint Learning of
                        Argument Roles and Predicate Senses
              Yotaro Watanabe                                Masayuki Asahara Yuji Matsumoto
    Graduate School of Information Sciences                  Graduate School of Information Science
              Tohoku University                              Nara Institute of Science and Technology
     6-6-05, Aramaki Aza Aoba, Aoba-ku,                             8916-5 Takayama, Ikoma,
            Sendai 980-8579, Japan                                    Nara, 630-0192, Japan
     yotaro-w@ecei.tohoku.ac.jp                             {masayu-a, matsu}@is.naist.jp

                    Abstract                                of core arguments in predicate-argument structure
                                                            analysis. They used argument sequences tied with
   In predicate-argument structure analysis,                a predicate sense (e.g. AGENT-buy.01/Active-
   it is important to capture non-local de-                 PATIENT) as a feature for the re-ranker of the
   pendencies among arguments and inter-                    system where predicate sense and argument role
   dependencies between the sense of a pred-                candidates are generated by their pipelined archi-
   icate and the semantic roles of its argu-                tecture. They reported that incorporating this type
   ments. However, no existing approach ex-                 of features provides substantial gain of the system
   plicitly handles both non-local dependen-                performance.
   cies and semantic dependencies between                      The other factor is inter-dependencies between
   predicates and arguments. In this pa-                    a predicate sense and argument roles, which re-
   per we propose a structured model that                   late to selectional preference, and motivated us
   overcomes the limitation of existing ap-                 to jointly identify a predicate sense and its argu-
   proaches; the model captures both types of               ment roles. This type of dependencies has been
   dependencies simultaneously by introduc-                 explored by Riedel and Meza-Ruiz (2008; 2009b;
   ing four types of factors including a global             2009a), all of which use Markov Logic Networks
   factor type capturing non-local dependen-                (MLN). The work uses the global formulae that
   cies among arguments and a pairwise fac-                 have atoms in terms of both a predicate sense and
   tor type capturing local dependencies be-                each of its argument roles, and the system identi-
   tween a predicate and an argument. In                    ﬁes predicate senses and argument roles simulta-
   experiments the proposed model achieved                  neously.
   competitive results compared to the state-                  Ideally, we want to capture both types of depen-
   of-the-art systems without applying any                  dencies simultaneously. The former approaches
   feature selection procedure.                             can not explicitly include features that capture
                                                            inter-dependencies between a predicate sense and
1 Introduction
                                                            its argument roles. Though these are implicitly in-
Predicate-argument structure analysis is a process          corporated by re-ranking where the most plausi-
of assigning who does what to whom, where,                  ble assignment is selected from a small subset of
when, etc. for each predicate. Arguments of a               predicate and argument candidates, which are gen-
predicate are assigned particular semantic roles,           erated independently. On the other hand, it is dif-
such as Agent, Theme, Patient, etc. Lately,                 ﬁcult to deal with core argument features in MLN.
predicate-argument structure analysis has been re-          Because the number of core arguments varies with
garded as a task of assigning semantic roles of             the role assignments, this type of features cannot
arguments as well as word senses of a predicate             be expressed by a single formula.
(Surdeanu et al., 2008; Hajič et al., 2009).                  Thompson et al. (2010) proposed a gener-
  Several researchers have paid much attention to           ative model that captures both predicate senses
predicate-argument structure analysis, and the fol-         and its argument roles. However, the ﬁrst-order
lowing two important factors have been shown.               markov assumption of the model eliminates abil-
Toutanova et al. (2008), Johansson and Nugues               ity to capture non-local dependencies among ar-
(2008), and Björkelund et al. (2009) presented             guments. Also, generative models are in general
importance of capturing non-local dependencies              inferior to discriminatively trained linear or log-


                                                       98
                       Proceedings of the ACL 2010 Conference Short Papers, pages 98–102,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


      "#!                                                         2.1 Factors of the Model
                            ,!         "$$!
                                                                  We deﬁne four types of factors for the model.
                                              "$%
                                               $%!
                                                                  Predicate Factor FP scores a sense of p, and
    &(!      &+!      &*!        &'!     !!!         &)!          does not depend on any arguments. The score
                                                                  function is deﬁned by FP (x, p, A) = w·ΦP (x, p).
                                                       "%!
                                                                  Argument Factor FA scores a label assignment
                                                                  of a particular argument a ∈ A. The score is deter-
Figure 1: Undirected graphical model representa-
                                                                  mined independently from a predicate sense, and
tion of the structured model
                                                                  is given by FA (x, p, a) = w · ΦA (x, a).

                                                                  Predicate-Argument         Pairwise        Factor
linear models.
                                                                  FP A captures inter-dependencies between
   In this paper we propose a structured model                    a predicate sense and one of its argument
that overcomes limitations of the previous ap-                    roles.      The score function is deﬁned as
proaches. For the model, we introduce several                     FP A (x, p, a) = w · ΦP A (x, p, a). The dif-
types of features including those that capture both               ference from FA is that FP A inﬂuences both
non-local dependencies of core arguments, and                     the predicate sense and the argument role. By
inter-dependencies between a predicate sense and                  introducing this factor, the role label can be
its argument roles. By doing this, both tasks are                 inﬂuenced by the predicate sense, and vise versa.
mutually inﬂuenced, and the model determines
the most plausible set of assignments of a predi-                 Global Factor FG is introduced to capture plau-
cate sense and its argument roles simultaneously.                 sibility of the whole predicate-argument structure.
We present an exact inference algorithm for the                   Like the other factors, the score function is de-
model, and a large-margin learning algorithm that                 ﬁned as FG (x, p, A) = w · ΦG (x, p, A). A pos-
can handle both local and global features.                        sible feature that can be considered by this fac-
                                                                  tor is the mutual dependencies among core argu-
                                                                  ments. For instance, if a predicate-argument struc-
2   Model                                                         ture has an agent (A0) followed by the predicate
                                                                  and a patient (A1), we encode the structure as a
Figure 1 shows the graphical representation of our                string A0-PRED-A1 and use it as a feature. This
proposed model. The node p corresponds to a                       type of features provide plausibility of predicate-
predicate, and the nodes a1 , ..., aN to arguments                argument structures. Even if the highest scoring
of the predicate. Each node is assigned a particu-                predicate-argument structure with the other factors
lar predicate sense or an argument role label. The                misses some core arguments, the global feature
black squares are factors which provide scores of                 demands the model to ﬁll the missing arguments.
label assignments. In the model, the nodes for ar-                   The numbers of factors for each factor type are:
guments depend on the predicate sense, and by in-                 FP and FG are 1, FA and FP A are |A|. By inte-
ﬂuencing labels of a predicate sense and its argu-                grating the all factors, the score function becomes
                                                                  ∑ A) = w · ΦP (x, p) + w · ΦG (x, p, A) + w ·
ment roles, the most plausible label assignment of                s(p,
                                                                     a∈A {ΦA (x, a) + ΦP A (x, p, a)}.
the nodes is determined considering all factors.
   In this work, we use linear models. Let x be
words in a sentence, p be a sense of a predicate in               2.2 Inference
x, and A = {an }N   1 be a set of possible role label             The crucial point of the model is how to deal
assignments for x. A predicate-argument structure                 with the global factor FG , because enumerating
is represented by a pair of p and A. We deﬁne                     possible assignments is too costly. A number of
the score function for  ∑ predicate-argument struc-               methods have been proposed for the use of global
tures as s(p, A) =        Fk ∈F Fk (x, p, A). F is a              features for linear models such as (Daumé III
set of all the factors, Fk (x, p, A) corresponds to a             and Marcu, 2005; Kazama and Torisawa, 2007).
particular factor in Figure 1, and gives a score to a             In this work, we use the approach proposed in
predicate or argument label assignments. Since we                 (Kazama and Torisawa, 2007). Although the ap-
use linear models, Fk (x, p, A) = w · Φk (x, p, A).               proach is proposed for sequence labeling tasks, it


                                                             99


can be easily extended to our structured model.                              lL+G is the loss function for the case of using
That is, for each possible predicate sense p of the                       both local and global features, corresponding to
predicate, we provide N-best argument role as-                            the constraint (A), and lL is the loss function for
signments using three local factors FP , FA and                           the case of using only local features, correspond-
FP A , and then add scores of the global factor FG ,                      ing to the constraints (B) provided that (A) is sat-
ﬁnally select the argmax from them. In this case,                         isﬁed.
the argmax is selected from |Pl |N candidates.
                                                                          2.4 The Role-less Argument Bias Problem
2.3 Learning the Model                                                    The fact that an argument candidate is not as-
For learning of the model, we borrow a funda-                             signed any role (namely it is assigned the la-
mental idea of Kazama and Torisawa’s perceptron                           bel “NONE”) is unlikely to contribute pred-
learning algorithm. However, we use a more so-                            icate sense disambiguation. However, it re-
phisticated online-learning algorithm based on the                        mains possible that “NONE” arguments is bi-
Passive-Aggressive Algorithm (PA) (Crammer et                             ased toward a particular predicate sense by FP A
al., 2006).                                                               (i.e. w · ΦP A (x, sensei , ak = “NONE00 ) > w ·
   For the sake of simplicity, we introduce some                          ΦP A (x, sensej , ak = “NONE00 ).
notations. We denote a predicate-argument struc-                             In order to avoid this bias, we deﬁne a spe-
ture y = hp, Ai, a local∑feature vector as                                cial sense label, senseany , that is used to cal-
ΦL (x, y) = ΦP (x, p) +          a∈A {ΦA (x, a) +                         culate the score for a predicate and a roll-less
ΦP A (x, p, a)}，a feature vector coupling both                            argument, regardless of the predicate’s sense.
local and global features as ΦL+G (x, y) =                                We use the feature vector ΦP A (x, senseany , ak )
ΦL (x, y) + ΦG (x, p, A), the argmax using ΦL+G                           if ak = “NONE00 and ΦP A (x, sensei , ak ) other-
as ŷL+G , the argmax using ΦL as ŷL . Also, we                          wise.
use a loss function ρ(y, y0 ), which is a cost func-
tion associated with y and y0 .                                           3 Experiment
   The margin perceptron learning proposed by
                                                                          3.1 Experimental Settings
Kazama and Torisawa can be seen as an optimiza-
tion with the following two constrains.                                   We use the CoNLL-2009 Shared Task dataset
                                                                          (Hajič et al., 2009) for experiments. It is a
 (A) w·ΦL+G (x, y)−w·ΦL+G (x, ŷ      L+G
                                            ) ≥ ρ(y, ŷ   L+G
                                                                )
                                                                          dataset for multi-lingual syntactic and semantic
 (B) w · ΦL (x, y) − w · ΦL (x, ŷL ) ≥ ρ(y, ŷL )                        dependency parsing 1 . In the SRL-only challenge
   (A) is the constraint that ensures a sufﬁcient                         of the task, participants are required to identify
margin ρ(y, ŷL+G ) between y and ŷL+G . (B)                             predicate-argument structures of only the speciﬁed
is the constraint that ensures a sufﬁcient margin                         predicates. Therefore the problems to be solved
ρ(y, ŷL ) between y and ŷL . The necessity of                           are predicate sense disambiguation and argument
this constraint is that if we apply only (A), the al-                     role labeling. We use Semantic Labeled F1 for
gorithm does not guarantee a sufﬁcient margin in                          evaluation.
terms of local features, and it leads to poor quality                        For generating N-bests, we used the beam-
in the N-best assignments. The Kazama and Tori-                           search algorithm, and the number of N-bests was
sawa’s perceptron algorithm uses constant values                          set to N = 64. For learning of the joint model, the
for the cost function ρ(y, ŷL+G ) and ρ(y, ŷL ).                        loss function ρ(yt , y0 ) of the Passive-Aggressive
   The proposed model is trained using the follow-                        Algorithm was set to the number of incorrect as-
ing optimization problem.                                                 signments of a predicate sense and its argument
                                                                          roles. Also, the number of iterations of the model
                      1
  wnew = arg min        ||w0 − w||2 + Cξ                                  used for testing was selected based on the perfor-
               w0 ∈<n 2
     (                                                                    mance on the development data.
       s.t. lL+G ≤ ξ, ξ ≥ 0 if ŷL+G 6= y
                                                           (1)               Table 1 shows the features used for the struc-
       s.t. lL ≤ ξ, ξ ≥ 0       if ŷL+G = y 6= ŷL
                                                                          tured model. The global features used for FG are
  lL+G = w · ΦL+G (x, ŷL+G )                                             based on those used in (Toutanova et al., 2008;
                   − w · ΦL+G (x, y) + ρ(y, ŷL+G )        (2)            Johansson and Nugues, 2008), and the features
                                                                             1
                                                                               The dataset consists of seven languages: Catalan, Chi-
   lL = w · ΦL (x, ŷL ) − w · ΦL (x, y) + ρ(y, ŷL )      (3)            nese, Czech, English, German, Japanese and Spanish.


                                                                    100


  FP      Plemma of the predicate and predicate’s head, and ppos of the predicate
          Dependency label between the predicate and predicate’s head
          The concatenation of the dependency labels of the predicate’s dependents
  FA      Plemma and ppos of the predicate, the predicate’s head, the argument candidate, and the argument’s head
          Plemma and ppos of the leftmost/rightmost dependent and leftmost/rightmost sibling
          The dependency label of predicate, argument candidate and argument candidate’s dependent
          The position of the argument candidate with respect to the predicate position in the dep. tree (e.g. CHILD)
          The position of the head of the dependency relation with respect to the predicate position in the sentence
          The left-to-right chain of the deplabels of the predicate’s dependents
          Plemma, ppos and dependency label paths between the predicate and the argument candidates
          The number of dependency edges between the predicate and the argument candidate
  FP A    Plemma and plemma&ppos of the argument candidate
          Dependency label path between the predicate and the argument candidates
  FG      The sequence of the predicate and the argument labels in the predicate-argument structure (e.g. A0-PRED-A1）
          Whether the semantic roles deﬁned in frames exist in the structure, (e.g. CONTAINS:A1)
          The conjunction of the predicate sense and the frame information (e.g. wear.01&CONTAINS:A1)

                                  Table 1: Features for the Structured Model

                                  Avg.      Ca      Ch       Cz        En       Ge       Jp       Sp
                 FP +FA           79.17    78.00   76.02    85.24     83.09    76.76    77.27    77.83
                 FP +FA +FP A     79.58    78.38   76.23    85.14     83.36    78.31    77.72    77.92
                 FP +FA +FG       80.42    79.50   76.96    85.88     84.49    78.64    78.32    79.21
                 ALL              80.75    79.55   77.20    85.94     84.97    79.62    78.69    79.29
                 Björkelund      80.80    80.01   78.60    85.41     85.63    79.71    76.30    79.91
                 Zhao             80.47    80.32   77.72    85.19     85.44    75.99    78.15    80.46
                 Meza-Ruiz        77.46    78.00   77.73    75.75     83.34    73.52    76.00    77.91

           Table 2: Results on the CoNLL-2009 Shared Task dataset (Semantic Labeled F1).


                            SENSE     ARG                        Next, we compare our system with top 3 sys-
          FP +FA             89.65    72.20
          FP +FA +FP A       89.78    72.74                   tems in the CoNLL-2009 Shared Task. By in-
          FP +FA +FG         89.83    74.11                   corporating both FP A and FG , our joint model
          ALL                90.15    74.46                   achieved competitive results compared to the top 2
Table 3: Predicate sense disambiguation and argu-             systems (Björkelund and Zhao), and achieved the
ment role labeling results (average).                         better results than the Meza-Ruiz’s system 2 . The
                                                              systems by Björkelund and Zhao applied feature
                                                              selection algorithms in order to select the best set
used for FP A are inspired by formulae used in                of feature templates for each language, requiring
the MLN-based SRL systems, such as (Meza-Ruiz                 about 1 to 2 months to obtain the best feature set.
and Riedel, 2009b). We used the same feature                  On the other hand, our system achieved the com-
templates for all languages.                                  petitive results with the top two systems, despite
                                                              the fact that we used the same feature templates
3.2 Results                                                   for all languages without applying any feature en-
                                                              gineering procedure.
Table 2 shows the results of the experiments, and                Table 3 shows the performances of predicate
also shows the results of the top 3 systems in the            sense disambiguation and argument role labeling
CoNLL-2009 Shared Task participants of the SRL-               separately. In terms of sense disambiguation re-
only system.                                                  sults, incorporating FP A and FG worked well. Al-
   By incorporating FP A , we achieved perfor-                though incorporating either of FP A and FG pro-
mance improvement for all languages. This results             vided improvements of +0.13 and +0.18 on av-
suggest that it is effective to capture local inter-          erage, adding both factors provided improvements
dependencies between a predicate sense and one                of +0.50. We compared the predicate sense dis-
of its argument roles. Comparing the results with
FP +FA and FP +FA +FG , incorporating FG also                    2
                                                                   The result of Meza-Ruiz for Czech is substantially worse
contributed performance improvements for all lan-             than the other systems because of inappropriate preprocess-
                                                              ing for predicate sense disambiguation. Excepting Czech, the
guages, especially the substantial F1 improvement             average F1 value of the Meza-Ruiz is 77.75, where as our
of +1.88 is obtained in German.                               system is 79.89.


                                                        101


ambiguation results of FP + FA and ALL with the                Shalev-Shwartz, and Yoram Singer. 2006. Online
McNemar test, and the difference was statistically             passive-aggressive algorithms. JMLR, 7:551–585.
signiﬁcant (p < 0.01). This result suggests that             Hal Daumé III and Daniel Marcu. 2005. Learning
combination of these factors is effective for sense            as search optimization: Approximate large margin
disambiguation.                                                methods for structured prediction. In ICML-2005.
   As for argument role labeling results, incorpo-           Koen Deschacht and Marie-Francine Moens. 2009.
rating FP A and FG contributed positively for all              Semi-supervised semantic role labeling using the la-
languages. Especially, we obtained a substan-                  tent words language model. In EMNLP-2009.
tial gain (+4.18) in German. By incorporating
                                                             Hagen Fürstenau and Mirella Lapata. 2009. Graph
FP A , the system achieved the F1 improvements                 alignment for semi-supervised semantic role label-
of +0.54 on average. This result shows that cap-               ing. In EMNLP-2009.
turing inter-dependencies between a predicate and
                                                             Jan Hajič, Massimiliano Ciaramita, Richard Johans-
its arguments contributes to argument role label-               son, Daisuke Kawahara, Maria Antònia Martı́, Lluı́s
ing. By incorporating FG , the system achieved the              Màrquez, Adam Meyers, Joakim Nivre, Sebastian
substantial improvement of F1 (+1.91).                          Padó, Jan Štěpánek, Pavel Straňák, Mihai Surdeanu,
   Since both tasks improved by using all factors,              Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
                                                                2009 shared task: Syntactic and semantic dependen-
we can say that the proposed joint model suc-
                                                                cies in multiple languages. In CoNLL-2009, Boul-
ceeded in joint learning of predicate senses and                der, Colorado, USA.
its argument roles.
                                                             Richard Johansson and Pierre Nugues. 2008.
4   Conclusion                                                 Dependency-based syntactic-semantic analysis
                                                               with propbank and nombank. In CoNLL-2008.
In this paper, we proposed a structured model that           Jun’Ichi Kazama and Kentaro Torisawa. 2007. A new
captures both non-local dependencies between ar-               perceptron algorithm for sequence labeling with
guments, and inter-dependencies between a pred-                non-local features. In EMNLP-CoNLL 2007.
icate sense and its argument roles. We designed
                                                             Ivan Meza-Ruiz and Sebastian Riedel. 2009a. Jointly
a linear model-based structured model, and de-                  identifying predicates, arguments and senses using
ﬁned four types of factors: predicate factor, ar-               markov logic. In HLT/NAACL-2009.
gument factor, predicate-argument pairwise fac-
                                                             Ivan Meza-Ruiz and Sebastian Riedel. 2009b. Multi-
tor and global factor for the model. In the ex-                 lingual semantic role labelling with markov logic.
periments, the proposed model achieved compet-                  In CoNLL-2009.
itive results compared to the state-of-the-art sys-
                                                             Sebastian Riedel and Ivan Meza-Ruiz. 2008. Collec-
tems without any feature engineering.
                                                               tive semantic role labelling with markov logic. In
   A further research direction we are investi-                CoNLL-2008.
gating is exploitation of unlabeled texts. Semi-
supervised semantic role labeling methods have               Mihai Surdeanu, Richard Johansson, Adam Mey-
                                                               ers, Lluı́s Màrquez, and Joakim Nivre. 2008. The
been explored by (Collobert and Weston, 2008;                  CoNLL-2008 shared task on joint parsing of syntac-
Deschacht and Moens, 2009; Fürstenau and La-                  tic and semantic dependencies. In CoNLL-2008.
pata, 2009), and they have achieved successful
                                                             Synthia A. Thompson, Roger Levy, and Christopher D.
outcomes. However, we believe that there is still              Manning. 2010. A generative model for semantic
room for further improvement.                                  role labeling. In Proceedings of the 48th Annual
                                                               Meeting of the Association of Computational Lin-
                                                               guistics (to appear).
References
                                                             Kristina Toutanova, Aria Haghighi, and Christopher D.
Anders Björkelund, Love Hafdell, and Pierre Nugues.           Manning. 2008. A global joint model for semantic
  2009. Multilingual semantic role labeling. In                role labeling. Computational Linguistics, 34(2).
  CoNLL-2009.

Ronan Collobert and Jason Weston. 2008. A uniﬁed
  architecture for natural language processing: Deep
  neural networks with multitask learning. In ICML
  2008.

Koby Crammer, Ofer Dekel, Joseph Keshet, Shai


                                                       102

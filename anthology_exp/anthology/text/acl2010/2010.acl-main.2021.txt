              Automatic Collocation Suggestion in Academic Writing

    Jian-Cheng Wu1               Yu-Chia Chang1,*               Teruko Mitamura2                Jason S. Chang1
          1                                                              2
      National Tsing Hua University                                          Carnegie Mellon University
            Hsinchu, Taiwan                                                  Pittsburgh, United States
{wujc86, richtrf, jason.jschang}                                             teruko@cs.cmu.edu
             @gmail.com

                                                             native speakers (Howarth, 1998). Granger (1998)
                      Abstract                               reported that learners underuse native-like collo-
                                                             cations and overuse atypical word combinations.
     In recent years, collocation has been                   This disparity in collocation usage between na-
     widely acknowledged as an essential                     tive and non-native speakers is clear and should
     characteristic to distinguish native speak-             receive more attention from the language tech-
     ers from non-native speakers. Research                  nology community.
     on academic writing has also shown that                    To tackle such word usage problems, tradi-
     collocations are not only common but                    tional language technology often employs a da-
     serve a particularly important discourse                tabase of the learners' common errors that are
     function within the academic community.                 manually tagged by teachers or specialists (e.g.
     In our study, we propose a machine                      Shei and Pain, 2000; Liu, 2002). Such system
     learning approach to implementing an                    then identifies errors via string or pattern match-
     online collocation writing assistant. We                ing and offer only pre-stored suggestions. Com-
     use a data-driven classifier to provide                 piling the database is time-consuming and not
     collocation suggestions to improve word                 easily maintainable, and the usefulness is limited
     choices, based on the result of classifica-             by the manual collection of pre-stored sugges-
     tion. The system generates and ranks                    tions. Therefore, it is beneficial if a system can
     suggestions to assist learners’ collocation             mainly use untagged data from a corpus contain-
     usages in their academic writing with sat-              ing correct language usages rather than the error-
     isfactory results. *                                    tagged data from a learner corpus. A large corpus
                                                             of correct language usages is more readily avail-
1     Introduction                                           able and useful than a small labeled corpus of
                                                             incorrect language usages.
The notion of collocation has been widely dis-                  For this suggestion task, the large corpus not
cussed in the field of language teaching for dec-            only provides us with a rich set of common col-
ades. It has been shown that collocation, a suc-             locations but also provides the context within
cessive common usage of words in a chain, is                 which these collocations appear. Intuitively, we
important in helping language learners achieve               can take account of such context of collocation to
native-like fluency. In the field of English for             generate more suitable suggestions. Contextual
Academic Purpose, more and more researchers                  information in this sense often entails more lin-
are also recognizing this important feature in               guistic clues to provide suggestions within sen-
academic writing. It is often argued that colloca-           tences or paragraph. However, the contextual
tion can influence the effectiveness of a piece of           information is messy and complex and thus has
writing and the lack of such knowledge might                 long been overlooked or ignored. To date, most
cause cumulative loss of precision (Howarth,                 fashionable suggestion methods still rely upon
1998).                                                       the linguistic components within collocations as
   Many researchers have discussed the function              well as the linguistic relationship between mis-
of collocations in the highly conventionalized               used words and their correct counterparts (Chang
and specialized writing used within academia.                et al., 2008; Liu, 2009).
Research also identified noticeable increases in                In contrast to other research, we employ con-
the quantity and quality of collocational usage by           textual information to automate suggestions for
*                                                            verb-noun lexical collocation. Verb-noun collo-
  Corresponding author: Yu-chia Chang (Email address:        cations are recognized as presenting the most
richtrf@gmail.com)


                                                         115
                        Proceedings of the ACL 2010 Conference Short Papers, pages 115–119,
                  Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


challenge to students (Howarth, 1996; Liu,
2002). More specifically, in this preliminary
study we start by focusing on the word choice of
verbs in collocations which are considered as the
most difficult ones for learners to master (Liu,
2002; Chang, 2008). The experiment confirms
that our collocation writing assistant proves the
feasibility of using machine learning methods to
automatically prompt learners with collocation
suggestions in academic writing.

2      Collocation Checking and Suggestion
This study aims to develop a web service, Collo-
cation Inspector (shown in Figure 1) that accepts
sentences as input and generates the related can-
didates for learners.                                          Figure 1. The interface for the collocation suggestion
   In this paper, we focus on automatically pro-
viding academic collocation suggestions when                         nsubj (introduce-2, We-1)
users are writing up their abstracts. After an ab-                   det (method-5, a-3)
stract is submitted, the system extracts linguistic                  amod (method-5, novel-4)
                                                                     dobj (introduce-2, method-5)
features from the user’s text for machine learning
                                                                     prepc_for (introduce-2, learning-7)
model. By using a corpus of published academic                       aux (find-9, to-8)
texts, we hope to match contextual linguistic                        ……
clues from users’ text to help elicit the most rele-              Figure 2. Dependency parsing of Example (1)
vant suggestions. We now formally state the
problem that we are addressing:
                                                              Traditionally, through part-of-speech tagging,
   Problem Statement: Given a sentence S writ-             we can obtain a tagged sentence as follows (ex-
ten by a learner and a reference corpus RC, our            ample (2)). We can observe that the desired col-
goal is to output a set of most probable sugges-           location “introduce method”, conforming to
tion candidates c1, c2, ... , cm. For this, we train a     “VERB+NOUN” relationship, exists within the
classifier MC to map the context (represented as           sentence. However, the distance between these
feature set f1, f2, ..., fn) of each sentence in RC to     two words is often flexible, not necessarily rigid.
the collocations. At run-time, we predict these            Heuristically writing patterns to extract such verb
collocations for S as suggestions.                         and noun might not be effective. The patterns
                                                           between them can be tremendously varied. In
2.1     Academic Collocation Checker Train-
                                                           addition, some verbs and nouns are adjacent, but
        ing Procedures
                                                           they might be intervened by clause and thus have
Sentence Parsing and Collocation Extraction:               no syntactic relation with one another (e.g. “pro-
We start by collecting a large number of ab-               pose model” in example (3)).
stracts from the Web to develop a reference cor-
pus for collocation suggestion. And we continue                  (2) We/PRP introduce/VB a/DT
                                                                 novel/JJ method/NN for/IN
to identify collocations in each sentence for the
                                                                 learning/VBG to/TO find/VB
subsequent processing.                                           documents/NNS on/IN the/DT
   Collocation extraction is an essential step in                web/NN ./.
preprocessing data. We only expect to extract the
collocation which comprises components having                    (3) We proposed that the web-
a syntactic relationship with one another. How-                  based model would be more ef-
ever, this extraction task can be complicated.                   fective than corpus-based one.
Take the following scholarly sentence from the
                                                              A natural language parser can facilitate the ex-
reference corpus as an example (example (1)):
                                                           traction of the target type of collocations. Such
      (1) We introduce a novel method                      parser is a program that works out the grammati-
      for learning to find documents                       cal structure of sentences, for instance, by identi-
      on the web.                                          fying which group of words go together or which


                                                         116


word is the subject or object of a verb. In our           Table 1. Example sentences and class tags (colloca-
study, we take advantage of a dependency parser,          tions)
Stanford Parser, which extracts typed dependen-           Example Sentence                            Class tag
cies for certain grammatical relations (shown in          We introduce a novel method for learning
Figure 2). Within the parsed sentence of example                                                            introduce
                                                          to find documents on the web.
(1), we can notice that the extracted dependency
                                                          We presented a method of improving Japa-
“dobj (introduce-2, method-4)” meets the crite-           nese dependency parsing by using large-  present
rion.                                                     scale statistical information.
                                                          In this paper, we will describe a method of
Using a Classifier for the Suggestion task: A
                                                          identifying the syntactic role of antece-   describe
classifier is a function generally to take a set of       dents, which consists of two phases
attributes as an input and to provide a tagged
class as an output. The basic way to build a clas-        In this paper, we suggest a method that
                                                          automatically constructs an NE tagged cor-
sifier is to derive a regression formula from a set                                                   suggest
                                                          pus from the web to be used for learning of
of tagged examples. And this trained classifier           NER systems.
can thus make predication and assign a tag to any
input data.
   The suggestion task in this study will be seen         consist of two elements, the head and the ngram
as a classification problem. We treat the colloca-        of context words:
tion extracted from each sentence as the class tag
(see examples in Table 1). Hopefully, the system             Head: Each collocation comprises two parts,
can learn the rules between tagged classes (i.e.          collocate and head. For example, in a given verb-
collocations) and example sentences (i.e. schol-          noun collocation, the verb is the collocate as well
arly sentences) and can predict which collocation         as the target for which we provide suggestions;
is the most appropriate one given attributes ex-          the noun serves as the head of collocation and
tracted from the sentences.                               convey the essential meaning of the collocation.
   Another advantage of using a classifier to             We use the head as a feature to condition the
automate suggestion is to provide alternatives            classifier to generate candidates relevant to a
with regard to the similar attributes shared by           given head.
sentences. In Table 1, we can observe that these
collocations exhibit a similar discourse function            Ngram: We use the context words around the
and can thus become interchangeable in these              target collocation by considering the correspond-
sentences. Therefore, based on the outputs along          ing unigrams and bigrams words within the sen-
with the probability from the classifier, we can          tence. Moreover, to ensure the relevance, those
provide more than one adequate suggestions.               context words, before and after the punctuation
                                                          marks enclosing the collocation in question, will
Feature Selection for Machine Learning: In                be excluded. We use the parsed sentence from
the final stage of training, we build a statistical       previous step (example (2)) to show the extracted
machine-learning model. For our task, we can              context features1 (example (4)):
use a supervised method to automatically learn                (4) CN=method UniV_L=we
the relationship between collocations and exam-               UniV_R=a UniV_R=novel UniN_L=a
ple sentences.                                                UniN_L=novel UniN_R=for
We choose Maximum Entropy (ME) as our train-                  UniN_R=learn BiV_R=a_novel
ing algorithm to build a collocation suggestion               BiN_L=a_novel BiN_R=for_learn
classifier. One advantage of an ME classifier is              BiV_I=we_a BiN_I=novel_for
that in addition to assigning a classification it can
provide the probability of each assignment. The
ME framework estimates probabilities based on
the principle of making as few assumptions as
possible. Such constraints are derived from the
training data, expressing relationships between           1
                                                            CN refers to the head within collocation. Uni and Bi indi-
features and outcomes.                                    cate the unigram and bigram context words of window size
   Moreover, an effective feature selection can           two respectively. V and N differentiate the contexts related
increase the precision of machine learning. In our        to verb or noun. The ending alphabets L, R, I show the posi-
study, we employ the contextual features which            tion of the words in context, L = left, R = right, and I = in
                                                          between.


                                                        117


2.2     Automatic Collocation Suggestion at                   Procedure CollocationSuggestion(sent, MEmodel)
        Run-time                                              (1) parsedSen = Parsing(sent)
                                                              (2) extractedColl = CollocationExtraction(parsedSent)
After the ME classifier is automatically trained,             (3) features = AssignFeature(ParsedSent)
the model is used to find out the best collocation            (4) probCollection = MEprob(features, MEmodel)
suggestion. Figure 3 shows the algorithm of pro-              (5) candidate = SuggestionFilter(probCollection)
                                                              (6) Return candidate
ducing suggestions for a given sentence. The
input is a learner’s sentence in an abstract, along           Figure 3. Collocation Suggestion at Run-time
with an ME model trained from the reference
                                                          Table 2. An example from learner’s sentence
corpus.
                                                          Extracted                                Ranked
   In Step (1) of the algorithm, we parse the sen-                      Features
                                                          Collocation                              Candidates
tence for data preprocessing. Based on the parser
output, we extract the collocation from a given                           CN=speed
sentence as well as generate features sets in Step                        UniV_L=important
                                                                          UniV_L=to
(2) and (3). After that in Step (4), with the
                                                                          UniV_R=internet
trained machine-learning model, we obtain a set                                                        improve
                                                                          UniV_R=transfer
of likely collocates with probability as predicted                                                     increase
                                                                          UniN_L=transfer
by the ME model. In Step (5), SuggestionFilter            add speed                                    determine
                                                                          UniN_L=calculation
singles out the valid collocation and returns the                                                      maintain
                                                                          BiV_L=important_to
                                                                                                       ……
best collocation suggestion as output in Step (6).                        BiV_R=internet_transfer
For example, if a learner inputs the sentence like                        BiN_L=transfer_calcula-
Example (5), the features and output candidates                           tion
are shown in Table 2.                                                     BiV_I=to_intenet

      (5) There are many investiga-                       Table 3. MRR for different feature sets
      tions about wireless network                        Feature Sets Included In Classifier               MRR
      communication, especially it is
                                                          Features of HEAD                                  0.407
      important to add Internet
      transfer calculation speeds.                        Features of CONTEXT                               0.469
                                                          Features of HEAD+CONTEXT                          0.518
3      Experiment
                                                          tem output. Table 3 shows that the best MRR of
From an online research database, CiteSeer, we            our prototype system is 0.518. The results indi-
have collected a corpus of 20,306 unique ab-              cate that on average users could easily find an-
stracts, which contained 95,650 sentences. To             swers (exactly reproduction of the blanked out
train a Maximum Entropy classifier, 46,255 col-           collocates) in the first two to three ranking of
locations are extracted and 790 verbal collocates         suggestions. It is very likely that we get a much
are identified as tagged classes for collocation          higher MMR value if we would go through the
suggestions. We tested the classifier on scholarly        lists and evaluate each suggestion by hand.
sentences in place of authentic student writings          Moreover, in Table 3, we can further notice that
which were not available at the time of this pilot        contextual features are quite informative in com-
study. We extracted 364 collocations among 600            parison with the baseline feature set containing
randomly selected sentences as the held out test          merely the feature of HEAD. Also the integrated
data not overlapping with the training set. To            feature set of HEAD and CONTEXT together
automate the evaluation, we blank out the verb            achieves a more satisfactory suggestion result.
collocates within these sentences and treat these
verbs directly as the only correct suggestions in         4    Conclusion
question, although two or more suggestions may
be interchangeable or at least appropriate. In this       Many avenues exist for future research that are
sense, our evaluation is an underestimate of the          important for improving the proposed method.
performance of the proposed method.                       For example, we need to carry out the experi-
  While evaluating the quality of the suggestions         ment on authentic learners’ texts. We will con-
provided by our system, we used the mean recip-           duct a user study to investigate whether our sys-
rocal rank (MRR) of the first relevant sugges-            tem would improve a learner’s writing in a real
tions returned so as to assess whether the sugges-        setting. Additionally, adding classifier features
tion list contains an answer and how far up the           based on the translation of misused words in
answer is in the list as a quality metric of the sys-     learners’ text could be beneficial (Chang et al.,


                                                        118


2008). The translation can help to resolve preva-
lent collocation misuses influenced by a learner's
native language. Yet another direction of this
research is to investigate if our methodology is
applicable to other types of collocations, such as
AN and PN in addition to VN dealt with in this
paper.
   In summary, we have presented an unsuper-
vised method for suggesting collocations based
on a corpus of abstracts collected from the Web.
The method involves selecting features from the
reference corpus of the scholarly texts. Then a
classifier is automatically trained to determine
the most probable collocation candidates with
regard to the given context. The preliminary re-
sults show that it is beneficial to use classifiers
for identifying and ranking collocation sugges-
tions based on the context features.

Reference
Y. Chang, J. Chang, H. Chen, and H. Liou. 2008. An
   automatic collocation writing assistant for Taiwan-
   ese EFL learners: A case of corpus-based NLP
   technology. Computer Assisted Language Learn-
   ing, 21(3), pages 283-299.
S. Granger. 1998. Prefabricated patterns in advanced
   EFL writing: collocations and formulae. In Cowie,
   A. (ed.) Phraseology: theory, analysis and applica-
   tions. Oxford University Press, Oxford, pages 145-
   160.
P. Howarth. 1996. Phraseology in English Academic
   Writing. Tübingen: Max Niemeyer Verlag.
P. Howarth. 1998. The phraseology of learner’s aca-
   demic writing. In Cowie, A. (ed.) Phraseology:
   theory, analysis and applications. Oxford Univer-
   sity Press, Oxford, pages 161-186.
D. Hawking and N. Craswell. 2002. Overview of the
  TREC-2001 Web track. In Proceedings of the 10th
  Text Retrieval Conference (TREC 2001), pages 25-
  31.
L. E. Liu. 2002. A corpus-based lexical semantic in-
   vestigation of verb-noun miscollocations in Taiwan
   learners’ English. Unpublished master’s thesis,
   Tamkang University, Taipei, January.
A. L. Liu, D. Wible, and N. L. Tsao. 2009. Automated
   suggestions for miscollocations. In Proceedings of
   the Fourth Workshop on Innovative Use of NLP for
   Building Educational Applications, pages 47-50.
C. C. Shei and H. Pain. 2000. An ESL writer’s collo-
   cational aid. Computer Assisted Language Learn-
   ing, 13, pages 167-182.




                                                         119

                      Generating Entailment Rules from FrameNet

      Roni Ben Aharon              Idan Szpektor            Ido Dagan
Department of Computer Science    Yahoo! Research Department of Computer Science
      Bar-Ilan University           Haifa, Israel       Bar-Ilan University
      Ramat Gan, Israel        idan@yahoo-inc.com       Ramat Gan, Israel
r.ben.aharon@gmail.com                              dagan@cs.biu.ac.il


                      Abstract                                    FrameNet is a manually constructed database
                                                                  based on Frame Semantics. It models the semantic
    Many NLP tasks need accurate knowl-                           argument structure of predicates in terms of proto-
    edge for semantic inference. To this end,                     typical situations called frames.
    mostly WordNet is utilized. Yet Word-                            Prior work utilized FrameNet’s argument map-
    Net is limited, especially for inference be-                  ping capabilities but took entailment relations
    tween predicates. To help filling this gap,                   from other resources, namely WordNet. We
    we present an algorithm that generates                        propose a novel method for generating entail-
    inference rules between predicates from                       ment rules from FrameNet by detecting the entail-
    FrameNet. Our experiment shows that the                       ment relations implied in FrameNet. We utilize
    novel resource is effective and comple-                       FrameNet’s annotated sentences and relations be-
    ments WordNet in terms of rule coverage.                      tween frames to extract both the entailment rela-
                                                                  tions and their argument mappings.
1   Introduction
                                                                     Our analysis shows that the rules generated by
Many text understanding applications, such as                     our algorithm have a reasonable “per-rule” accu-
Question Answering (QA) and Information Ex-                       racy of about 70%2 . We tested the generated rule-
traction (IE), need to infer a target textual mean-               set on an entailment testbed derived from an IE
ing from other texts. This need was proposed as a                 benchmark and compared it both to WordNet and
generic semantic inference task under the Textual                 to state-of-the-art rule generation from FrameNet.
Entailment (TE) paradigm (Dagan et al., 2006).                    Our experiment shows that our method outper-
   A fundamental component in semantic infer-                     forms prior work. In addition, our rule-set’s per-
ence is the utilization of knowledge resources.                   formance is comparable to WordNet and it is com-
However, a major obstacle to improving semantic                   plementary to WordNet when uniting the two re-
inference performance is the lack of such knowl-                  sources. Finally, additional analysis shows that
edge (Bar-Haim et al., 2006; Giampiccolo et al.,                  our rule-set accuracy is 90% in practical use.
2007). We address one prominent type of infer-
ence knowledge known as entailment rules, focus-                  2     Background
ing specifically on rules between predicates, such
                                                                  2.1    Entailment Rules and their Acquisition
as ‘cure X ⇒ X recover’.
   We aim at highly accurate rule acquisition,                    To generate entailment rules, two issues should
for which utilizing manually constructed sources                  be addressed: a) identifying the lexical entailment
seem appropriate. The most widely used manual                     relations between predicates, e.g. ‘cure ⇒ re-
resource is WordNet (Fellbaum, 1998). Yet it is in-               cover’; b) mapping argument positions, e.g. ‘cure
complete for generating entailment rules between                  X ⇒ X recover’. The main approach for gener-
predicates (Section 2.1). Hence, other manual re-                 ating highly accurate rule-sets is to use manually
sources should also be targeted.                                  constructed resources. To this end, most systems
   In this work1 , we explore how FrameNet                        mainly utilize WordNet (Fellbaum, 1998), being
(Baker et al., 1998) could be effectively used for                the most prominent lexical resource with broad
generating entailment rules between predicates.                   coverage of predicates. Furthermore, some of its
   1                                                                2
     The detailed description of our work can be found in             The rule-set is available at: http://www.cs.biu.
(Ben Aharon, 2010).                                               ac.il/˜nlp/downloads


                                                            241
                        Proceedings of the ACL 2010 Conference Short Papers, pages 241–246,
                  Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


relations capture types of entailment relations, in-          same frame or whose frames are related by one of
cluding synonymy, hypernymy, morphologically-                 FrameNet’s inter-frame relations. Each candidate
derived, entailment and cause.                                pair is considered entailing if the two LUs are ei-
   Yet, WordNet is limited for entailment rule gen-           ther synonyms or in a direct hypernymy relation in
eration. First, many entailment relations, no-                WordNet (providing the vast majority of LexPar’s
tably for the WordNet entailment and cause re-                relations), or if their related frames are connected
lation types, are missing, e.g. ‘elect ⇒ vote’.               via the Perspective relation in FrameNet.
Furthermore, WordNet does not include argument                   Then, argument mappings between each entail-
mapping between related predicates. Thus, only                ing LU pair are extracted based on the core FEs
substitutable WordNet relations (synonymy and                 that are shared between the two LUs. The syntac-
hypernymy), for which argument positions are                  tic positions of the shared FEs are taken from the
preserved, could be used to generate entailment               valence patterns of the LUs. A LexPar rule exam-
rules. The other non-substitutable relations, e.g.            ple is presented in Figure 3 (top part).
cause (‘kill ⇒ die’) and morphologically-derived                 Since most of LexPar’s entailment relations
(‘meet.v ⇔ meeting.n’), cannot be used.                       are based on WordNet’s relations, LexPar’s rules
                                                              could be viewed as an intersection of WordNet and
2.2   FrameNet
                                                              FrameNet lexical relations, accompanied with ar-
FrameNet (Baker et al., 1998) is a knowledge-                 gument mappings taken from FrameNet.
base of frames, describing prototypical situations.
Frames can be related to each other by inter-frame            3     Rule Extraction from FrameNet
relations, e.g. Inheritance, Precedence, Usage and
Perspective.                                                  The above prior work identified lexical entailment
   For each frame, several semantic roles are spec-           relations mainly from WordNet, which limits the
ified, called frame elements (FEs), denoting the              use of FrameNet in two ways. First, some rela-
participants in the situation described. Each FE              tions that appear in FrameNet are missed because
may be labeled as core if it is central to the frame.         they do not appear in WordNet. Second, unlike
For example, some core FEs of the Commerce pay                FrameNet, WordNet does not include argument
frame are Buyer and Goods, while a non-core FE                mappings for its relations. Thus, prior work for
is Place. Each FE may also be labeled with a se-              rule generation considered only substitutable rela-
mantic type, e.g. Sentient, Event, and Time.                  tions from WordNet (synonyms and hypernyms),
   A frame includes a list of predicates that can             not utilizing FrameNet’s capability to map argu-
evoke the described situation, called lexical units           ments of non-substitutable relations.
(LUs). LUs are mainly verbs but may also be                      Our goal in this paper is to generate entail-
nouns or adjectives. For example, the frame Com-              ment rules solely from the information within
merce pay lists the LUs pay.v and payment.n.                  FrameNet. We present a novel algorithm for gen-
   Finally, FrameNet contains annotated sentences             erating entailment rules from FrameNet, called
that represent typical LU occurrences in texts.               FRED (FrameNet Entailment-rule Derivation),
Each annotation refers to one LU in a specific                which operates in three steps: a) extracting tem-
frame and the FEs of the frame that occur in the              plates for each LU; b) detecting lexical entailment
sentence. An example sentence is “IBuyer have to              relations between pairs of LUs; c) generating en-
pay the billsM oney ”. Each sentence is accompa-              tailment rules by mapping the arguments between
nied by a valence pattern, which provides, among              two LUs in each entailing pair.
other info, grammatical functions of the core FEs
                                                              3.1    Template Extraction
with respect to the LU. The valence pattern of the
above sentence is [(Buyer Subj), (Money Obj)].                Many LUs in FrameNet are accompanied by an-
                                                              notated sentences (Section 2.2). From each sen-
2.3   Using FrameNet for Semantic Inference                   tence of a given LU, we extract one template for
To the best of our knowledge, the only work that              each annotated FE in the sentence. Each tem-
utilized FrameNet for entailment rule generation              plate includes the LU, one argument correspond-
is LexPar (Coyne and Rambow, 2009). LexPar                    ing to the target FE and their syntactic relation
first identifies lexical entailment relations by go-          in the sentence parse-tree. We focus on extract-
ing over all LU pairs which are either in the                 ing unary templates, as they can describe any ar-


                                                        242


                                                             3.2   Identifying Lexical Entailment Relations
                                                             FrameNet groups LUs in frames and describes re-
                                                             lations between frames. However, relations be-
                                                             tween LUs are not explicitly defined. We next de-
                                                             scribe how we automatically extract several types
                                                             of lexical entailment relations between LUs using
                                                             two approaches.
                                                                In the first approach, LUs in the same frame
                                                             that are morphological derivations of each other,
                                                             e.g. ‘negotiation.n’ and ‘negotiate.v’, are marked
                                                             as paraphrases. We take morphological derivation
                                                             information from the CATVAR database (Habash
                                                             and Dorr, 2003).
                                                                The second approach is based on our observa-
                                                             tion that some LUs express the prototypical situ-
                                                             ation that their frame describes, which we denote
                                                             dominant LUs. For example, the LU ‘recover’ is
                                                             dominant for the Recovery frame. We mark LUs
Figure 1: Template extraction for a sentence con-            as dominant if they are morphologically derived
taining the LU ‘arrest’.                                     from the frame’s name.
                                                                Our assumption is that since dominant LUs ex-
                                                             press the frame’s generic meaning, their meaning
gument mapping by decomposing templates with                 is likely to be entailed by the other LUs in this
several arguments into unary ones (Szpektor and              frame. Consequently, we generate such lexical
Dagan, 2008). Figure 1 exemplifies this process.             rules between any dominant LU and any other LU
   As a pre-parsing step, all FE phrases in a given          in a given frame, e.g. ‘heal ⇒ recover’ and ‘con-
sentence are replaced by their related FE names,             valescence ⇒ recover’ for the Recovery frame.
excluding syntactic information such as preposi-                In addition, we assume that if two frames are
tions or possessives (step (b) in Figure 1). Then,           related by some type of entailment relation, their
the sentence is parsed using the Minipar depen-              dominant LUs are also related by the same rela-
dency parser (Lin, 1998) (step (c)). Finally, a              tion. Accordingly, we extract entailment relations
path in the parse-tree is extracted between each FE          between dominant LUs of frames that are con-
node and the node of the LU (step (d)). Each ex-             nected via the Inheritance, Cause and Perspective
tracted path is converted into a template by replac-         relations, where Inheritance and Cause generate
ing the FE node with an argument variable.                   directional entailment relations (e.g. ‘choose ⇒
   We simplify each extracted path by removing               decide’ and ‘cure ⇒ recover’, respectively) while
nodes along the path that are not part of the syn-           Perspective generates bidirectional paraphrase re-
tactic relation between the LU and the FE, such              lations (e.g. ‘transfer ⇔ receive’).
as conjunctions and other FE nodes. For example,                Finally, we generate the transitive closure of
               subj            conj                          the set of lexical relations identified by the above
‘Authorities ←− enter −→ arrest’ is simplified
                      subj                                   methods. For example, the combination of ‘sell ⇔
into ‘Authorities ←− arrest’.
                                                             buy’ and ‘buy ⇒ get’ generates ‘sell ⇒ get’.
   Some templates originated from different anno-
tated sentences share the same LU and syntactic              3.3   Generating Entailment Rules
structure, but differ in their FEs. Usually, one of
                                                             The final step in the FRED algorithm generates
these templates is incorrect, due to erroneous parse
                obj
                                                             lexical syntactic entailment rules from the ex-
(e.g. ‘Suspect ←− arrest’ is a correct template, in          tracted templates and lexical entailment relations.
                             obj
contrast to ‘Charges ←− arrest’). We thus keep                  For each identified lexical relation ‘left ⇒ right’
only the most frequently annotated template out of           between two LUs, the set of FEs that are shared by
the identical templates, assuming it is the correct          both LUs is collected. Then, for each shared FE,
one.                                                         we take the list of templates that connect this FE


                                                       243


Lexical Relation:                                                in practice, as well as to compare its performance
cure ⇒ recovery                                                  to related resources. To this end, we follow the ex-
Templates:
                                                                 perimental setup presented in (Szpektor and Da-
         obj
P atient ←− cure              (cure Patient)
                                                                 gan, 2009), which utilized the ACE 2005 event
               of
Af f liction ←− cure          (cure of Affliction)
                                                                 dataset3 as a testbed for entailment rule-sets. We
          gen
P atient ←− recovery          (Patient’s recovery)               briefly describe this setup here.
         of
P atient ←− recovery          (recovery of Patient)                 The task is to extract argument mentions for
               f rom
Af f liction ←− recovery      (recovery from Affliction)         26 events, such as Sue and Attack, from the ACE
                                                                 annotated corpus, using a given tested entailment
Intra-LU Entailment Rules:
         gen                     of
P atient ←− recovery ⇐⇒ P atient ←− recovery
                                                                 rule-set. Each event is represented by a set of
                                                                 unary seed templates, one for each event argu-
Inter-LU Entailment Rules:                                       ment. Some seed templates for Attack are ‘At-
         obj                 gen                                          subj                   obj
P atient ←− cure =⇒ P atient ←− recovery                         tacker←−attack’ and ‘attack−→Target’.
         obj                      of
P atient ←− cure =⇒ P atient ←− recovery                            Argument mentions are found in the ACE cor-
               of                       f rom
Af f liction ←− cure =⇒ Af f liction ←− recovery                 pus by matching either the seed templates or tem-
                                                                 plates entailing them found in the tested rule-set.
Figure 2: Some entailment rules generated for the                We manually added for each event its relevant
lexical relation ‘cure.v ⇒ recovery.n’.                          WordNet synset-ids and FrameNet frame-ids, so
                                                                 only rules fitting the event target meaning will be
        Configuration         R (%)    P (%)     F1              extracted from the tested rule-sets.
        No-Rules              13.8     57.7     20.9
        LexPar                14.1     42.9     17.4             4.2     Tested Configurations
        WordNet               18.3     32.2     17.8
        FRED                  17.6     55.1     24.6             We evaluated several rule-set configurations:
        FRED ∪ WordNet        21.8     33.3     20.9
                                                                 No-Rules The system matches only the seed
Table 1: Macro average Recall (R), Precision (P)                 templates directly, without any additional rules.
and F1 results for the tested configurations.
                                                                 WordNet Rules are generated from WordNet
                                 fe        fe                    3.0, using only the synonymy and hypernymy rela-
to each of the LUs, denoted by Tlef t and Tright .               tions (see Section 2.1). Transitive chaining of re-
                                       fe
Finally, for each template pair, l ∈ Tlef t and r ∈              lations is allowed (Moldovan and Novischi, 2002).
  fe
Tright , the rule ‘l ⇒ r’ is generated. In addition,
                                                                 LexPar Rules are generated from the publicly
we generate paraphrase rules between the various
                                                                 available LexPar database. We generated unary
templates including the same FE and the same LU.
                                                                 rules from each LexPar rule based on a manually
Figure 2 illustrates this process.
                                                                 constructed mapping from FrameNet grammatical
   To improve rule quality, we filter out rules that
                                                                 functions to Minipar dependency relations. Fig-
map FEs of adjunct-like semantic types, such as
                                                                 ure 3 presents an example of this procedure.
Time and Location, since different templates of
such FEs may have different semantic meanings                    FRED Rules are generated by our algorithm.
                    bef ore                af ter
(e.g. ‘T ime ←− arrive’ ‘T ime ←− arrive’).
                                                                 FRED ∪ WordNet The union of the rule-sets of
Thus, it is hard to identify those template pairs that
                                                                 FRED and WordNet.
correctly map these FEs for entailment.
   We manually evaluated a random sample of 250                  4.3     Results
rules from the resulting rule-set, out of which we
                                                                 Each configuration was tested on each ACE event.
judged 69% as correct.
                                                                 We measured recall, precision and F1. Table 1
                                                                 reports macro averages of the three measures over
4     Application-based Evaluation
                                                                 the 26 ACE events.
4.1    Experimental Setup                                           As expected, using No-Rules achieves the high-
                                                                 est precision and the lowest recall compared to all
We would like to evaluate the overall utility of our
                                                                 other configurations. When adding LexPar rules,
resource for NLP applications, assessing the cor-
                                                                    3
rectness of the actual rule applications performed                      http://projects.ldc.upenn.edu/ace/


                                                           244


LexPar rule:
Lexemes: arrest −→ apprehend
Valencies: [(Authorities Subj), (Suspect Obj), (Offense (for))] =⇒ [(Authorities Subj), (Suspect Obj), (Offense (in))]

Generated unary rules:
  subj              subj                      obj                      obj           f or                   in
X ←− arrest =⇒ X ←− apprehend , arrest −→ Y =⇒ apprehend −→ Y , arrest −→ Z =⇒ apprehend −→ Z


             Figure 3: An example for generation of unary entailment rules from a LexPar rule.


only a slight increase in recall is gained. This                   Net, since FrameNet is a much smaller resource.
shows that the subset of WordNet rules captured                    Yet, its rules are mostly complementary to those
by LexPar (Section 2.3) might be too small for the                 from WordNet. This added value is demon-
ACE application setting.                                           strated by the 19% recall increase for the union of
   When using all WordNet’s substitutable rela-                    FRED and WordNet rule-sets compared to Word-
tions, a substantial relative increase in recall is                Net alone. FRED provides mainly argument map-
achieved (32%). Yet, precision decreases dramat-                   pings for non-substitutable WordNet relations, e.g.
ically (relative decrease of 44%), causing an over-                ‘attack.n on X ⇒ attack.v X’, but also lexical re-
all decrease in F1. Most errors are due to correct                 lations that are missing from WordNet, e.g. ‘am-
WordNet rules whose LHS is ambiguous. Since                        bush.v ⇒ attack.v’.
we do not apply a WSD module, these rules are                         Overall, our experiment shows that the rule-
also incorrectly applied to other senses of the LHS.               base generated by FRED seems an appropri-
While this phenomenon is common to all rule-sets,                  ate complementary resource to the widely used
WordNet suffers from it the most since it contains                 WordNet-based rules in semantic inference and
many infrequent word senses.                                       expansion over predicates. This suggestion is es-
   Our main result is that using FRED’s rule-set,                  pecially appealing since our rule-set performs well
recall increases significantly, a relative increase                even when a WSD module is not applied.
of 27% compared to No-Rules, while precision
hardly decreases. Hence, overall F1 is the high-                   5     Conclusions
est compared to all other configurations (a rela-
tive increase of 17% compared to No-Rules). The                    We presented FRED, a novel algorithm for gener-
improvement in F1 is statistically significant com-                ating entailment rules solely from the information
pared to all other configurations, according to the                contained in FrameNet. Our experiment showed
two-sided Wilcoxon signed rank test at the level of                that FRED’s rules perform substantially better
0.01 (Wilcoxon, 1945).                                             than LexPar, the only prior rule-set derived from
   FRED preforms significantly better than LexPar                  FrameNet. In addition, FRED’s rule-set largely
in both recall, precision and F1 (a relative increase              complements the rules generated from WordNet
of 25%, 28% and 41% respectively). For example,                    because it contains argument mappings between
LexPar hardly utilizes FrameNet’s argument map-                    non-substitutable predicates, which are missing
ping capabilities since most of its rules are based                from WordNet, as well as lexical relations that are
on a sub-set of WordNet’s substitutable relations.                 not included in WordNet.
   FRED’s precision is substantially higher than                      In future work we plan to investigate combin-
WordNet. This mostly results from the fact                         ing FrameNet and WordNet rule-sets in a transitive
that FrameNet mainly contains common senses                        manner, instead of their simple union.
of predicates while WordNet includes many rare
word senses; which, as said above, harms preci-                    Acknowledgments
sion when WSD is not applied. Error analysis
showed that only 7.5% of incorrect extractions are                 This work was partially supported by the Rec-
due to erronous rules in FRED, while the majority                  tor’s research grant of Bar-Ilan University, the
of errors are due to sense mismatch or syntactic                   PASCAL-2 Network of Excellence of the Eu-
matching errors of the seed templates ot entailing                 ropean Community FP7-ICT-2007-1-216886 and
templates in texts.                                                the Israel Science Foundation grant 1112/08.
   FRED’s Recall is somewhat lower than Word-


                                                             245


References
Collin Baker, Charles Fillmore, and John Lowe. 1998.
  The berkeley framenet project. In Proceedings of
  COLING-ACL, Montreal, Canada.
Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,
  Danilo Giampiccolo, Bernardo Magnini, and Idan
  Szpektor. 2006. The second pascal recognising tex-
  tual entailment challenge. In Second PASCAL Chal-
  lenge Workshop for Recognizing Textual Entailment.
Roni Ben Aharon. 2010. Generating entailment rules
  from framenet. Master’s thesis, Bar-Ilan University.
Robert Coyne and Owen Rambow. 2009. Lexpar: A
  freely available english paraphrase lexicon automat-
  ically extracted from framenet. In Proceedings of
  the Third IEEE International Conference on Seman-
  tic Computing.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
   2006. The pascal recognising textual entailment
   challenge. In Lecture Notes in Computer Science,
   volume 3944, pages 177–190.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
  tronic Lexical Database. MIT Press, Cambridge,
  Massachusetts.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
  and Bill Dolan. 2007. The third pascal recogniz-
  ing textual entailment challenge. In Proceedings of
  the ACL-PASCAL Workshop on Textual Entailment
  and Paraphrasing.
Nizar Habash and Bonnie Dorr. 2003. A categorial
  variation database for english. In Proceedings of
  the North American Association for Computational
  Linguistics (NAACL ’03), pages 96–102, Edmonton,
  Canada. Association for Computational Linguistics.
Dekang Lin. 1998. Dependency-based evaluation of
  minipar. In Proceedings of the Workshop on Evalu-
  ation of Parsing Systems at LREC.
Dan Moldovan and Adrian Novischi. 2002. Lexical
  chains for question answering. In Proceedings of
  COLING.
Idan Szpektor and Ido Dagan. 2008. Learning en-
   tailment rules for unary templates. In Proceedings
   of the 22nd International Conference on Compu-
   tational Linguistics (Coling 2008), pages 849–856,
   Manchester, UK, August.
Idan Szpektor and Ido Dagan. 2009. Augmenting
   wordnet-based inference with argument mapping.
   In Proceedings of the 2009 Workshop on Applied
   Textual Inference, pages 27–35, Suntec, Singapore,
   August.
Frank Wilcoxon. 1945. Individual comparisons by
  ranking methods. Biometrics Bulletin, 1(6):80–83.




                                                         246

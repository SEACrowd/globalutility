                       Vocabulary Choice as an Indicator of Perspective

                   Beata Beigman Klebanov, Eyal Beigman, Daniel Diermeier
                  Northwestern University and Washington University in St. Louis
              beata,d-diermeier@northwestern.edu, beigman@wustl.edu




                          Abstract                                 one can talk about perspectives of people on two
                                                                   sides of a conflict; this is not opposition or sup-
        We establish the following characteris-                    port for any particular proposal, but ideas about
        tics of the task of perspective classifi-                  a highly related cluster of issues, such as Israeli
        cation: (a) using term frequencies in a                    and Palestinian perspectives on the conflict in all
        document does not improve classification                   its manifestations. Zooming out even further, one
        achieved with absence/presence features;                   can talk about perspectives due to certain life con-
        (b) for datasets allowing the relevant com-                tingencies, such as being born and raised in a par-
        parisons, a small number of top features is                ticular culture, region, religion, or political tradi-
        found to be as effective as the full feature               tion, such perspectives manifesting themselves in
        set and indispensable for the best achieved                certain patterns of discourse on a wide variety of
        performance, testifying to the existence                   issues, for example, views on political issues in the
        of perspective-specific keywords. We re-                   Middle East from Arab vs Western observers.
        late our findings to research on word fre-                    In this article, we consider perspective at all
        quency distributions and to discourse ana-                 the four levels of abstraction. We apply the same
        lytic studies of perspective.                              types of models to all, in order to discover any
1       Introduction                                               common properties of perspective classification.
                                                                   We contrast it with text categorization and with
We address the task of perspective classification.                 opinion classification by employing models rou-
Apart from the spatial sense not considered here,                  tinely used for such tasks. Specifically, we con-
perspective can refer to an agent’s role (doctor vs                sider models that use term frequencies as features
patient in a dialogue), or understood as “a par-                   (usually found to be superior for text categoriza-
ticular way of thinking about something, espe-                     tion) and models that use term absence/presence
cially one that is influenced by one’s beliefs or                  (usually found to be superior for opinion classi-
experiences,” stressing the manifestation of one’s                 fication). We motivate our hypothesis that pre-
broader perspective in some specific issue, or “the                sence/absence features would be as good as or
state of one’s ideas, the facts known to one, etc.,                better than frequencies, and test it experimentally.
in having a meaningful interrelationship,” stress-                 Secondly, we investigate the question of feature
ing the meaningful connectedness of one’s stances                  redundancy often observed in text categorization.
and pronouncements on possibly different issues.1
   Accordingly, one can talk about, say, opinion                   2   Vocabulary Selection
on a particular proposed legislation on abortion                   A line of inquiry going back at least to Zipf strives
within pro-choice or pro-life perspectives; in this                to characterize word frequency distributions in
case, perspective essentially boils down to opi-                   texts and corpora; see Baayen (2001) for a sur-
nion in a particular debate. Holding the issue con-                vey. One of the findings in this literature is that
stant but relaxing the requirement of a debate on a                a multinomial (called “urn model” by Baayen)
specific document, we can consider writings from                   is not a good model for word frequency distri-
pro- and con- perspective, in, for example, the                    butions. Among the many proposed remedies
death penalty controversy over a course of a period                (Baayen, 2001; Jansche, 2003; Baroni and Evert,
of time. Relaxing the issue specificity somewhat,                  2007; Bhat and Sproat, 2009), we would like to
    1
        Google English Dictionary, Dictionary.com                  draw attention to the following insight articulated


                                                             253
                            Proceedings of the ACL 2010 Conference Short Papers, pages 253–257,
                      Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


most clearly in Jansche (2003). Estimation is im-              by President Bush in 2003. We use data from
proved if texts are construed as being generated by            278 legislators, with 669 speeches in all. We
two processes, one choosing which words would                  take only one speech per speaker per year; since
appear at all in the text, and then, for words that            many serve multiple years, each speaker is repre-
have been chosen to appear, how many times they                sented with 1 to 5 speeches. We perform 10-fold
would in fact appear. Jansche (2003) describes a               cross-validation splitting by speakers, so that all
two-stage generation process: (1) Toss a z-biased              speeches by the same speaker are assigned to the
coin; if it comes up heads, generate 0; if it comes            same fold and testing is always inter-speaker.
up tails, (2) generate according to F (θ), where                  When deriving the label for perspective, it is im-
F (θ) is a negative binomial distribution and z is a           portant to differentiate between a particular leg-
parameter controlling the extent of zero-inflation.            islation and a pro-choice / pro-life perspective.
   The postulation of two separate processes is                A pro-choice person might still support the bill:
effective for predicting word frequencies, but is              “I am pro-choice, but believe late-term abortions
there any meaning to the two processes? The first              are wrong. Abortion is a very personal decision
process of deciding on the vocabulary, or word                 and a woman’s right to choose whether to ter-
types, for the text – what is its function? Jansche            minate a pregnancy subject to the restrictions of
(2003) suggests that the zero-inflation component              Roe v. Wade must be protected. In my judgment,
takes care of the multitude of vocabulary words                however, the use of this particular procedure can-
that are not “on topic” for the given text, including          not be justified.” (Rep. Shays, R-CT, 2003). To
taboo words, technical jargon, proper names. This              avoid inconsistency between vote and perspective,
implies that words that are chosen to appear are               we use data from pro-choice and pro-life non-
all “on topic”. Indeed, text segmentation studies              governmental organizations, NARAL and NRLC,
show that tracing recurrence of words in a text                that track legislators’ votes on abortion-related
permits topical segmentation (Hearst, 1997; Hoey,              bills, showing the percentage of times a legislator
1991). Yet, if a person compares abortion to infan-            supported the side the organization deems consis-
ticide – are we content with describing this word              tent with its perspective. We removed 22 legisla-
as being merely “on topic,” that is, having a certain          tors with a mixed record, that is, those who gave
probability of occurrence once the topic of abor-              20-60% support to one of the positions.2
tion comes up? In fact, it is only likely to occur                Death Penalty (DP) blogs: We use University
if the speaker holds a pro-life perspective, while a           of Maryland Death Penalty Corpus (Greene and
pro-choicer would avoid this term.                             Resnik, 2009) of 1085 texts from a number of pro-
   We therefore hypothesize that the choice of vo-             and anti-death penalty websites. We report 4-fold
cabulary is not only a matter of topic but also                cross-validation (DP-4) using the folds in Greene
of perspective, while word recurrence has mainly               and Resnik (2009), where training and testing data
to do with the topical composition of the text.                come from different websites for each of the sides,
Therefore, tracing word frequencies is not going to            as well as 10-fold cross-validation performance on
be effective for perspective classification beyond             the entire corpus, irrespective of the site.3
noting the mere presence/absence of words, dif-                   Bitter Lemons (BL): We use the GUEST part
ferently from the findings in text categorization,             of the BitterLemons corpus (Lin et al., 2006), con-
where frequency-based features usually do better               taining 296 articles published in 2001-2005 on
than boolean features for sufficiently large voca-             http://www.bitterlemons.org by more than 200 dif-
bulary sizes (McCallum and Nigam, 1998).                       ferent Israeli and Palestinian writers on issues re-
                                                               lated to the conflict.
3   Data                                                          Bitter Lemons International (BL-I): We col-
                                                               lected 150 documents each by a different per-
Partial Birth Abortion (PBA) debates: We use
                                                                   2
transcripts of the debates on Partial Birth Abor-                    Ratings are from: http://www.OnTheIssues.org/. We fur-
                                                               ther excluded data from Rep. James Moran, D-VA, as he
tion Ban Act on the floors of the US House and                 changed his vote over the years. For legislators rated by nei-
Senate in 104-108 Congresses (1995-2003). Simi-                ther NRLC nor NARAL, we assumed the vote aligns with the
lar legislation was proposed multiple times, passed            perspective.
                                                                   3
                                                                     The 10-fold setting yields almost perfect performance
the legislatures, and, after having initially been ve-         likely due to site-specific features beyond perspective per se,
toed by President Clinton, was signed into law                 hence we do not use this setting in subsequent experiments.


                                                         254


son from either Arab or Western perspectives                           NB - COUNT and SVM - NORMF for perspective clas-
on Middle Eastern affairs in 2003-2009 from                            sification; Pang et al. (2002) consider most and
http://www.bitterlemons-international.org/. The                        Yu et al. (2008) all of the above for related tasks
writers and interviewees on this site are usually                      of movie review and political party classification.
former diplomats or government officials, aca-                         We use SVMlight (Joachims, 1999) for SVM and
demics, journalists, media and political analysts.4                    WEKA toolkit (Witten and Frank, 2005; Hall et
The specific issues cover a broad spectrum, includ-                    al., 2009) for both version of Naive Bayes. Param-
ing public life, politics, wars and conflicts, educa-                  eter optimization for all SVM models is performed
tion, trade relations in and between countries like                    using grid search on the training data separately
Lebanon, Jordan, Iraq, Egypt, Yemen, Morocco,                          for each partition into train and test data.6
Saudi Arabia, as well as their relations with the
US and members of the European Union.                                  5        Results

3.1    Pre-processing                                                  Table 2 summarizes the cross-validation results for
                                                                       the four datasets discussed above. Notably, the
We are interested in perspective manifestations                        SVM - BOOL model is either the best or not signif-
using common English vocabulary. To avoid the                          icantly different from the best performing model,
possibility that artifacts such as names of senators                   although the competitors use more detailed textual
or states drive the classification, we use as features                 information, namely, the count of each word’s ap-
words that contain only lowercase letters, possibly                    pearance in the text, either raw (NB - COUNT), nor-
hyphenated. No stemming is performed, and no                           malized (SVM - NORMF), or combined with docu-
stopwords are excluded.5                                               ment frequency (SVM - TFIDF).

            Table 1: Summary of corpora                                Table 2: Classification accuracy. Scores sig-
         Data    #Docs     #Features     # CV folds                    nificantly different from the best performance
         PBA       669       9.8 K          10
         BL        296       10 K           10                         (p2t <0.05 on paired t-test) are given an asterisk.
         BL-I      150        9K            10                             Data             NB                      SVM
         DP       1085       25 K            4                                      BOOL      COUNT      BOOL      NORMF       TFIDF
                                                                           PBA      *0.93      0.96       0.96       0.96       0.97
                                                                           DP-4     0.82      0.82        0.83       0.82      0.727
                                                                           DP-10    *0.88     *0.93       0.98      *0.97      *0.97
4     Models                                                               BL       0.89      0.88        0.89       0.86       0.84
                                                                           BL-I     0.68      0.66        0.73       0.65       0.65
For generative models, we use two versions
of Naive Bayes models termed multi-variate                                We conclude that there is no evidence for the
Bernoulli (here, NB - BOOL) and multinomial (here,                     relevance of the frequency composition of the
NB - COUNT ), respectively, in McCallum and
                                                                       text for perspective classification, for all levels of
Nigam (1998) study of event models for text cate-                      venue- and topic-control, from the tightest (PBA
gorization. The first records presence/absence of a                    debates) to the loosest (Western vs Arab authors
word in a text, while the second records the num-                      on Middle Eastern affairs). This result is a clear
ber of occurrences. McCallum and Nigam (1998)                          indication that perspective classification is quite
found NB - COUNT to do better than NB - BOOL for                       different from text categorization by topic, where
sufficiently large vocabulary sizes for text catego-                   count-based features usually perform better than
rization by topic. For discriminative models, we                       boolean features. On the other hand, we have not
use linear SVM, with presence-absence, norma-
                                                                            6
lized frequency, and tfidf feature weighting. Both                           Parameter c controlling the trade-off between errors
                                                                       on training data and margin is optimized for all datasets,
types of models are commonly used for text clas-                       with the grid c = {10−6 , 10−5 , . . . , 105 }. On the DP
sification tasks. For example, Lin et al. (2006) use                   data parameter j controlling penalties for misclassification
                                                                       of positive and negative cases is optimized as well (j =
    4
      We excluded Israeli, Turkish, Iranian, Pakistani writers         {10−2 , 10−1 , . . . , 102 }), since datasets are unbalanced (for
as not clearly representing either perspective.                        example, there is a fold with 27%-73% split).
    5                                                                      7
      We additionally removed words containing support, op-                  Here SVM - TFIDF is doing somewhat better than SVM -
pos, sustain, overrid from the PBA data, in order not to in-           BOOL on one of the folds and much worse on two other folds;
flate the performance on perspective classification due to the         paired t-test with just 4 pairs of observations does not detect
explicit reference to the upcoming vote.                               a significant difference.


                                                                 255


observed that boolean features are reliably better                   in long-lasting controversies tend to consolidate
than count-based features, as reported for the sen-                  their vocabulary and signal their perspective with
timent classification task in the movie review do-                   certain stigma words and banner words, that is,
main (Pang et al., 2002).                                            specific keywords used by a discourse commu-
   We note the low performance on BL-I, which                        nity to implicate adversaries and to create sym-
could testify to a low degree of lexical consolida-                  pathy with own perspective, respectively (Teubert,
tion in the Arab vs Western perspectives (more on                    2001). Thus, in abortion debates, using infanti-
this below). It is also possible that the small size of              cide as a synonym for abortion is a pro-life stigma.
BL-I leads to overfitting and low accuracies. How-                   Note that this does not mean the rest of the fea-
ever, PBA subset with only 151 items (only 2002                      tures are not informative for classification, only
and 2003 speeches) is still 96% classifiable, so size                that they are redundant with respect to a small per-
alone does not explain low BL-I performance.                         centage of top weight features.
                                                                         When N best features are eliminated, perfor-
6   Consolidation of perspective
                                                                     mance goes down significantly with even smaller
We explore feature redundancy in perspective                         N for PBA and BL datasets. Thus, top features
classification.We first investigate retention of only                are not only effective, they are also crucial for ac-
N best features, then elimination thereof. As a                      curate classification, as their discrimination capa-
proxy of feature quality, we use the weight as-                      city is not replicated by any of the other vocabu-
signed to the feature by the SVM - BOOL model                        lary words. This finding is consistent with Lin
based on the training data. Thus, to get the per-                    and Hauptmann (2006) study of perspective vs
formance with N best features, we take the N2                        topic classification: While topical differences be-
highest and lowest weight features, for the posi-                    tween two corpora are manifested in difference in
tive and negative classes, respectively, and retrain                 distributions of great many words, they observed
SVM - BOOL with these features only.8                                little perspective-based variation in distributions
                                                                     of most words, apart from certain words that are
Table 3: Consolidation of perspective. Nbest                         preferentially used by adherents of one or the other
shows the smallest N and its proportion out of                       perspective on the given topic.
all features for which the performance of SVM -                         For DP and BL-I datasets, the results seem
BOOL with only the best N features is not sig-                       to suggest perspectives with more diffused key-
nificantly inferior (p1t >0.1) to that of the full                   word distribution (No-NBest figures are higher).
feature set. No-Nbest shows the largest num-                         We note, however, that feature redundancy exper-
ber N for which a model without N best fea-                          iments are confounded in these cases by either a
tures is not significantly inferior to the full model.               low power of the paired t-test with only 4 pairs
N={50, 100, 150, . . . , 1000}; for DP and BL-I, ad-                 (DP) or by a high variance in performance among
ditionally N={1050, 1100, ..., 1500}; for PBA, ad-                   the 10 folds (BL-I), both of which lead to nume-
ditionally N={10, 20, 30, 40}.                                       rically large discrepancy in performance that is not
           Data       Nbest          No-Nbest                        deemed significant, making it easy to “match” the
                    N     %         N      %                         full set performance with small-N best features as
           PBA     250 2.6%         10    <1%
           BL      500 4.9%        100    <1%
                                                                     well as without large-N best features. Better com-
           DP      100 <1%         1250 5.2%                         parisons are needed in order to verify the hypo-
           BL-I    200 2.2%        950    11%                        thesis of low consolidation.
                                                                        In future work, we plan to experiment with ad-
   We observe that it is generally sufficient to use                 ditional features. For example, Greene and Resnik
a small percentage of the available words to ob-                     (2009) reported higher classification accuracies
tain the same classification accuracy as with the                    for the DP-4 data using syntactic frames in which
full feature set, even in high-accuracy cases such                   a selected group of words appeared, rather than
as PBA and BL. The effectiveness of a small                          mere presence/absence of the words. Another di-
subset of features is consistent with the observa-                   rection is exploring words as members of seman-
tion in the discourse analysis studies that rivals                   tic fields – while word use might be insufficiently
    8
      We experimented with the mutual information based fea-         consistent within a perspective, selection of a se-
ture selection as well, with generally worse results.                mantic domain might show better consistency.


                                                               256


References                                                      Wolfgang Teubert. 2001. A Province of a Federal
                                                                 Superstate, Ruled by an Unelected Bureaucracy –
Herald Baayen. 2001. Word frequency distributions.               Keywords of the Euro-Sceptic Discourse in Britain.
  Dordrecht: Kluwer.                                             In Andreas Musolff, Colin Good, Petra Points, and
                                                                 Ruth Wittlinger, editors, Attitudes towards Europe:
Marco Baroni and Stefan Evert. 2007. Words                       Language in the unification process, pages 45–86.
 and Echoes: Assessing and Mitigating the Non-                   Ashgate Publishing Ltd, Hants, England.
 Randomness Problem in Word Frequency Distribu-
 tion Modeling. In Proceedings of the ACL, pages                Ian H. Witten and Eibe Frank. 2005. Data Mining:
 904–911, Prague, Czech Republic.                                  Practical Machine Learning Tools and Techniques.
                                                                   Morgan Kaufmann, 2 edition.
Suma Bhat and Richard Sproat. 2009. Knowing the
  Unseen: Estimating Vocabulary Size over Unseen                Bei Yu, Stefan Kaufmann, and Daniel Diermeier.
  Samples. In Proceedings of the ACL, pages 109–                  2008. Classifying party affiliation from political
  117, Suntec, Singapore, August.                                 speech. Journal of Information Technology and Pol-
                                                                  itics, 5(1):33–48.
Stephan Greene and Philip Resnik. 2009. More
   than Words: Syntactic Packaging and Implicit Sen-
   timent. In Proceedings of HLT-NAACL, pages 503–
   511, Boulder, CO, June.

Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
 Pfahringe, Peter Reutemann, and Ian H. Witten.
 2009. The WEKA data mining software: An up-
 date. SIGKDD Explorations, 11(1).

Marti Hearst. 1997. TextTiling: Segmenting Text into
 Multi-Paragraph Subtopic Passages. Computational
 Linguistics, 23(1):33–64.

Michael Hoey. 1991. Patterns of Lexis in Text. Oxford
  University Press.

Martin Jansche. 2003. Parametric Models of Linguis-
 tic Count Data. In Proceedings of the ACL, pages
 288–295, Sapporo, Japan, July.

Thorsten Joachims. 1999. Making large-scale SVM
  learning practical. In B. Schlkopf, C. Burges, and
  A. Smola, editors, Advances in Kernel Methods -
  Support Vector Learning. MIT Press.

Wei-Hao Lin and Alexander Hauptmann. 2006. Are
  these documents written from different perspec-
  tives? A test of different perspectives based on sta-
  tistical distribution divergence. In Proceedings of
  the ACL, pages 1057–1064, Morristown, NJ, USA.

Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and
  Alexander Hauptmann. 2006. Which side are you
  on? Identifying perspectives at the document and
  sentence levels. In Proceedings of CoNLL, pages
  109–116, Morristown, NJ, USA.

Andrew McCallum and Kamal Nigam. 1998. A com-
  parison of event models for Naive Bayes text clas-
  sification. In Proceedings of AAAI-98 Workshop
  on Learning for Text Categorization, pages 41–48,
  Madison, WI, July.

Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
  2002. Thumbs up? Sentiment Classification using
  Machine Learning Techniques. In Proceedings of
  EMNLP, Philadelphia, PA, July.


                                                          257

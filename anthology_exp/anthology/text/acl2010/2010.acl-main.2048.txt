    Cross Lingual Adaptation: An Experiment on Sentiment Classifications

                       Bin Wei                                       Christopher Pal
                University of Rochester                      École Polytechnique de Montréal
                 Rochester, NY, USA.                              Montréal, QC, Canada.
             bwei@cs.rochester.edu                         christopher.pal@polymtl.ca



                     Abstract                                 error introduced by the translator, Wan in (Wan,
                                                              2009) applied a co-training scheme. In this setting
     In this paper, we study the problem of                   classifiers are trained in both languages and the
     using an annotated corpus in English for                 two classifiers teach each other for the unlabeled
     the same natural language processing task                examples. The co-training approach manages to
     in another language. While various ma-                   boost the performance as it allows the text simi-
     chine translation systems are available, au-             larity in the target language to compete with the
     tomated translation is still far from per-               “fake” similarity from the translated texts. How-
     fect. To minimize the noise introduced                   ever, the translated texts are still used as training
     by translations, we propose to use only                  data and thus can potentially mislead the classifier.
     key ‘reliable” parts from the translations               As we are not really interested in predicting some-
     and apply structural correspondence learn-               thing on the language created by the translator,
     ing (SCL) to find a low dimensional rep-                 but rather on the real one, it may be better to fur-
     resentation shared by the two languages.                 ther diminish the role of the translated texts in the
     We perform experiments on an English-                    learning process. Motivated by this observation,
     Chinese sentiment classification task and                we suggest here to view this problem as a special
     compare our results with a previous co-                  case of domain adaptation, in the source domain,
     training approach. To alleviate the prob-                we mainly observe English features, while in the
     lem of data sparseness, we create ex-                    other domain mostly features from Chinese. The
     tra pseudo-examples for SCL by making                    problem we address is how to associate the fea-
     queries to a search engine. Experiments                  tures under a unified setting.
     on real-world on-line review data demon-                    There has been a lot of work in domain adaption
     strate the two techniques can effectively                for NLP (Dai et al., 2007)(Jiang and Zhai, 2007)
     improve the performance compared to pre-                 and one suitable choice for our problem is the ap-
     vious work.                                              proach based on structural correspondence learn-
                                                              ing (SCL) as in (Blitzer et al., 2006) and (Blitzer
1    Introduction
                                                              et al., 2007b). The key idea of SCL is to identify a
In this paper we are interested in the problem of             low-dimensional representations that capture cor-
transferring knowledge gained from data gathered              respondence between features from both domains
in one language to another language. A simple and             (xs and xt in our case) by modeling their correla-
straightforward solution for this problem might               tions with some special pivot features. The SCL
be to use automatic machine translations. How-                approach is a good fit for our problem as it per-
ever, while machine translation has been the sub-             forms knowledge transfer through identifying im-
ject of a great deal of development in recent years,          portant features. In the cross-lingual setting, we
many of the recent gains in performance manifest              can restrict the translated texts by using them only
as syntactically as opposed to semantically cor-              through the pivot features. We believe this form is
rect sentences. For example, “PIANYI” is a word               more robust to errors in the language produced by
mainly used in positive comments in Chinese but               the translator.
its translation from the online Google translator is             Adapting language resources and knowledge to
always “cheap”, a word typically used in a neg-               a new language was first studied for general text
ative context in English. To reduce this kind of              categorization and information retrieval as in (Bel


                                                        258
                       Proceedings of the ACL 2010 Conference Short Papers, pages 258–262,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


et al., 2003), where the authors translate a key-               2.1   Structural Correspondence
word lexicon to perform cross-lingual text cate-                      Learning(SCL)
gorization. In (Mihalcea et al., 2007), different
shortcomings of lexicon-based translation scheme                Due to space limitations, we give a very brief
was discussed for the more semantic-oriented task               overview of the SCL framework here. For a
subjective analysis, instead the authors proposed               detailed illustration, please refer to (Ando and
to use a parallel-corpus, apply the classifier in the           Zhang, 2005). When SCL is used in a domain
source language and use the corresponding sen-                  adaptation problem, one first needs to find a set
tences in the target language to train a new clas-              of pivot features xp . These pivot features should
sifier. With the rapid development of automatic                 behave in a similar manner in both domains, and
machine translations, translating the whole corpus              can be used as “references” to estimate how much
becomes a plausible option. One can either choose               other features may contribute when used in a clas-
to translate a corpus in the target language and ap-            sifier to predict a target variable. These features
ply the classifier in the source language to obtain             can either be identified with heuristics (Blitzer
labeled data, or directly translated the existing data          et al., 2006) or by automatic selection (Blitzer
set to the new language. Various experiments of                 et al., 2007b). Take sentiment classification as
the first strategy are performed in (Banea et al.,              an example, “very good” and “awful” are good
2008) for the subjective analysis task and an aver-             pivot features, if a certain feature in the target do-
age 65 F1 score was reported. In (Wan, 2008), the               main co-occurs often with “very good” but infre-
authors propose to combine both strategies with                 quently with “awful”, we could expect this fea-
ensemble learning and train a bi-lingual classifier.            ture will play a similar role as “very good” in
                                                                the final classifier but a different role from “aw-
   In this paper, we are also interested in explor-             ful”. We can make this observation purely based
ing whether a search engine can be used to im-                  on the co-occurrence between these features. No
prove the performance of NLP systems through re-                hand-labeling is required and this specific feature
ducing the effect of data sparseness. As the SCL                doesn’t need to be present in our labeled training
algorithm we use here is based on co-occurrence                 data of the source domain.
statistics, we adopt a simple approach of creating
                                                                   The SCL approach of (Ando and Zhang, 2005)
pseudo-examples from the query counts returned
                                                                formulates the above idea by constructing a set
by Google.
                                                                of linear predictors for each of the pivot fea-
                                                                tures. Each of these linear predictor is binary like
                                                                whether “very good” occurs in the text and we
2   Our Approach
                                                                have a set of training instances (1|0, {xi }). The
                                                                weight matrix of these linear predictors will en-
To begin, we give a formal definition of the prob-              code the co-occurrence statistics between an or-
lem we are considering. Assume we have two lan-                 dinary feature and the pivot features. As the co-
guages ls and lt and denote features in these two               occurrence data are generally very sparse for a typ-
languages as xs and xt respectively. We also have               ical NLP task, we usually compress the weight
text-level translations and we use xt0 for features             matrix using the singular vector decomposition
in the translations from ls to lt and xs0 for the               and only selects the top k eigenvectors vk . This
other direction. Let y be the output variable we                matrix w of the k vectors {vk } gives a mapping
want to predict, we have labeled examples (y, xs )              from the original feature space to a lower dimen-
and some unlabeled examples (xt ). Our task is to               sional representation and is shown in (Ando and
train a classifier for (y, xt ). In this paper, we con-         Zhang, 2005) to be the optimal choice of dimen-
sider the binary sentiment classification (positive             sion k under common loss functions. In the next
or negative) problem where ls and lt correspond to              step we can then train a classifier on the extended
English and Chinese (for general sentiment analy-               feature (x, w ∗ x) in the source domain. As w
sis, we refer the readers to the various previous               groups the features from different domains with
studies as in (Turney, 2002),(Pang et al., 2002),and            similar behavior relative to the pivot features to-
(McDonald et al., 2007)). With these definitions                gether, if such a classifier has good performance
in place, we now describe our approach in further               on the source domain, it will likely do well on the
detail.                                                         target domain as well.


                                                          259


2.2   SCL for the Cross-lingual Adaptation                         English Pivot Features
                                                                   “poor quality”, “not buy”, “easy use”, “very easy”
Viewing our task as a domain adaptation prob-
                                                                   “excellent”, “perfect”, “still very”, “garbage”,
lem. The source domain correspond to English
                                                                   “poor”, “not work”, “not to”, “very comfortable”
reviews and the target domain for Chinese ones.
The full feature vector is (xs , xt ). The difficulty              Chinese Pivot Features
we are facing is, due to noise in the translations,                wanmei(perfect), xiaoguo hen(effect is very...)
the conditional probabilities p(y|xs ) and the one                 tisheng(improve),feichang hao(very good),
in the translated texts p(y|xs0 ) may be quite differ-             cha(poor), shushi(comfortable), chuse(excellent)
ent. Consider the following two straightforward
strategies of using automatic machine translations:                          Table 1: Some pivot features.
one can translate the original English labeled data
(y, xs ) into (y, xt0 ) in Chinese and train a clas-              translations associated with the Chinese pivot fea-
sifier, or one can train a classifier on (y, xs ) and             tures. As we can see from the table, although
translate xt in Chinese into xs0 in English so as to              we only have text-level translations we still get
use the classifier. But as the conditional distribu-              some features with similar meaning from differ-
tion can be quite different for the original language             ent languages, just like performing an alignment
and the pseudo language produced by the machine                   of words.
translators, these two strategies give poor perfor-
mance as reported in (Wan, 2009).                                 2.3   Utilizing the Search Engine
   Our solution to this problem is simple: instead                Data sparseness is a common problem in NLP
of using all the features as (xs , xt0 ) and (xs0 , xt ),         tasks. On the other hand, search engines nowadays
we only preserves the pivot features in the trans-                usually index a huge amount of web pages. We
lated texts xs0 and xt0 respectively and discard the              now show how they can also be used as a valuable
other features produced by the translator. So, now                data source in a less obvious way. Previous studies
we will have (xs , xtp ) and (xsp , xt ) where x(s|t)p            like (Bollegala, 2007) have shown that search en-
are pivot features in the source and the target lan-              gine results can be comparable to language statis-
guages. In other words, when we use the SCL on                    tics from a large scale corpus for some NLP tasks
our problem, the translations are only used to de-                like word sense disambiguation. For our problem,
cide if a certain pivot feature occurs or not in the              we use the query counts returned by a search en-
training of the linear predictors. All the other non-             gine to compute the correlations between a normal
pivot features in the translators are blocked to re-              feature and the pivot features.
duce the noise.                                                      Consider the word “PIANYI” which is mostly
   In the original SCL as we mentioned earlier,                   used in positive comments, the query “CHAN-
the final classifier is trained on the extended fea-              PIN(product) PING(comment) CHA(bad) PI-
tures (x, w ∗ x). However, as mentioned above                     ANYI” has 2,900,000 results, while “CHAN-
we will only use the pivot features. To represent                 PIN(product) PING(comment) HAO(good) PI-
this constraint, we can modify the vector to be                   ANYI” returns 57,400,000 pages. The results im-
(wp ∗ x, w ∗ x) where wp is a constant matrix that                ply the word “PIANYI” is closer to the pivot fea-
only selects the pivot features. This modification                ture “good” and it behaves less similar with the
will not affect the deduction procedure and results               pivot feature “bad”.
in (Ando and Zhang, 2005). Experiments show                          To add the query counts into the SCL scheme,
that using only pivot features actually outperforms               we create pseudo examples when training lin-
the full feature setting.                                         ear predictors for pivot features. To construct a
   For the selection of the pivot features, we fol-               pseudo-positive example between a certain feature
low the automatic selection method proposed in                    xi and a certain pivot feature xp , we simply query
(Blitzer et al., 2007a). We first select some candi-              the term xi xp and get a count c1 . We also query
dates that occur at least some constant number of                 xp alone and get another count c2 .Then we can
times in reviews of the two languages. Then, we                   create an example (1, {0, ..., 0, xi = cc21 , 0, ..., 0}).
rank these features according to their conditional                The pseudo-negative examples are created simi-
entropy to the labels on the training set. In table               larly. These pseudo examples are equivalent to
1, we give some of the pivot features with English                texts with a single word and the count is used to


                                                            260


approximate the empirical expectation. As an ini-                         Models     Precision   Recall    F-Score
tial experiment, we select 10,000 Chinese features                        CoTrain    0.768       0.905     0.831
that occur more than once in the Chinese unla-                            SCL-B      0.772       0.914     0.837
beled data set but not frequent enough to be cap-                         SCL-C      0.764       0.896     0.825
tured by the original SCL. And we also select the                         SCL-O      0.760       0.909     0.828
top 20 most informative Chinese pivot features to                         SCL-E      0.801       0.909     0.851
perform the queries.
                                                                          Table 2: Results on the Positive Reviews
3       Experiment                                                        Models     Precision   Recall    F-Score
                                                                          CoTrain    0.879       0.717     0.790
3.1      Data Set
                                                                          SCL-B      0.931       0.752     0.833
For comparsion, we use the same data set in (Wan,                         SCL-C      0.908       0.743     0.817
2009):                                                                    SCL-O      0.928       0.739     0.823
   Test Set(Labeled Chinese Reviews): The data                            SCL-E      0.928       0.796     0.857
set contains a total of 886 labeled product reviews
in Chinese (451 positive reviews and 435 negative                         Table 3: Results on the Negative Reviews
ones). These reviews are extracted from a popular
Chinese IT product website IT168 1 . The reviews                    3.2    Comparisons
are mainly about electronic devices like mp3 play-
                                                                    We compare our procedure with the co-training
ers, mobile phones, digital cameras and comput-
                                                                    scheme reported in (Wan, 2009):
ers.
                                                                       CoTrain: The method with the best perfor-
   Training Set(Labeled English Reviews): This
                                                                    mance in (Wan, 2009). Two standard SVMs are
is the data set used in the domain adaption exper-
                                                                    trained using the co-training scheme for the Chi-
iment of (Blitzer et al., 2007b). It contains four
                                                                    nese views and the English views. And the results
major categories: books, DVDs, electronics and
                                                                    of the two SVMs are combined to give the final
kitchen appliances. The data set consists of 8000
                                                                    output.
reviews with 4000 positive and 4000 negative, It is
                                                                       SCL-B: The basic SCL procedure as explained.
a public data set available on the web 2 .
                                                                       SCL-O: The basic SCL except that we use all
   Unlabeled Set (Unlabeled Chinese Reviews):                       features from the translated texts instead of only
1000 Chinese reviews downloaded from the same                       the pivot features.
website as the Chinese training set. They are of                       SCL-C: The training procedure is still the same
the same domain as the test set.                                    as SCL-B except in the test time we only use
   We translate each English review into Chinese                    the Chinese pivot features and neglect the English
and vice versus through the public Google Trans-                    pivot features from translations.
lation service. Also following the setting in (Wan,                    SCL-E: The same as SCL-B except that in the
2009), we only use the Chinese unlabeled data and                   training of linear pivot predictors, we also use the
English training sets for our SCL training proce-                   pseudo examples constructed from queries of the
dures. The test set is blind to the training stage.                 search engine.
   The features we used are bigrams and unigrams                       Table 2 and 3 give results measured on the pos-
in the two languages as in (Wan, 2009). In Chi-                     itive labeled reviews and negative reviews sep-
nese, we first apply the stanford Chinese word seg-                 arately. Table 4 gives the overall accuracy on
menter 3 to segment the reviews. Bigrams refers                     the whole 886 reviews. Our basic SCL approach
to a single Chinese word and a bigram refers to                     SCL-B outperforms the original Co-Training ap-
two adjacent Chinese words. The features are also                   proach by 2.2% in the overall accuracy. We can
pre-processed and normalized as in (Blitzer et al.,
2007b).
                                                                     CoTrain        SCL-B   SCL-O     SCL-C      SCL-E
    1
                                                                     0.813          0.835   0.826     0.822      0.854
      http://www.it168.com
    2
      http://www.cis.upenn.edu/ mdredze/datasets/sentiment/
    3
      http://nlp.stanford.edu/software/segmenter.shtml              Table 4: Overall Accuracy of Different Methods


                                                              261


also notice that using all the features including the           ple tasks and unlabeled data. Journal of Machine
ones from translations actually deteriorate the per-            Learning Research.
formance from 0.835 to 0.826.                                 Carmen Banea, Rada Mihalcea, Janyce Wiebe, and
   The model incorporating the co-occurrence                    Samer Hassan. 2008. Multilingual subjectivity
count information from the search engine has the                analysis using machine translation. In Proceedings
best overall performance of 0.857. It is interesting            of EMNLP.
to note that the simple scheme we have adopted in-            Nuria Bel, Cornelis H. A. Koster, and Marta Ville-
creased the recall performance on the negative re-              gas. 2003. Cross-lingual text categorization. In
views significantly. After examining the reviews,               Research and AdvancedTechnology for Digital Li-
                                                                braries.
we find the negative part contains some idioms and
words mainly used on the internet and the query               John Blitzer, Ryan McDonald, and Fernando Pereira.
count seems to be able to capture their usage.                  2006. Domain adaptation with structural correspon-
   Finally, as our final goal is to train a Chinese             dence learning. In Proceedings of EMNLP.
sentiment classifier, it will be best if our model            John Blitzer, Koby Crammer, Alex Kulesza, Fernando
can only rely on the Chinese features. The SCL-                 Pereira, and Jennifer Wortman. 2007a. Learning
C model improves the performance from the Co-                   bounds for domain adaptation. In Proceedings of
                                                                NIPS.
Training method a little but not as much as the
SCL − B and the SCL − O approaches. This                      John Blitzer, Mark Dredze, and Fernando Pereira.
observation suggests that the translations are still            2007b. Biographies, bollywood, boom-boxes and
helpful for the cross-lingual adaptation problem                blenders: Domain adaptation for sentiment classi-
                                                                fication. In Proceedings of ACL.
as the translators perform some implicit semantic
mapping.                                                      Danushka Bollegala. 2007. Measuring semantic sim-
                                                                ilarity between words using web search engines. In
4   Conclusion                                                  Proceedings of WWW 07.

In this paper, we are interested in adapting ex-              Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and Yong
isting knowledge to a new language. We show                     Yu. 2007. Co-clustering based classification for
                                                                out-of-domain documents. In Proceedings of KDD.
that instead of fully relying on automatic trans-
lation, which may be misleading for a highly se-              Jing Jiang and ChengXiang Zhai. 2007. A two-stage
mantic task like the sentiment analysis, using tech-             approach to domain adaptation for statistical classi-
                                                                 fiers. In Proceedings of CIKM.
niques like SCL to connect the two languages
through feature-level mapping seems a more suit-              Ryan T. McDonald, Kerry Hannan, Tyler Neylon, Mike
able choice. We also perform an initial experiment              Wells, and Jeffrey C. Reynar. 2007. Structured
using the co-occurrence statistics from a search                models for fine-to-coarse sentiment analysis. In
                                                                Proceedings of ACL.
engine to handle the data sparseness problem in
the adaptation process, and the result is encourag-           Rada Mihalcea, Carmen Banea, and Janyce Wiebe.
ing.                                                            2007. Learning multilingual subjective language via
                                                                cross-lingual projections. In Proceedings of ACL.
   As future research we believe a promising av-
enue of exploration is to construct a probabilistic           Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
version of the SCL approach which could offer a                 2002. Thumbs up? sentiment classification us-
more explicit model of the relations between the                ing machine learning techniques. In Proceedings of
                                                                EMNLP.
two domains and the relations between the search
engine results and the model parameters. Also,                Peter D. Turney. 2002. Thumbs up or thumbs down?
in the current work, we select the pivot features               semantic orientation applied to unsupervised classi-
                                                                fication of reviews. In Proceedings of ACL.
by simple ranking with mutual information, which
only considers the distribution information. Incor-           Xiaojun Wan. 2008. Using bilingual knowledge and
porating the confidence from the translator may                 ensemble techniques for unsupervised chinese sen-
further improve the performance.                                timent analysis. In Proceedings of EMNLP.
                                                              Xiaojun Wan. 2009. Co-training for cross-lingual sen-
                                                                timent classification. In Proceedings of ACL.
References
Rie Kubota Ando and Tong Zhang. 2005. A frame-
  work for learning predictive structures from multi-


                                                        262

                       Using Anaphora Resolution to Improve
                    Opinion Target Identification in Movie Reviews

                   Niklas Jakob                      Iryna Gurevych
         Technische Universität Darmstadt   Technische Universität Darmstadt
        Hochschulstraße 10, 64289 Darmstadt Hochschulstraße 10, 64289 Darmstadt
                   http://www.ukp.tu-darmstadt.de/people


                     Abstract                                  put, it’s unfathomable that this movie cracks the
                                                               Top 250. It is absolutely awful.”. If one wants to
    Current work on automatic opinion min-                     extract what the opinion in the second sentence is
    ing has ignored opinion targets expressed                  about, an algorithm which resolves the anaphoric
    by anaphorical pronouns, thereby missing                   reference to the opinion target is required.
    a significant number of opinion targets. In                The extraction of such anaphoric opinion targets
    this paper we empirically evaluate whether                 has been noted as an open issue multiple times
    using an off-the-shelf anaphora resolution                 in the OM context (Zhuang et al., 2006; Hu and
    algorithm can improve the performance of                   Liu, 2004; Nasukawa and Yi, 2003). It is not a
    a baseline opinion mining system. We                       marginal phenomenon, since Kessler and Nicolov
    present an analysis based on two different                 (2009) report that in their data, 14% of the opin-
    anaphora resolution systems. Our exper-                    ion targets are pronouns. However, the task of re-
    iments on a movie review corpus demon-                     solving anaphora to mine opinion targets has not
    strate, that an unsupervised anaphora reso-                been addressed and evaluated yet to the best of our
    lution algorithm significantly improves the                knowledge.
    opinion target extraction. We furthermore                  In this work, we investigate whether anaphora res-
    suggest domain and task specific exten-                    olution (AR) can be successfully integrated into
    sions to an off-the-shelf algorithm which                  an OM algorithm and whether we can achieve an
    in turn yield significant improvements.                    improvement regarding the OM in doing so. This
                                                               paper is structured as follows: Section 2 discusses
1   Introduction                                               the related work on opinion target identification
Over the last years the task of opinion mining                 and OM on movie reviews. Section 3 outlines the
(OM) has been the topic of many publications.                  OM algorithm we employed by us, while in Sec-
It has been approached with different goals in                 tion 4 we discuss two different algorithms for AR
mind: Some research strived to perform subjec-                 which we experiment with. Finally, in Section 5
tivity analysis at the document or sentence level,             we present our experimental work including error
without focusing on what the individual opinions               analysis and discussion, and we conclude in Sec-
uttered in the document are about. Other ap-                   tion 6.
proaches focused on extracting individual opinion
                                                               2     Related Work
words or phrases and what they are about. This
aboutness has been referred to as the opinion tar-             We split the description of the related work in two
get or opinion topic in the literature from the field.         parts: In Section 2.1 we discuss the related work
In this work our goal is to extract opinion target             on OM with a focus on approaches for opinion
- opinion word pairs from sentences from movie                 target identification. In Section 2.2 we elaborate
reviews. A challenge which is frequently encoun-               on findings from related OM research which also
tered in text mining tasks at this level of gran-              worked with movie reviews as this is our target
ularity is, that entities are being referred to by             domain in the present paper.
anaphora. In the task of OM, it can therefore also
be necessary to analyze more than the content of               2.1    Opinion Target Identification
one individual sentence when extracting opinion                The extraction of opinions and especially opin-
targets. Consider this example sentence: “Simply               ion targets has been performed with quite diverse


                                                         263
                       Proceedings of the ACL 2010 Conference Short Papers, pages 263–268,
                 Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


approaches. Initial approaches combined statisti-              ions of the reviewers regarding the movie. Zhuang
cal information and basic linguistic features such             et al. (2006) also observe that movie reviews are
as part-of-speech tags. The goal was to identify               different from e.g. customer reviews on Ama-
the opinion targets, here in form of products and              zon.com. This is reflected in their experiments, in
their attributes, without a pre-built knowledge base           which their system outperforms the system by Hu
which models the domain. For the target candidate              and Liu (2004) which attributes an opinion tar-
identification, simple part-of-speech patterns were            get to the opinion word which is closest regard-
employed. The relevance ranking and extraction                 ing word distance in a sentence. The sentences in
was then performed with different statistical mea-             the movie reviews tend to be more complex, which
sures: Pointwise Mutual Information (Popescu                   can also be explained by their origin. The reviews
and Etzioni, 2005), the Likelihood Ratio Test (Yi              were taken from the Internet Movie Database1 ,
et al., 2003) and Association Mining (Hu and Liu,              on which the users are given a set of guidelines
2004). A more linguistically motivated approach                on how to write a review. Due to these insights,
was taken by Kim and Hovy (2006) through iden-                 we are confident that the overall textual quality
tifying opinion holders and targets with semantic              of the movie reviews is high enough for linguisti-
role labeling. This approach was promising, since              cally more advanced technologies such as parsing
their goal was to extract opinions from profession-            or AR to be successfully applied.
ally edited content i.e. newswire.
Zhuang et al. (2006) present an algorithm for the              3       Opinion Target Identification
extraction of opinion target - opinion word pairs.
                                                               3.1      Dataset
The opinion word and target candidates are iden-
tified in the annotated corpus and their extraction            Currently the only freely available dataset anno-
is then performed by applying possible paths con-              tated with opinions including annotated anaphoric
necting them in a dependency graph. These paths                opinion targets is a corpus of movie reviews
are combined with part-of-speech information and               by Zhuang et al. (2006). Kessler and Nicolov
also learned from the annotated corpus.                        (2009) describe a collection of product reviews
To the best of our knowledge, there is currently               in which anaphoric opinion targets are also an-
only one system which integrates coreference in-               notated, but it is not available to the public
formation in OM. The algorithm by Stoyanov                     (yet). Zhuang et al. (2006) used a subset of the
and Cardie (2008) identifies coreferring targets in            dataset they published (1829 documents), namely
newspaper articles. A candidate selection or ex-               1100 documents, however they do not state which
traction step for the opinion targets is not required,         documents comprise this subset used in their eval-
since they rely on manually annotated targets and              uation. In our experiments, we therefore use the
focus solely on the coreference resolution. How-               complete dataset available, detailed in Table 1. As
ever they do not resolve pronominal anaphora in                shown, roughly 9.5% of the opinion targets are re-
order to achieve that.                                         ferred to by pronouns. Table 2 outlines detailed
                                                               statistics on which pronouns occur as opinion tar-
                                                               gets.
2.2   Opinion Mining on Movie Reviews

There is a huge body of work on OM in movie re-                                Table 1: Dataset Statistics
views which was sparked by the dataset from Pang                           # Documents                       1829
and Lee (2005). This dataset consists of sen-                              # Sentences                      24918
tences which are annotated as expressing positive                          # Tokens                        273715
                                                                           # Target + Opinion Pairs          5298
or negative opinions. An interesting insight was                           # Targets which are Pronouns       504
gained from the document level sentiment analy-                            # Pronouns                     > 11000
sis on movie reviews in comparison to documents
from other domains: Turney (2002) observes that
the movie reviews are hardest to classify since the            3.2      Baseline Opinion Mining
review authors tend to give information about the
                                                               We reimplemented the algorithm presented
storyline of the movie which often contain charac-
                                                               by Zhuang et al. (2006) as the baseline for our
terizations, such as “bad guy” or “violent scene”.
                                                                   1
These statements however do not reflect any opin-                      http://www.imdb.com (IMDB)


                                                         264


                                                               tual opinion targets (see Table 1). We extended the
       Table 2: Pronouns as Opinion Targets
                                                               CogNIAC implementation to also resolve “it” and
     it    274    he   58    she   22   they   22
    this   77    his   26    her   10
                                                               “this” as anaphora candidates, since off-the-shelf
                 him   15                                      it only resolves personal pronouns. We will refer
                                                               to this extension with [id]. Both algorithms fol-
                                                               low the common approach that noun phrases are
experiments. Their approach is a supervised one.               antecedent candidates for the anaphora. In our ex-
The annotated dataset is split in five folds, of               periments we employed both the MARS and the
which four are used as the training data. In the first         CogNIAC algorithm, for which we created three
step, opinion target and opinion word candidates               extensions which are detailed in the following.
are extracted from the training data. Frequency
counts of the annotated opinion targets and opin-              4.1   Extensions of CogNIAC
ion words are extracted from four training folds.
The most frequently occurring opinion targets and              We identified a few typical sources of errors in
opinion words are selected as candidates. Then                 a preliminary error analysis. We therefore sug-
the annotated sentences are parsed and a graph                 gest three extensions to the algorithm which are
containing the words of the sentence is created,               on the one hand possible in the OM setting and
which are connected by the dependency relations                on the other hand represent special features of the
between them. For each opinion target - opinion                target discourse type: [1.] We observed that the
word pair, the shortest path connecting them is                Stanford Named Entity Recognizer (Finkel et al.,
extracted from the dependency graph. A path                    2005) is superior to the Person detection of the
consists of the part-of-speech tags of the nodes               (MUC6 trained) CogNIAC implementation. We
and the dependency types of the edges.                         therefore filter out Person antecedent candidates
In order to be able to identify rarely occurring               which the Stanford NER detects for the imper-
opinion targets which are not in the candidate                 sonal and demonstrative pronouns and Location
list, they expand it by crawling the cast and crew             & Organization candidates for the personal pro-
names of the movies from the IMDB. How this                    nouns. This way the input to the AR is optimized.
crawling and extraction is done is not explained.              [2.] The second extension exploits the fact that re-
                                                               views from the IMDB exhibit certain contextual
4   Algorithms for Anaphora Resolution                         properties. They are gathered and to be presented
                                                               in the context of one particular entity (=movie).
As pointed out by Charniak and Elsner (2009)                   The context or topic under which it occurs is there-
there are hardly any freely available systems                  fore typically clear to the reader and is therefore
for AR. Although Charniak and Elsner (2009)                    not explicitly introduced in the discourse. This is
present a machine-learning based algorithm for                 equivalent to the situational context we often refer
AR, they evaluate its performance in comparison                to in dialogue. In the reviews, the authors often
to three non machine-learning based algorithms,                refer to the movie or film as a whole by a pro-
since those are the only ones available. They                  noun. We exploit this by an additional rule which
observe that the best performing baseline algo-                resolves an impersonal or demonstrative pronoun
rithm (OpenNLP) is hardly documented. The al-                  to “movie” or “film” if there is no other (match-
gorithm with the next-to-highest results in (Char-             ing) antecedent candidate in the previous two sen-
niak and Elsner, 2009) is MARS (Mitkov, 1998)                  tences. [3.] The rules by which CogNIAC resolves
from the GuiTAR (Poesio and Kabadjov, 2004)                    anaphora were designed so that anaphora which
toolkit. This algorithm is based on statistical anal-          have ambiguous antecedents are left unresolved.
ysis of the antecedent candidates. Another promis-             This strategy should lead to a high precision AR,
ing algorithm for AR employs a rule based ap-                  but at the same time it can have a negative impact
proach for antecedent identification. The Cog-                 on the recall. In the OM context, it happens quite
NIAC algorithm (Baldwin, 1997) was designed                    frequently that the authors comment on the entity
for high-precision AR. This approach seems like                they want to criticize in a series of arguments. In
an adequate strategy for our OM task, since in                 such argument chains, we try to solve cases of an-
the dataset used in our experiments only a small               tecedent ambiguity by analyzing the opinions: If
fraction of the total number of pronouns are ac-               there are ambiguous antecedent candidates for a


                                                         265


pronoun, we check whether there is an opinion ut-            up over all folds. In Table 4, a true positive refers
tered in the previous sentence. If this is the case          to an extracted pronoun which was annotated as
and if the opinion target matches the pronoun re-            an opinion target and is resolved to the correct
garding gender and number, we resolve the pro-               antecedent. A false positive subsumes two error
noun to the antecedent which was the previous                classes: A pronoun which was not annotated as an
opinion target.                                              opinion target but extracted as such, or a pronoun
In the results of our experiments in Section 5, we           which is resolved to an incorrect antecedent.
will refer to the configurations using these exten-          As shown in Table 3, the recall of our reimplemen-
sions with the numbers attributed to them above.             tation is slightly higher than the recall reported
                                                             in Zhuang et al. (2006). However, our precision
5   Experimental Work                                        and thus f-measure are lower. This can be at-
                                                             tributed to the different document sets used in our
To integrate AR in the OM algorithm, we add the              experiments (see Section 3.1), or our substitution
antecedents of the pronouns annotated as opinion             of the list of peoples’ names with the NER compo-
targets to the target candidate list. Then we ex-            nent, or differences regarding the evaluation strat-
tract the dependency paths connecting pronouns               egy as mentioned above.
and opinion words and add them to the list of valid          We observe that the MARS algorithm yields an
paths. When we run the algorithm, we extract                 improvement regarding recall compared to the
anaphora which were resolved, if they occur with             baseline system. However, it also extracts a high
a valid dependency path to an opinion word. In               number of false positives for both the personal and
such a case, the anaphor is substituted for its an-          impersonal / demonstrative pronouns. This is due
tecedent and thus extracted as part of an opinion            to the fact that the MARS algorithm is designed
target - opinion word pair.                                  for robustness and always resolves a pronoun to
To reproduce the system by Zhuang et al. (2006),             an antecedent.
we substitute the cast and crew list employed                CogNIAC in its off-the-shelf configuration already
by them (see Section 3.2), with a NER compo-                 yields significant improvements over the baseline
nent (Finkel et al., 2005). One aspect regarding the         regarding f-measure2 . Our CogNIAC extension
extraction of opinion target - opinion word pairs            [id] improves recall slightly in comparison to the
remains open in Zhuang et al. (2006): The de-                off-the-shelf system. As shown in Table 4, the
pendency paths only identify connections between             algorithm extracts impersonal and demonstrative
pairs of single words. However, almost 50% of                pronouns with lower precision than personal pro-
the opinion target candidates are multiword ex-              nouns. Our error analysis shows that this is mostly
pressions. Zhuang et al. (2006) do not explain how           due to the Person / Location / Organization clas-
they extract multiword opinion targets with the de-          sification of the CogNIAC implementation. The
pendency paths. In our experiments, we require a             names of actors and movies are thus often misclas-
dependency path to be found to each word of a                sified. Extension [1] mitigates this problem, since
multiword target candidate for it to be extracted.           it increases precision (Table 3 row 6), while not af-
Furthermore, Zhuang et al. (2006) do not state               fecting recall. The overall improvement of our ex-
whether in their evaluation annotated multiword              tensions [id] + [1] is however not statistically sig-
targets are treated as a single unit which needs to          nificant in comparison to off-the-shelf CogNIAC.
be extracted, or whether a partial matching is em-           Our extensions [2] and [3] in combination with
ployed in such cases. We require all individual              [id] each increase recall at the expense of preci-
words of a multiword expression to be extracted              sion. The improvement in f-measure of CogNIAC
by the algorithm. As mentioned above, the depen-             [id] + [3] over the off-the-shelf system is statisti-
dency path based approach will only identify con-            cally significant. The best overall results regard-
nections between pairs of single words. We there-            ing f-measure are reached if we combine all our
fore employ a merging step, in which we combine              extensions of the CogNIAC algorithm. The re-
adjacent opinion targets to a multiword expres-              sults of this configuration show that the positive
sion. We have compiled two result sets: Table 3              effects of extensions [2] and [3] are complemen-
shows the results of the overall OM in a five-fold
cross-validation. Table 4 gives a detailed overview             2
                                                                  Significance of improvements was tested using a paired
of the AR for opinion target identification summed           two-tailed t-test and p ≤ 0.05 (∗ ) and p ≤ 0.01 (∗∗ )


                                                       266


                                                               gender and number identification can lead to an
 Table 3: Op. Target - Op. Word Pair Extraction
                                                               incorrect selection of antecedent candidates. Even
                                                               if the gender and number identification is correct,
             Configuration     Reca.   Prec.   F-Meas.
    Results in Zhuang et al.   0.548   0.654   0.596
                                                               the algorithm might select an incorrect antecedent
     Our Reimplementation      0.554   0.523   0.538           if there is more than one possible candidate. A
       MARS off-the-shelf      0.595   0.467   0.523           non-robust algorithm as CogNIAC might leave
    CogNIAC off-the-shelf      0.586   0.534   0.559∗∗         a pronoun which is an actual opinion target
             CogNIAC+[id]      0.594   0.516   0.552
       CogNIAC+[id]+[1]        0.594   0.533   0.561           unresolved, due to the ambiguity of its antecedent
       CogNIAC+[id]+[2]        0.603   0.501   0.547           candidates.
       CogNIAC+[id]+[3]        0.613   0.521   0.563∗          The upper bound for the OM with perfect AR
 CogNIAC+[id]+[1]+[2]+[3]      0.614   0.531   0.569∗
                                                               on top of the baseline would be recall: 0.649,
                                                               precision: 0.562, f-measure: 0.602. Our best
      Table 4: Results of AR for Opinion Targets               configuration reaches ∼ 50% of the improvements
                                                               which are theoretically possible with perfect AR.
                                     Pers.1 Imp. & Dem.1
                 Algorithm
                                   TP2 FP2 TP      FP
         MARS off-the-shelf 102 164 115            623
      CogNIAC off-the-shelf 117          95  0       0         6   Conclusions
               CogNIAC+[id] 117          95 105    180
         CogNIAC+[id]+[1] 117            41 105     51         We have shown that by extending an OM al-
         CogNIAC+[id]+[2] 117            95 153    410         gorithm with AR for opinion target extraction
         CogNIAC+[id]+[3] 131 103 182              206
 CogNIAC+[id]+[1]+[2]+[3] 124            64 194    132
                                                               significant improvements can be achieved. The
 1
   personal, impersonal & demonstrative pronouns
                                                               rule based AR algorithm CogNIAC performs well
 2
   true positives, false positives                             regarding the extraction of opinion targets which
                                                               are personal pronouns. The algorithm does not
                                                               yield high precision when resolving impersonal
tary regarding the extraction of impersonal and
                                                               and demonstrative pronouns. We present a set
demonstrative pronouns. This configuration yields
                                                               of extensions which address this challenge and
statistically significant improvements regarding f-
                                                               in combination yield significant improvements
measure over the off-the-shelf CogNIAC configu-
                                                               over the off-the-shelf configuration. A robust
ration, while also having the overall highest recall.
                                                               AR algorithm does not yield any improvements
5.1     Error Analysis                                         regarding f-measure in the OM task. This type of
                                                               algorithm creates many false positives, which are
When extracting opinions from movie reviews, we
                                                               not filtered out by the dependency paths employed
observe the same challenge as Turney (2002): The
                                                               in the algorithm by Zhuang et al. (2006).
users often characterize events in the storyline or
                                                               AR could also be employed in other OM algo-
roles the characters play. These characterizations
                                                               rithms which aim at identifying opinion targets
contain the same words which are also used to
                                                               by means of a statistical analysis. Vicedo and
express opinions. Hence these combinations are
                                                               Ferrández (2000) successfully modified the
frequently but falsely extracted as opinion target
                                                               relevance ranking of terms in their documents by
- opinion word pairs, negatively affecting the
                                                               replacing anaphora with their antecedents. The
precision. The algorithm cannot distinguish them
                                                               approach can be taken for OM algorithms which
from opinions expressing the stance of the author.
                                                               select the opinion target candidates with a rel-
Overall, the recall of the baseline is rather low.
                                                               evance ranking (Hu and Liu, 2004; Yi et al., 2003).
This is due to the fact that the algorithm only
learns a subset of the opinion words and opinion
targets annotated in the training data. Currently,             Acknowledgments
it cannot discover any new opinion words and
targets. This could be addressed by integrating a              The project was funded by means of the German Federal
component which identifies new opinion targets                 Ministry of Economy and Technology under the promotional
by calculating the relevance of a word in the                  reference “01MQ07012”. The authors take the responsibility
corpus based on statistical measures.                          for the contents. This work has been supported by the Volk-
The AR introduces new sources of errors regard-                swagen Foundation as part of the Lichtenberg-Professorship
ing the extraction of opinion targets: Errors in               Program under grant No. I/82806.


                                                         267


References                                                       Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
                                                                   ing product features and opinions from reviews. In
Breck Baldwin. 1997. Cogniac: High precision coref-                Proceedings of Human Language Technology Con-
  erence with limited knowledge and linguistic re-                 ference and Conference on Empirical Methods in
  sources. In Proceedings of a Workshop on Opera-                  Natural Language Processing, pages 339–346, Van-
  tional Factors in Practical, Robust Anaphora Reso-               couver, Canada, October.
  lution for Unrestricted Texts, pages 38–45, Madrid,
  Spain, July.                                                   Veselin Stoyanov and Claire Cardie. 2008. Topic iden-
                                                                   tification for fine-grained opinion analysis. In Pro-
Eugene Charniak and Micha Elsner. 2009. EM works                   ceedings of the 22nd International Conference on
  for pronoun anaphora resolution. In Proceedings of               Computational Linguistics, pages 817–824, Manch-
  the 12th Conference of the European Chapter of the               ester, UK, August.
  ACL, pages 148–156, Athens, Greece, March.
                                                                 Peter Turney. 2002. Thumbs up or thumbs down? se-
Jenny Rose Finkel, Trond Grenager, and Christopher                 mantic orientation applied to unsupervised classifi-
   Manning. 2005. Incorporating non-local informa-                 cation of reviews. In Proceedings of the 40th An-
   tion into information extraction systems by gibbs               nual Meeting of the Association for Computational
   sampling. In Proceedings of the 43rd Annual Meet-               Linguistics, pages 417–424, Philadelphia, Pennsyl-
   ing of the Association for Computational Linguis-               vania, USA, July.
   tics, pages 363–370, Michigan, USA, June.
                                                                 José L. Vicedo and Antonio Ferrández. 2000. Apply-
Minqing Hu and Bing Liu. 2004. Mining and summa-                    ing anaphora resolution to question answering and
  rizing customer reviews. In Proceedings of the 10th               information retrieval systems. In Proceedings of the
  ACM SIGKDD International Conference on Knowl-                     First International Conference on Web-Age Informa-
  edge Discovery and Data Mining, pages 168–177,                    tion Management, volume 1846 of Lecture Notes In
  Seattle, WA, USA, August.                                         Computer Science, pages 344–355. Springer, Shang-
                                                                    hai, China.
Jason Kessler and Nicolas Nicolov. 2009. Targeting
   sentiment expressions through supervised ranking              Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu, and
   of linguistic configurations. In Proceedings of the              Wayne Niblack. 2003. Sentiment analyzer: Extract-
   Third International AAAI Conference on Weblogs                   ing sentiments about a given topic using natural lan-
   and Social Media, San Jose, CA, USA, May.                        guage processing techniques. In Proceedings of the
                                                                    3rd IEEE International Conference on Data Mining,
Soo-Min Kim and Eduard Hovy. 2006. Extracting                       pages 427–434, Melbourne, FL, USA, December.
  opinions, opinion holders, and topics expressed in
  online news media text. In Proceedings of the ACL              Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006.
  Workshop on Sentiment and Subjectivity in Text,                  Movie review mining and summarization. In Pro-
  pages 1–8, Sydney, Australia, July.                              ceedings of the ACM 15th Conference on Informa-
                                                                   tion and Knowledge Management, pages 43–50, Ar-
Ruslan Mitkov. 1998. Robust pronoun resolution with                lington, VA, USA, November.
  limited knowledge. In Proceedings of the 36th An-
  nual Meeting of the Association for Computational
  Linguistics and 17th International Conference on
  Computational Linguistics, pages 869–875, Mon-
  treal, Canada, August.

Tetsuya Nasukawa and Jeonghee Yi. 2003. Sentiment
  analysis: Capturing favorability using natural lan-
  guage processing. In Proceedings of the 2nd Inter-
  national Conference on Knowledge Capture, pages
  70–77, Sanibel Island, FL, USA, October.

Bo Pang and Lillian Lee. 2005. Seeing stars: Ex-
  ploiting class relationships for sentiment categoriza-
  tion with respect to rating scales. In Proceedings
  of the 43rd Annual Meeting of the Association for
  Computational Linguistics, pages 115–124, Michi-
  gan, USA, June.

Massimo Poesio and Mijail A. Kabadjov. 2004. A
 general-purpose, off-the-shelf anaphora resolution
 module: Implementation and preliminary evalua-
 tion. In Proceedings of the 4th International Confer-
 ence on Language Resources and Evaluation, pages
 663–666, Lisboa, Portugal, May.


                                                           268

    Hierarchical Sequential Learning for Extracting Opinions and their
                                Attributes
                                  Yejin Choi and Claire Cardie
                                 Department of Computer Science
                                        Cornell University
                                        Ithaca, NY 14853
                              {ychoi,cardie}@cs.cornell.edu


                    Abstract                                 systems with cascaded component architectures,
                                                             causing performance degradation in the end-to-
    Automatic opinion recognition involves a                 end system (e.g. Finkel et al. (2006)) — in our
    number of related tasks, such as identi-                 case, in the end-to-end opinion recognition sys-
    fying the boundaries of opinion expres-                  tem.
    sion, determining their polarity, and de-                   In this paper, we apply a hierarchical param-
    termining their intensity. Although much                 eter sharing technique (e.g., Cai and Hofmann
    progress has been made in this area, ex-                 (2004), Zhao et al. (2008)) using Conditional Ran-
    isting research typically treats each of the             dom Fields (CRFs) (Lafferty et al., 2001) to fine-
    above tasks in isolation. In this paper,                 grained opinion analysis. In particular, we aim to
    we apply a hierarchical parameter shar-                  jointly identify the boundaries of opinion expres-
    ing technique using Conditional Random                   sions as well as to determine two of their key at-
    Fields for fine-grained opinion analysis,                tributes — polarity and intensity.
    jointly detecting the boundaries of opinion
                                                                Experimental results show that our proposed ap-
    expressions as well as determining two of
                                                             proach improves the performance over the base-
    their key attributes — polarity and inten-
                                                             line that does not exploit the hierarchical structure
    sity. Our experimental results show that
                                                             among the classes. In addition, we find that the
    our proposed approach improves the per-
                                                             joint approach outperforms a baseline that is based
    formance over a baseline that does not
                                                             on cascading two separate systems.
    exploit hierarchical structure among the
    classes. In addition, we find that the joint
    approach outperforms a baseline that is                  2 Hierarchical Sequential Learning
    based on cascading two separate compo-
                                                             We define the problem of joint extraction of opin-
    nents.
                                                             ion expressions and their attributes as a sequence
1 Introduction                                               tagging task as follows. Given a sequence of to-
                                                             kens, x = x1 ... xn , we predict a sequence of
Automatic opinion recognition involves a number              labels, y = y1 ... yn , where yi ∈ {0, ..., 9} are
of related tasks, such as identifying expressions of         defined as conjunctive values of polarity labels
opinion (e.g. Kim and Hovy (2005), Popescu and               and intensity labels, as shown in Table 1. Then
Etzioni (2005), Breck et al. (2007)), determining            the conditional probability p(y|x) for linear-chain
their polarity (e.g. Hu and Liu (2004), Kim and              CRFs is given as (Lafferty et al., 2001)
Hovy (2004), Wilson et al. (2005)), and determin-
ing their strength, or intensity (e.g. Popescu and
                                                                         1      X                                           
Etzioni (2005), Wilson et al. (2006)). Most pre-             P (y|x) =      exp    λ f (yi , x, i)+λ′ f ′ (yi−1 , yi , x, i)
                                                                         Zx
vious work treats each subtask in isolation: opin-                                 i

ion expression extraction (i.e. detecting the bound-
aries of opinion expressions) and opinion attribute           where Zx is the normalization factor.
classification (e.g. determining values for polar-             In order to apply a hierarchical parameter shar-
ity and intensity) are tackled as separate steps in          ing technique (e.g., Cai and Hofmann (2004),
opinion recognition systems. Unfortunately, er-              Zhao et al. (2008)), we extend parameters as fol-
rors from individual components will propagate in            lows.


                                                       269
                      Proceedings of the ACL 2010 Conference Short Papers, pages 269–274,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


                                                                                       




                                                                                                                                              




                                                                                                                     

                                                                                                                                                          




Figure 1: The hierarchical structure of classes for opinion expressions with polarity (positive, neutral,
negative) and intensity (high, medium, low)

    L ABEL                        0           1                2               3            4           5               6                7          8                   9
 P OLARITY                    none         positive         positive     positive      neutral      neutral           neutral     negative      negative         negative
 I NTENSITY                   none          high        medium                 low       high      medium              low             high     medium              low

                                  Table 1: Labels for Opinion Extraction with Polarity and Intensity


                                                             yi ∈ {1, 2, 3} will share the same compo-
                                                             nent λPOSITIVE gP (POSITVE, x, i). Note that there
             λ f (yi , x, i) = λα gO (α, x, i)           (1)
                                                             can be other variations of hierarchical construc-
                              + λβ gP (β, x, i)
                                                             tion. For instance, one can add λδ gI (δ, x, i)
                              + λγ gS (γ, x, i)
                                                             and λ′ gI′ (δ, δ̂, x, i) to Equation (1) for δ ∈
                                                                     δ,δ̂
    λ′ f ′ (yi−1 , yi , x, i) = λ′α,α̂ gO′ (α, α̂, x, i)     {0, 1, ..., 9}, in order to allow more individualized
                              + λ′β,β̂ gP′ (β, β̂, x, i)
                                                             learning for each label.
                                                                Notice also that the number of sets of param-
                              + λ′γ,γ̂ gS′ (γ, γ̂, x, i)
                                                             eters constructed by Equation (1) is significantly
                                                             smaller than the number of sets of parameters that
                        ′
where gO and gO are feature vectors defined for              are needed without the hierarchy. The former re-
Opinion extraction, gP and gP′ are feature vectors           quires (2 + 4 + 4) + (2 × 2 + 4 × 4 + 4 × 4) = 46
defined for Polarity extraction, and gS and gS′ are          sets of parameters, but the latter requires (10) +
feature vectors defined for Strength extraction, and         (10 × 10) = 110 sets of parameters. Because a
α, α̂ ∈ {OPINION , NO - OPINION}                             combination      of a polarity component and an in-
β, β̂ ∈ {POSITIVE , NEGATIVE , NEUTRAL , NO - POLARITY}
                                                             tensity component can distinguish each label, it is
γ, γ̂ ∈ {HIGH , MEDIUM , LOW, NO - INTENSITY}                not necessary to define a separate set of parameters
                                                             for each label.
 For instance, if yi = 1, then
                                                                                             3 Features
       λ f (1, x, i)              =      λOPINION gO (OPINION, x, i)
                                  +                                We first introduce definitions of key terms that will
                                         λPOSITIVE gP (POSITVE, x, i)
                                  +      λHIGH gS (HIGH, x, i)     be used to describe features.
                                                                   • PRIOR-POLARITY & PRIOR-INTENSITY:
 If yi−1 = 0, yi = 4, then
                                                                     We obtain these prior-attributes from the polar-
       ′ ′
      λ f (0, 4, x, i)                                               ity lexicon populated by Wilson et al. (2005).
      = λ′NO -OPINION , OPINION gO′ (NO - OPINION , OPINION, x, i) • EXP-POLARITY, EXP-INTENSITY & EXP-SPAN:
      + λ′NO -POLARITY, NEUTRAL gP′ (NO - POLARITY, NEUTRAL, x, i) Words in a given opinion expression often do
      + λ′NO -INTENSITY, HIGH gS′ (NO - INTENSITY, HIGH, x, i)       not share the same prior-attributes. Such dis-
                                                                     continuous distribution of features can make
                                                                     it harder to learn the desired opinion expres-
This hierarchical construction of feature and                        sion boundaries. Therefore, we try to obtain
weight vectors allows similar labels to share the                    expression-level attributes (E XP -P OLARITY and
same subcomponents of feature and weight vec-                        E XP -I NTENSITY) using simple heuristics. In or-
tors. For instance, all λ f (yi , x, i) such that                    der to derive E XP -P OLARITY, we perform simple


                                                                                      270


  voting. If there is a word with a negation effect,        Intensity Per-Token Features
  such as “never”, “not”, “hardly”, “against”, then         These features are included only for gO (α, x, i)
  we flip the polarity. For E XP -I NTENSITY, we use        and gS (γ, x, i), which are the feature functions cor-
  the highest PRIOR - INTENSITY in the span. The text       responding to the intensity-based classes.
  span with the same expression-level attributes            • P RIOR -I NTENSITY(xi), E XP -I NTENSITY(xi)
  are referred to as E XP -S PAN.                           • S TEM(xi) ⊗ E XP -I NTENSITY(xi)
3.1   Per-Token Features                                    • C OUNT- OF -S TRONG, C OUNT- OF -W EAK:
                                                              the number of strong and weak E XP - INTENSITY
Per-token features are defined in the form of                 words in the current sentence.
gO (α, x, i), gP (β, x, i) and gS (γ, x, i). The do-        • I NTENSIFIER(xi): whether xi is an intensifier,
mains of α, β, γ are as given in Section 3.                   such as “extremely”, “highly”, “really”.
Common Per-Token Features                                   • S TRONG M ODAL(xi): whether xi is a strong modal
                                                              verb, such as “must”, “can”, “will”.
Following features are common for all class labels.
                                                            • W EAK M ODAL(xi): whether xi is a weak modal
The notation ⊗ indicates conjunctive operation of
                                                              verb, such as “may”, “could”, “would”.
two values.
                                                            • D IMINISHER(xi): whether xi is a diminisher, such
• PART-O F -S PEECH (xi):
                                                              as “little”, “somewhat”, “less”.
  based on GATE (Cunningham et al., 2002).
                                                            • P RECEDED - BY-τ (xi),
• W ORD (xi ), W ORD (xi−1 ), W ORD (xi+1 )
                                                              P RECEDED - BY-τ (xi) ⊗ E XP -I NTENSITY(xi):
• W ORD N ET-H YPERNYM (xi):                                  where τ ∈ { I NTENSIFIER , S TRONG M ODAL , W EAK -
  based on WordNet (Miller, 1995).                            M ODAL , D IMINISHER}
• O PINION -L EXICON (xi):                                  • τ (xi ) ⊗ E XP -I NTENSITY (xi),
  based on opinion lexicon (Wiebe et al., 2002).              τ (xi ) ⊗ E XP -I NTENSITY (xi−1),
• S HALLOW-PARSER (xi):                                       τ (xi−1 ) ⊗ E XP -I NTENSITY (xi+1)
  based on CASS partial parser (Abney, 1996).               • E XP -S PAN(xi) ⊗ E XP -I NTENSITY(xi)
• P RIOR -P OLARITY (xi) ⊗ P RIOR -I NTENSITY (xi)          • D ISTANCE - TO -E XP -S PAN(xi) ⊗ E XP -I NTENSITY(xp)
• E XP -P OLARITY (xi) ⊗ E XP -I NTENSITY (xi)
• E XP -P OLARITY (xi) ⊗ E XP -I NTENSITY (xi) ⊗                3.2 Transition Features
  S TEM (xi )                                                   Transition features are employed to help with
• E XP -S PAN (xi ):                                            boundary extraction as follows:
  boolean to indicate whether xi is in an E XP -S PAN.
                                                            Polarity Transition Features
• D ISTANCE - TO -E XP -S PAN (xi): 0, 1, 2, 3+.
                                                            Polarity transition features are features that are
• E XP -P OLARITY (xi) ⊗ E XP -I NTENSITY (xi) ⊗
                                                            used only for gO′ (α, α̂, x, i) and gP′ (β, β̂, x, i).
  E XP -S PAN (xi )
                                                            • PART- OF -S PEECH(xi) ⊗ PART- OF -S PEECH(xi+1) ⊗
Polarity Per-Token Features                                   E XP -P OLARITY(xi)
These features are included only for gO (α, x, i)           • E XP -P OLARITY(xi) ⊗ E XP -P OLARITY(xi+1)
and gP (β, x, i), which are the feature functions           Intensity Transition Features
corresponding to the polarity-based classes.
                                                            Intensity transition features are features that are
• P RIOR -P OLARITY (xi), E XP -P OLARITY ((xi)             used only for gO′ (α, α̂, x, i) and gS′ (γ, γ̂, x, i).
• S TEM(xi) ⊗ E XP -P OLARITY(xi)                           • PART- OF -S PEECH(xi) ⊗ PART- OF -S PEECH(xi+1) ⊗
• C OUNT- OF -P olarity :                                     E XP -I NTENSITY(xi)
  where P olarity ∈ {positive, neutral, negative}.          • E XP -I NTENSITY(xi) ⊗ E XP -I NTENSITY(xi+1)
  This feature encodes the number of positive,
  neutral, and negative E XP - POLARITY words re-               4 Evaluation
  spectively, in the current sentence.
                                                                We evaluate our system using the Multi-
• S TEM(xi) ⊗ C OUNT- OF -P olarity
                                                                Perspective Question Answering (MPQA) cor-
• E XP -P OLARITY(xi) ⊗ C OUNT- OF -P olarity                   pus1 . Our gold standard opinion expressions cor-
• E XP -S PAN(xi) and E XP -P OLARITY(xi)                           1
                                                                      The MPQA corpus can be obtained             at
• D ISTANCE - TO -E XP -S PAN(xi) ⊗ E XP -P OLARITY(xp)         http://nrrc.mitre.org/NRRC/publications.htm.


                                                          271


                                                            Positive                         Neutral               Negative
 Method Description                                    r(%) p(%) f(%)                r(%)     p(%) f(%)       r(%) p(%) f(%)
 Polarity-Only ∩ Intensity-Only (BASELINE 1)            29.6 65.7 40.8                26.5    69.1 38.3        35.5 77.0 48.6
 Joint without Hierarchy (BASELINE2)                    30.7 65.7 41.9                29.9    66.5 41.2        37.3 77.1 50.3
 Joint with Hierarchy                                   31.8 67.1 43.1                31.9    66.6 43.1        40.4 76.2 52.8

                 Table 2: Performance of Opinion Extraction with Correct Polarity Attribute

                                                                 High                     Medium                      Low
 Method Description                                    r(%)      p(%)      f(%)      r(%) p(%) f(%)           r(%)    p(%)    f(%)
 Polarity-Only ∩ Intensity-Only (BASELINE 1)            26.4     58.3      36.3       29.7 59.0 39.6           15.4   60.3    24.5
 Joint without Hierarchy (BASELINE2)                    29.7     54.2      38.4       28.0 57.4 37.6           18.8   55.0    28.0
 Joint with Hierarchy                                   27.1     55.2      36.3       32.0 56.5 40.9           21.1   56.3    30.7

                Table 3: Performance of Opinion Extraction with Correct Intensity Attribute


 Method Description                     r(%)   p(%)    f(%)            baseline effectively represents a cascaded compo-
 Polar-Only ∩ Intensity-Only            43.3   92.0    58.9            nent approach.
 Joint without Hierarchy                46.0   88.4    60.5
                                                                       [Baseline-2] Joint without Hierarchy: Here
 Joint with Hierarchy                   48.0   87.8    62.0            we use simple linear-chain CRFs without exploit-
   Table 4: Performance of Opinion Extraction                          ing the class hierarchy for the opinion recognition
                                                                       task. We use the tags shown in Table 1.

                                                                       Joint with Hierarchy: Finally, we test the hi-
respond to direct subjective expression and expres-
                                                                       erarchical sequential learning approach elaborated
sive subjective element (Wiebe et al., 2005).2
                                                                       in Section 3.
   Our implementation of hierarchical sequential
learning is based on the Mallet (McCallum, 2002)                       4.1 Evaluation Results
code for CRFs. In all experiments, we use a Gaus-
sian prior of 1.0 for regularization. We use 135                       We evaluate all experiments at the opinion entity
documents for development, and test on a dif-                          level, i.e. at the level of each opinion expression
ferent set of 400 documents using 10-fold cross-                       rather than at the token level. We use three evalua-
validation. We investigate three options for jointly                   tion metrics: recall, precision, and F-measure with
extracting opinion expressions with their attributes                   equally weighted recall and precision.
as follows:                                                               Table 4 shows the performance of opinion ex-
                                                                       traction without matching any attribute. That is, an
[Baseline-1] Polarity-Only ∩ Intensity-Only:                           extracted opinion entity is counted as correct if it
For this baseline, we train two separate sequence                      overlaps4 with a gold standard opinion expression,
tagging CRFs: one that extracts opinion expres-                        without checking the correctness of its attributes.
sions only with the polarity attribute (using com-                     Table 2 and 3 show the performance of opinion
mon features and polarity extraction features in                       extraction with the correct polarity and intensity
Section 3), and another that extracts opinion ex-                      respectively.
pressions only with the intensity attribute (using                        From all of these evaluation criteria, J OINT WITH
common features and intensity extraction features
                                                                           4
in Section 3). We then combine the results from                              Overlap matching is a reasonable choice as the annotator
                                                                       agreement study is also based on overlap matching (Wiebe
two separate CRFs by collecting all opinion en-                        et al., 2005). One might wonder whether the overlap match-
tities extracted by both sequence taggers.3 This                       ing scheme could allow a degenerative case where extracting
                                                                       the entire test dataset as one giant opinion expression would
   2
      Only 1.5% of the polarity annotations correspond to              yield 100% recall and precision. Because each sentence cor-
both; hence, we merge both into the neutral. Similarly, for            responds to a different test instance in our model, and because
gold standard intensity, we merge extremely high into high.            some sentences do not contain any opinion expression in the
    3
      We collect all entities whose portions of text spans are         dataset, such degenerative case is not possible in our experi-
extracted by both models.                                              ments.


                                                                 272


H IERARCHY performs the best, and the least effec-                  directly comparable to our results; much of previ-
tive one is BASELINE -1, which cascades two sepa-                   ous work studies only a subset of what we tackle
rately trained models. It is interesting that the sim-              in this paper. However, as shown in Section 4.1,
ple sequential tagging approach even without ex-                    when we train the learning models only for a sub-
ploiting the hierarchy (BASELINE -2) performs better                set of the tasks, we can achieve a better perfor-
than the cascaded approach (BASELINE -1).                           mance instantly by making the problem simpler.
   When evaluating with respect to the polarity at-                 Our work differs from most of previous work in
tribute, the performance of the negative class is                   that we investigate how solving multiple related
substantially higher than the that of other classes.                tasks affects performance on sub-tasks.
This is not surprising as there is approximately                       The hierarchical parameter sharing technique
twice as much data for the negative class. When                     used in this paper has been previously used by
evaluating with respect to the intensity attribute,                 Zhao et al. (2008) for opinion analysis. However,
the performance of the L OW class is substantially                  Zhao et al. (2008) employs this technique only to
lower than that of other classes. This result reflects              classify sentence-level attributes (polarity and in-
the fact that it is inherently harder to distinguish                tensity), without involving a much harder task of
an opinion expression with low intensity from no                    detecting boundaries of sub-sentential entities.
opinion. In general, we observe that determining
correct intensity attributes is a much harder task                  6 Conclusion
than determining correct polarity attributes.
                                                                    We applied a hierarchical parameter sharing tech-
   In order to have a sense of upper bound, we                      nique using Conditional Random Fields for fine-
also report the individual performance of two sep-                  grained opinion analysis. Our proposed approach
arately trained models used for BASELINE -1: for the                jointly extract opinion expressions from unstruc-
Polarity-Only model that extracts opinion bound-                    tured text and determine their attributes — polar-
aries only with polarity attribute, the F-scores with               ity and intensity. Empirical results indicate that
respect to the positive, neutral, negative classes are              the simple joint sequential tagging approach even
46.7, 47.5, 57.0, respectively. For the Intensity-                  without exploiting the hierarchy brings a better
Only model, the F-scores with respect to the high,                  performance than combining two separately de-
medium, low classes are 37.1, 40.8, 26.6, respec-                   veloped systems. In addition, we found that the
tively. Remind that neither of these models alone                   hierarchical joint sequential learning approach im-
fully solve the joint task of extracting boundaries                 proves the performance over the simple joint se-
as well as determining two attributions simultane-                  quential tagging method.
ously. As a result, when conjoining the results
from the two models (BASELINE -1), the final per-                   Acknowledgments
formance drops substantially.
   We conclude from our experiments that the sim-                   This work was supported in part by National
ple joint sequential tagging approach even with-                    Science Foundation Grants BCS-0904822, BCS-
out exploiting the hierarchy brings a better perfor-                0624277, IIS-0535099 and by the Department of
mance than combining two separately developed                       Homeland Security under ONR Grant N0014-07-
systems. In addition, our hierarchical joint se-                    1-0152. We thank the reviewers and Ainur Yesse-
quential learning approach brings a further perfor-                 nalina for many helpful comments.
mance gain over the simple joint sequential tag-
ging method.
                                                                    References
5 Related Work                                                      S. Abney. 1996. Partial parsing via finite-state cas-
                                                                       cades. In Journal of Natural Language Engineering,
Although there have been much research for fine-                       2(4).
grained opinion analysis (e.g., Hu and Liu (2004),                  E. Breck, Y. Choi and C. Cardie. 2007. Identifying
Wilson et al. (2005), Wilson et al. (2006), Choi                       Expressions of Opinion in Context. In IJCAI.
and Claire (2008), Wilson et al. (2009)),5 none is                  on the entire corpus as unstructured input. Instead, Wilson
                                                                    et al. (2005) evaluate only on known words that are in their
   5
   For instance, the results of Wilson et al. (2005) is not         opinion lexicon. Furthermore, Wilson et al. (2005) simplifies
comparable even for our Polarity-Only model used inside             the problem by combining neutral opinions and no opinions
BASELINE -1, because Wilson et al. (2005) does not operate          into the same class, while our system distinguishes the two.


                                                              273


L. Cai and T. Hofmann. 2004. Hierarchical docu-
   ment categorization with support vector machines.
   In CIKM.
Y. Choi and C. Cardie. 2008. Learning with Composi-
   tional Semantics as Structural Inference for Subsen-
   tential Sentiment Analysis. In EMNLP.
H. Cunningham, D. Maynard, K. Bontcheva and V.
   Tablan. 2002. GATE: A Framework and Graphical
   Development Environment for Robust NLP Tools
   and Applications. In ACL.
J. R. Finkel, C. D. Manning and A. Y. Ng. 2006.
   Solving the Problem of Cascading Errors: Approx-
   imate Bayesian Inference for Linguistic Annotation
   Pipelines. In EMNLP.
M. Hu and B. Liu. 2004. Mining and Summarizing
   Customer Reviews. In KDD.
S. Kim and E. Hovy. 2004. Determining the sentiment
   of opinions. In COLING.
S. Kim and E. Hovy. 2005. Automatic Detection of
   Opinion Bearing Words and Sentences. In Com-
   panion Volume to the Proceedings of the Second In-
   ternational Joint Conference on Natural Language
   Processing (IJCNLP-05).
J. Lafferty, A. McCallum and F. Pereira. 2001. Condi-
   tional Random Fields: Probabilistic Models for Seg-
   menting and Labeling Sequence Data. In ICML.
A. McCallum. 2002. MALLET: A Machine Learning
   for Language Toolkit. http://mallet.cs.umass.edu.
G. A. Miller. 1995. WordNet: a lexical database for
   English. In Communications of the ACM, 38(11).
Ana-Maria Popescu and O. Etzioni. 2005. Extracting
   Product Features and Opinions from Reviews. In
   HLT-EMNLP.
J. Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis,
   B. Fraser, D. Litman, D. Pierce, E. Riloff and T.
   Wilson. 2002. Summer Workshop on Multiple-
   Perspective Question Answering: Final Report. In
   NRRC.
J. Wiebe and T. Wilson and C. Cardie 2005. Annotat-
   ing Expressions of Opinions and Emotions in Lan-
   guage. In Language Resources and Evaluation, vol-
   ume 39, issue 2-3.
T. Wilson, J. Wiebe and P. Hoffmann. 2005. Recogniz-
   ing Contextual Polarity in Phrase-Level Sentiment
   Analysis. In HLT-EMNLP.
T. Wilson, J. Wiebe and R. Hwa. 2006. Recognizing
   strong and weak opinion clauses. In Computational
   Intelligence. 22 (2): 73-99.
T. Wilson, J. Wiebe and P. Hoffmann. 2009. Recogniz-
   ing Contextual Polarity: an exploration of features
   for phrase-level sentiment analysis. Computational
   Linguistics 35(3).
J. Zhao, K. Liu and G. Wang. 2008. Adding Redun-
   dant Features for CRFs-based Sentence Sentiment
   Classification. In EMNLP.




                                                      274

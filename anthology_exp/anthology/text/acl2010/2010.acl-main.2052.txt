                                Arabic Named Entity Recognition:
                             Using Features Extracted from Noisy Data
                    Yassine Benajiba1 Imed Zitouni2 Mona Diab1 Paolo Rosso3
                 1
                   Center for Computational Learning Systems, Columbia University
                        2
                          IBM T.J. Watson Research Center, Yorktown Heights
          3
            Natural Language Engineering Lab. - ELiRF, Universidad Politécnica de Valencia
         {ybenajiba,mdiab}@ccls.columbia.edu, izitouni@us.ibm.com, prosso@dsic.upv.es

                           Abstract                                Given current state-of-the-art syntactic processing
                                                                   of Arabic text and the relative small size of man-
        Building an accurate Named Entity                          ually annotated Arabic NER data, we set out to
        Recognition (NER) system for languages                     explore a main concrete research goal: to fully ex-
        with complex morphology is a challeng-                     ploit the level of advancement in Arabic lexical
        ing task. In this paper, we present research               and syntactic processing to explore deeper linguis-
        that explores the feature space using both                 tic features for the NER task. Realizing that the
        gold and bootstrapped noisy features to                    gold data available for NER is quite limited in size
        build an improved highly accurate Arabic                   especially given the diverse genres in the set, we
        NER system. We bootstrap noisy features                    devise a method to bootstrap additional instances
        by projection from an Arabic-English par-                  for the new features of interest from noisily NER
        allel corpus that is automatically tagged                  tagged Arabic data.
        with a baseline NER system. The feature
        space covers lexical, morphological, and                   2   Our Approach
        syntactic features. The proposed approach                  We use our state-of-the-art NER system described
        yields an improvement of up to 1.64                        in (Benajiba et al., 2008) as our baseline sys-
        F-measure (absolute).                                      tem (BASE) since it yields, to our knowledge, the
                                                                   best performance for Arabic NER . BASE em-
                                                                   ploys Support Vector Machines (SVMs) and Con-
1       Introduction                                               ditional Random Fields (CRFs) as Machine Learn-
Named Entity Recognition (NER) has earned an                       ing (ML) approaches. BASE uses lexical, syn-
important place in Natural Language Processing                     tactic and morphological features extracted using
(NLP) as an enabling process for other tasks.                      highly accurate automatic Arabic POS-taggers.
When explicitly taken into account, research                       BASE employs a multi-classifier approach where
shows that it helps such applications achieve bet-                 each classifier is tagging a NE class separately.
ter performance levels (Babych and Hartley, 2003;                  The feature selection is performed by using an in-
Thompson and Dozier, 1997). NER is defined as                      cremental approach selecting the top n features
the computational identification and classification                (the features are ranked according to their individ-
of Named Entities (NEs) in running text. For in-                   ual impact) at each iteration and keeping the set
stance, consider the following text:                               that yields the best results. In case of conflict - a
        Barack Obama is visiting the Middle East.                  word is classified with more than one class/tag si-
                                                                   multaneously - the global NER system selects the
A NER system should be able to identify Barack                     output of the classifier with the highest precision.
Obama and Middle East as NEs and classify them                         The following is the feature set used in (Bena-
as Person (PER) and Geo-Political Entity (GPE),                    jiba et al., 2008) and accordingly in the BASE sys-
respectively. The class-set used to tag NEs may                    tem. 1. Context: a −/ + 1 token window; 2. Lex-
vary according to user needs. In this research,                    ical: character n − grams where n ranges from
we adopt the Automatic Content Extraction (ACE)                    1 − 3; 3. Gazetteers: automatically harvested and
2007 nomenclature1 .                                               manually cleaned Person NE class (PER), Geopo-
According to (Nadeau and Sekine, 2007), opti-                      litical Entity NE class (GPE), and Organization
mization of the feature set is the key component in                NE class (ORG) lexica; 4. POS-tag and Base
enhancing the performance of a global NER sys-                     Phrase Chunk (BPC): automatically tagged us-
tem.     In this paper we investigate the possibil-                ing AMIRA (Diab et al., 2007) which yields F-
ity of building a high performance Arabic NER                      measures for both tasks in the high 90’s; 5. Mor-
system by using a large space of available feature                 phological features: automatically tagged using
sets that go beyond the explored shallow feature                   the Morphological Analysis and Disambiguation
sets used to date in the literature for Arabic NER.                for Arabic (MADA) tool to extract information
    1
        http://www.nist.gov/speech/tests/ace/index.htm             about gender, number, person, definiteness and as-


                                                             281
                            Proceedings of the ACL 2010 Conference Short Papers, pages 281–285,
                      Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


pect for each word (Habash and Rambow, 2005);
6. Capitalization: derived as a side effect from
running MADA. MADA chooses a specific mor-
phological analysis given the context of a given
word. As part of the morphological information
available in the underlying lexicon that MADA ex-
ploits. As part of the information present, the un-
derlying lexicon has an English gloss associated
with each entry. More often than not, if the word
is a NE in Arabic then the gloss will also be a NE
in English and hence capitalized.                              Figure 1: Example for the head word and syntactic
We devise an extended Arabic NER system (EX-                   environment feature
TENDED) that uses the same architecture as
BASE but employs additional features to those in
BASE. EXTENDED defines new additional syn-                     bArAk AwbAma ytrAs”, which means “de-
tagmatic features.                                             clared yesterday that Barack Obama governs
   We specifically investigate the space of the sur-           ...”, glossed “SrH/declared Ams/yesterday An/that
rounding context for the NEs. We explore gener-                bArAk/Barack AwbAmA/Obama ytrAs/governs
alizations over the kinds of words that occur with             ...”, is parsed in Figure 1. According to the phrase
NEs and the syntactic relations NEs engage in. We              structure parse, the first parent sub-tree headword
use an off-the-shelf Arabic syntactic parser. State-           of the NE “bArAk AwbAmA” is the verb ‘ytrAs’
of-the-art for Arabic syntactic parsing for the most           (governs), the second one is ‘An’ (that) and the
common genre (with the most training data) of                  third one is the verb ‘SrH’ (declared). This exam-
Arabic data, newswire, is in the low 80%s. Hence,              ple illustrates that the word “Ams” is ignored for
we acknowledge that some of the derived syntactic              this feature set since it is not a syntactic head. This
features will be noisy.                                        is a lexicalized feature.
   Similar to all supervised ML problems, it is de-            - Syntactic Environment (SE): This follows in the
sirable to have sufficient training data for the rele-         same spirit as SHW, but expands the idea in that
vant phenomena. The size of the manually anno-                 it looks at the parent non-terminal instead of the
tated gold data typically used for training Arabic             parent head word, hence it is not a lexicalized fea-
NER systems poses a significant challenge for ro-              ture. The goal being to use a more abstract repre-
bustly exploring deeper syntactic and lexical fea-             sentation level of the context in which a NE ap-
tures. Accordingly, we bootstrap more NE tagged                pears. For instance, for the same example pre-
data via projection over Arabic-English parallel               sented in Figure 1, the first, second, and third non-
data. The role of this data is simply to give us more          terminal parents of the NE “bArAk AwbAmA” are
instances of the newly defined features (namely                ‘S’, ‘SBAR’ and ‘VP’, respectively.
the syntagmatic features) in the EXTENDED sys-                 In our experiments we use the Bikel implementa-
tem as well as more instances for the Gazetteers               tion (Bikel, 2004) of the Collins parser (Collins,
and Context features defined in BASE. It is worth              1999) which is freely available on the web2 . It is a
noting that we do not use the bootstrapped NE                  head-driven CFG-style parser trained to parse En-
tagged data directly as training data with the gold            glish, Arabic, and Chinese.
data.
                                                               2.2   Bootstrapping Noisy Arabic NER Data
2.1 Syntagmatic Features
                                                               Extracting the syntagmatic features from the
For deriving our deeper linguistic features, we
                                                               training data yields relatively small number of
parse the Arabic sentences that contain an NE. For
                                                               instances. Hence the need for additional tagged
each of the NEs, we extract a number of features
                                                               data. The new Arabic NER tagged data is derived
described as follows:
                                                               via projection exploiting parallel Arabic English
   - Syntactic head-word (SHW): The idea here
                                                               data. The process depends on the availability
is to look for a broader relevant context.
                                                               of two key components: a large Arabic English
Whereas the feature lexical n-gram context fea-
                                                               parallel corpus that is sentence and word aligned,
ture used in BASE, and hence here for EX-
                                                               and a robust high performing English NER
TENDED, considers the linearly adjacent neigh-
                                                               system. The process is as follows. We NE tag the
boring words of a NE, SHW uses a parse tree
to look at farther, yet related, words.        For                2
                                                                    http://www.cis.upenn.edu/∼dbikel/software.html#stat-
instance, in the Arabic phrase “SrH Ams An                     parser


                                                         282


English side of the parallel corpus. We project                        Additionally for the ACE 2004 and 2005 data, two
the automatically tagged NER tags from the                             NE classes are added to the ACE 2003 tag-set:
English side to the Arabic side of the parallel                        Vehicles (e.g. Rotterdam Ship) and Weapons (e.g.
corpus. In our case, we have access to a large                         Kalashnikof). We use the same split for train, de-
manually aligned parallel corpus, therefore the                        velopment, and test used in (Benajiba et al., 2008).
NER projection is direct. However, the English
side of the parallel corpus is not NER tagged,                         3.2 Parallel Data
hence we use an off-the-shelf competitive robust                       Most of the hand-aligned Arabic-English parallel
automatic English NER system which has a                               data used in our experiments is from the Language
published performance of 92% (Zitouni and                              Data Consortium (LDC).5 . Another set of the par-
Florian, 2009). The result of these two processes                      allel data is annotated in-house by professional an-
is a large Arabic NER, albeit noisy, tagged data                       notators. The corpus has texts of five different gen-
set. As mentioned earlier this data is used only                       res, namely: newswire, news groups, broadcast
for deriving additional instances for training                         news, broadcast conversation and weblogs corre-
for the syntagmatic features and for the context                       sponding to the data genres in the ACE gold data.
and gazetteer features.3 Given this additional                         The Arabic side of the parallel corpus contains
source of data, we changed the lexical features                        941,282 tokens. After projecting the NE tags from
extracted from the BASE to the EXTENDED. We                            the English side to the Arabic side of the paral-
added two other lexical features: CBG and NGC,                         lel corpus, we obtain a total of 57,290 Arabic NE
described as follows: - Class Based Gazetteers                         instances. Table 1 shows the number of NEs for
(CBG): This feature focuses on the surface form                        each class.
of the NEs. We group the NEs encountered on the                           Class      Number of NEs       Class    Number of NEs
Arabic side of the parallel corpus by class as they                       FAC            998             PER         17,964
are found in different dictionaries. The difference                       LOC           27,651           VEH           85
                                                                          ORG           10,572           WEA           20
between this feature and that in BASE is that the
Gazetteers are not restricted to Wikipedia sources.                    Table 1: Number of NEs per class in the Arabic
                                                                       side of the parallel corpus
   - N-gram context (NGC): Here we disregard
the surface form of the NE, instead we focus on its                    3.3 Individual Feature Impact
lexical context. For each n, where n varies from 1                     Across the board, all the features yield improved
to 3, we compile a list of the −n, +n, and −/ + n                      performance. The highest obtained result is ob-
words surrounding the NE. Similar to the CBG                           served where the first non-terminal parent is used
feature, these lists are also separated by NE class.                   as a feature, a Syntactic Environment (SE) fea-
It is worth highlighting that the NCG feature is                       ture, yielding an improvement of up to 4 points
different from the Context feature in BASE in                          over the baseline. We experiment with different
that the window size is different +/ − 1 − 3 for                       sizes for the SE, i.e. taking the first parent versus
EXTENDED versus +/ − 1 for BASE.                                       adding neighboring non-terminal parents. We note
3       Experiments and Results                                        that even though we observe an overall increase
                                                                       in performance, considering both the {first, sec-
3.1 Gold Data for training and evaluation                              ond} or the {first, second, and third} non-terminal
We use the standard sets of ACE 2003, ACE                              parents decreases performance by 0.5 and 1.5 F-
2004 and ACE 2005.4 The ACE data is annotated                          measure points, respectively, compared to consid-
for many tasks: Entity Detection and Tracking                          ering the first parent information alone. The head
(EDT), Relation Detection and Recognition                              word features, SHW, show a higher positive im-
(RDR), Event Detection and Recognition (EDR).                          pact than the lexical context feature, NGC. Finally,
All the data sets comprise Broadcast News                              the Gazetteer feature, CBG, impact is comparable
(BN) and Newswire (NW) genres. ACE 2004                                to the obtained improvement of the lexical context
includes an additional NW data set from the                            feature.
Arabic TreeBank (ATB). ACE 2005 includes
a different genre of Weblogs (WL). The NE                              3.4 Feature Combination Experiments
classes adopted in the annotation of the ACE                           Table 2 illustrates the final results. It shows for
2003 data are: Person (PER), Geo Political Entity                      each data set and each genre the F-measure ob-
(GPE), Organization (ORG) and Facility (FAC).                          tained using the best feature set and ML approach.
                                                                       It shows results for both the dev and test data us-
    3
      Therefore, we did not do the full feature extraction for         ing the optimal number of features selected from
the other features described in BASE for this data.
    4                                                                     5
      http://www.nist.gov/speech/tests/ace/                                   All the LDC data are publicly available


                                                                 283


                                 ACE 2003              ACE 2004                       ACE 2005
                                 BN    NW          BN    NW     ATB               BN    NW     WL
               FreqBaseline     73.74 67.61       62.17 51.67 62.94              70.18 57.17 27.66
               All-Synt.        83.41 79.11       76.90 72.90 74.82              81.42 76.07 54.49
        dev
               All              83.93 79.72       78.54 72.80 74.97              81.82 75.92 55.65
               All-Synt.        83.50 78.90       76.70 72.40 73.50              81.31 75.30 57.30
        test
               All              84.32 79.4        78.12 72.13 74.54              81.73 75.67 58.11

     Table 2: Final Results obtained with selected features contrasted against all features combined


the all the features except the syntagmatic ones              works, they augment training data from parallel
(All-Synt.) contrasted against the system in-                 data for training supervised systems. In (Diab,
cluding the semantic features, i.e. All the features,         2004), the author uses projections from English
per class All . The baseline results, FreqBaseline,           into Arabic to bootstrap a sense tagging system
assigns a test token the most frequent tag observed           for Arabic as well as a seed Arabic WordNet
for it in the gold training data, if a test token is          through projection. In (Hwa et al., 2002), the
not observed in the training data, it is assigned the         authors report promising results of inducing Chi-
most frequent tag which is the O tag.                         nese dependency trees from English. The ob-
                                                              tained model outperformed the baseline. More re-
4   Results Discussion                                        cently, in (Chen and Ji, 2009), the authors report
Individual feature impact results show that the               their comparative study between monolingual and
syntagmatic features are helpful for most of the              cross-lingual bootstrapping. Finally, in Mention
data sets. The highest improvements are obtained              Detection (MD), a task which includes NER and
for the 2003 BN and 2005 WL data-sets. The im-                adds the identification and classification of nom-
provement varies significantly from one data-set              inal and pronominal mentions, (Zitouni and Flo-
to another because it highly depends on the num-              rian, 2008) show the impact of using a MT sys-
ber of NEs which the model has not been able to               tem to enhance the performance of an Arabic MD
capture using the contextual, lexical, syntactic and          model. The authors report an improvement of up
morphological features.                                       to 1.6F when the baseline system uses lexical fea-
Impact of the features extracted from the paral-              tures only. Unlike the work we present here, their
lel corpus per class: The syntagmatic features                approach requires the availability of an accurate
have varied in their influence on the different NE            MT system which is a more expensive process.
classes. Generally, the LOC and PER classes ben-
                                                              6   Conclusion and Future Directions
efitted more from the head word features, SHW),
                                                              In this paper we investigate the possibility of
than the other classes. On the other hand for the
                                                              building a high performance Arabic NER system
syntactic environment feature (SE), the PER class
                                                              by using lexical, syntactic and morphological fea-
seemed not to benefit much from the presence of
                                                              tures and augmenting the model with deeper lexi-
this feature. Weblogs: Our results show that the
                                                              cal features and more syntagmatic features. These
random contexts in which the NEs tend to ap-
                                                              extra features are extracted from noisy data ob-
pear in the WL documents stand against obtain-
                                                              tained via projection from an Arabic-English par-
ing a significant improvement. Consequently, the
                                                              allel corpus. Our results show that we achieve a
features which use a more global context (syntac-
                                                              significantly high performance for almost all the
tic environment, SE, and head word, SHW, fea-
                                                              data-sets. The greatest impact of the syntagmatic
tures) have helped obtain better results than the
                                                              features (1.64 points of F-measure) is obtained for
ones which we have obtained using local context
                                                              the ACE 2004, BN genre. Also, the WL genre
namely CBG and NGC.
                                                              yields an improvement of 1.16 F1 points absolute.
5   Related Work
Projecting explicit linguistic tags from another              Acknowledgments
language via parallel corpora has been widely used
in the NLP tasks and has proved to contribute sig-            This work has been partially funded by DARPA GALE
nificantly to achieving better performance. Dif-              project. The research of the last author was funded
ferent research works report positive results when            by MICINN research project TEXT-ENTERPRISE 2.0
using this technique to enhance WSD (Diab and                 TIN2009-13391-C04-03 (Plan I+D+i).
Resnik, 2002; Ng et al., 2003). In the latter two


                                                        284


References                                                      I. Zitouni and R. Florian. 2008. Mention detection
                                                                   crossing the language barrier. In Proceedings of
B. Babych and A. Hartley. 2003. Improving Machine                  EMNLP’08, Honolulu, Hawaii, October.
   Translation Quality with Automatic Named Entity
   Recognition. In Proc. of EACL-EAMT.                          Imed Zitouni and Radu Florian. 2009. Cross language
                                                                  information propagation for arabic mention detec-
Y. Benajiba, M. Diab, and P. Rosso. 2008. Ara-                    tion. Journal of ACM Transactions on Asian Lan-
   bic named entity recognition using optimized feature           guage Information Processing, December.
   sets. In Proceedings of EMNLP’08, pages 284–293.

Daniel M. Bikel. 2004. On the parameter space
  of generative lexicalized statistical parsing models.
  University of Pennsylvania, Philadelphia, PA, USA.
  Supervisor-Marcus, Mitchell P.

Z. Chen and H. Ji. 2009. Can one language bootstrap
   the other: A case study of event extraction. In Pro-
   ceedings of NAACL’09.

M. Collins. 1999. Head-Driven Statistical Models for
  Nat- ural Language Parsing. University of Pennsyl-
  vania, Philadelphia, PA, USA.

Mona Diab and Philip Resnik. 2002. An unsuper-
 vised method for word sense tagging using parallel
 corpora. In Proceedings of 40th Annual Meeting
 of the Association for Computational Linguistics,
 pages 255–262, Philadelphia, Pennsylvania, USA,
 July. Association for Computational Linguistics.

M. Diab, K. Hacioglu, and D. Jurafsky, 2007. Arabic
  Computational Morphology: Knowledge-based and
  Empirical Methods, chapter 9. Springer.

Mona Diab. 2004. Bootstrapping a wordnet taxonomy
 for arabic. In Proceedings of First Arabic Language
 Technology Conference (NEMLAR), Cairo Egypt,.

N. Habash and O. Rambow. 2005. Arabic Tok-
  enization, Part-of-Speech Tagging and Morpholog-
  ical Disambiguation in One Fell Swoop. In Proc.
  of the 43rd Annual Meeting of the Association for
  Computational Linguistics (ACL’05), pages 573–
  580, Ann Arbor, Michigan, June. Association for
  Computational Linguistics.

R. Hwa, P. Resnik, and A. Weinberg. 2002. Break-
  ing the resource bottleneck for multilingual parsing.
  In In Proceedings of the Workshop on Linguistic
  Knowledge Acquisition and Representation: Boot-
  strapping Annotated Language Data.

D. Nadeau and S. Sekine. 2007. A Survey of Named
  Entity Recognition and Classification. Linguisticae
  Investigationes, 30(7).

H.-T. Ng, B. Wang, and Y.-S. Chan. 2003. Exploit-
  ing parallel texts for word sense disambiguation: An
  empirical study. In ACL’03, pages 455–462, Sap-
  poro, Japan.

P. Thompson and C. Dozier. 1997. Name Searching
   and Information Retrieval. In In Proc. of Second
   Conference on Empirical Methods in Natural Lan-
   guage Processing, Providence, Rhode Island.


                                                          285

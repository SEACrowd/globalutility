              Decision detection using hierarchical graphical models

                    Trung H. Bui                                      Stanley Peters
                        CSLI                                               CSLI
                 Stanford University                                Stanford University
              Stanford, CA 94305, USA                            Stanford, CA 94305, USA
              thbui@stanford.edu                              peters@csli.stanford.edu


                    Abstract                                 their performance at this task compared with non-
    We investigate hierarchical graphical                    hierarchical DGMs.
    models (HGMs) for automatically detect-                     We proceed as follows. Section 2 discusses re-
    ing decisions in multi-party discussions.                lated work, and section 3 our data set and anno-
    Several types of dialogue act (DA) are                   tation scheme for decision discussions. Section
    distinguished on the basis of their roles in             4 summarizes previous decision detection exper-
    formulating decisions. HGMs enable us                    iments using DGMs. Section 5 presents the HGM
    to model dependencies between observed                   approach, and section 6 describes our HGM exper-
    features of discussions, decision DAs, and               iments. Finally, section 7 draws conclusions and
    subdialogues that result in a decision. For              presents ideas for future work.
    the task of detecting decision regions, an               2 Related work
    HGM classifier was found to outperform
    non-hierarchical graphical models and                    User studies (Banerjee et al., 2005) have con-
    support vector machines, raising the                     firmed that meeting participants consider deci-
    F1-score to 0.80 from 0.55.                              sions to be one of the most important meeting
                                                             outputs, and Whittaker et al. (2006) found that
1   Introduction
                                                             the development of an automatic decision de-
In work environments, people share information               tection component is critical for re-using meet-
and make decisions in multi-party conversations              ing archives. With the new availability of sub-
known as meetings. The demand for systems that               stantial meeting corpora such as the AMI cor-
can automatically process information contained              pus (McCowan et al., 2005), recent years have
in audio and video recordings of meetings is grow-           seen an increasing amount of research on decision-
ing rapidly. Our own research, and that of other             making dialogue. This research has tackled is-
contemporary projects (Janin et al., 2004) aim at            sues such as the automatic detection of agreement
meeting this demand.                                         and disagreement (Galley et al., 2004), and of
   We are currently investigating the automatic de-          the level of involvement of conversational partic-
tection of decision discussions. Our approach in-            ipants (Gatica-Perez et al., 2005). Recent work
volves distinguishing between different dialogue             on automatic detection of decisions has been con-
act (DA) types based on their role in the decision-          ducted by Hsueh and Moore (2007), Fernández et
making process. These DA types are called De-                al. (2008), and Bui et al. (2009).
cision Dialogue Acts (DDAs). Groups of DDAs                     Fernández et al. (2008) proposed an approach
combine to form a decision region.                           to modeling the structure of decision-making di-
   Recent work (Bui et al., 2009) showed that                alogue. These authors designed an annotation
Directed Graphical Models (DGMs) outperform                  scheme that takes account of the different roles
other machine learning techniques such as Sup-               that utterances can play in the decision-making
port Vector Machines (SVMs) for detecting in-                process—for example it distinguishes between
dividual DDAs. However, the proposed mod-                    DDAs that initiate a decision discussion by rais-
els, which were non-hierarchical, did not signifi-           ing an issue, those that propose a resolution of the
cantly improve identification of decision regions.           issue, and those that express agreement to a pro-
This paper tests whether giving DGMs hierarchi-              posed resolution. The authors annotated a por-
cal structure (making them HGMs) can improve                 tion of the AMI corpus, and then applied what


                                                       307
                      Proceedings of the ACL 2010 Conference Short Papers, pages 307–312,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


they refer to as “hierarchical classification.” Here,         Random Fields (CRFs), a simple UGM case, can
one sub-classifier per DDA class hypothesizes oc-             avoid the label bias problem (Lafferty et al., 2001)
currences of that type of DDA and then, based                 and outperform maximum entropy Markov mod-
on these hypotheses, a super-classifier determines            els and HMMs.
which regions of dialogue are decision discus-                   However, the graphical models used in these
sions. All of the classifiers, (sub and super), were          applications are mainly non-hierarchical, includ-
linear kernel binary SVMs. Results were bet-                  ing those in Bui et al. (2009). Only Sutton et al.
ter than those obtained with (Hsueh and Moore,                (2007) proposed a three-level HGM (in the form of
2007)’s approach—the F1-score for detecting de-               a dynamic CRF) for the joint noun phrase chunk-
cision discussions in manual transcripts was 0.58             ing and part of speech labeling problem; they
vs. 0.50. Purver et al. (2007) had earlier detected           showed that this model performs better than a non-
action items with the approach Fernández et al.              hierarchical counterpart.
(2008) extended to decisions.
                                                              3 Data
   Bui et al. (2009) built on the promising results
of (Fernández et al., 2008), by employing DGMs               For the experiments reported in this study, we
in place of SVMs. DGMs are attractive because                 used 17 meetings from the AMI Meeting Corpus1 ,
they provide a natural framework for modeling se-             a freely available corpus of multi-party meetings
quence and dependencies between variables, in-                with both audio and video recordings, and a wide
cluding the DDAs. Bui et al. (2009) were espe-                range of annotated information including DAs and
cially interested in whether DGMs better exploit              topic segmentation. The meetings last around 30
non-lexical features. Fernández et al. (2008) ob-            minutes each, and are scenario-driven, wherein
tained much more value from lexical than non-                 four participants play different roles in a com-
lexical features (and indeed no value at all from             pany’s design team: project manager, marketing
prosodic features), but lexical features have limi-           expert, interface designer and industrial designer.
tations. In particular, they can be domain specific,             We use the same annotation scheme as
increase the size of the feature space dramatically,          Fernández et al. (2008) to model decision-making
and deteriorate more in quality than other features           dialogue. As stated in section 2, this scheme dis-
when automatic speech recognition (ASR) is poor.              tinguishes between a small number of DA types
More detail about decision detection using DGMs               based on the role which they perform in the for-
will be presented in section 4.                               mulation of a decision. Besides improving the de-
   Beyond decision detection, DGMs are used for               tection of decision discussions (Fernández et al.,
labeling and segmenting sequences of observa-                 2008), such a scheme also aids in summarization
tions in many different fields—including bioin-               of them, because it indicates which utterances pro-
formatics, ASR, Natural Language Processing                   vide particular types of information.
(NLP), and information extraction. In particular,                The annotation scheme is based on the observa-
Dynamic Bayesian Networks (DBNs) are a pop-                   tion that a decision discussion typically contains
ular model for probabilistic sequence modeling                the following main structural components: (a) A
because they exploit structure in the problem to              topic or issue requiring resolution is raised; (b)
compactly represent distributions over multi-state            One or more possible resolutions are considered;
and observation variables. Hidden Markov Mod-                 (c) A particular resolution is agreed upon, and so
els (HMMs), a special case of DBNs, are a classi-             adopted as the decision. Hence the scheme dis-
cal method for important NLP applications such                tinguishes between three main DDA classes: issue
as unsupervised part-of-speech tagging (Gael et               (I), resolution (R), and agreement (A). Class R is
al., 2009) and grammar induction (Johnson et al.,             further subdivided into resolution proposal (RP)
2007) as well as for ASR. More complex DBNs                   and resolution restatement (RR). I utterances in-
have been used for applications such as DA recog-             troduce the topic of the decision discussion, ex-
nition (Crook et al., 2009) and activity recogni-             amples being “Are we going to have a backup?”
tion (Bui et al., 2002).                                      and “But would a backup really be necessary?” in
                                                              Table 1. In comparison, R utterances specify the
  Undirected graphical models (UGMs) are also
                                                              resolution which is ultimately adopted as the deci-
valuable for building probabilistic models for seg-
                                                                 1
menting and labeling sequence data. Conditional                      http://corpus.amiproject.org/


                                                        308


 (1) A: Are we going to have a backup? Or we do               (UTT) such as length in words2 , duration in mil-
     just–                                                    liseconds, position within the meeting (as percent-
     B: But would a backup really be necessary?               age of elapsed time), manually annotated dialogue
     A: I think maybe we could just go for the                act (DA) features3 such as inform, assess, suggest,
        kinetic energy and be bold and innovative.            and prosodic features (PROS) such as energy and
     C: Yeah.                                                 pitch. These features are the same as the non-
     B: I think– yeah.                                        lexical features used by Fernández et al. (2008).
     A: It could even be one of our selling points.           The hidden component node (C) in the -mix mod-
     C: Yeah –laugh–.                                         els represents the distribution of observable evi-
     D: Environmentally conscious or something.               dence E as a mixture of Gaussian distributions.
     A: Yeah.                                                 The number of Gaussian components was hand-
     B: Okay, fully kinetic energy.                           tuned during the training phase.
     D: Good.
                                                                                DDA                           DDA


                                                                                                                       C
Table 1: An excerpt from the AMI dialogue
                                                                                    E                          E
ES2015c. It has been modified slightly for pre-
sentation purposes.                                                          a) BN-sim                         b) BN-mix

                                                                         time t-1       time t           time t-1    time t

                                                                          DDA           DDA               DDA         DDA
sion. RP utterances propose this resolution (e.g. “I
                                                                                                     C                         C
think maybe we could just go for the kinetic energy
                                                                            E             E                   E        E
. . . ”), while RR utterances close the discussion by
                                                                           c) DBN-sim                         d) DBN-mix
confirming/summarizing the decision (e.g. “Okay,
fully kinetic energy”). Finally, A utterances agree
                                                              Figure 1: Simple DGMs for individual decision
with the proposed resolution, signaling that it is
                                                              dialogue act detection. The clear nodes are hidden,
adopted as the decision, (e.g. “Yeah”, “Good” and
                                                              and the shaded nodes are observable.
“Okay”). Unsurprisingly, an utterance may be as-
signed to more than one DDA class; and within a                  More complex models were constructed from
decision discussion, more than one utterance can              the four simple models in Fig. 1 to allow for de-
be assigned to the same DDA class.                            pendencies between different DDAs. For exam-
     We use manual transcripts in the experiments             ple, the model in Fig. 2 generalizes Fig. 1c with
described here. Inter-annotator agreement was sat-            arcs connecting the DDA classes based on analy-
isfactory, with kappa values ranging from .63 to              sis of the annotated AMI data.
.73 for the four DDA classes. The manual tran-                              time t-1                                  time t
scripts contain a total of 15,680 utterances, and on
                                                                     I     RP           RR       A        I           RP       RR   A
average 40 DDAs per meeting. DDAs are sparse
in the transcripts: for all DDAs, 6.7% of the total-
                                                                                E                                          E
ity of utterances; for I,1.6%; for RP, 2%; for RR,
0.5%; and for A, 2.6%. In all, 3753 utterances (i.e.,
23.9%) are tagged as decision-related utterances,             Figure 2: A DGM that takes the dependencies be-
and on average there are 221 decision-related ut-             tween decision dialogue acts into account.
terances per meeting.
                                                                 Decision discussion regions were identified us-
4   Prior Work on Decision Detection                          ing the DGM output and the following two simple
    using Graphical Models                                    rules: (1) A decision discussion region begins with
To detect each individual DDA class, Bui et al.               an Issue DDA; (2) A decision discussion region
(2009) examined the four simple DGMs shown                    contains at least one Issue DDA and one Resolu-
in Fig. 1. The DDA node is binary valued, with                tion DDA.
                                                                 2
value 1 indicating the presence of a DDA and 0                      This feature is a manual count of lexical tokens; but word
its absence. The evidence node (E) is a multi-                count was extracted automatically from ASR output by Bui
                                                              et al. (2009). We plan experiments to determine how much
dimensional vector of observed values of non-                 using ASR output degrades detection of decision regions.
                                                                  3
lexical features. These include utterance features                  The authors used the AMI DA annotations.


                                                        309


                                                                                     current utterance          next utterance
   The authors conducted experiments using the
AMI corpus and found that when using non-                                        Level 3         DR                  DR

lexical features, the DGMs outperform the hierar-
chical SVM classification method of (Fernández et                                                     Cn                   Cn
                                                                             Level 2
al., 2008). The F1-score for the four DDA classes                                                C1C              C1C

increased between 0.04 and 0.19 (p < 0.005),
and for identifying decision discussion regions, by
0.05 (p > 0.05).                                                                 Level 1         E                      E




5   Hierarchical graphical models                             Figure 3: A simple structure of a three-level
                                                              HGM: DRs are high-level discourse regions;
                                                              C1 , C2 , ..., Cn are mid-level utterance classes; and
Although the results just discussed showed graph-
                                                              Es are vectors of observed features.
ical models are better than SVMs for detecting de-
cision dialogue acts (Bui et al., 2009), two-level
graphical models like those shown in Figs. 1 and 2            6 Experiments
cannot exploit dependencies between high-level                The HGM classifier in Figure 3 was implemented
discourse items such as decision discussions and              in Matlab using the BNT software4 . The classifier
DDAs; and the “superclassifier” rule (Bui et al.,             hypothesizes that an utterance belongs to a deci-
2009) used for detecting decision regions did not             sion region if the marginal probability of the ut-
significantly improve the F1-score for decisions.             terance’s DR node is above a hand-tuned thresh-
   We thus investigate whether HGMs (structured               old. The threshold is selected using the ROC curve
as three or more levels) are superior for discov-             analysis5 to obtain the highest F1-score. To evalu-
ering the structure and learning the parameters               ate the accuracy of hypothesized decision regions,
of decision recognition. Our approach composes                we divided the dialogue into 30-second windows
graphical models to increase hierarchy with an ad-            and evaluated on a per window basis.
ditional level above or below previous ones, or in-              The best model structure was selected by com-
serts a new level such as for discourse topics into           paring the performance of various handcrafted
the interior of a given model.                                structures. For example, the model in Fig. 4b out-
   Fig. 3 shows a simple structure for three-level            performs the one in Fig. 4a. Fig. 4b explicitly
HGMs. The top level corresponds to high-level                 models the dependency between the decision re-
discourse regions such as decision discussions.               gions and the observed features.
The segmentation into these regions is represented
                                                                                           DR                           DR
in terms of a random variable (at each DR node)
that takes on discrete values: {positive, negative}                          I      RP          RR     A    I      RP            RR   A

(the utterance belongs to a decision region or not)
or {begin, middle, end, outside} (indicating the                                           E                                E

position of the utterance relative to a decision dis-                                      a)                               b)

cussion region). The middle level corresponds to
mid-level discourse items such as issues, resolu-             Figure 4: Three-level HGMs for recognition of de-
tion proposals, resolution restatements, and agree-           cisions. This illustrates the choice of the structure
ments. These classes (C1 , C2 , ..., Cn nodes) are            for each time slice of the HGM sequence models.
represented as a collection of random variables,
each corresponding to an individual mid-level ut-                Table 2 shows the results of 17-fold cross-
terance class. For example, the middle level of the           validation for the hierarchical SVM classifica-
three-level HGM Fig. 3 could be the top-level of              tion (Fernández et al., 2008), rule-based classifi-
the two-level DGM in Fig. 2, each middle level                cation with DGM output (Bui et al., 2009), and
node containing random variables for the DDA                  our HGM classification using the best combina-
classes I, RP, RR, and A. The bottom level cor-               tion of non-lexical features. All three methods
responds to vectors of observed features as before,              4
                                                                     http://www.cs.ubc.ca/∼murphyk/Software/BNT/bnt.html
                                                                 5
e.g. lexical, utterance, and prosodic features.                      http://en.wikipedia.org/wiki/Receiver operating characteristic


                                                        310


were implemented by us using exactly the same                            the DGMs studied in (Bui et al., 2009). When
data and 17-fold cross-validation. The features                          using non-lexical features, HGMs outperform the
were selected based on the best combination of                           non-hierarchical DGMs of (Bui et al., 2009) and
non-lexical features for each method. The HGM                            also the hierarchical SVM classification method
classifier outperforms both its SVM and DGM                              of Fernández et al. (2008). The F1-score for
counterparts (p < 0.0001)6 . In fact, even when the                      identifying decision discussion regions increased
SVM uses lexical as well as non-lexical features,                        to 0.80 from 0.55 and 0.50 respectively (p <
its F1-score is still lower than the HGM classifier.                     0.0001).
                                                                            In future work, we plan to (a) investigate cas-
                                                                         caded learning methods (Sutton et al., 2007) to
            Classifier     Pr       Re        F1                         improve the detection of DDAs further by using
            SVM            0.35     0.88      0.50                       detected decision regions and (b) extend HGMs
            DGM            0.39     0.93      0.55                       beyond three levels in order to integrate useful se-
            HGM            0.69     0.96      0.80                       mantic information such as topic structure.
Table 2: Results for detection of decision dis-
                                                                         Acknowledgments
cussion regions by the SVM super-classifier,
rule-based DGM classifier, and HGM clas-                                 The research reported in this paper was spon-
sifier, each using its best combination of                               sored by the Department of the Navy, Office of
non-lexical features: SVM (UTT+DA), DGM                                  Naval Research, under grants number N00014-
(UTT+DA+PROS), HGM (UTT+DA).                                             09-1-0106 and N00014-09-1-0122. Any opinions,
                                                                         findings, and conclusions or recommendations ex-
   In contrast with the hierarchical SVM and rule-                       pressed in this material are those of the authors and
based DGM methods, the HGM method identifies                             do not necessarily reflect the views of the Office of
decision-related utterances by exploiting not just                       Naval Research.
DDAs but also direct dependencies between deci-
sion regions and UTT, DA, and PROS features. As
mentioned in the second paragraph of this section,
                                                                         References
explicitly modeling the dependency between deci-                         Satanjeev Banerjee, Carolyn Rosé, and Alex Rudnicky.
sion regions and observable features helps to im-                          2005. The necessity of a meeting recording and
                                                                           playback system, and the benefit of topic-level anno-
prove detection of decision regions. Furthermore,                          tations to meeting browsing. In Proceedings of the
a three-level HGM can straightforwardly model                              10th International Conference on Human-Computer
the composition of each high-level decision region                         Interaction.
as a sequence of mid-level DDA utterances. While                         H. H. Bui, S. Venkatesh, and G. West. 2002. Pol-
the hierarchical SVM method can also take depen-                           icy recognition in the abstract hidden markov model.
dency between successive utterances into account,                          Journal of Artificial Intelligence Research, 17:451–
it has no principled way to associate this depen-                          499.
dency with more extended decision regions. In                            Trung Huu Bui, Matthew Frampton, John Dowding,
addition, this dependency is only meaningful for                           and Stanley Peters. 2009. Extracting decisions from
lexical features (Fernández et al., 2008).                                multi-party dialogue using directed graphical mod-
   The HGM result presented in Table 2 was                                 els and semantic similarity. In Proceedings of the
                                                                           10th Annual SIGDIAL Meeting on Discourse and
computed using the three-level DBN model (see                              Dialogue (SIGdial09).
Fig. 4b) using the combination of UTT and DA
features. Without DA features, the F1-score de-                          Nigel Crook, Ramon Granell, and Stephen Pulman.
                                                                           2009. Unsupervised classification of dialogue acts
grades from 0.8 to 0.78. However, this difference                          using a dirichlet process mixture model. In Pro-
is not statistically significant (i.e., p > 0.5).                          ceedings of SIGDIAL 2009: the 10th Annual Meet-
                                                                           ing of the Special Interest Group in Discourse and
7    Conclusions and Future Work                                           Dialogue, pages 341–348.

To detect decision discussions in multi-party dia-                       Raquel Fernández, Matthew Frampton, Patrick Ehlen,
logue, we investigated HGMs as an extension of                             Matthew Purver, and Stanley Peters. 2008. Mod-
                                                                           elling and detecting decisions in multi-party dia-
   6                                                                       logue. In Proceedings of the 9th SIGdial Workshop
     We used the paired t test for computing statistical signif-
icance. http://www.graphpad.com/quickcalcs/ttest1.cfm                      on Discourse and Dialogue.


                                                                   311


Jurgen Van Gael, Andreas Vlachos, and Zoubin                     fields: Factorized probabilistic models for labeling
   Ghahramani. 2009. The infinite HMM for unsu-                  and segmenting sequence data. Journal of Machine
   pervised PoS tagging. In Proceedings of the 2009              Learning Research, 8:693–723.
   Conference on Empirical Methods in Natural Lan-
   guage Processing, pages 678–687.                            Steve Whittaker, Rachel Laban, and Simon Tucker.
                                                                  2006. Analysing meeting records: An ethnographic
Michel Galley, Kathleen McKeown, Julia Hirschberg,                study and technological implications. In S. Renals
  and Elizabeth Shriberg. 2004. Identifying agree-                and S. Bengio, editors, Machine Learning for Multi-
  ment and disagreement in conversational speech:                 modal Interaction: Second International Workshop,
  Use of Bayesian networks to model pragmatic de-                 MLMI 2005, Revised Selected Papers, volume 3869
  pendencies. In Proceedings of the 42nd Annual                   of Lecture Notes in Computer Science, pages 101–
  Meeting of the Association for Computational Lin-               113. Springer.
  guistics (ACL).

Daniel Gatica-Perez, Ian McCowan, Dong Zhang, and
  Samy Bengio. 2005. Detecting group interest level
  in meetings. In Proceedings of ICASSP.

Pey-Yun Hsueh and Johanna Moore. 2007. Automatic
  decision detection in meeting speech. In Proceed-
  ings of MLMI 2007, Lecture Notes in Computer Sci-
  ence. Springer-Verlag.

Adam Janin, Jeremy Ang, Sonali Bhagat, Rajdip
  Dhillon, Jane Edwards, Javier Marcı́as-Guarasa,
  Nelson Morgan, Barbara Peskin, Elizabeth Shriberg,
  Andreas Stolcke, Chuck Wooters, and Britta Wrede.
  2004. The ICSI meeting project: Resources and re-
  search. In Proceedings of the 2004 ICASSP NIST
  Meeting Recognition Workshop.

Mark Johnson, Thomas Griffiths, and Sharon Gold-
 water. 2007. Bayesian inference for PCFGs via
 Markov chain Monte Carlo. In Proceedings of
 Human Language Technologies 2007: The Confer-
 ence of the North American Chapter of the Associa-
 tion for Computational Linguistics, pages 139–146,
 Rochester, New York, April. Association for Com-
 putational Linguistics.

John Lafferty, Andrew McCallum, and Fernando
  Pereira. 2001. Conditional random fields: Prob-
  abilistic models for segmenting and labeling se-
  quence data. In Proceedings of the 18th Interna-
  tional Conference on Machine Learning, pages 282–
  289. Morgan Kaufmann.

Iain McCowan, Jean Carletta, W. Kraaij, S. Ashby,
   S. Bourban, M. Flynn, M. Guillemot, T. Hain,
   J. Kadlec, V. Karaiskos, M. Kronenthal, G. Lathoud,
   M. Lincoln, A. Lisowska, W. Post, D. Reidsma, and
   P. Wellner. 2005. The AMI Meeting Corpus. In
   Proceedings of Measuring Behavior, the 5th Inter-
   national Conference on Methods and Techniques in
   Behavioral Research, Wageningen, Netherlands.

Matthew Purver, John Dowding, John Niekrasz,
 Patrick Ehlen, Sharareh Noorbaloochi, and Stanley
 Peters. 2007. Detecting and summarizing action
 items in multi-party dialogue. In Proceedings of the
 8th SIGdial Workshop on Discourse and Dialogue,
 Antwerp, Belgium.

Charles Sutton, Andrew McCallum, and Khashayar
  Rohanimanesh. 2007. Dynamic conditional random


                                                         312

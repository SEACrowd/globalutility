           Using Speech to Reply to SMS Messages While Driving:
                      An In-Car Simulator User Study
                                  Yun-Cheng Ju, Tim Paek
                                     Microsoft Research
                                     Redmond, WA USA
                             {yuncj|timpaek}@microsoft.com


                                                           begun to explore techniques. In previous re-
                    Abstract                               search (Ju & Paek, 2009), we examined three
                                                           ASR approaches to replying to SMS messages:
    Speech recognition affords automobile                  dictation using a language model trained on SMS
    drivers a hands-free, eyes-free method of              responses, canned responses using a probabilistic
    replying to Short Message Service (SMS)                context-free grammar (PCFG), and a “voice
    text messages. Although a voice search                 search” approach based on template matching.
    approach based on template matching has                Voice search proceeds in two steps (Natarajan et
    been shown to be more robust to the chal-              al., 2002): an utterance is first converted into
    lenging acoustic environment of automo-                text, which is then used as a search query to
    biles than using dictation, users may have             match the most similar items of an index using
    difficulties verifying whether SMS re-                 IR techniques (Yu et al., 2007). For SMS replies,
    sponse templates match their intended                  we created an index of SMS response templates,
    meaning, especially while driving. Using a             with slots for semantic concepts such as time and
    high-fidelity driving simulator, we com-               place, from a large SMS corpus. After convolv-
    pared dictation for SMS replies versus                 ing recorded SMS replies so that the audio would
    voice search in increasingly difficult driv-           exhibit the acoustic characteristics of in-car rec-
    ing conditions. Although the two ap-                   ognition, they compared how the three approach-
    proaches did not differ in terms of driving            es handled the convolved audio with respect to
    performance measures, users made about                 the top n-best reply candidates. The voice search
    six times more errors on average using                 approach consistently outperformed dictation and
    dictation than voice search.                           canned responses, achieving as high as 89.7%
                                                           task completion with respect to the top 5 reply
1    Introduction                                          candidates.
                                                              Even if the voice search approach may be
Users love Short Message Service (SMS) text                more robust to in-car noise, this does not guaran-
messaging; so much so that 3 trillion SMS mes-             tee that it will be more usable. Indeed, because
sages are expected to have been sent in 2009               voice search can only match semantic concepts
alone (Stross, 2008). Because research has                 contained in the templates (which may or may
shown that SMS messaging while driving results             not utilize the same wording as the reply), users
in 35% slower reaction time than being intox-              must verify that a retrieved template matches the
icated (Reed & Robbins, 2008), campaigns have              semantics of their intended reply. For example,
been launched by states, governments and even              suppose a user replies to the SMS message “how
cell phone carriers to discourage and ban SMS              about lunch” with “can’t right now running er-
messaging while driving (DOT, 2009). Yet, au-              rands”. Voice search may find “nope, got er-
tomobile manufacturers have started to offer in-           rands to run” as the closest template match, in
fotainment systems, such as the Ford Sync,                 which case, users will have to decide whether
which feature the ability to listen to incoming            this response has the same meaning as their re-
SMS messages using text-to-speech (TTS). Au-               ply. This of course entails cognitive effort, which
tomatic speech recognition (ASR) affords users a           is very limited in the context of driving. On the
hands-free, eyes-free method of replying to SMS            other hand, a dictation approach to replying to
messages. However, to date, manufacturers have             SMS messages may be far worse due to misre-
not established a safe and reliable method of le-          cognitions. For example, dictation may interpret
veraging ASR, though some researchers have                 “can’t right now running errands” as “can right

                                                       313
                      Proceedings of the ACL 2010 Conference Short Papers, pages 313–317,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


now fun in errands”. We posited that voice
search has the advantage because it always gene-
rates intelligible SMS replies (since response
templates are manually filtered), as opposed to
dictation, which can sometimes result in unpre-
dictable and nonsensical misrecognitions. How-
ever, this advantage has not been empirically
demonstrated in a user study. This paper presents
a user study investigating how the two approach-
es compare when users are actually driving – that
is, when usability matters most.
                                                                 Figure 1. Driving simulator setup.
2 Driving Simulator Study                               subjects design experiment in which the order of
                                                        SMS Reply for each Driving Condition was coun-
Although ASR affords users hands-free, eyes-
                                                        ter-balanced. Because our primary variable of
free interaction, the benefits of leveraging speech
                                                        interest was SMS Reply, we had users experience
can be forfeit if users are expending cognitive
                                                        both voice search and dictation with no driving
effort judging whether the speech interface cor-
                                                        first, then easy driving, followed by difficult
rectly interpreted their utterances. Indeed, re-
                                                        driving. This gave users a chance to adjust them-
search has shown that the cognitive demands of
                                                        selves to increasingly difficult road conditions.
dialogue seem to play a more important role in
distracting drivers than physically handling cell
                                                        Driving Task: As the primary task, users were
phones (Nunes & Recarte, 2002; Strayer &
                                                        asked to drive two courses we developed with
Johnston, 2001). Furthermore, Kun et al. (2007)
                                                        easy driving and difficult driving conditions
have found that when in-car speech interfaces
                                                        while obeying all rules of the road, as they would
encounter recognition problems, users tend to
                                                        in real driving and not in a videogame. With
drive more dangerously as they attempt to figure
                                                        speed limits ranging from 25 mph to 55 mph,
out why their utterances are failing. Hence, any
                                                        both courses contained five sequential sections
approach to replying to SMS messages in auto-
                                                        which took about 15-20 minutes to complete: a
mobiles must avoid distracting drivers with er-
                                                        residential area, a country highway, and a small
rors and be highly usable while users are en-
                                                        city with a downtown area as well as a busi-
gaged in their primary task, driving.
                                                        ness/industrial park. Although both courses were
2.1   Method                                            almost identical in the number of turns, curves,
                                                        stops, and traffic lights, the easy course consisted
To assess the usability and performance of both         mostly of simple road segments with relatively
the voice search approach and dictation, we con-        no traffic, whereas the difficult course had four
ducted a controlled experiment using the STISIM         times as many vehicles, cyclists, and pedestrians.
Drive™ simulator. Our simulation setup con-             The difficult course also included a foggy road
sisted of a central console with a steering wheel       section, a few busy construction sites, and many
and two turn signals, surrounded by three 47’’          unexpected events, such as a car in front sudden-
flat panels placed at a 45° angle to immerse the        ly breaking, a parked car merging into traffic,
driver. Figure 1 displays the setup.
                                                        and a pedestrian jaywalking. In short, the diffi-
   We recruited 16 participants (9 males, 7 fe-         cult course was designed to fully engage the at-
males) through an email sent to employees of our        tention and cognitive resources of drivers.
organization. The mean age was 38.8. All partic-
ipants had a driver’s license and were compen-          SMS Reply Task: As the secondary task, we
sated for their time.
                                                        asked users to listen to an incoming SMS mes-
   We examined two independent variables: SMS           sage together with a formulated reply, such as:
Reply Approach, consisting of voice search and
dictation, and Driving Condition, consisting of         (1) Message Received: “Are you lost?” Your
no driving, easy driving and difficult driving. We          Reply: “No, never with my GPS”
included Driving Condition as a way of increas-
ing cognitive demand (see next section). Overall,       The users were asked to repeat the reply back to
we conducted a 2 (SMS Reply Approach) × 3               the system. For Example (1) above, users would
(Driving Condition) repeated measures, within-          have to utter “No, never with my GPS”. Users


                                                      314


could also say “Repeat” if they had any difficul-           In the dictation condition, the correct answer
ties understanding the TTS rendering or if they          was not always an exact copy of the reply in 0-2
experienced lapses in attention. For each course,        of the 10 SMS messages. For instance, a correct
users engaged in 10 SMS reply tasks. SMS mes-            dictation answer for Example (1) above was “no
sages were cued every 3000 feet, roughly every           I’m never with my GPS”. On the other hand, the
90 seconds, which provided enough time to                voice search condition had more cases (2-4 mes-
complete each SMS dialogue. Once users uttered           sages) in which the correct answer was not an
the formulated reply, they received a list of 4          exact copy (e.g., “no I have GPS”) due to the
possible reply candidates (each labeled as “One”,        nature of the template approach. To some degree,
“Two”, etc.), from which they were asked to ei-          this could be seen as handicapping the voice
ther pick the correct reply (by stating its number       search condition, though the results did not re-
at any time) or reject them all (by stating “All         flect the disadvantage, as we discuss later.
wrong”). We did not provide any feedback about
whether the replies they picked were correct or          Measures: Performance for both the driving task
incorrect in order to avoid priming users to pay         and the SMS reply tasks were recorded. For the
more or less attention in subsequent messages.           driving task, we measured the numbers of colli-
Users did not have to finish listening to the entire     sions, speeding (exceeding 10 mph above the
list before making their selection.                      limit), traffic light and stop sign violations, and
                                                         missed or incorrect turns. For the SMS reply
Stimuli: Because we were interested in examin-           task, we measured duration (i.e., time elapsed
ing which was worse, verifying whether SMS               between the beginning of the 4-best list and
response templates matched the meaning of an             when users ultimately provided their answer) and
intended reply, or deciphering the sometimes             the number of times users correctly identified
nonsensical misrecognitions of dictation, we de-         which of the 4 reply candidates contained the
cided to experimentally control both the SMS             correct answer.
reply uttered by the user as well as the 4-best list         Originally, we had an independent rater verify
generated by the system. However, all SMS rep-           the position of the correct answer in all 4-best
lies and 4-best lists were derived from the logs of      lists, however, we considered that some partici-
an actual SMS Reply interface which imple-               pants might be choosing replies that are semanti-
mented the dictation and the voice search ap-            cally sufficient, even if they are not exactly cor-
proaches (see Ju & Paek, 2009). For each course,         rect. For example, a 4-best list generated by the
5 of the SMS replies were short (with 3 or fewer         dictation approach for Example (1) had: “One:
words) and 5 were long (with 4 to 7 words). The          no I’m never want my GPS. Two: no I’m never
mean length of the replies was 3.5 words (17.3           with my GPS. Three: no I’m never when my
chars). The order of the short and long replies          GPS. Or Four: no no I’m in my GPS.” Although
was randomized.                                          the rater identified the second reply as being
   We selected 4-best lists where the correct an-        “correct”, a participant might view the first or
swer was in each of four possible positions (1-4)        third replies as sufficient. In order to avoid am-
or All Wrong; that is, there were as many 4-best         biguity about correctness, after the study, we
lists with the first choice correct as there were        showed the same 16 participants the SMS mes-
with the second choice correct, and so forth. We         sages and replies as well as the 4-best lists they
then randomly ordered the presentation of differ-        received during the study and asked them to se-
ent 4-best lists. Although one might argue that          lect, for each SMS reply, any 4-best list items
the four positions are not equally likely and that       they felt sufficiently conveyed the same mean-
the top item of a 4-best list is most often the cor-     ing, even if the items were ungrammatical. Par-
rect answer, we decided to experimentally con-           ticipants were explicitly told that they could se-
trol the position for two reasons: first, our pre-       lect multiple items from the 4-best list. We did
vious research (Ju & Paek, 2009) had already             not indicate which item they selected during the
demonstrated the superiority of the voice search         experiment and because this selection task oc-
approach with respect to the top position (i.e., 1-      curred months after the experiment, it was un-
best), and second, our experimental design               likely that they would remember anyway. Partic-
sought to identify whether the voice search ap-          ipants were compensated with a cafeteria vouch-
proach was more usable than the dictation ap-            er.
proach even when the ASR accuracy of the two                 In computing the number of “correct” an-
approaches was the same.                                 swers, for each SMS reply, we counted an an-

                                                       315


swer to be correct if it was included among the
participants’ set of semantically sufficient 4-best
list items. Hence, we calculated the number of
correct items in a personalized fashion for every
participant.
2.2    Results
We conducted a series of repeated measures
ANOVAs on all driving task and SMS reply task
measures. For the driving task, we did not find
any statistically significant differences between
the voice search and dictation conditions. In oth-
er words, we could not reject the null hypothesis
that the two approaches were the same in terms                    Figure 2. Mean number of errors for the dictation
of their influence on driving performance. How-                   and voice search approaches. Error bars represent
ever, for the SMS reply task, we did find a main                           standard errors about the mean.
effect for SMS Reply Approach (F1,47 = 81.28, p <
.001, µDictation = 2.13 (.19), µVoiceSearch = .38 (.10)).     further discarded to only present the distinct con-
As shown in Figure 2, the average number of                   cepts at the rendering time using the paraphrase
errors per driving course for dictation is roughly            detection algorithms reported in (Wu et al.,
6 times that for voice search. We also found a                2010).
main effect for total duration (F1,47 = 11.94, p <               Given that users committed more errors in the
.01, µDictation = 113.75 sec (3.54) or 11.4 sec/reply,        dictation condition, we initially expected that
µVoiceSearch = 125.32 sec (3.37) or 12.5 sec/reply).          dictation would exhibit higher duration than
We discuss our explanation for the shorter dura-              voice search since users might be spending more
tion below. For both errors and duration, we did              time figuring out the differences between the
not find any interaction effects with Driving                 similar 4-best list candidates generated by the
Conditions.                                                   dictation approach. However, in our error analy-
                                                              sis we observed that most likely users did not
3     Discussion                                              discover the misrecognitions, and prematurely
                                                              selected a reply candidate, resulting in shorter
We conducted a simulator study in order to ex-                durations. The slightly higher duration for the
amine which was worse while driving: verifying                voice search approach does not constitute a prob-
whether SMS response templates matched the                    lem if users are listening to all of their choices
meaning of an intended reply, or deciphering the              and correctly selecting their intended SMS reply.
sometimes nonsensical misrecognitions of dicta-               Note that the duration did not bring about any
tion. Our results suggest that deciphering dicta-             significant driving performance differences.
tion results under the duress of driving leads to                Although we did not find any significant driv-
more errors. In conducting a post-hoc error anal-             ing performance differences, users experienced
ysis, we noticed that participants tended to err              more difficulties confirming whether the dicta-
when the 4-best lists generated by the dictation              tion approach correctly interpreted their utter-
approach contained phonetically similar candi-                ances than they did with the voice search ap-
date replies. Because it is not atypical for the dic-         proach. As such, if a user deems it absolutely
tation approach to have n-best list candidates                necessary to respond to SMS messages while
differing from each other in this way, we rec-                driving, our simulator study suggests that the
ommend not utilizing this approach in speech-                 most reliable (i.e., least error-prone) way to re-
only user interfaces, unless the n-best list candi-           spond may just well be the voice search ap-
dates can be made as distinct from each other as              proach.
possible, phonetically, syntactically and most
importantly, semantically. The voice search ap-               References
proach circumvents this problem in two ways: 1)
templates were real responses and manually se-                Distracted Driving Summit. 2009. Department of
lected and cleaned up during the development                    Transportation. Retrieved Dec. 1:
phase so there were no grammatical mistakes,                    http://www.rita.dot.gov/distracted_driving_summit
and 2) semantically redundant templates can be


                                                            316


Y.C. Ju & T. Paek. 2009. A Voice Search Approach
   to Replying to SMS Messages in Automobiles. In
   Proc. of Interspeech.
A. Kun, T. Paek & Z. Medenica. 2007. The Effect of
   Speech Interface Accuracy on Driving Perfor-
   mance, In Proc. of Interspeech.
P. Natarajan, R. Prasad, R. Schwartz, & J. Makhoul.
   2002. A Scalable Architecture for Directory Assis-
   tance Automation. In Proc. of ICASSP, pp. 21-24.
L. Nunes & M. Recarte. 2002. Cognitive Deamnds of
   Hands-Free-Phone Conversation While Driving.
   Transportation Research Part F, 5: 133-144.
N. Reed & R. Robbins. 2008. The Effect of Text
   Messaging on Driver Behaviour: A Simulator
   Study. Transport Research Lab Report, PPR 367.
D. Strayer & W. Johnston. 2001. Driven to Distrac-
   tion: Dual-task Studies of Simulated Driving and
   Conversing on a Cellular Phone. Psychological
   Science, 12: 462-466.
R. Stross. 2008. “What carriers aren’t eager to tell you
   about texting”, New York Times, Dec. 26, 2008:
   http://www.nytimes.com/2008/12/28/business/28di
   gi.html?_r=3
D. Yu, Y.C. Ju, Y.-Y. Wang, G. Zweig, & A. Acero.
   2007. Automated Directory Assistance System:
   From Theory to Practice. In Proc. of Interspeech.
Wei Wu, Yun-Cheng Ju, Xiao Li, and Ye-Yi Wang,
 Paraphrase Detection on SMS Messages in Auto-
 mobiles, in ICASSP, IEEE, March 2010




                                                           317

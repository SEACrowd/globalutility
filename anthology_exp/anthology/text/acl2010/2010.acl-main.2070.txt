                                 Wrapping up a Summary:
                             from Representation to Generation
    Josef Steinberger and Marco Turchi and                                 Nello Cristianini
      Mijail Kabadjov and Ralf Steinberger                               University of Bristol,
              EC Joint Research Centre                                   Bristol, BS8 1UB, UK
               21027, Ispra (VA), Italy                                nello@support-vector.net
         {Josef.Steinberger, Marco.Turchi,
        Mijail.Kabadjov, Ralf.Steinberger}
                   @jrc.ec.europa.eu

                    Abstract                                 amount of approaches assume simple sentence se-
                                                             lection, a type of extractive summarization, where
    The main focus of this work is to investi-               often the summary representation and the end
    gate robust ways for generating summaries                summary are, indeed, conflated.
    from summary representations without re-                    The main focus of this work is, thus, to in-
    curring to simple sentence extraction and                vestigate robust ways for generating summaries
    aiming at more human-like summaries.                     from summary representations without recurring
    This is motivated by empirical evidence                  to simple sentence extraction and aiming at more
    from TAC 2009 data showing that human                    human-like summaries. This decision is also mo-
    summaries contain on average more and                    tivated by empirical evidence from TAC 2009 data
    shorter sentences than the system sum-                   (see table 1) showing that human summaries con-
    maries. We report encouraging prelimi-                   tain on average more and shorter sentences than
    nary results comparable to those attained                the system summaries. The intuition behind this is
    by participating systems at TAC 2009.                    that, by containing more sentences, a summary is
                                                             able to capture more of the important content from
1   Introduction                                             the source.
In this paper we adopt the general framework                    Our initial experimental results show that our
for summarization put forward by Spärck-Jones               approach is feasible, since it produces summaries,
(1999) – which views summarization as a three-               which when evaluated against the TAC 2009 data1
fold process: interpretation, transformation and             yield ROUGE scores (Lin and Hovy, 2003) com-
generation – and attempt to provide a clean in-              parable to the participating systems in the Sum-
stantiation for each processing phase, with a par-           marization task at TAC 2009. Taking into account
ticular emphasis on the last, summary-generation             that our approach is completely unsupervised and
phase often omitted or over-simplified in the main-          language-independent, we find our preliminary re-
stream work on summarization.                                sults encouraging.
   The advantages of looking at the summarization               The remainder of the paper is organised as fol-
problem in terms of distinct processing phases are           lows: in the next section we briefly survey the
numerous. It not only serves as a common ground              related work, in §3 we describe our approach to
for comparing different systems and understand-              summarization, in §4 we explain how we tackle
ing better the underlying logic and assumptions,             the generation step, in §5 we present and discuss
but it also provides a neat framework for devel-             our experimental results and towards the end we
oping systems based on clean and extendable de-              conclude and give pointers to future work.
signs. For instance, Gong and Liu (2002) pro-
posed a method based on Latent Semantic Anal-                2       Related Work
ysis (LSA) and later J. Steinberger et al. (2007)
                                                             There is a large body of literature on summariza-
showed that solely by enhancing the first source
                                                             tion (Hovy, 2005; Erkan and Radev, 2004; Kupiec
interpretation phase, one is already able to pro-
                                                             et al., 1995). The most closely related work to the
duce better summaries.
                                                             approach presented hereby is work on summariza-
   There has been limited work on the last sum-
                                                             tion attempting to go beyond simple sentence ex-
mary generation phase due to the fact that it is
                                                                 1
unarguably a very challenging problem. The vast                      http://www.nist.gov/tac/


                                                       382
                      Proceedings of the ACL 2010 Conference Short Papers, pages 382–386,
                Uppsala, Sweden, 11-16 July 2010. c 2010 Association for Computational Linguistics


traction and to a lesser degree work on sentence                ing a succinct summary representation comprised
compression. We survey below work along these                   only of salient terms – Term Summary Represen-
lines.                                                          tation (TSR). Then this TSR is passed on to an-
   Although our approach is related to sentence                 other module which attempts to produce complete
compression (Knight and Marcu, 2002; Clarke                     sentences. The module for sentence reconstruc-
and Lapata, 2008), it is subtly different. Firstly, we          tion is described in detail in section 4, in what fol-
reduce the number of terms to be used in the sum-               lows we explain the method for producing a TSR.
mary at a global level, not at a local per-sentence
level. Secondly, we directly exploit the resulting              3.1   Term Summary Representation
structures from the SVD making the last genera-                 To explain how a term summary representation
tion step fully aware of previous processing stages,            (TSR) is produced, we first need to define two con-
as opposed to tackling the problem of sentence                  cepts: salience score of a given term and salience
compression in isolation.                                       threshold. Salience score for each term in matrix
   A similar approach to our sentence reconstruc-               A is given by the magnitude of the corresponding
tion method has been developed by Quirk et al.                  vector in the matrix resulting from the dot product
(2004) for paraphrase generation. In their work,                of the matrix of left singular vectors with the diag-
training and test sets contain sentence pairs that              onal matrix of singular values. More formally, let
are composed of two different proper English sen-               T = U · Σ and then for each term i, the salience
tences and a paraphrase of a source sentence is                 score is given by |T~i |. Salience threshold is equal
generated by finding the optimal path through a                 to the salience score of the top k th term, when all
paraphrases lattice.                                            terms are sorted in descending order on the basis
   Finally, it is worth mentioning that we are aware            of their salience scores and a cutoff is defined as a
of the ‘capsule overview’ summaries proposed by                 percentage (e.g., top 15%). In other words, if the
Boguraev and Kennedy (1997) which is similar to                 total number of terms is n, then 100 ∗ k/n must be
our TSR (see below), however, as opposed to their               equal to the percentage cutoff specified.
emphasis on a suitable browsing interface rather                   The generation of a TSR is performed in two
than producing a readable summary, we precisely                 steps. First, an initial pool of sentences is selected
attempt the latter.                                             by using the same technique as in (Steinberger and
                                                                Jez̆ek, 2009) which exploits the dot product of the
3   Three-fold Summarization:                                   diagonal matrix of singular values with the right
    Interpretation, Transformation and                          singular vectors: Σ · V T .2 This initial pool of sen-
    Generation                                                  tences is the output of standard LSA approaches.
                                                                   Second, the terms from the source matrix A are
We chose the LSA paradigm for summarization,                    identified in the initial pool of sentences and those
since it provides a clear and direct instantiation of           terms whose salience score is above the salience
Spärck-Jones’ three-stage framework.                           threshold are copied across to the TSR. Thus, the
   In LSA-based summarization the interpreta-                   TSR is formed by the most (globally) salient terms
tion phase takes the form of building a term-by-                from each one of the sentences. For example:
sentence matrix A = [A1 , A2 , . . . , An ], where
each column Aj = [a1j , a2j , . . . , anj ]T represents            • Extracted Sentence: “Irish Prime Minister Bertie
the weighted term-frequency vector of sentence j                      Ahern admitted on Tuesday that he had held a series of
in a given set of documents. We adopt the same                        private one-on-one meetings on the Northern Ireland
weighting scheme as the one described in (Stein-                      peace process with Sinn Fein leader Gerry Adams, but
berger et al., 2007), as well as their more general                   denied they had been secret in any way.”
definition of term entailing not only unigrams and
                                                                   • TSR Sentence at 10%: “Irish Prime Minister
bigrams, but also named entities.
                                                                      Bertie Ahern Tuesday had held one-on-one meetings
   The transformation phase is done by applying
                                                                      Northern Ireland peace process Sinn Fein leader Gerry
singular value decomposition (SVD) to the initial
                                                                      Adams”3
term-by-sentence matrix defined as A = U ΣV T .
                                                                    2
   The generation phase is where our main contri-                     Due to space constraints, full details on that step are
                                                                omitted here, see (Steinberger and Jez̆ek, 2009).
bution comes in. At this point we depart from stan-                 3
                                                                      The TSR sentence is stemmed just before feeding it to
dard LSA-based approaches and aim at produc-                    the reconstruction module discussed in the next section.


                                                          383


       Average                      Human             System        At 100%        At 15%    At 10%     At 5%     At 1%
       number of:                  Summaries        Summaries
        Sentences/summary             6.17             3.82              3.8         3.95       4.39      5.18     12.58
        Words/sentence                15.96            25.01            26.24        25.1      22.61     19.08      7.55
        Words/summary                 98.46            95.59            99.59       99.25      99.18     98.86     94.96

                      Table 1: Summary statistics on TAC’09 data (initial summaries).

                   Metric              LSAextract       At 100%         At 15%     At 10%     At 5%    At 1%
                   ROUGE-1                0.371           0.361          0.362      0.365     0.372     0.298
                   ROUGE-2                0.096           0.08           0.081      0.083     0.083     0.083
                   ROUGE-SU4              0.131           0.125          0.126      0.128     0.131     0.104

                    Table 2: Summarization results on TAC’09 data (initial summaries).


4   Noisy-channel model for sentence                                    start position of the source phrase that was trans-
    reconstruction                                                      lated into the ith target phrase, and bi−1 denotes
                                                                        the end position of the source phrase translated
This section describes a probabilistic approach to
                                                                        into the (i−1th ) target phrase. pLM (ei |e1 . . . ei−1 )
the reconstruction problem. We adopt the noisy-
                                                                        is the language model probability that is based on
channel framework that has been widely used in a
                                                                        the Markov chain assumption. It assigns a higher
number of other NLP applications. Our interpre-
                                                                        probability to fluent/grammatical sentences. λφ ,
tation of the noisy channel consists of looking at a
                                                                        λLM and λd are used to give a different weight to
stemmed string without stopwords and imagining
                                                                        each element (for more details see (Koehn et al.,
that it was originally a long string and that some-
                                                                        2003)).
one removed or stemmed some text from it. In our
framework, reconstruction consists of identifying                          In our reconstruction problem, the difference
the original long string.                                               between the source and target sentences is not in
   To model our interpretation of the noisy chan-                       terms of languages, but in terms of forms. In fact,
nel, we make use of one of the most popular                             our source sentence f is a stemmed sentence with-
classes of SMT systems: the Phrase Based Model                          out stopwords, while the target sentence e is a
(PBM) (Zens et al., 2002; Och and Ney, 2001;                            complete English sentence. “Translate” means to
Koehn et al., 2003). It is an extension of the noisy-                   reconstruct the most probable sentence e given f
channel model and was introduced by Brown et al.                        inserting new words and reproducing the inflected
(1994), using phrases rather than words. In PBM,                        surface forms of the source words.
a source sentence f is segmented into a sequence
of I phrases f I = [f1 , f2 , . . . fI ] and the same is                4.1     Training of the model
done for the target sentence e, where the notion of
phrase is not related to any grammatical assump-                        In Statistical Machine Translation, a PBM system
tion; a phrase is an n-gram. The best translation                       is trained using parallel sentences, where each sen-
ebest of f is obtained by:                                              tence in a language is paired with another sentence
                                              I                         in a different language and one is the translation of
                                              Y
ebest = arg max p(e|f ) = arg max                   φ(fi |ei )λφ        the other.
               e                         e
                                              i=1                          In the reconstruction problem, we use a set, S1
                            |e|                                         of 2,487,414 English sentences extracted from the
                            Y
        d(ai − bi−1 )λd           pLM (ei |e1 . . . ei−1 )λLM           news. This set is duplicated, S2 , and for each sen-
                            i=1
                                                                        tence in S2 , stopwords are removed and the re-
where φ(fi |ei ) is the probability of translating                      maining words are stemmed using Porter’s stem-
a phrase ei into a phrase fi . d(ai − bi−1 ) is                         mer (Porter, 1980). Our stopword list contains 488
the distance-based reordering model that drives                         words. Verbs are not included in this list, because
the system to penalize substantial reorderings of                       they are relevant for the reconstruction task. To
words during translation, while still allowing some                     optimize the lambda parameters, we select 2,000
flexibility. In the reordering model, ai denotes the                    pairs as development set.


                                                                  384


    An example of training sentence pair is:                          unit. The last five columns of table 2 (from left to
                                                                      right) correspond to summaries produced by our
    • Source Sentence: “royal mail ha doubl profit 321                system at various percentage cutoffs. The 2nd col-
      million huge fall number letter post”
                                                                      umn, LSAextract , corresponds to the performance
    • Target Sentence: “royal mail has doubled its prof-              of our system at producing summaries by sentence
      its to 321 million despite a huge fall in the number of         extraction only.5
      letters being posted”                                              In the light of the above, the decrease in per-
                                                                      formance from column LSAextract to column ‘At
   In this work we use Moses (Koehn et al., 2007),                    100%’ can be regarded as reconstruction error.6
a complete phrase-based translation toolkit for                       Then, as we decrease the percentage cutoff (from
academic purposes. It provides all the state-of-the-                  4th column rightwards) we are increasingly cover-
art components needed to create a phrase-based                        ing more of the content comprised by the human
machine translation system. It contains different                     summaries (as far as the ROUGE metrics are able
modules to preprocess data, train the Language                        to gauge this, of course). In other words, the im-
Models and the Translation Models.                                    provement of content coverage makes up for the
5    Experimental Results                                             reconstruction error, and at 5% cutoff we already
                                                                      obtain ROUGE scores comparable to LSAextract .
For our experiments we made use of the TAC                            This suggests that if we improve the quality of our
2009 data which conveniently contains human-                          sentence reconstruction we would potentially end
produced summaries against which we could eval-                       up with a better performing system than a typical
uate the output of our system (NIST, 2009).                           LSA system based on sentence selection. Hence,
   To begin our inquiry we carried out a phase                        we find these results very encouraging.
of exploratory data analysis, in which we mea-                           Finally, we admittedly note that by applying a
sured the average number of sentences per sum-                        percentage cutoff on the initial term set and further
mary, words per sentence and words per summary                        performing the sentence reconstruction we gain in
in human vs. system summaries in the TAC 2009                         content coverage, to a certain extent, on the ex-
data. Additionally, we also measured these statis-                    pense of sentence readability.
tics of summaries produced by our system at five
different percentage cutoffs: 100%, 15%, 10%,                         6       Conclusion
5% and 1%. 4 The results from this exploration
are summarised in table 1. The most notable thing                     In this paper we proposed a novel approach to
is that human summaries contain on average more                       summary generation from summary representa-
and shorter sentences than the system summaries                       tion based on the LSA summarization framework
(see 2nd and 3rd column from left to right). Sec-                     and on a machine-translation-inspired technique
ondly, we note that as the percentage cutoff de-                      for sentence reconstruction.
creases (from 4th column rightwards) the charac-                         Our preliminary results show that our approach
teristics of the summaries produced by our system                     is feasible, since it produces summaries which re-
are increasingly more similar to those of the hu-                     semble better human summaries in terms of the av-
man summaries. In other words, within the 100-                        erage number of sentences per summary and yield
word window imposed by the TAC guidelines, our                        ROUGE scores comparable to the participating
system is able to fit more (and hence shorter) sen-                   systems in the Summarization task at TAC 2009.
tences as we decrease the percentage cutoff.                          Bearing in mind that our approach is completely
   Summarization performance results are shown                        unsupervised and language-independent, we find
in table 2. We used the standard ROUGE evalu-                         our results promising.
ation (Lin and Hovy, 2003) which has been also                           In future work we plan on working towards im-
used for TAC. We include the usual ROUGE met-                         proving the quality of our sentence reconstruction
rics: R1 is the maximum number of co-occurring                        step in order to produce better and more readable
unigrams, R2 is the maximum number of co-                             sentences.
occurring bigrams and RSU 4 is the skip bigram                            5
                                                                            These are, effectively, what we called initial pool of sen-
measure with the addition of unigrams as counting                     tences in section 3, before the TSR generation.
                                                                          6
                                                                            The only difference between the two types of summaries
   4
     Recall from section §3 that the salience threshold is a          is the reconstruction step, since we are including 100% of the
function of the percentage cutoff.                                    terms.


                                                                385


References                                                       C. Quirk, C. Brockett, and W. Dolan. 2004. Monolin-
                                                                    gual machine translation for paraphrase generation.
B. Boguraev and C. Kennedy. 1997. Salience-                         In Proceedings of EMNLP, volume 149. Barcelona,
  based content characterisation of text documents. In              Spain.
  I. Mani, editor, Proceedings of the Workshop on In-
  telligent and Scalable Text Summarization at the An-           K. Spärck-Jones. 1999. Automatic summarising: Fac-
  nual Joint Meeting of the ACL/EACL, Madrid.                      tors and directions. In I. Mani and M. Maybury,
                                                                   editors, Advances in Automatic Text Summarization.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mer-            MIT Press.
   cer. 1994. The mathematic of statistical machine
   translation: Parameter estimation. Computational              J. Steinberger and K. Jez̆ek. 2009. Update summariza-
   Linguistics, 19(2):263–311.                                      tion based on novel topic distribution. In Proceed-
                                                                    ings of the 9th ACM DocEng, Munich, Germany.
J. Clarke and M. Lapata. 2008. Global inference for
   sentence compression: An integer linear program-              J. Steinberger, M. Poesio, M. Kabadjov, and K. Jez̆ek.
   ming approach. Journal of Artificial Intelligence Re-            2007. Two uses of anaphora resolution in summa-
   search, 31:273–318.                                              rization. Information Processing and Management,
                                                                    43(6):1663–1680. Special Issue on Text Summari-
G. Erkan and D. Radev. 2004. LexRank: Graph-based                   sation (Donna Harman, ed.).
  centrality as salience in text summarization. Journal
  of Artificial Intelligence Research (JAIR).                    R. Zens, F. J. Och, and H. Ney. 2002. Phrase-based
                                                                    statistical machine translation. In Proceedings of KI
Y. Gong and X. Liu. 2002. Generic text summarization                ’02, pages 18–32, London, UK. Springer-Verlag.
   using relevance measure and latent semantic analy-
   sis. In Proceedings of ACM SIGIR, New Orleans,
   US.

E. Hovy. 2005. Automated text summarization. In
   Ruslan Mitkov, editor, The Oxford Handbook of
   Computational Linguistics, pages 583–598. Oxford
   University Press, Oxford, UK.

K. Knight and D. Marcu. 2002. Summarization be-
  yond sentence extraction: A probabilistic approach
  to sentence compression. Artificial Intelligence,
  139(1):91–107.

P. Koehn, F. Och, and D. Marcu. 2003. Statistical
   phrase-based translation. In Proceedings of NAACL
   ’03, pages 48–54, Morristown, NJ, USA.

P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
   M. Federico, N. Bertoldi, B. Cowan, W. Shen,
   C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
   and E. Herbst. 2007. Moses: Open source toolkit
   for statistical machine translation. In Proceedings
   of ACL ’07, demonstration session.

J. Kupiec, J. Pedersen, and F. Chen. 1995. A trainable
   document summarizer. In Proceedings of the ACM
   SIGIR, pages 68–73, Seattle, Washington.

C. Lin and E. Hovy. 2003. Automatic evaluation of
   summaries using n-gram co-occurrence statistics. In
   Proceedings of HLT-NAACL, Edmonton, Canada.

NIST, editor. 2009. Proceeding of the Text Analysis
  Conference, Gaithersburg, MD, November.

F. Och and H. Ney. 2001. Discriminative training
   and maximum entropy models for statistical ma-
   chine translation. In Proceedings of ACL ’02, pages
   295–302, Morristown, NJ, USA.

M. Porter. 1980. An algorithm for suffix stripping.
  Program, 14(3):130–137.


                                                           386
